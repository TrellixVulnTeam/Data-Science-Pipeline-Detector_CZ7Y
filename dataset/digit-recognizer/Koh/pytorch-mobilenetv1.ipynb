{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-01T02:46:25.155733Z","iopub.execute_input":"2021-12-01T02:46:25.157058Z","iopub.status.idle":"2021-12-01T02:46:25.169833Z","shell.execute_reply.started":"2021-12-01T02:46:25.157012Z","shell.execute_reply":"2021-12-01T02:46:25.168474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntrain_y = df_train['label']\ntrain_x = df_train.drop('label', axis = 1)\nx = np.array(train_x, dtype = 'float')\nx_reshape = [x_.reshape(28,28) for x_ in tqdm(x)]","metadata":{"execution":{"iopub.status.busy":"2021-12-01T02:46:25.172488Z","iopub.execute_input":"2021-12-01T02:46:25.172963Z","iopub.status.idle":"2021-12-01T02:46:29.39233Z","shell.execute_reply.started":"2021-12-01T02:46:25.172916Z","shell.execute_reply":"2021-12-01T02:46:29.391294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load Dataset**\n\nDue to given dataset shape (Dataframe & 1 dimension shape), it needs to be reshaped to (28 X 28 array).","metadata":{}},{"cell_type":"code","source":"#EDA\n#Image Visualization\nprint('Image Visualization')\nimport matplotlib.pyplot as plt\nrnum = np.random.randint(0, len(x_reshape) -1 , 10)\nplt.figure(figsize = (10,10))\nfor n, i in enumerate(rnum):\n    plt.subplot(1,10,n+1)\n    plt.tick_params(left = False, bottom = False, labelleft = False, labelbottom = False)\n    plt.imshow(x_reshape[i])\nplt.show()\n#label balance\nprint('label size')\nlabel_balance = df_train.groupby('label').size().to_frame().rename(columns = {0 : 'count'})\nplt.title('label balance')\nplt.bar(label_balance.index, label_balance['count'])\nplt.show()\nprint('****************************************************************************\\n')\n#Null value detection\ntrain_x.isnull().sum().loc[train_x.isnull().sum() != 0]","metadata":{"execution":{"iopub.status.busy":"2021-12-01T02:46:29.394166Z","iopub.execute_input":"2021-12-01T02:46:29.394959Z","iopub.status.idle":"2021-12-01T02:46:30.752156Z","shell.execute_reply.started":"2021-12-01T02:46:29.394911Z","shell.execute_reply":"2021-12-01T02:46:30.750899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Custom Dataset\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport torchvision.transforms as T\n\ntransforms = T.Compose([T.ToTensor(), T.Resize((224, 224))])\n\nclass CustomDataset(Dataset):\n    def __init__(self, x_data, y_data, transforms = transforms):\n        self.x_data = x_data\n        self.y_data = y_data\n        self.transforms = transforms\n    def __len__(self):\n        return len(self.x_data)\n    def __getitem__(self, idx):\n        image = self.x_data[idx]\n        label = self.y_data.iloc[idx]\n        image = image / 255.0\n        sample = {'image' : image, 'label' : label}\n        if self.transforms:\n            sample['image'] = self.transforms(sample['image'])        \n        return sample","metadata":{"execution":{"iopub.status.busy":"2021-12-01T02:46:30.75517Z","iopub.execute_input":"2021-12-01T02:46:30.756194Z","iopub.status.idle":"2021-12-01T02:46:30.766786Z","shell.execute_reply.started":"2021-12-01T02:46:30.756145Z","shell.execute_reply":"2021-12-01T02:46:30.765425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **MobileNetV1 Structure**\n ![figure1](https://static-01.hindawi.com/articles/cin/volume-2020/8817849/figures/8817849.fig.002.svgz)\n","metadata":{}},{"cell_type":"markdown","source":"> **On network..**\n* **Define Depthwise Convolution Network (blue background on the picture)**\n* **Define Basic convolution**","metadata":{}},{"cell_type":"code","source":"\n\n#MobileNet Define\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass MobileNet(nn.Module):\n    def __init__(self, num_classes = 10):\n        super(MobileNet, self).__init__()\n        #Define \n        \n        def convdw(in_channels, out_channels, kernel_size, stride):\n            layers = []\n            #Depthwise Convolution\n            layers += [nn.Conv2d(in_channels, out_channels,kernel_size = 3,padding = 1, stride = stride, groups = in_channels)]\n            layers += [nn.BatchNorm2d(out_channels)]\n            layers += [nn.ReLU()]\n            \n            #Pointwise Convolution\n            layers += [nn.Conv2d(in_channels, out_channels,kernel_size =1,padding = 1, stride = stride)]\n            layers += [nn.BatchNorm2d(out_channels)]\n            layers += [nn.ReLU()]\n            return nn.Sequential(*layers)\n        \n        def convd(in_channels, out_channels, kernel_size, stride):\n            layers = []\n            layers += [nn.Conv2d(in_channels, out_channels, kernel_size, stride = stride)]\n            layers += [nn.BatchNorm2d(out_channels)]\n            layers += [nn.ReLU()]\n            return nn.Sequential(*layers)\n        \n        self.conv1 = convd(1,32,3, stride = 2)\n        self.convdw1 = convdw(32, 32, 3, 1)\n        self.conv2 = convd(32, 64, 1, stride = 1)\n        self.convdw2 = convdw(64, 64, 3, 2)\n        self.conv3 = convd(64, 128, 1, stride = 1)\n        self.convdw3 = convdw(128, 128, 3, 1)\n        self.conv4 = convd(128, 128, 1, stride = 1)\n        self.convdw4 = convdw(128, 128, 3, 2)\n        self.conv5 = convd(128, 256, 1, stride = 1)\n        self.convdw5 = convdw(256, 256, 3, 1)\n        self.conv6 = convd(256, 256, 1, stride = 1)\n        self.convdw6 = convdw(256, 256, 3, 2)\n        self.conv7 = convd(256, 512, 1, stride = 1)\n        #--------------------------------------------\n        #need x5\n        self.convdw = convdw(512, 512, 3, 1)\n        self.conv = convd(512, 512, 1, stride = 1)\n        #--------------------------------------------\n        self.convdw7 = convdw(512, 512, 3, 2)\n        self.conv8 = convd(512, 1024, 1, stride = 1)\n        self.convdw8 = convdw(1024, 1024, 3, 2)\n        self.conv9 = convd(1024, 1024, 1, stride = 1)\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(1024, num_classes)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.convdw1(x)\n        x = self.conv2(x)\n        x = self.convdw2(x)\n        x = self.conv3(x)\n        x = self.convdw3(x)\n        x = self.conv4(x)\n        x = self.convdw4(x)\n        x = self.conv5(x)\n        x = self.convdw5(x)\n        x = self.conv6(x)\n        x = self.convdw6(x)\n        x = self.conv7(x)\n            \n        for i in range(0,5):\n            x = self.convdw(x)\n            x = self.conv(x)\n                \n        x = self.convdw7(x)\n        x = self.conv8(x)\n        x = self.convdw8(x)\n        x = self.conv9(x)\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        output = self.fc(x)\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-12-01T02:46:30.768747Z","iopub.execute_input":"2021-12-01T02:46:30.769411Z","iopub.status.idle":"2021-12-01T02:46:30.796633Z","shell.execute_reply.started":"2021-12-01T02:46:30.769363Z","shell.execute_reply":"2021-12-01T02:46:30.795434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **Train Configure**\n","metadata":{}},{"cell_type":"markdown","source":"> **For training..**\n* **Setting simple early_stopping (number of patience = 5)**\n* **Loss function : Crossentropyloss (softmax)**\n* **Data split : Randomly getting dataset from train_df -> due to random extraction, 'shuffle = False' on dataloader.**\n* **Initialize network weight : xavier method uniform distribution (makes model's performance worse -> why?)**","metadata":{}},{"cell_type":"code","source":"#Training configure\n#basic options\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n# set seed\nimport random\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n    torch.cuda.manual_seed_all(777)\n\n#Initialized weight -> not used\ndef init_weights(m):\n    if isinstance(m, nn.Linear):\n        nn.init.xavier_uniform_(m.weight)\n        m.bias.data.fill_(0.01)\n    elif isinstance(m, nn.Conv2d):\n        nn.init.xavier_uniform_(m.weight)\n        m.bias.data.fill_(0.01)\n\nmodel = MobileNet()\n\nlr = 1e-3\nsetting_patience = 7\nn_epoch = 50\nbatch_size = 100\n#optimizer & criterion function\ncriterion = nn.CrossEntropyLoss().cuda()\noptimizer = torch.optim.Adam(params = model.parameters(), lr = lr)\n#Define dataset\n#data split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x_reshape, train_y, test_size = 0.33, random_state = 26)\ntrain_dataset = CustomDataset(X_train, y_train)\ntest_dataset = CustomDataset(X_test, y_test)\ntrain_data_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = False)\ntest_data_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\ntrain_total_batch = len(train_data_loader)\ntest_total_batch = len(test_data_loader)\ntrn_acc_list = []\ntrn_loss_list = []\ntest_acc_list = []\ntest_loss_list = []","metadata":{"execution":{"iopub.status.busy":"2021-12-01T02:46:30.798354Z","iopub.execute_input":"2021-12-01T02:46:30.799061Z","iopub.status.idle":"2021-12-01T02:46:30.881472Z","shell.execute_reply.started":"2021-12-01T02:46:30.799014Z","shell.execute_reply":"2021-12-01T02:46:30.880461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training & Evaluation\ntorch.cuda.empty_cache()\nbest_accuracy = 0\ntotal_patience = 0\nfor epoch in range(n_epoch):\n    model.train()    \n    model.cuda()\n    optimizer.zero_grad()\n    trn_avg_loss = 0\n    trn_total = 0\n    trn_correct = 0\n    test_avg_loss = 0\n    test_total = 0\n    test_correct = 0\n    with tqdm(train_data_loader, unit = 'batch') as train_bar:\n        for sample in train_bar:  \n            image = sample['image'].float().cuda()\n            label = sample['label'].cuda()\n            trn_probs = model(image)\n            loss = criterion(trn_probs, label)\n            loss.backward()\n            optimizer.step()\n            trn_avg_loss += loss / train_total_batch\n            _, trn_predict = torch.max(trn_probs.data, 1)\n            trn_total += label.size(0)\n            trn_correct += (trn_predict == label).sum()\n            trn_accuracy = 100 * trn_correct / trn_total\n            train_bar.set_postfix(epoch = epoch+1, loss = loss.item(), accuracy = trn_accuracy.item())\n    model.eval()\n    with torch.no_grad():\n        with tqdm(test_data_loader, unit = 'batch') as test_bar:\n            for sample in test_bar:  \n                image = sample['image'].float().cuda()\n                label = sample['label'].cuda()\n                test_probs = model(image)\n                loss = criterion(test_probs, label)\n                test_avg_loss += loss / test_total_batch\n                _, test_predict = torch.max(test_probs.data, 1)\n                test_total += label.size(0)\n                test_correct += (test_predict == label).sum()\n                test_accuracy = 100 * test_correct / test_total\n                test_bar.set_postfix(epoch = epoch+1, loss = loss.item(), accuracy = test_accuracy.item())\n    trn_acc_list.append(trn_accuracy)\n    trn_loss_list.append(trn_avg_loss)\n    test_acc_list.append(test_accuracy)\n    test_loss_list.append(test_avg_loss)\n    \n    if total_patience == setting_patience:\n        break\n    else:\n        if best_accuracy < test_accuracy:\n            total_patience = 0\n            best_accuracy = test_accuracy\n            print('Model Improving')\n            print('Epoch : {}, Loss : {:.4f}, Accuracy : {} model save.....'.format(epoch+1, test_avg_loss, test_accuracy))\n            torch.save(model.state_dict(), './checkpoint.pt')\n        else:\n            print('early stop counter : {}/{}'.format(total_patience+1, setting_patience))\n            total_patience += 1","metadata":{"execution":{"iopub.status.busy":"2021-12-01T02:46:30.883129Z","iopub.execute_input":"2021-12-01T02:46:30.884773Z","iopub.status.idle":"2021-12-01T03:52:36.569279Z","shell.execute_reply.started":"2021-12-01T02:46:30.884726Z","shell.execute_reply":"2021-12-01T03:52:36.568263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize = (20,5))\nplt.subplot(1,2,1)\nplt.title('Loss')\nx = range(len(trn_loss_list))\nplt.plot(x, trn_loss_list, label = 'Train Loss')\nplt.plot(x, test_loss_list, label = 'Valid Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.title('Accuracy')\nx = range(len(trn_loss_list))\nplt.plot(x, trn_acc_list, label = 'Train Accuracy')\nplt.plot(x, test_acc_list, label = 'Valid Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T03:52:36.570789Z","iopub.execute_input":"2021-12-01T03:52:36.57164Z","iopub.status.idle":"2021-12-01T03:52:36.991489Z","shell.execute_reply.started":"2021-12-01T03:52:36.571589Z","shell.execute_reply":"2021-12-01T03:52:36.990655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms = T.Compose([T.ToTensor(), T.Resize((224, 224))])\n\nclass CustomDataset_test(Dataset):\n    def __init__(self, x_data, transforms = transforms):\n        self.x_data = x_data\n        self.transforms = transforms\n    def __len__(self):\n        return len(self.x_data)\n    def __getitem__(self, idx):\n        image = self.x_data[idx]\n        image = image / 255.0\n        if self.transforms:\n            image = self.transforms(image)        \n        return image","metadata":{"execution":{"iopub.status.busy":"2021-12-01T03:52:36.993081Z","iopub.execute_input":"2021-12-01T03:52:36.993693Z","iopub.status.idle":"2021-12-01T03:52:37.002442Z","shell.execute_reply.started":"2021-12-01T03:52:36.993637Z","shell.execute_reply":"2021-12-01T03:52:37.001572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n# Normal distribution initializing\ntorch.cuda.empty_cache()\nmodel.load_state_dict(torch.load('./checkpoint.pt'))\nmodel.cuda()\nmodel.eval()\ntest_df = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\nx = np.array(test_df, dtype = 'float')\nx_reshape = [x_.reshape(28,28) for x_ in tqdm(x)]\ntest_dataset = CustomDataset_test(x_reshape)\ntest_data_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False)\ny_hat_list = []\nfor image in tqdm(test_data_loader):\n    image = image.float().cuda()\n    y_hat = model(image)\n    _, predict = torch.max(y_hat.data, 1)\n    y_hat_list.append(predict.item())","metadata":{"execution":{"iopub.status.busy":"2021-12-01T03:52:37.006507Z","iopub.execute_input":"2021-12-01T03:52:37.00704Z","iopub.status.idle":"2021-12-01T03:58:19.531487Z","shell.execute_reply.started":"2021-12-01T03:52:37.006997Z","shell.execute_reply":"2021-12-01T03:58:19.53032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')\nsubmission['Label'] = y_hat_list\nsubmission.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T03:58:19.533787Z","iopub.execute_input":"2021-12-01T03:58:19.534239Z","iopub.status.idle":"2021-12-01T03:58:19.619849Z","shell.execute_reply.started":"2021-12-01T03:58:19.534191Z","shell.execute_reply":"2021-12-01T03:58:19.618955Z"},"trusted":true},"execution_count":null,"outputs":[]}]}