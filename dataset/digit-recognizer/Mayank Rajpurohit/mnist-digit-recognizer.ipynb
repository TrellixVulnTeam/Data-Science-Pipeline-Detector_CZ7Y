{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### MNIST Digit Recognizer using CNN ###","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-10T04:46:37.533413Z","iopub.execute_input":"2021-06-10T04:46:37.533774Z","iopub.status.idle":"2021-06-10T04:46:37.541655Z","shell.execute_reply.started":"2021-06-10T04:46:37.533687Z","shell.execute_reply":"2021-06-10T04:46:37.540684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout,BatchNormalization\nimport matplotlib.pyplot as plt \nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:46:40.102661Z","iopub.execute_input":"2021-06-10T04:46:40.102989Z","iopub.status.idle":"2021-06-10T04:46:45.455981Z","shell.execute_reply.started":"2021-06-10T04:46:40.102959Z","shell.execute_reply":"2021-06-10T04:46:45.455173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Exploring The Dataset**\nData consists of two csv files i.e train and test","metadata":{}},{"cell_type":"code","source":"filepath_train = \"/kaggle/input/digit-recognizer/train.csv\"\nfilepath_test = \"/kaggle/input/digit-recognizer/test.csv\"","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:46:48.860402Z","iopub.execute_input":"2021-06-10T04:46:48.860735Z","iopub.status.idle":"2021-06-10T04:46:48.867125Z","shell.execute_reply.started":"2021-06-10T04:46:48.860689Z","shell.execute_reply":"2021-06-10T04:46:48.866206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(filepath_train)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:46:50.027959Z","iopub.execute_input":"2021-06-10T04:46:50.028274Z","iopub.status.idle":"2021-06-10T04:46:52.830177Z","shell.execute_reply.started":"2021-06-10T04:46:50.028244Z","shell.execute_reply":"2021-06-10T04:46:52.82945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Every row of data corresponds to an example , which is having 784 pixel values(columns from 0 t0 783)which is a 28*28 array(or image of digit )**","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:46:55.661364Z","iopub.execute_input":"2021-06-10T04:46:55.661691Z","iopub.status.idle":"2021-06-10T04:46:55.667338Z","shell.execute_reply.started":"2021-06-10T04:46:55.66166Z","shell.execute_reply":"2021-06-10T04:46:55.666436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training Data has 42000 examples of images of digits**","metadata":{}},{"cell_type":"code","source":"df.isnull().sum().sort_values(ascending = False) ","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:46:58.050765Z","iopub.execute_input":"2021-06-10T04:46:58.051086Z","iopub.status.idle":"2021-06-10T04:46:58.098401Z","shell.execute_reply.started":"2021-06-10T04:46:58.051058Z","shell.execute_reply":"2021-06-10T04:46:58.097537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**No Null Values here**","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(filepath_test)\ndf_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:02.6523Z","iopub.execute_input":"2021-06-10T04:47:02.652609Z","iopub.status.idle":"2021-06-10T04:47:04.360659Z","shell.execute_reply.started":"2021-06-10T04:47:02.652579Z","shell.execute_reply":"2021-06-10T04:47:04.359803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**test Data has 28000 images of size 784(28*28)**","metadata":{}},{"cell_type":"markdown","source":"**Converting the dataframe into array and seperating train data and labels**","metadata":{}},{"cell_type":"code","source":"X_train,y_train = np.asarray(df.drop('label',axis= 1)), np.asarray(df.loc[:,'label'])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:07.806689Z","iopub.execute_input":"2021-06-10T04:47:07.807057Z","iopub.status.idle":"2021-06-10T04:47:07.889496Z","shell.execute_reply.started":"2021-06-10T04:47:07.80702Z","shell.execute_reply":"2021-06-10T04:47:07.888468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape, y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:09.131991Z","iopub.execute_input":"2021-06-10T04:47:09.132295Z","iopub.status.idle":"2021-06-10T04:47:09.136563Z","shell.execute_reply.started":"2021-06-10T04:47:09.132265Z","shell.execute_reply":"2021-06-10T04:47:09.135532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**42000 images (28* 28) and 42000 labels : 1 corresponding to each**","metadata":{}},{"cell_type":"code","source":"X_test = np.asarray(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:11.506704Z","iopub.execute_input":"2021-06-10T04:47:11.507056Z","iopub.status.idle":"2021-06-10T04:47:11.510967Z","shell.execute_reply.started":"2021-06-10T04:47:11.507024Z","shell.execute_reply":"2021-06-10T04:47:11.509909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:12.843135Z","iopub.execute_input":"2021-06-10T04:47:12.843465Z","iopub.status.idle":"2021-06-10T04:47:12.848287Z","shell.execute_reply.started":"2021-06-10T04:47:12.843428Z","shell.execute_reply":"2021-06-10T04:47:12.847294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test data is now array of 28000 examples and 784 pixels(28* 28) per image**","metadata":{}},{"cell_type":"markdown","source":"**Lets check the distribution of data**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20,15))\n\nplt.xticks(size=15)\nsns.countplot(y_train,linewidth = 3,edgecolor=sns.color_palette())\nplt.title('Distribution of labels in the train dataset', fontdict={'color' : 'Black' , 'fontsize' : 30})\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:15.861842Z","iopub.execute_input":"2021-06-10T04:47:15.862162Z","iopub.status.idle":"2021-06-10T04:47:16.069573Z","shell.execute_reply.started":"2021-06-10T04:47:15.862131Z","shell.execute_reply":"2021-06-10T04:47:16.068739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are nearly equal examples of each label(i.e digits from 0 to 9) , hence data is balanced.**","metadata":{}},{"cell_type":"markdown","source":"**As we have discussed so far, image pixel values are in the form of columns, we have to reshape the values to visualise them as an image. Also apart from visualisation we also have to feed the CNN in the form of images(or reshaped 2D matrices)** ","metadata":{}},{"cell_type":"code","source":"print(\"Before Reshaping : \")\nprint(\"Shape of X_train :\" ,X_train.shape)\nprint(\"Shape of y_train :\" ,y_train.shape)\nprint(\"Shape of X_test :\" ,X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:19.816858Z","iopub.execute_input":"2021-06-10T04:47:19.81722Z","iopub.status.idle":"2021-06-10T04:47:19.823909Z","shell.execute_reply.started":"2021-06-10T04:47:19.817187Z","shell.execute_reply":"2021-06-10T04:47:19.821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.reshape(len(X_train), 28,28,1)\nX_test = X_test.reshape(len(X_test), 28,28,1)\n\ny_train = tf.keras.utils.to_categorical(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:21.077007Z","iopub.execute_input":"2021-06-10T04:47:21.077315Z","iopub.status.idle":"2021-06-10T04:47:21.083473Z","shell.execute_reply.started":"2021-06-10T04:47:21.077286Z","shell.execute_reply":"2021-06-10T04:47:21.082536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"After Reshaping : \")\nprint(\"Shape of X_train :\" ,X_train.shape)\nprint(\"Shape of y_train :\" ,y_train.shape)\nprint(\"Shape of X_test :\" ,X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:22.322107Z","iopub.execute_input":"2021-06-10T04:47:22.32242Z","iopub.status.idle":"2021-06-10T04:47:22.331247Z","shell.execute_reply.started":"2021-06-10T04:47:22.322389Z","shell.execute_reply":"2021-06-10T04:47:22.33036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data has been reshaped and it can be seen that train data is of 42000 examples/images of size 28* 28 and labels are one hot encoded and hence shape changed form (42000,1) to (42000,10).**","metadata":{}},{"cell_type":"markdown","source":"**Visualising the images**","metadata":{}},{"cell_type":"code","source":"L = 5\nW = 5\nfig, axes = plt.subplots(L, W, figsize = (15,15))\naxes = axes.ravel()\n\nfor i in range(0, L * W):  \n    axes[i].imshow(X_train[i],cmap='gray')\n    axes[i].set_title(\"Digit = \"+str(i))\n    axes[i].axis('off')\nplt.subplots_adjust(wspace=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:35.396803Z","iopub.execute_input":"2021-06-10T04:47:35.397115Z","iopub.status.idle":"2021-06-10T04:47:36.515758Z","shell.execute_reply.started":"2021-06-10T04:47:35.397084Z","shell.execute_reply":"2021-06-10T04:47:36.514802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Perfect!!! , Lets build a simple CNN model.**","metadata":{}},{"cell_type":"code","source":"def get_model(input_shape):\n    model = Sequential()\n    model.add(Conv2D(filters = 16,kernel_size = (3,3),activation = 'relu',input_shape = input_shape))\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(filters = 32,kernel_size = (3,3),activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2,2)))\n    # model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters = 128,kernel_size = (3,3),activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2,2)))\n    # model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters = 256,kernel_size = (3,3),activation = 'relu'))\n    model.add(MaxPooling2D((2,2)))\n    \n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(10,activation='softmax')) \n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:39.167034Z","iopub.execute_input":"2021-06-10T04:47:39.167346Z","iopub.status.idle":"2021-06-10T04:47:39.176731Z","shell.execute_reply.started":"2021-06-10T04:47:39.167315Z","shell.execute_reply":"2021-06-10T04:47:39.175839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model(input_shape = (28,28,1))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:40.376695Z","iopub.execute_input":"2021-06-10T04:47:40.377024Z","iopub.status.idle":"2021-06-10T04:47:42.614283Z","shell.execute_reply.started":"2021-06-10T04:47:40.376993Z","shell.execute_reply":"2021-06-10T04:47:42.613308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',metrics = ['accuracy'],loss = 'categorical_crossentropy')\nhistory = model.fit( X_train, y_train, batch_size = 300  , epochs = 30)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:47:43.980132Z","iopub.execute_input":"2021-06-10T04:47:43.980454Z","iopub.status.idle":"2021-06-10T04:48:31.672045Z","shell.execute_reply.started":"2021-06-10T04:47:43.980422Z","shell.execute_reply":"2021-06-10T04:48:31.671243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing the training performance\nplt.figure(figsize=(6, 4))\n\nplt.subplot(1, 2, 1)\nplt.title('Loss')\nplt.plot(history.history['loss'], label='Loss')\nplt.legend()\nplt.grid()\n\nplt.subplot(1, 2, 2)\nplt.title('Accuracy')\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.legend()\nplt.grid()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:51:07.498632Z","iopub.execute_input":"2021-06-10T04:51:07.499047Z","iopub.status.idle":"2021-06-10T04:51:07.734154Z","shell.execute_reply.started":"2021-06-10T04:51:07.49901Z","shell.execute_reply":"2021-06-10T04:51:07.732784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model is converging satisfactorily , let's make predictions on test set**","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:52:06.972166Z","iopub.execute_input":"2021-06-10T04:52:06.972504Z","iopub.status.idle":"2021-06-10T04:52:08.106739Z","shell.execute_reply.started":"2021-06-10T04:52:06.972472Z","shell.execute_reply":"2021-06-10T04:52:08.105921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = np.argmax(predictions, axis= 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:52:10.966183Z","iopub.execute_input":"2021-06-10T04:52:10.966496Z","iopub.status.idle":"2021-06-10T04:52:10.971233Z","shell.execute_reply.started":"2021-06-10T04:52:10.966466Z","shell.execute_reply":"2021-06-10T04:52:10.970339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.Series(results, name=\"Label\")\nresults.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:52:16.173513Z","iopub.execute_input":"2021-06-10T04:52:16.173842Z","iopub.status.idle":"2021-06-10T04:52:16.18073Z","shell.execute_reply.started":"2021-06-10T04:52:16.17381Z","shell.execute_reply":"2021-06-10T04:52:16.179913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T04:52:18.108222Z","iopub.execute_input":"2021-06-10T04:52:18.108562Z","iopub.status.idle":"2021-06-10T04:52:18.315242Z","shell.execute_reply.started":"2021-06-10T04:52:18.108531Z","shell.execute_reply":"2021-06-10T04:52:18.314517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Submit this CSV to the competition and lets see where we stand.**","metadata":{}},{"cell_type":"markdown","source":"**Please like and comment if you find this useful, Thanks!!!**","metadata":{}}]}