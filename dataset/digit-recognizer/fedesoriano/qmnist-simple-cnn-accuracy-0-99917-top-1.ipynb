{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# QMNIST: Using a Simple CNN to reach the Top 1% \n\nThe goal of this notebook is to classify with the best accuracy possible handwritten digits. The input is a (28,28) \"image\" in grey scale. This notebook is presents multiple technics to achieve 99.9 accuracy:\n\n- CNN\n- Denser Dataset (we use MNIST images and the extended QMNIST Dataset)\n- Data Augmentation","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport warnings\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nwarnings.filterwarnings(\"ignore\")\nplt.rcParams['figure.figsize'] = [20, 20]\n\ndef plot_images(images, labels, shape=(3,3)):\n    fig, p = plt.subplots(shape[0], shape[1])\n    i = 0\n    for x in p:\n        for ax in x:\n            ax.imshow(images[i])\n            ax.set_title(labels[i])\n            i += 1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-11T12:50:45.440336Z","iopub.execute_input":"2021-10-11T12:50:45.441375Z","iopub.status.idle":"2021-10-11T12:50:50.365313Z","shell.execute_reply.started":"2021-10-11T12:50:45.441266Z","shell.execute_reply":"2021-10-11T12:50:50.363981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read the data","metadata":{}},{"cell_type":"code","source":"def unpickle(file):\n    import pickle\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:50:50.368293Z","iopub.execute_input":"2021-10-11T12:50:50.36849Z","iopub.status.idle":"2021-10-11T12:50:50.375048Z","shell.execute_reply.started":"2021-10-11T12:50:50.368467Z","shell.execute_reply":"2021-10-11T12:50:50.374389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will use the QMNIST extended data to boost the performance to the max, see https://www.kaggle.com/fedesoriano/qmnist-the-extended-mnist-dataset-120k-images","metadata":{}},{"cell_type":"code","source":"# Read qmnist data\nqmnist = unpickle(\"/kaggle/input/qmnist-the-extended-mnist-dataset-120k-images/MNIST-120k\")\n \n# Load test data\ntest = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\n\n# we reshape and normalize the data\nX_qmnist = np.array(qmnist['data'], dtype=\"float32\") / 255\nX_qmnist = X_qmnist.reshape(-1, 28, 28, 1)\n\n# Convert labels to one hot vectors\ny_qmnist = tf.keras.utils.to_categorical(qmnist['labels'])\n\nX_test = np.array(test, dtype=\"float32\") / 255\nX_test = X_test.reshape(-1, 28, 28, 1)\n\nplot_images(X_qmnist[:9], y_qmnist[:9], shape=(3,3))","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:50:50.376176Z","iopub.execute_input":"2021-10-11T12:50:50.376488Z","iopub.status.idle":"2021-10-11T12:50:56.299192Z","shell.execute_reply.started":"2021-10-11T12:50:50.376456Z","shell.execute_reply":"2021-10-11T12:50:56.29848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to get the biggest amount of data possible we will train our model with both the MNIST and the QMNIST data.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.datasets import mnist\n\n# Load MNIST data\n(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()\n\nX_mnist = np.concatenate((X_train_mnist, X_test_mnist))\ny_mnist = np.concatenate((y_train_mnist, y_test_mnist))\n\n# Preprocess MNIST to match our preprocessing\nX_mnist = X_mnist.reshape(-1,28,28,1)\nX_mnist = X_mnist.astype(np.float32) / 255\ny_mnist = tf.keras.utils.to_categorical(y_mnist,num_classes=10)\n\n# Combine MNIST and QMNIST\nX_train = np.concatenate((X_qmnist, X_mnist))\ny_train = np.concatenate((y_qmnist, y_mnist))\n\n# final dataset shape\nprint(\"MNIST image dataset shape:\", X_qmnist.shape)\nprint(\"QMNIST image dataset shape:\", X_mnist.shape)\nprint(\"Final image dataset shape:\", X_train.shape)\n\nplot_images(X_train[:9], y_train[:9], shape=(3,3))","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:50:56.311065Z","iopub.execute_input":"2021-10-11T12:50:56.311568Z","iopub.status.idle":"2021-10-11T12:50:56.31845Z","shell.execute_reply.started":"2021-10-11T12:50:56.311534Z","shell.execute_reply":"2021-10-11T12:50:56.317737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Augmentation\n\nTo provide more data during the training process, we are also going to use Data Augmentation.","metadata":{}},{"cell_type":"code","source":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.20,\n    shear_range=15,\n    zoom_range=0.10,\n    validation_split=0.25,\n    horizontal_flip=False\n)\n\ntrain_generator = datagen.flow(\n    X_train,\n    y_train, \n    batch_size=256,\n    subset='training',\n)\n\nvalidation_generator = datagen.flow(\n    X_train,\n    y_train, \n    batch_size=64,\n    subset='validation',\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:50:56.319477Z","iopub.execute_input":"2021-10-11T12:50:56.320155Z","iopub.status.idle":"2021-10-11T12:50:56.386649Z","shell.execute_reply.started":"2021-10-11T12:50:56.320118Z","shell.execute_reply":"2021-10-11T12:50:56.38602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN","metadata":{}},{"cell_type":"code","source":"def create_model():\n    model = tf.keras.Sequential([\n        \n        tf.keras.layers.Reshape((28, 28, 1)),\n        tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\", padding=\"same\", input_shape=(28,28,1)),\n        tf.keras.layers.MaxPool2D((2,2)),\n        \n        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"),\n        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"),\n        tf.keras.layers.MaxPool2D((2,2)),\n        \n        tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\", padding=\"same\"),\n        tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\", padding=\"same\"),\n        tf.keras.layers.MaxPool2D((2,2)),\n\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(512, activation=\"sigmoid\"),\n        tf.keras.layers.Dropout(0.25),\n        \n        tf.keras.layers.Dense(512, activation=\"sigmoid\"),\n        tf.keras.layers.Dropout(0.25),\n        \n        tf.keras.layers.Dense(256, activation=\"sigmoid\"),\n        tf.keras.layers.Dropout(0.1),\n        \n        tf.keras.layers.Dense(10, activation=\"sigmoid\")\n    ])\n\n    model.compile(\n        optimizer=\"adam\",\n        loss = 'categorical_crossentropy',\n        metrics = ['accuracy']\n    )\n\n    return model\n\nmodel = create_model()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:50:56.387711Z","iopub.execute_input":"2021-10-11T12:50:56.388018Z","iopub.status.idle":"2021-10-11T12:50:58.326109Z","shell.execute_reply.started":"2021-10-11T12:50:56.387983Z","shell.execute_reply":"2021-10-11T12:50:58.325355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                 factor=0.1,\n                                                 patience=5,\n                                                 min_lr=0.000001,\n                                                 verbose=1)\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath='model.hdf5',\n                                                monitor='val_loss',\n                                                save_best_only=True,\n                                                save_weights_only=True,\n                                                verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:50:58.327531Z","iopub.execute_input":"2021-10-11T12:50:58.327801Z","iopub.status.idle":"2021-10-11T12:50:58.333068Z","shell.execute_reply.started":"2021-10-11T12:50:58.327767Z","shell.execute_reply":"2021-10-11T12:50:58.332321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"history = model.fit_generator(train_generator, \n                              epochs=100, \n                              validation_data=validation_generator, \n                              callbacks=[reduce_lr,checkpoint], \n                              verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:50:58.334587Z","iopub.execute_input":"2021-10-11T12:50:58.335088Z","iopub.status.idle":"2021-10-11T13:24:23.049377Z","shell.execute_reply.started":"2021-10-11T12:50:58.335052Z","shell.execute_reply":"2021-10-11T13:24:23.048678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('model.hdf5')\n\nfig, ax = plt.subplots(1,2, figsize=(15, 5))\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)\n\nfinal_loss, final_acc = model.evaluate(X_train,  y_train, verbose=2)\nprint(\"Model accuracy: \", final_acc, \", model loss: \", final_loss)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:25:23.083141Z","iopub.execute_input":"2021-10-11T13:25:23.084008Z","iopub.status.idle":"2021-10-11T13:25:23.793092Z","shell.execute_reply.started":"2021-10-11T13:25:23.083972Z","shell.execute_reply":"2021-10-11T13:25:23.791427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submbit predictions","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\").astype(\"float32\") / 255.0\npredictions = tf.keras.backend.argmax(model.predict(df))\nsubmission = pd.DataFrame({'ImageId': range(1, len(predictions) + 1), \"Label\": predictions})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T16:54:48.961269Z","iopub.execute_input":"2021-10-11T16:54:48.961706Z","iopub.status.idle":"2021-10-11T16:54:49.117489Z","shell.execute_reply.started":"2021-10-11T16:54:48.961616Z","shell.execute_reply":"2021-10-11T16:54:49.11575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}