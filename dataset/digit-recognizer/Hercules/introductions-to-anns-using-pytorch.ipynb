{"cells":[{"metadata":{"_uuid":"f71121d964c739a4cf8688b6adfc1e446f283508"},"cell_type":"markdown","source":"# Introduction Artificial Neural Networks using PyTorch\n\n*15 November 2018*  \n\n#### ***[Soumya Ranjan Behera](https://www.linkedin.com/in/soumya044)***\n\n### In this Kernel I have demonstrated a beginner's approach of implementing an  Artificial Neural Network (ANN) using [PyTorch](https://pytorch.org/) to classify the digits into their respective categories which have scored **97.7 %** Accuracy in the Digit Recognizer Competition.\n\n### Goals of this Kenel:  \n* To demonstrate a new Deep Learning framework **[PyTorch](https://pytorch.org/)**\n* To provide a basic implementation of Artificial Neural Network (ANN)\n* A beginner friendly kernel to show a procedure to compete in Kaggle Digit Recognizer Competition"},{"metadata":{"_uuid":"4582ccd944dab08b20bc4942d17d8b8f8f545cdb"},"cell_type":"markdown","source":"## What is PyTorch?\n> A NEW WAY FROM RESEARCH TO PRODUCTION\n\nPyTorch is an open source deep learning platform that provides a seamless path from research prototyping to production deployment."},{"metadata":{"_uuid":"e5f5784576b0a73bda7d8177188c6e314521ff3c"},"cell_type":"markdown","source":"## Key Features Of PyTorch\n* HYBRID FRONT-END\n* DISTRIBUTED TRAINING\n* PYTHON-FIRST\n* ADVANCED TOOLS & LIBRARIES\n* NATIVE ONNX SUPPORT  (Open Neural Network Exchange Support) \n* VERY FAST PRODUCTION READY DEPLOYMENT WITH C++\n\nReference: [click here](https://pytorch.org/features)"},{"metadata":{"_uuid":"ea4e421aa42419fa574b736a5c76f8373ca71d1a"},"cell_type":"markdown","source":"## Dataset Overview\n ``` \n ../input/\n     |_ train.csv  \n     |_ test.csv  \n     |_ sample_submission.csv```  \n     \n* ```train.csv``` contains 42k samples of 28x28 digit images with their labels\n* ```test.csv``` contains 28k samples of 28x28 digit images without labels\n* We've to predict the labels for the ```test``` samples and submit them in a csv file as shown  in ```sample_submission.csv```\n"},{"metadata":{"_uuid":"57f7a748c7767ece8f82f9896f32cc03475c4e03"},"cell_type":"markdown","source":"**Note:** In this kernel I have provided only the implementation of ANN using PyTorch. For basics of ANN or PyTorch please refer to this free course [Intro to Deep Learning using PyTorch](https://in.udacity.com/course/deep-learning-pytorch--ud188) "},{"metadata":{"_uuid":"cd6e41fbca78f8320c75d44e681986af0172959d"},"cell_type":"markdown","source":"# 1. Prepare our Data\n\n### Import Numpy, Pandas and Matplotlib"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #Visualization\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8c62843cff714c5e6bdc3a4515b84df7f39910c"},"cell_type":"markdown","source":"### Import Training data as Numpy array"},{"metadata":{"trusted":true,"_uuid":"139094763203c6a2cd7ea747c74f2573b2024452"},"cell_type":"code","source":"dataset = pd.read_csv('../input/train.csv')\nX = dataset.iloc[:, 1:].values\ny = dataset.iloc[:, 0].values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd90a67c8e69eff6c953722fe53ad3f81e83a73a"},"cell_type":"markdown","source":"### Let's see the distribution of data"},{"metadata":{"trusted":true,"_uuid":"2a557e44359c5372d070b448edb46e7b7fc55341"},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a50d74fc85be59b612f5b436c28d343d90f847a"},"cell_type":"markdown","source":"Since all our target classes are well-balanced we can move to our next step."},{"metadata":{"_uuid":"09cdcb3371990a4cee6ac83e9dfa1ae6264efad9"},"cell_type":"markdown","source":"### Visualization of our Data (Sample Images)"},{"metadata":{"trusted":true,"_uuid":"ecad750c7d2ee2e2b0bc9fde66dc42dfa8b708ca"},"cell_type":"code","source":"# Let's see some sample images\nfig = plt.figure(figsize=(25,4))\nfig.subplots_adjust(hspace=0.5)\nfor i,index in enumerate(np.random.randint(0,100,10)):\n    ax = fig.add_subplot(2,5,i+1)\n    ax.imshow(X[index].reshape(28,28), cmap='gray')\n    ax.set_title(\"Label= {}\".format(y[index]), fontsize = 20)\n    ax.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f1db4dec43293a41e2bf68d562f5d4512371420"},"cell_type":"markdown","source":"### Check for Null Values"},{"metadata":{"trusted":true,"_uuid":"43af10cefab95c65bb3ad9f66ef6c139cdcba4d5"},"cell_type":"code","source":"# Check IF some Feature variables are NaN\nnp.unique(np.isnan(X))[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be2e1c896c8fed5499d4c7f5b4ae3b3cb3300ba4"},"cell_type":"code","source":"# Check IF some Target Variables are NaN\nnp.unique(np.isnan(y))[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcefe791f3e63563e885739b50d23fcba400db99"},"cell_type":"markdown","source":"Since no NULL or NaN values are there, we're good to go!"},{"metadata":{"_uuid":"02eb1f8d09c1755f6e2fe915a6c9ff220f1e6373"},"cell_type":"markdown","source":"### Splitting Dataset into Training set and Test set"},{"metadata":{"trusted":true,"_uuid":"ba3315a746e917046bf3492fc00807ee65091a09"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c4d0ded880d1fb478e48c80a56fcfc6e53b2ea5"},"cell_type":"markdown","source":"### Normalization\nThe goal of normalization is to change the values of numeric columns in the dataset to use a common scale, without distorting differences in the ranges of values or losing information. Here we're dividing all the pixel values with 255.0 to make all pixel values lie in between 0 and 1."},{"metadata":{"trusted":true,"_uuid":"3c93b95e4ebac682d6fe1e7e94044dea67fcb92d"},"cell_type":"code","source":"# Normalization\nX_train = X_train / 255.0\nX_test = X_test / 255.0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"928bda1c0e1bbb9001c676ee636237926427386d"},"cell_type":"markdown","source":"# 2. Building our ANN using PyTorch"},{"metadata":{"_uuid":"b83b8c633cd4f561a545f25ce1818bb96c68108a"},"cell_type":"markdown","source":"### Import required libraries"},{"metadata":{"trusted":true,"_uuid":"b928902514f6716783007b1dbf56c21da922f505"},"cell_type":"code","source":"import torch\nimport torch.utils.data\nfrom torch.autograd import Variable","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85627d593eaa9902e4ef45cf5eaa5370b47a3049"},"cell_type":"markdown","source":"### Convert Numpy Arrays to Tensors \nHere we have to convert our train and test data sets (which are in numpy array format) to tensors. Because PyTorch only takes tensors as input."},{"metadata":{"trusted":true,"_uuid":"e21576cbf8a44706f34fbcf57e90c1a6db97d455"},"cell_type":"code","source":"'''Create tensors for our train and test set. \nAs you remember we need variable to accumulate gradients. \nTherefore first we create tensor, then we will create variable '''\n# Numpy to Tensor Conversion (Train Set)\nX_train = torch.from_numpy(X_train)\ny_train = torch.from_numpy(y_train)\n\n# Numpy to Tensor Conversion (Train Set)\nX_test = torch.from_numpy(X_test)\ny_test = torch.from_numpy(y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69f054ef96ac0b6bef522d88ff11f5e9899b758f"},"cell_type":"markdown","source":"### Build Train and Test Data loaders"},{"metadata":{"trusted":true,"_uuid":"447eed0ad5c4c4e12125cb53e4649f7a83d38ac2"},"cell_type":"code","source":"# Make torch datasets from train and test sets\ntrain = torch.utils.data.TensorDataset(X_train,y_train)\ntest = torch.utils.data.TensorDataset(X_test,y_test)\n\n# Create train and test data loaders\ntrain_loader = torch.utils.data.DataLoader(train, batch_size = 64, shuffle = True)\ntest_loader = torch.utils.data.DataLoader(test, batch_size = 64, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e96f57be36f205e04831824b38797b5954fb5ab3"},"cell_type":"markdown","source":"### Architect our Neural Network"},{"metadata":{"trusted":true,"_uuid":"e0c82a933b9528798f972ce174b1a0c97bd2981d"},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"866aefed6b1df57e1d049609ca31717dc20062b5"},"cell_type":"markdown","source":"Define any desired architecture with feed-forward function"},{"metadata":{"trusted":true,"_uuid":"471b169380db336de491f941d31f0b234348620e"},"cell_type":"code","source":"class ANN(nn.Module):\n    def __init__(self, input_dim = 784, output_dim = 10):\n        super(ANN, self).__init__()\n    \n        # Input Layer (784) -> 784\n        self.fc1 = nn.Linear(input_dim, 784)\n        # 784 -> 128\n        self.fc2 = nn.Linear(784, 128)\n        # 128 -> 128\n        self.fc3 = nn.Linear(128, 128)\n        # 128 -> 64\n        self.fc4 = nn.Linear(128, 64)\n        # 64 -> 64\n        self.fc5 = nn.Linear(64, 64)\n        # 64 -> 32\n        self.fc6 = nn.Linear(64, 32)\n        # 32 -> 32\n        self.fc7 = nn.Linear(32, 32)\n        # 32 -> output layer(10)\n        self.output_layer = nn.Linear(32,10)\n        # Dropout Layer (20%) to reduce overfitting\n        self.dropout = nn.Dropout(0.2)\n    \n    # Feed Forward Function\n    def forward(self, x):\n        \n        # flatten image input\n        x = x.view(-1, 28 * 28)\n        \n        # Add ReLU activation function to each layer\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        # Add dropout layer\n        x = self.dropout(x)\n        x = F.relu(self.fc4(x))\n        x = F.relu(self.fc5(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc6(x))\n        x = F.relu(self.fc7(x))\n        x = self.dropout(x)\n        # Don't add any ReLU activation function to Last Output Layer\n        x = self.output_layer(x)\n        \n        # Return the created model\n        return x","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ac42ada578f7d4dd6b644dbb005a4a3057a0e0a"},"cell_type":"markdown","source":"### Create the Model"},{"metadata":{"trusted":true,"_uuid":"571be884abcb4e65afa29e4f8b193f0ddb1c6c19"},"cell_type":"code","source":"# Create the Neural Network Model\nmodel = ANN(input_dim = 784, output_dim = 10)\n# Print its architecture\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52be0628178885745303abc63292e61b74c92f11"},"cell_type":"markdown","source":"### Define Loss Function and Optimizer\nHere we've used Cross Entropy Loss Function and SGD optimizer. Feel free to experiment with other hyperparameters."},{"metadata":{"trusted":true,"_uuid":"a2930ad701a6cc794a3b3c1299d39babc15fc300"},"cell_type":"code","source":"import torch.optim as optim\n# specify loss function\nloss_fn = nn.CrossEntropyLoss()\n\n# specify optimizer\noptimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay= 1e-6, momentum = 0.9,nesterov = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da22a895c35c667e68a790006830eeb878641ab2"},"cell_type":"markdown","source":"# 3. Train our Model with simultaneous Validation"},{"metadata":{"trusted":true,"_uuid":"38a2af35c948ae75cdab728651d50d0a2179f788"},"cell_type":"code","source":"# Define epochs (between 20-50)\nepochs = 30\n\n# initialize tracker for minimum validation loss\nvalid_loss_min = np.Inf # set initial \"min\" to infinity\n\n# Some lists to keep track of loss and accuracy during each epoch\nepoch_list = []\ntrain_loss_list = []\nval_loss_list = []\ntrain_acc_list = []\nval_acc_list = []\n\n\n\n# Start epochs\nfor epoch in range(epochs):\n    # monitor training loss\n    train_loss = 0.0\n    val_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    # Set the training mode ON -> Activate Dropout Layers\n    model.train() # prepare model for training\n    # Calculate Accuracy         \n    correct = 0\n    total = 0\n    \n    # Load Train Images with Labels(Targets)\n    for data, target in train_loader:\n        \n        # Convert our images and labels to Variables to accumulate Gradients\n        data = Variable(data).float()\n        target = Variable(target).type(torch.LongTensor)\n        \n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        \n        # Calculate Training Accuracy \n        predicted = torch.max(output.data, 1)[1]        \n        # Total number of labels\n        total += len(target)\n        # Total correct predictions\n        correct += (predicted == target).sum()\n        \n        # calculate the loss\n        loss = loss_fn(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update running training loss\n        train_loss += loss.item()*data.size(0)\n    \n    # calculate average training loss over an epoch\n    train_loss = train_loss/len(train_loader.dataset)\n    \n    # Avg Accuracy\n    accuracy = 100 * correct / float(total)\n    \n    # Put them in their list\n    train_acc_list.append(accuracy)\n    train_loss_list.append(train_loss)\n    \n        \n    # Implement Validation like K-fold Cross-validation \n    # Set Evaluation Mode ON -> Turn Off Dropout\n    model.eval() # Required for Evaluation/Test\n\n    # Calculate Test/Validation Accuracy         \n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n\n            # Convert our images and labels to Variables to accumulate Gradients\n            data = Variable(data).float()\n            target = Variable(target).type(torch.LongTensor)\n\n            # Predict Output\n            output = model(data)\n\n            # Calculate Loss\n            loss = loss_fn(output, target)\n            val_loss += loss.item()*data.size(0)\n            # Get predictions from the maximum value\n            predicted = torch.max(output.data, 1)[1]\n\n            # Total number of labels\n            total += len(target)\n\n            # Total correct predictions\n            correct += (predicted == target).sum()\n    \n    # calculate average training loss and accuracy over an epoch\n    val_loss = val_loss/len(test_loader.dataset)\n    accuracy = 100 * correct/ float(total)\n    \n    # Put them in their list\n    val_acc_list.append(accuracy)\n    val_loss_list.append(val_loss)\n    \n    # Print the Epoch and Training Loss Details with Validation Accuracy   \n    print('Epoch: {} \\tTraining Loss: {:.4f}\\t Val. acc: {:.2f}%'.format(\n        epoch+1, \n        train_loss,\n        accuracy\n        ))\n    # save model if validation loss has decreased\n    if val_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        val_loss))\n        torch.save(model.state_dict(), 'model.pt')\n        valid_loss_min = val_loss\n    # Move to next epoch\n    epoch_list.append(epoch + 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0410fba8fc2b1e06a0c6b868b224d9104a90bd18"},"cell_type":"markdown","source":"## Load the Model with the Lowest Validation Loss"},{"metadata":{"trusted":true,"_uuid":"88961ee72ddb50796f98acd2ab8722381e4b380e"},"cell_type":"code","source":"model.load_state_dict(torch.load('model.pt'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8c18a080eda8a0bc75f2a7f20f92ca43e6c20d5"},"cell_type":"markdown","source":"# 4.  Performance Evaluation"},{"metadata":{"_uuid":"b867e8dce8082f91e04d0168f70ee9240097f692"},"cell_type":"markdown","source":"### Visualize Training Stats"},{"metadata":{"_uuid":"47e06efde4324812827fea3705398ca23459278d"},"cell_type":"markdown","source":"**Average Loss VS Number of Epochs Graph**"},{"metadata":{"trusted":true,"_uuid":"ce879a6f57aa0720844d038968c87c1235b7be1e"},"cell_type":"code","source":"plt.plot(epoch_list,train_loss_list)\nplt.plot(val_loss_list)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss vs Number of Epochs\")\nplt.legend(['Train', 'Test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"714f6b529acc95aba6e6fd0229e9acf808cdc74e"},"cell_type":"markdown","source":"**Avg. Accuracy VS Number of Epochs Graph**"},{"metadata":{"trusted":true,"_uuid":"d61565fc6654d7e5c64894a582471e31314ba177"},"cell_type":"code","source":"plt.plot(epoch_list,train_acc_list)\nplt.plot(val_acc_list)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Training Accuracy\")\nplt.title(\"Accuracy vs Number of Epochs\")\nplt.legend(['Train', 'Test'], loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb99eafd6af52b71bf35be003640c05ee367c385"},"cell_type":"markdown","source":"### Validation/Test Accuracy\nHere we're taking average of last 10 validation accuracies"},{"metadata":{"trusted":true,"_uuid":"03c300bc6f05b4b238975ec5cb08fc1d5dccbe91"},"cell_type":"code","source":"val_acc = sum(val_acc_list[20:]).item()/10\nprint(\"Test Accuracy of model = {} %\".format(val_acc))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8b9794c5ef090178919823ec0fda76e9017deef"},"cell_type":"markdown","source":"# 5. Prepare Final Submission"},{"metadata":{"_uuid":"b075b7f298992247eb11fca3ddf87bff7e40f525"},"cell_type":"markdown","source":"### Import test data"},{"metadata":{"trusted":true,"_uuid":"f58d4392524dfe649d975cd7ecacdbb20f6fb49a"},"cell_type":"code","source":"kaggle_test_set = pd.read_csv('../input/test.csv')\n\n# Convert it to numpy array and Normalize it\nkaggle_test_set = kaggle_test_set.values/255.0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b589b12ef035d0a702905601dd86ab44defd8dfb"},"cell_type":"markdown","source":"### Convert our Test Data to Tensor Variable"},{"metadata":{"trusted":true,"_uuid":"dfbd66840548d41abee139329e41dbe4f92b1b95"},"cell_type":"code","source":"kaggle_test_set = Variable(torch.from_numpy(kaggle_test_set)).float()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1e896330fc1fc1b8eae5202aa168d46430c0322"},"cell_type":"markdown","source":"### Predict Labels/Targets for Test Images"},{"metadata":{"trusted":true,"_uuid":"d2bbd56abe73ef9a8e7cc0913e272a3e8f5d5f6e"},"cell_type":"code","source":"# Predicted Labels will be stored here\nresults = []\n\n# Set Evaluation Mode ON -> Turn Off Dropout\nmodel.eval() # Required for Evaluation/Test\n\nwith torch.no_grad():\n    for image in kaggle_test_set:\n        output = model(image)\n        pred = torch.max(output.data, 1)[1]\n        results.append(pred[0].numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15d57e6752b1f3bfcd7b668a6a0ffd8c2b6861db"},"cell_type":"code","source":"# Convert List to Numpy Array\nresults = np.array(results)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e534af39ab5287eda9adeb54f0b50dc27a9bb77"},"cell_type":"markdown","source":"### Visualiza some Test Images and their Predicted Labels"},{"metadata":{"trusted":true,"_uuid":"504a9f14bc7559625dadc6100d6281406fff30bd"},"cell_type":"code","source":"# Plot using Matplotlib\nfig = plt.figure(figsize=(25,4))\nfig.subplots_adjust(hspace=0.5)\nfor i,index in enumerate(np.random.randint(0,100,10)):\n    ax = fig.add_subplot(2,5,i+1)\n    ax.imshow(kaggle_test_set[index].reshape(28,28), cmap='gray')\n    ax.set_title(\"Label= {}\".format(results[index]), fontsize = 20)\n    ax.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae7b0febeb6bdc8c2ed4ace36b3917e4ef16d015"},"cell_type":"markdown","source":"**From the visualization we can see that our model performs really Good !!!**"},{"metadata":{"_uuid":"513bb6a2f665af4204d6fa184de74d8ae02814c9"},"cell_type":"markdown","source":"### Let's make our Final Submission CSV file"},{"metadata":{"_uuid":"d2906883997d51ddccdf13a7066a213c560ec015"},"cell_type":"markdown","source":"**Convert our Results Numpy Array to Pandas Series**"},{"metadata":{"trusted":true,"_uuid":"e430e1dd5e294f0e547a8baf8cd52f65fbccdb61"},"cell_type":"code","source":"results = pd.Series(results,name=\"Label\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae347799d3997c1b141843de58dcdd4bdb5c8138"},"cell_type":"markdown","source":"**Add an ' ImageId ' Column and Save as CSV file**"},{"metadata":{"trusted":true,"_uuid":"66888adc5c20ae5935c3e4e0bfc3e0b6b7447fe7"},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a193a0412cec442cdb6fdf743f67bcc6f9e05feb"},"cell_type":"markdown","source":"**Just Check our format to ensure correctness**"},{"metadata":{"trusted":true,"_uuid":"49c75b0208a80c55c8611459d50a99c7dcb758c2"},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Thank You  \n\nIf you liked this kernel please **Upvote**. Don't forget to drop a comment or suggestion.  \n\n### *Soumya Ranjan Behera*\nLet's stay Connected! [LinkedIn](https://www.linkedin.com/in/soumya044)  \n\n**Happy Coding !**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}