{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"266c0734-ebf3-a6d3-f7a6-13ec3d3e53f0"},"source":"## Tiny ResNet with Keras ##\n\n----------\n\nLet's solve this classic problem elegantly, using modern approaches and using as little code as possible."},{"cell_type":"markdown","metadata":{"_cell_guid":"bf235d4d-d91f-1cc4-daf4-d99b5c3f302b"},"source":"### Imports ###\n\nLet's import basic packages"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2f47932d-4b20-9a55-f3f7-59ba9d02ae50"},"outputs":[],"source":"import numpy as np                  # for working with tensors outside the network\nimport pandas as pd                 # for data reading and writing\nimport matplotlib.pyplot as plt     # for data inspection"},{"cell_type":"markdown","metadata":{"_cell_guid":"9f68fd1c-fbd6-6cf3-0474-3531cdd68370"},"source":"and all the Keras stuff we will need"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9dcdf9c7-be76-7559-5ee4-472850f7db75"},"outputs":[],"source":"from keras.layers import Input, Conv2D, Activation, BatchNormalization, GlobalAveragePooling2D, Dense, Dropout\nfrom keras.layers.merge import add\nfrom keras.activations import relu, softmax\nfrom keras.models import Model\nfrom keras import regularizers"},{"cell_type":"markdown","metadata":{"_cell_guid":"08b7dec9-2ab6-7265-1152-2929c41f0823"},"source":"and two handy sklearn functions for data preprocessing"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7c38b28d-0969-eb64-8975-3c081e03cf61","collapsed":true},"outputs":[],"source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split"},{"cell_type":"markdown","metadata":{"_cell_guid":"1ae0474f-dc60-84fa-1c9a-582048e3aad2"},"source":"### The model ###\n\nThe main idea of residual architecture is the shortcut connections. Instead of learning mapping\n$$\\mathcal{H}(x)$$\nwe learn the mapping\n$$\\mathcal{F}(x) = f(x) + \\mathcal{H}(x).$$\n\nIf\n$$f(x) = x$$\nthen  the entire network can be written as\n$$\\mathcal{F}(x) = x + \\sum_{l=0}^{L-1} \\mathcal{F}_{l+1} ( x_l ) $$\nwhich allows the error to propagate unchanged to the top of the network.\n\nMoreover, It's easier to learn the\n$$\\mathcal{F}_l(x) = 0$$\nmapping than the\n$$\\mathcal{H}(x) = x$$\nmapping when it's necessary to exclude some layer from the network."},{"cell_type":"markdown","metadata":{"_cell_guid":"b23725a9-5a07-8a27-cde7-02353dc97b71"},"source":"In practice, we can't use the identity function as f everywhere because of inconsistent dimensions, so when the input and output of the H_l have the different dimensionality we will use the 2d convolution with 1x1 kernel as the f function. Let's define the basic building block which consists of two 3x3 convolutional layers with pre-activation and the shortcut connection."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"053c496e-c063-5bac-fc8e-53fc4f3e50fd","collapsed":true},"outputs":[],"source":"def block(n_output, upscale=False):\n    # n_output: number of feature maps in the block\n    # upscale: should we use the 1x1 conv2d mapping for shortcut or not\n    \n    # keras functional api: return the function of type\n    # Tensor -> Tensor\n    def f(x):\n        \n        # H_l(x):\n        # first pre-activation\n        h = BatchNormalization()(x)\n        h = Activation(relu)(h)\n        # first convolution\n        h = Conv2D(kernel_size=3, filters=n_output, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(h)\n        \n        # second pre-activation\n        h = BatchNormalization()(x)\n        h = Activation(relu)(h)\n        # second convolution\n        h = Conv2D(kernel_size=3, filters=n_output, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(h)\n        \n        # f(x):\n        if upscale:\n            # 1x1 conv2d\n            f = Conv2D(kernel_size=1, filters=n_output, strides=1, padding='same')(x)\n        else:\n            # identity\n            f = x\n        \n        # F_l(x) = f(x) + H_l(x):\n        return add([f, h])\n    \n    return f"},{"cell_type":"markdown","metadata":{"_cell_guid":"80c62193-cef5-a9dd-4f38-dc73da7c18c3"},"source":"And now let's define the entire model."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b62b145-470e-02a1-7463-079a88b074b0"},"outputs":[],"source":"# input tensor is the 28x28 grayscale image\ninput_tensor = Input((28, 28, 1))\n\n# first conv2d with post-activation to transform the input data to some reasonable form\nx = Conv2D(kernel_size=3, filters=16, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(input_tensor)\nx = BatchNormalization()(x)\nx = Activation(relu)(x)\n\n# F_1\nx = block(16)(x)\n# F_2\nx = block(16)(x)\n\n# F_3\n# H_3 is the function from the tensor of size 28x28x16 to the the tensor of size 28x28x32\n# and we can't add together tensors of inconsistent sizes, so we use upscale=True\n# x = block(32, upscale=True)(x)       # !!! <------- Uncomment for local evaluation\n# F_4\n# x = block(32)(x)                     # !!! <------- Uncomment for local evaluation\n# F_5\n# x = block(32)(x)                     # !!! <------- Uncomment for local evaluation\n\n# F_6\n# x = block(48, upscale=True)(x)       # !!! <------- Uncomment for local evaluation\n# F_7\n# x = block(48)(x)                     # !!! <------- Uncomment for local evaluation\n\n# last activation of the entire network's output\nx = BatchNormalization()(x)\nx = Activation(relu)(x)\n\n# average pooling across the channels\n# 28x28x48 -> 1x48\nx = GlobalAveragePooling2D()(x)\n\n# dropout for more robust learning\nx = Dropout(0.2)(x)\n\n# last softmax layer\nx = Dense(units=10, kernel_regularizer=regularizers.l2(0.01))(x)\nx = Activation(softmax)(x)\n\nmodel = Model(inputs=input_tensor, outputs=x)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"e590f9e7-3143-849a-0cc6-1cacd95d0807"},"source":"The depth of the network is 16 layers."},{"cell_type":"markdown","metadata":{"_cell_guid":"b082f9c5-edd2-8d1c-258d-40e47249e04f"},"source":"Let's load and preprocess the data to test our network's possibilities."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b0f5c527-127a-52f4-6121-f7f7ee8b8039"},"outputs":[],"source":"df_train = pd.read_csv('../input/train.csv')\n\ny_train_ = df_train.ix[:, 0].values.astype(np.int).reshape(-1, 1)\nx_train = df_train.ix[:, 1:].values.astype(np.float32).reshape((-1, 28, 28, 1))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4660aa9d-0f75-2fb2-64a1-c1e95fdb9841","collapsed":true},"outputs":[],"source":"df_test = pd.read_csv('../input/test.csv')\n\nx_test = df_test.values.astype(np.float32).reshape((-1, 28, 28, 1))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32bcf504-31d4-a515-419f-9a61a3404164","collapsed":true},"outputs":[],"source":"y_train = OneHotEncoder(sparse=False).fit_transform(y_train_)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3a05b359-70d3-21cb-b8f3-b6f972b95cc7"},"source":"Randomly take 20% of data for validation:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d6c8580-ccad-7c18-568e-899c6a8e0135","collapsed":true},"outputs":[],"source":"x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train_)"},{"cell_type":"markdown","metadata":{"_cell_guid":"037eddeb-45ed-6508-b5b3-54ca635af067"},"source":"Normalize data by subtracting the mean image:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f91a205f-f096-5bd2-2c1b-c9fccef588b1"},"outputs":[],"source":"m = x_train.mean(axis=0)\n\nx_train -= m\nx_val -= m\nx_test -= m"},{"cell_type":"markdown","metadata":{"_cell_guid":"94b0f32a-ec24-ae62-3a98-ca14d736a578"},"source":"Now we will define two useful callbacks: one for the model checkpointing and one for managing the learning rate policy."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6c582de2-77fe-04e3-de3b-640389b46efe"},"outputs":[],"source":"from keras.callbacks import LearningRateScheduler, ModelCheckpoint"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"948858e5-c9fd-8ae3-1624-f012aea26976"},"outputs":[],"source":"mc = ModelCheckpoint('weights.best.keras', monitor='val_acc', save_best_only=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"9c4ec88f-3c52-59b6-cf3d-d1a257b947d0"},"source":"Let's use the sigmoidal decay as the learning rate policy:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e38fe08c-0e5e-fb2b-22b5-ba53ec86a010"},"outputs":[],"source":"def sigmoidal_decay(e, start=0, end=100, lr_start=1e-3, lr_end=1e-5):\n    if e < start:\n        return lr_start\n    \n    if e > end:\n        return lr_end\n    \n    middle = (start + end) / 2\n    s = lambda x: 1 / (1 + np.exp(-x))\n    \n    return s(13 * (-e + middle) / np.abs(end - start)) * np.abs(lr_start - lr_end) + lr_end"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"445a0c85-8c1c-d146-8156-45eb5db0b2ce"},"outputs":[],"source":"xs = np.linspace(0, 100)\nys = np.vectorize(sigmoidal_decay)(xs)\nplt.plot(xs, ys)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"21759fb6-9e6d-d422-fdf6-81d1dfb5c697"},"outputs":[],"source":"EPOCHS = 3                        # !!! <------- Chnage to 30-100 for local evaluation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bc011a85-f095-8381-ca8e-04e7d1a79994"},"outputs":[],"source":"lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))"},{"cell_type":"markdown","metadata":{"_cell_guid":"9ead3001-065f-8b0c-fed1-aa8341318f84"},"source":"And now we can train the model:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7515770-ca4c-41d0-0951-c60bdcbe2c88"},"outputs":[],"source":"hist = model.fit(x_train, y_train, epochs=EPOCHS, validation_data=(x_val, y_val), batch_size=512, callbacks=[lr, mc])"},{"cell_type":"markdown","metadata":{"_cell_guid":"432312e2-d156-dad0-a3f9-d50488fb2f61"},"source":"Training the full model for 100 epochs leads to 99.17% validation and 99.314% test accuracy. One epoch takes 40s on GTX 960."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"94c79da0-f8c2-41c4-42bc-a8fb92aa5e11"},"outputs":[],"source":"loss = hist.history['loss']\nval_loss = hist.history['val_loss']\nepochs = np.arange(1, EPOCHS + 1)\n\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"40496fc2-fc09-13eb-c1fd-b1bdfdb5df23"},"outputs":[],"source":"acc = hist.history['acc']\nval_acc = hist.history['val_acc']\nepochs = np.arange(1, EPOCHS + 1)\n\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"40d21b2b-e13c-ce3e-0a5f-7299c029bc61"},"source":"Now we can predict the test values and save them."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0be11e5d-9249-535c-3e27-a21798437ee2"},"outputs":[],"source":"model.load_weights('weights.best.keras')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"071f8b36-00e5-5f60-995b-c5e3132f6b09"},"outputs":[],"source":"p_test = model.predict(x_test, batch_size=512)\np_test = np.argmax(p_test, axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"680ac609-13b3-ce08-15c2-247a18b746ef"},"outputs":[],"source":"pd.DataFrame({'ImageId': 1 + np.arange(p_test.shape[0]), 'Label': p_test}).to_csv('output.csv', index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"4558def3-6b8a-cd46-89c6-1349f40afbb6"},"source":"Now we can predict the test values and save them."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"46e8bcf9-1b33-4896-0a73-2fb51c8813c8"},"outputs":[],"source":"model.load_weights('weights.best.keras')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"41ac45e3-4daa-9953-798d-e54cc8a93087"},"outputs":[],"source":"p_test = model.predict(x_test, batch_size=512)\np_test = np.argmax(p_test, axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"760777ac-d43b-0599-8044-fb68629de148"},"outputs":[],"source":"pd.DataFrame({'ImageId': 1 + np.arange(p_test.shape[0]), 'Label': p_test}).to_csv('output.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}