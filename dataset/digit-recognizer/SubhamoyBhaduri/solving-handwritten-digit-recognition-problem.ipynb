{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Handwritten Digit Recognization is one of the oldest problem of Machine Learning and is used to baseline performance of new algorithm.\n\n#### I will share my way of addressing this challenge starting from applying Classification algorithms, PCA, Neural Network and ultimately CNN.\n\n#### There is ample scope to improve this Notebook but I am sure the small footsteps outlined here will be helpful to solidify our learning."},{"metadata":{},"cell_type":"markdown","source":"#### Import the basic libraries."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas import DataFrame\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Load the train data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/digit-recognizer/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Explore train data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The 'label' is the target column and it says whether the values of pixel0 to pixel784 make it to any digit from 0 to 9.\n\n#### Each pixel has value in the range of 0 to 255."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Separate out predictor variables i.e pixel values and label."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_train_data_unscaled = train_data.drop(['label'], axis=1)\nmodel_train_label = train_data['label']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's visualize one row of the train dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(np.array(model_train_data_unscaled.loc[10]).reshape(28, 28), cmap='Greys')\nprint(model_train_label[10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### There is no missing value and there is very little scope of feature engineering; so we will only do scaling of pixel values to bring them within 0 and 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nstd_scaler = MinMaxScaler()\nmodel_train_data = std_scaler.fit_transform(model_train_data_unscaled.astype(np.float64))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We will create a standard function so that we can have similar metrics displayed for different algorithms."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, precision_recall_curve\n\ndef model_def(model, model_name, m_train_data, m_train_label):\n    model.fit(m_train_data, m_train_label)\n    s = \"predict_\"\n    p = s + model_name\n    p = model.predict(m_train_data)\n    cm = confusion_matrix(m_train_label, p)\n    precision = np.diag(cm)/np.sum(cm, axis=0)\n    recall    = np.diag(cm)/np.sum(cm, axis=1)\n    F1 = 2 * np.mean(precision) * np.mean(recall)/(np.mean(precision) + np.mean(recall))\n    cv_score = cross_val_score(model, m_train_data, m_train_label, cv=3, scoring='accuracy')\n    print(\"Precision Is      :\", np.mean(precision))\n    print(\"Recall Is         :\", np.mean(recall))\n    print(\"F1 Score IS       :\", F1)\n    print(\"Mean CV Score     :\", cv_score.mean())\n    print(\"Std Dev CV Score  :\", cv_score.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's start applying different algorithm on the train dataset.\n\n#### Softmax Regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nsoftmax = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial', C=0.05)\nmodel_def(softmax, \"softmax\", model_train_data, model_train_label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now we will apply PCA and which is one of the main dimensionality reduction technique. PCA stands for Principal Component Analysis and here the columns across which the data has maximum variability are retained; so we can drop few columns without losing significant amount of insights."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = 200)\nmodel_train_data2D = pca.fit_transform(model_train_data)\nprint(\"Explained Variance Ratio:\", np.sum(pca.explained_variance_ratio_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### So you can see if we use only 200 columns out of 784 columns we are able to explain 96.61% variability of the data.\n\n#### We will use this updated dataset on Polynomial Kernel Classification."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\npoly6 = SVC(C=2, kernel='poly', degree=3, gamma='auto', random_state=42)\nmodel_def(poly6, \"poly6\", model_train_data2D, model_train_label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We can see a slight improvement in model performance.\n\n#### Now we will apply ANN to solve the challenge. Since we want to use the standard function to display model metrics like CV score we need to build an wrapper."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_classifier():\n    classifier = Sequential([Dense(128, kernel_initializer='random_uniform', activation='relu', input_shape=(200,)),\n                             Dropout(rate=0.2),\n                             Dense(128, kernel_initializer='random_uniform', activation='relu'),\n                             Dropout(rate=0.2),\n                             Dense(10, kernel_initializer='random_uniform', activation='softmax')])\n    classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    return classifier\n\nANN_classifier = KerasClassifier(build_fn=build_classifier, batch_size=100, epochs=20)\nANN_classifier.fit(model_train_data2D, model_train_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_score = cross_val_score(ANN_classifier, model_train_data2D, model_train_label, cv=5, scoring='accuracy')\nprint(\"Mean CV Score Is:\", cv_score.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean CV Score Is:\", cv_score.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### So we can see a significant improvement in accuracy using an ANN to classify.\n\n#### Now we will use test data to predict."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n\nmodel_test_data = std_scaler.transform(test_data.astype(np.float64))\nmodel_test_data2D = pca.transform(model_test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_test_poly6 = poly6.predict(model_test_data2D)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_test_softmax = softmax.predict(model_test_data)\npredict_test_ANN = ANN_classifier.predict(model_test_data2D)\n\nId = DataFrame(np.arange(1,28001))\nId.columns = ['ImageId']\n\nprediction = DataFrame(predict_test_poly6)\nprediction.columns = ['Label']\n\nresult = pd.concat([Id, prediction], axis=1)\nresult.to_csv(\"Submission_Poly.csv\", index=False)\n\nId = DataFrame(np.arange(1,28001))\nId.columns = ['ImageId']\n\nprediction = DataFrame(predict_test_softmax)\nprediction.columns = ['Label']\n\nresult = pd.concat([Id, prediction], axis=1)\nresult.to_csv(\"Submission_Softmax.csv\", index=False)\n\nId = DataFrame(np.arange(1,28001))\nId.columns = ['ImageId']\n\nprediction = DataFrame(predict_test_ANN)\nprediction.columns = ['Label']\n\nresult = pd.concat([Id, prediction], axis=1)\nresult.to_csv(\"Submission_ANN.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now we will apply Convolutional Neural Network(CNN) techniques on the original data."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense, Dropout","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Reshaping the data to the format Convolution layer expects.\n\n#### Input shape - 4D tensor with shape: (batch_size, channels, rows, cols) if data_format='channels_first' or 4D tensor with shape: (batch_size, rows, cols, channels) if data_format='channels_last'."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(model_train_data_unscaled).reshape(42000, 28, 28, 1)\ny_train = model_train_label\nX_test = np.array(test_data).reshape(28000, 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CNN_model = Sequential([Convolution2D(filters=32, kernel_size=(3, 3), strides=(1, 1), input_shape=(28,28,1),\n                            padding='valid', activation='relu'),\n                         MaxPooling2D(pool_size=(2, 2)),\n                         Convolution2D(filters=32, kernel_size=(3, 3), strides=(1, 1),\n                            padding='valid', activation='relu'),\n                         MaxPooling2D(pool_size=(2, 2)),\n                         Flatten(),\n                         Dense(128, kernel_initializer='random_uniform', activation='relu'),\n                         Dropout(rate=0.2),\n                         Dense(128, kernel_initializer='random_uniform', activation='relu'),\n                         Dropout(rate=0.2),\n                         Dense(10, kernel_initializer='random_uniform', activation='softmax')])\n\nCNN_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nCNN_model.fit(X_train, y_train, batch_size=100, epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = CNN_model.predict(X_test)\ny_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_test_CNN = np.argmax(y_test, axis=1)\nplt.imshow(np.array(test_data.loc[0]).reshape(28, 28), cmap='Greys')\nprint(predict_test_CNN[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Id = DataFrame(np.arange(1,28001))\nId.columns = ['ImageId']\n\nprediction = DataFrame(predict_test_CNN)\nprediction.columns = ['Label']\n\nresult = pd.concat([Id, prediction], axis=1)\nresult.to_csv(\"Submission_CNN.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}