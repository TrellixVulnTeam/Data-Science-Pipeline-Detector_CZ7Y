{"cells":[{"metadata":{"_cell_guid":"654456b6-e648-0379-0d66-1cc97af6d00d","_uuid":"6b48ce0e361bdb67689dd2f254ecedd9ade1f5ff"},"cell_type":"markdown","source":"# Pydata Dec. 2020 - Stanley Zheng\n\nThis notebook is intended to explore various pseudolabelling schemes. Validation, model, data isn't hugely important here, so the cells are collapsed. Keep in mind this is a minimal example without much of the techniques discussed, and this dataset is very basic - adding augmentations, stochastic depth, etc. during training would result in better results. This is intended to be a minimal code example.\n\n### Reproducibility\nTo make this as fair a comparison as possible, I have seeded random weights and all pseudolabels are produced from the same set of weights. "},{"metadata":{"_cell_guid":"e5b02688-c589-5a89-e11c-837c6a99eb6e","_uuid":"f043e48097bfd98e41710142dd8aac41fa88a801","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom keras import  backend as K\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score\n\nimport os\nimport random","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"22a7fd70-ab61-432d-24cb-93e558414495","_uuid":"62fbd0fe9c338b7ac0b04e688c8ee7947e6170f7"},"cell_type":"markdown","source":"**Load Train and Test data and cross validation**\n============================"},{"metadata":{"_cell_guid":"05226b08-226a-1a00-044d-a0e6b2101388","_uuid":"4eff577bcd43479a3b7e91180393cbad9fcfca33","trusted":true},"cell_type":"code","source":"def standardize(x): \n    return (x-mean_px)/std_px\n\ndef seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest= pd.read_csv(\"../input/digit-recognizer/test.csv\")\nX_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\ny_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\nX_test = test.values.astype('float32')\nmean_px = X_train.mean().astype(np.float32)\nstd_px = X_train.std().astype(np.float32) \n\ny_train = tf.keras.utils.to_categorical(y_train)\nnum_classes = y_train.shape[1]\n\n# fix random seed for reproducibility\nseed_everything(seed=42)\n\nX_test = X_test.reshape(X_test.shape[0], 28, 28,1)\nX_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n\n# cross validation\nX = X_train\ny = y_train\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\n\nmnist_test = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\nmnist_train = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\nground_truth = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")\n\ncols = test.columns\n\ntest['dataset'] = 'test'\n\ntrain['dataset'] = 'train'\n\ndataset = pd.concat([train.drop('label', axis=1), test]).reset_index()\n\nmnist = pd.concat([mnist_train, mnist_test]).reset_index(drop=True)\nlabels = mnist['label'].values\nmnist.drop('label', axis=1, inplace=True)\nmnist.columns = cols\n\nidx_mnist = mnist.sort_values(by=list(mnist.columns)).index\ndataset_from = dataset.sort_values(by=list(mnist.columns))['dataset'].values\noriginal_idx = dataset.sort_values(by=list(mnist.columns))['index'].values\n\nfor i in range(len(idx_mnist)):\n    if dataset_from[i] == 'test':\n        ground_truth.loc[original_idx[i], 'Label'] = labels[idx_mnist[i]]\n        \ndef get_test_acc(model):\n    predictions = model.predict(X_test, verbose=0)\n    predictions = np.argmax(predictions,axis=1)\n\n    submissions = pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                                \"Label\": predictions})\n    return accuracy_score(ground_truth['Label'].values, submissions['Label'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b72580fbb06f5f4f769c514cb0d7d2f15aa2c2f"},"cell_type":"code","source":"verbosity = 0\n\ndef get_model():\n    input_1 = tf.keras.layers.Input((28,28,1))\n    x = tf.keras.layers.Lambda(standardize)(input_1)\n    x = tf.keras.layers.Convolution2D(32,(3,3), activation='relu')(x)\n    x = tf.keras.layers.BatchNormalization(axis=1)(x)\n    x = tf.keras.layers.Convolution2D(32,(3,3), activation='relu')(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.BatchNormalization(axis=1)(x)\n    x = tf.keras.layers.Convolution2D(64,(3,3), activation='relu')(x)\n    x = tf.keras.layers.BatchNormalization(axis=1)(x)\n    x = tf.keras.layers.Convolution2D(64,(3,3), activation='relu')(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(512, activation='relu')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    out = tf.keras.layers.Dense(10, activation='softmax')(x)\n    model = tf.keras.Model(inputs=input_1, outputs=out)\n    model.compile(tf.keras.optimizers.Adam(lr=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# No pseudolabelling baseline"},{"metadata":{"trusted":true},"cell_type":"code","source":"ckp = tf.keras.callbacks.ModelCheckpoint(f'baseline.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=True, mode='max')\nmodel = get_model()\nmodel.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32, verbose=verbosity, callbacks=[ckp])\n\nmodel.load_weights('baseline.hdf5') # load best weights\nno_pseudo_acc = get_test_acc(model)\nprint(f\"No pseudolabelling accuracy: {format(no_pseudo_acc, '.5g')}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Self training\n\nFirst, we train on the labelled data, then produce pseudolabels and finetune on the pseudolabels."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = get_model()\nmodel.load_weights('baseline.hdf5')\n\npseudolabels = model.predict(X_test, verbose=0) # create our pseudolabels\npseudolabels = np.argmax(pseudolabels,axis=1) # convert probabilities into classes\npseudolabels = tf.keras.utils.to_categorical(pseudolabels) \n\nmodel.optimizer.lr = 1e-4 # reduce learning rate since we are finetuning\n\nckp = tf.keras.callbacks.ModelCheckpoint(f'selftrain.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=True, mode='max')\nmodel.fit(X_test, pseudolabels, validation_data=(X_val, y_val), epochs=10, batch_size=32, verbose=verbosity, callbacks=[ckp])\n\nmodel.load_weights('selftrain.hdf5') # load best weights\nself_train_acc = get_test_acc(model)\nprint(f\"Self training accuracy: {format(self_train_acc, '.5g')}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simultaneous training\nFirst, we train on the labelled data, then initialize a new model and train with labelled data and pseudolabels simultaneously."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = get_model()\nmodel.load_weights('baseline.hdf5')\n\npseudolabels = model.predict(X_test, verbose=0) # create our pseudolabels\npseudolabels = np.argmax(pseudolabels,axis=1) # convert probabilities into classes\npseudolabels = tf.keras.utils.to_categorical(pseudolabels) \ny_combined = np.concatenate([pseudolabels, y_train]) # combine our pseudolabels with labelled data\nX_combined = np.concatenate([X_test, X_train]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ckp = tf.keras.callbacks.ModelCheckpoint('simultaneous_train.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=True, mode='max')\n\nmodel = get_model() # reinitialize model\nmodel.fit(X_combined, y_combined, validation_data=(X_val, y_val), epochs=20, batch_size=32, callbacks=[ckp], verbose=verbosity) # train a new model on all data together\n\nmodel.load_weights('simultaneous_train.hdf5') # load best weights\n\nsimultaneous_acc = get_test_acc(model) # get test accuracy\nprint(f\"Simultaneous training accuracy: {format(simultaneous_acc, '.5g')}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pretraining\nFirst, we train on labelled data, then we create pseudolabels. \n\nNext, we initialize a new model and train it on "},{"metadata":{"trusted":true,"_uuid":"78e382d0b3de14312e762edc480b5d215be82269"},"cell_type":"code","source":"model = get_model()\nmodel.load_weights('baseline.hdf5')\n\npseudolabels = model.predict(X_test, verbose=0) # create our pseudolabels\npseudolabels = np.argmax(pseudolabels,axis=1) # convert probabilities into classes\npseudolabels = tf.keras.utils.to_categorical(pseudolabels) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ckp = tf.keras.callbacks.ModelCheckpoint('pretrain.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=True, mode='max')\n\nprint(\"Pretrain on pseudolabels\")\nmodel = get_model() # reinitialize model\nmodel.fit(X_test, pseudolabels, validation_data=(X_val, y_val), epochs=15, batch_size=32, callbacks=[ckp], verbose=verbosity) # first train on pseudolabels only\n\nprint(\"Finetune on labelled data\")\nmodel.optimizer.lr = 1e-4 # reduce learning rate since we are finetuning\nmodel.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32, callbacks=[ckp], verbose=verbosity) # finetune on labelled data\n\nmodel.load_weights('pretrain.hdf5') # load best weights\npretrain_acc = get_test_acc(model) # get test accuracy\nprint(f\"Pretraining accuracy: {pretrain_acc}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nIn my talk, I explained the use cases for various pseudolabelling methods. Even though MNIST is not a particularly complex dataset and it's not very fit for pseudolabelling, we still see an improvement over baseline. MNIST's test set is only about half the size of the train set. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"No pseudolabelling accuracy: {no_pseudo_acc}\")\nprint(f\"Self training accuracy: {self_train_acc}\")\nprint(f\"Simultaneous training accuracy: {simultaneous_acc}\")\nprint(f\"Pretraining accuracy: {pretrain_acc}\")\n\nprint(\"-\"*30)\n\nprint(f\"Percent difference from no pseudolabelling to self training: {100*(self_train_acc-no_pseudo_acc)/no_pseudo_acc}%\")\nprint(f\"Percent difference from self training to simultaneous training: {100*(simultaneous_acc-self_train_acc)/self_train_acc}%\")\nprint(f\"Percent difference from simultaneous training to pretraining: {100*(pretrain_acc-simultaneous_acc)/simultaneous_acc}%\")\n\nprint(\"-\"*30)\n\nprint(f\"Percent difference from no pseudolabelling to pretraining: {100*(pretrain_acc-no_pseudo_acc)/no_pseudo_acc}%\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}