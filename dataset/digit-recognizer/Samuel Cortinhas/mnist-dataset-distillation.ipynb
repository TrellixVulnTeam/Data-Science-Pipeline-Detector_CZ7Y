{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"The purpose of this notebook is to explore the idea of dataset distillation as presented in this [Google AI Blogpost](https://ai.googleblog.com/2021/12/training-machine-learning-models-more.html). We will build a simple CNN and compare its accuracy and training times on:\n1. the whole dataset (support size=33600)\n2. a tiny subset (support size=10)\n3. a tiny distilled subset (support size=10)\n4. a small subset (support size=500)\n5. a small distilled subset (support size=500)\n\nTL;DR A summary of the results are at the end.","metadata":{}},{"cell_type":"markdown","source":"# Libraries","metadata":{"_kg_hide-input":false,"_kg_hide-output":false}},{"cell_type":"code","source":"# Core\nimport numpy as np\nnp.random.seed(0)\nimport pandas as pd\nimport seaborn as sns\nsns.set(style='darkgrid', font_scale=1.4)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport time\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\n# Tensorflow\nimport tensorflow as tf\ntf.random.set_seed(0)\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom keras.utils.vis_utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:42:51.334738Z","iopub.execute_input":"2022-02-14T15:42:51.334975Z","iopub.status.idle":"2022-02-14T15:42:56.828807Z","shell.execute_reply.started":"2022-02-14T15:42:51.334949Z","shell.execute_reply":"2022-02-14T15:42:56.828022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"# Load data\nmnist_data=pd.read_csv('../input/digit-recognizer/train.csv')\n\n# Print shape + head\nprint('Training dataframe dimensions:',mnist_data.shape)\nmnist_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:42:56.830466Z","iopub.execute_input":"2022-02-14T15:42:56.830699Z","iopub.status.idle":"2022-02-14T15:43:00.53368Z","shell.execute_reply.started":"2022-02-14T15:42:56.830666Z","shell.execute_reply":"2022-02-14T15:43:00.533008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preview first few images**","metadata":{}},{"cell_type":"code","source":"# Figure size\nplt.figure(figsize=(9,9))\nplt.suptitle('Training set images', fontsize=20)\n\n# Subplot \nfor i in range(9):\n    img = np.asarray(mnist_data.iloc[i,1:].values.reshape((28,28))/255);\n    ax=plt.subplot(3, 3, i+1)\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.title.set_text(f'{mnist_data.iloc[i,0]}')\n    plt.imshow(img, cmap='gray')\n    \nplt.show()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-14T15:43:00.534853Z","iopub.execute_input":"2022-02-14T15:43:00.535174Z","iopub.status.idle":"2022-02-14T15:43:00.997623Z","shell.execute_reply.started":"2022-02-14T15:43:00.535137Z","shell.execute_reply":"2022-02-14T15:43:00.99692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Label distribution**","metadata":{}},{"cell_type":"code","source":"# Figure size\nplt.figure(figsize=(10,5))\n\n# Countplot\nsns.countplot(x='label', data=mnist_data)\nplt.title('Distribution of digits in dataset')","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-14T15:43:00.999593Z","iopub.execute_input":"2022-02-14T15:43:01.000003Z","iopub.status.idle":"2022-02-14T15:43:01.284685Z","shell.execute_reply.started":"2022-02-14T15:43:00.999965Z","shell.execute_reply":"2022-02-14T15:43:01.284019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution is balanced.","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Labels and features**","metadata":{}},{"cell_type":"code","source":"# Labels\ny=mnist_data.label\n\n# Scale features to be in [0,1]\nX=mnist_data.drop('label', axis=1)/255\n\n# Reshape (-1 means unspecified)\nX = X.values.reshape(-1, 28, 28, 1)\n\n# One-hot encode target\ny=pd.get_dummies(y)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:43:01.286003Z","iopub.execute_input":"2022-02-14T15:43:01.286459Z","iopub.status.idle":"2022-02-14T15:43:01.477262Z","shell.execute_reply.started":"2022-02-14T15:43:01.286422Z","shell.execute_reply":"2022-02-14T15:43:01.47645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train test split**","metadata":{}},{"cell_type":"code","source":"# Create a validation set\nX_train, X_valid, y_train, y_valid = train_test_split(X,y,train_size=0.8, test_size=0.2,\n                                                      stratify=y, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:43:01.478787Z","iopub.execute_input":"2022-02-14T15:43:01.479092Z","iopub.status.idle":"2022-02-14T15:43:02.549407Z","shell.execute_reply.started":"2022-02-14T15:43:01.479043Z","shell.execute_reply":"2022-02-14T15:43:02.548657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# Parameters\nBATCH_SIZE=250\nEPOCHS=50\n\n# Define model\ndef build_model():\n    model = keras.Sequential([\n\n        # Convolutional layer 1\n        layers.Conv2D(filters=64, kernel_size=5, strides=1, padding='same',\n                      input_shape=[28,28,1], activation='relu'),\n        layers.MaxPool2D(pool_size=2, padding='same'),\n        layers.Dropout(rate=0.4),\n\n        # Convolutional layer 2\n        layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same',\n                      activation='relu'),\n        layers.MaxPool2D(pool_size=4, padding='same'),\n        layers.Dropout(rate=0.4),\n        layers.Flatten(),\n\n        # Hidden layer 3\n        layers.Dense(units=256, activation='relu'),\n        layers.Dropout(rate=0.4),\n\n        # Output layer (softmax returns a probability distribution)\n        layers.Dense(units=10, activation='softmax')\n    ])\n\n    # Define optimizer, loss function and accuracy metric\n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    \n    return model","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-14T15:43:02.550622Z","iopub.execute_input":"2022-02-14T15:43:02.55089Z","iopub.status.idle":"2022-02-14T15:43:02.558825Z","shell.execute_reply.started":"2022-02-14T15:43:02.550858Z","shell.execute_reply":"2022-02-14T15:43:02.558151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# Define model\nmodel=build_model()\n\n# Measure training time\nstart=time.time()\n\n# Train model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    verbose=True)\n\nstop=time.time()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-14T15:43:02.559962Z","iopub.execute_input":"2022-02-14T15:43:02.560351Z","iopub.status.idle":"2022-02-14T15:44:16.844274Z","shell.execute_reply.started":"2022-02-14T15:43:02.560316Z","shell.execute_reply":"2022-02-14T15:44:16.843553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Learning curves**","metadata":{}},{"cell_type":"code","source":"# Convert to dataframe\nhistory_df = pd.DataFrame(history.history)\n\n# Subplots\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,4))\n\n# Plot loss metric\nplt.subplot(1,2,1)\nax=history_df.reset_index().loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\", ax=axes[0])\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'])\n\n# Plot accuracy metric\nplt.subplot(1,2,2)\nax=history_df.reset_index().loc[:, ['categorical_accuracy', 'val_categorical_accuracy']].plot(title=\"Accuracy\", ax=axes[1])\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:44:16.845636Z","iopub.execute_input":"2022-02-14T15:44:16.845884Z","iopub.status.idle":"2022-02-14T15:44:17.388752Z","shell.execute_reply.started":"2022-02-14T15:44:16.845849Z","shell.execute_reply":"2022-02-14T15:44:17.388066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluate**","metadata":{}},{"cell_type":"code","source":"# Predictions\npreds=np.argmax(model.predict(X_valid), axis=1)\n\n# Confidence\nconf=np.max(model.predict(X_valid), axis=1)\n\n# Final accuracy and time\nscore1=accuracy_score(np.argmax(y_valid.values, axis=1), preds)\ntime1=np.round(stop-start,1)\nprint(f'Final accuracy on validation set:{np.round(100*score1,1)}%')\nprint(f'Training time: {time1} secs')","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:47:19.655187Z","iopub.execute_input":"2022-02-14T15:47:19.655825Z","iopub.status.idle":"2022-02-14T15:47:20.366625Z","shell.execute_reply.started":"2022-02-14T15:47:19.655789Z","shell.execute_reply":"2022-02-14T15:47:20.365903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot predictions**","metadata":{}},{"cell_type":"code","source":"# Plot some model predictions\nplt.figure(figsize=(15,4))\nplt.suptitle('Model predictions', fontsize=20, y=1.05)\n\n# Subplot\nfor i in range(20):\n    img = X_valid[i];\n    ax=plt.subplot(2, 10, i+1)\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.set_title(f'Pred:{preds[i]} \\n Conf:{np.round(100*conf[i],1)}', fontdict = {'fontsize':14})\n    plt.imshow(img, cmap='gray')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:56:22.450439Z","iopub.execute_input":"2022-02-14T15:56:22.450982Z","iopub.status.idle":"2022-02-14T15:56:23.312878Z","shell.execute_reply.started":"2022-02-14T15:56:22.450946Z","shell.execute_reply":"2022-02-14T15:56:23.312109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset distillation (support size=10)","metadata":{}},{"cell_type":"markdown","source":"The idea is instead of optimising our network, we optimise our dataset - reducing it as much as possible, whilst keeping the key information. The implication is that it could massively reduce training times and hence reduce energy demand/gpu time. \n\nBlog: [https://ai.googleblog.com/2021/12/training-machine-learning-models-more.html](https://ai.googleblog.com/2021/12/training-machine-learning-models-more.html).","metadata":{}},{"cell_type":"markdown","source":"**Baseline**","metadata":{}},{"cell_type":"markdown","source":"We choose 1 sample for each digit. No distilation has occured yet.","metadata":{}},{"cell_type":"code","source":"# Training set with only 1 sample for each digit\nmnist_10=mnist_data.drop_duplicates('label').sort_values('label')\n\n# Plot entire training set\nplt.figure(figsize=(15,6))\nplt.suptitle('Entire training set', fontsize=20, y=1.02)\n\n# Subplot\nfor i in range(10):\n    img = np.asarray(mnist_10.iloc[i,1:].values.reshape((28,28))/255);\n    ax=plt.subplot(2, 5, i+1)\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.title.set_text(f'{mnist_10.iloc[i,0]}')\n    plt.imshow(img, cmap='gray')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:56:40.051325Z","iopub.execute_input":"2022-02-14T15:56:40.052139Z","iopub.status.idle":"2022-02-14T15:56:40.726257Z","shell.execute_reply.started":"2022-02-14T15:56:40.052093Z","shell.execute_reply":"2022-02-14T15:56:40.725609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train model**","metadata":{}},{"cell_type":"code","source":"# Define model\nmodel=build_model()\n\n# Measure training time\nstart=time.time()\n\n# Train model\nhistory = model.fit(\n    mnist_10.iloc[:,1:].values.reshape(-1, 28, 28, 1), pd.get_dummies(mnist_10.label),\n    validation_data=(X_valid, y_valid),\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    verbose=True)\n\nstop = time.time()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-14T15:56:40.730269Z","iopub.execute_input":"2022-02-14T15:56:40.732128Z","iopub.status.idle":"2022-02-14T15:56:49.222754Z","shell.execute_reply.started":"2022-02-14T15:56:40.732091Z","shell.execute_reply":"2022-02-14T15:56:49.221927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Learning curves**","metadata":{}},{"cell_type":"code","source":"# Convert to dataframe\nhistory_df = pd.DataFrame(history.history)\n\n# Subplots\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,4))\n\n# Plot loss metric\nplt.subplot(1,2,1)\nax=history_df.reset_index().loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\", ax=axes[0])\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'])\n\n# Plot accuracy metric\nplt.subplot(1,2,2)\nax=history_df.reset_index().loc[:, ['categorical_accuracy', 'val_categorical_accuracy']].plot(title=\"Accuracy\", ax=axes[1])\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:56:49.227977Z","iopub.execute_input":"2022-02-14T15:56:49.230888Z","iopub.status.idle":"2022-02-14T15:56:49.825672Z","shell.execute_reply.started":"2022-02-14T15:56:49.230848Z","shell.execute_reply":"2022-02-14T15:56:49.824955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluate**","metadata":{}},{"cell_type":"code","source":"# Predictions\npreds=np.argmax(model.predict(X_valid), axis=1)\n\n# Confidence\nconf=np.max(model.predict(X_valid), axis=1)\n\n# Final accuracy and time\nscore2=accuracy_score(np.argmax(y_valid.values, axis=1), preds)\ntime2=np.round(stop-start,1)\nprint(f'Final accuracy on validation set:{np.round(100*score2,1)}%')\nprint(f'Training time: {time2} secs')","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:56:49.826827Z","iopub.execute_input":"2022-02-14T15:56:49.827688Z","iopub.status.idle":"2022-02-14T15:56:50.888367Z","shell.execute_reply.started":"2022-02-14T15:56:49.827644Z","shell.execute_reply":"2022-02-14T15:56:50.887541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot predictions**","metadata":{}},{"cell_type":"code","source":"# Plot some model predictions\nplt.figure(figsize=(15,4))\nplt.suptitle('Model predictions', fontsize=20, y=1.05)\n\n# Subplot\nfor i in range(20):\n    img = X_valid[i];\n    ax=plt.subplot(2, 10, i+1)\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.set_title(f'Pred:{preds[i]} \\n Conf:{np.round(100*conf[i],1)}', fontdict = {'fontsize':14})\n    plt.imshow(img, cmap='gray')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:57:40.117426Z","iopub.execute_input":"2022-02-14T15:57:40.117891Z","iopub.status.idle":"2022-02-14T15:57:40.947352Z","shell.execute_reply.started":"2022-02-14T15:57:40.117857Z","shell.execute_reply":"2022-02-14T15:57:40.946669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Distillation - KIP**","metadata":{}},{"cell_type":"markdown","source":"The code below is based off of the following github repo.\n\nGitHub: [https://github.com/google-research/google-research/tree/master/kip](https://github.com/google-research/google-research/tree/master/kip).","metadata":{}},{"cell_type":"markdown","source":"**Plot distillation**","metadata":{}},{"cell_type":"markdown","source":"These images have been created using an algorithm called KIP (Kernel Inducing Points). Broadly speaking, it works by optimising a loss function arising from Kernel Regression.","metadata":{}},{"cell_type":"code","source":"# Load KIP data (1 image per class)\nwith tf.io.gfile.GFile('gs://kip-datasets/kip/mnist/ConvNet_ssize10_nozca_l_noaug_ckpt78.npz', 'rb') as f:\n    npz = np.load(f)\n\n# Linear projection onto [0,1]\nnpz_normalised=npz['images'].copy()\nfor i in range(10):\n    npz_normalised[i] = (npz['images'][i]-npz['images'][i].min())/(npz['images'][i].max()-npz['images'][i].min())\n\n# Plot entire training set\nplt.figure(figsize=(15,6))\nplt.suptitle('Entire distilled training set', fontsize=20, y=1.02)\n\n# Subplot\nfor i in range(10):\n    img = npz_normalised[i];\n    ax=plt.subplot(2, 5, i+1)\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.title.set_text(f'{i}')\n    plt.imshow(img, cmap='gray')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:58:49.238631Z","iopub.execute_input":"2022-02-14T15:58:49.23889Z","iopub.status.idle":"2022-02-14T15:58:51.074906Z","shell.execute_reply.started":"2022-02-14T15:58:49.238861Z","shell.execute_reply":"2022-02-14T15:58:51.07419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot labels**","metadata":{}},{"cell_type":"markdown","source":"Labels can also be optimised as well as the images to maximise the performance at no extra training cost. ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,5.5))\n\nax1=plt.subplot(1, 2, 1)\nax1.title.set_text('Untrained labels')\nsns.heatmap(pd.get_dummies(np.arange(10)), cmap='magma')\n\nax2=plt.subplot(1, 2, 2)\nax2.title.set_text('Trained labels (unscaled)')\nsns.heatmap(npz['labels'], cmap='magma')","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:58:51.076367Z","iopub.execute_input":"2022-02-14T15:58:51.077205Z","iopub.status.idle":"2022-02-14T15:58:51.732776Z","shell.execute_reply.started":"2022-02-14T15:58:51.077164Z","shell.execute_reply":"2022-02-14T15:58:51.732081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train model**","metadata":{}},{"cell_type":"code","source":"# Define model\nmodel=build_model()\n\n# Measure training time\nstart=time.time()\n\n# Train model\nhistory = model.fit(\n    npz_normalised, pd.get_dummies(np.arange(10)),#npz['labels'],\n    validation_data=(X_valid, y_valid),\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    verbose=True)\n\nstop = time.time()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-14T15:58:52.972288Z","iopub.execute_input":"2022-02-14T15:58:52.972553Z","iopub.status.idle":"2022-02-14T15:59:01.294362Z","shell.execute_reply.started":"2022-02-14T15:58:52.972526Z","shell.execute_reply":"2022-02-14T15:59:01.293678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Learning curves**","metadata":{}},{"cell_type":"code","source":"# Convert to dataframe\nhistory_df = pd.DataFrame(history.history)\n\n# Subplots\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,4))\n\n# Plot loss metric\nplt.subplot(1,2,1)\nax=history_df.reset_index().loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\", ax=axes[0])\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'])\n\n# Plot accuracy metric\nplt.subplot(1,2,2)\nax=history_df.reset_index().loc[:, ['categorical_accuracy', 'val_categorical_accuracy']].plot(title=\"Accuracy\", ax=axes[1])\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:59:01.296062Z","iopub.execute_input":"2022-02-14T15:59:01.29633Z","iopub.status.idle":"2022-02-14T15:59:01.78459Z","shell.execute_reply.started":"2022-02-14T15:59:01.296295Z","shell.execute_reply":"2022-02-14T15:59:01.783915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluation**","metadata":{}},{"cell_type":"code","source":"# Predictions\npreds=np.argmax(model.predict(X_valid), axis=1)\n\n# Confidence\nconf=np.max(model.predict(X_valid), axis=1)\n\n# Final accuracy and time\nscore3=accuracy_score(np.argmax(y_valid.values, axis=1), preds)\ntime3=np.round(stop-start,1)\nprint(f'Final accuracy on validation set:{np.round(100*score3,1)}%')\nprint(f'Training time: {time3} secs')","metadata":{"execution":{"iopub.status.busy":"2022-02-14T15:59:26.486744Z","iopub.execute_input":"2022-02-14T15:59:26.487006Z","iopub.status.idle":"2022-02-14T15:59:27.283663Z","shell.execute_reply.started":"2022-02-14T15:59:26.486979Z","shell.execute_reply":"2022-02-14T15:59:27.282898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot predictions**","metadata":{}},{"cell_type":"code","source":"# Plot some model predictions\nplt.figure(figsize=(15,4))\nplt.suptitle('Model predictions', fontsize=20, y=1.05)\n\n# Subplot\nfor i in range(20):\n    img = X_valid[i];\n    ax=plt.subplot(2, 10, i+1)\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.set_title(f'Pred:{preds[i]} \\n Conf:{np.round(100*conf[i],1)}', fontdict = {'fontsize':14})\n    plt.imshow(img, cmap='gray')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:00:08.774916Z","iopub.execute_input":"2022-02-14T16:00:08.775173Z","iopub.status.idle":"2022-02-14T16:00:10.09172Z","shell.execute_reply.started":"2022-02-14T16:00:08.775146Z","shell.execute_reply":"2022-02-14T16:00:10.091064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset distillation (support size=500)","metadata":{}},{"cell_type":"markdown","source":"This time each of the 10 classes gets 50 training samples. ","metadata":{}},{"cell_type":"markdown","source":"**Baseline**","metadata":{}},{"cell_type":"markdown","source":"No dataset distillation happens here.","metadata":{}},{"cell_type":"code","source":"# Training set with 50 samples for each digit\nmnist_500=pd.DataFrame([])\nfor i in range(10):\n    mnist_label_i=mnist_data[mnist_data.label==i]\n    mnist_500=mnist_500.append(mnist_label_i.iloc[:50,:])\n    \nmnist_500=mnist_500.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:02:55.107129Z","iopub.execute_input":"2022-02-14T16:02:55.107831Z","iopub.status.idle":"2022-02-14T16:02:55.348822Z","shell.execute_reply.started":"2022-02-14T16:02:55.107783Z","shell.execute_reply":"2022-02-14T16:02:55.348096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train model**","metadata":{}},{"cell_type":"code","source":"# Define model\nmodel=build_model()\n\n# Measure training time\nstart=time.time()\n\n# Train model\nhistory = model.fit(\n    mnist_500.iloc[:,1:].values.reshape(-1, 28, 28, 1), pd.get_dummies(mnist_500.label),\n    validation_data=(X_valid, y_valid),\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    verbose=True)\n\nstop = time.time()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-14T16:02:55.798456Z","iopub.execute_input":"2022-02-14T16:02:55.798716Z","iopub.status.idle":"2022-02-14T16:03:04.434242Z","shell.execute_reply.started":"2022-02-14T16:02:55.798688Z","shell.execute_reply":"2022-02-14T16:03:04.433466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Learning curves**","metadata":{}},{"cell_type":"code","source":"# Convert to dataframe\nhistory_df = pd.DataFrame(history.history)\n\n# Subplots\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,4))\n\n# Plot loss metric\nplt.subplot(1,2,1)\nax=history_df.reset_index().loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\", ax=axes[0])\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'])\n\n# Plot accuracy metric\nplt.subplot(1,2,2)\nax=history_df.reset_index().loc[:, ['categorical_accuracy', 'val_categorical_accuracy']].plot(title=\"Accuracy\", ax=axes[1])\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:03:04.437502Z","iopub.execute_input":"2022-02-14T16:03:04.437721Z","iopub.status.idle":"2022-02-14T16:03:04.960775Z","shell.execute_reply.started":"2022-02-14T16:03:04.437696Z","shell.execute_reply":"2022-02-14T16:03:04.960092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluation**","metadata":{}},{"cell_type":"code","source":"# Predictions\npreds=np.argmax(model.predict(X_valid), axis=1)\n\n# Confidence\nconf=np.max(model.predict(X_valid), axis=1)\n\n# Final accuracy and time\nscore4=accuracy_score(np.argmax(y_valid.values, axis=1), preds)\ntime4=np.round(stop-start,1)\nprint(f'Final accuracy on validation set:{np.round(100*score4,1)}%')\nprint(f'Training time: {time4} secs')","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:03:04.96194Z","iopub.execute_input":"2022-02-14T16:03:04.963405Z","iopub.status.idle":"2022-02-14T16:03:06.031696Z","shell.execute_reply.started":"2022-02-14T16:03:04.963366Z","shell.execute_reply":"2022-02-14T16:03:06.030996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot predictions**","metadata":{}},{"cell_type":"code","source":"# Plot some model predictions\nplt.figure(figsize=(15,4))\nplt.suptitle('Model predictions', fontsize=20, y=1.05)\n\n# Subplot\nfor i in range(20):\n    img = X_valid[i];\n    ax=plt.subplot(2, 10, i+1)\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.set_title(f'Pred:{preds[i]} \\n Conf:{np.round(100*conf[i],1)}', fontdict = {'fontsize':14})\n    plt.imshow(img, cmap='gray')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:03:20.441073Z","iopub.execute_input":"2022-02-14T16:03:20.441809Z","iopub.status.idle":"2022-02-14T16:03:21.259759Z","shell.execute_reply.started":"2022-02-14T16:03:20.441771Z","shell.execute_reply":"2022-02-14T16:03:21.259042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Distillation - KIP**","metadata":{}},{"cell_type":"code","source":"# Load KIP data (50 images per class)\nwith tf.io.gfile.GFile('gs://kip-datasets/kip/mnist/ConvNet_ssize500_nozca_l_noaug_ckpt78.npz', 'rb') as f:\n    npz2 = np.load(f)\n\n# Linear projection onto [0,1]\nnpz_normalised2=npz2['images'].copy()\nfor i in range(len(npz_normalised)):\n    npz_normalised2[i] = (npz2['images'][i]-npz2['images'][i].min())/(npz2['images'][i].max()-npz2['images'][i].min())\n    \n# Construct (untrained) labels\nlabels_500=[]\nfor i in range(10):\n    labels_500=np.concatenate([labels_500,i*np.ones(50)])    ","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:03:46.141574Z","iopub.execute_input":"2022-02-14T16:03:46.141855Z","iopub.status.idle":"2022-02-14T16:03:47.395927Z","shell.execute_reply.started":"2022-02-14T16:03:46.141825Z","shell.execute_reply":"2022-02-14T16:03:47.394997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train model**","metadata":{}},{"cell_type":"code","source":"# Define model\nmodel=build_model()\n\n# Measure training time\nstart=time.time()\n\n# Train model\nhistory = model.fit(\n    npz_normalised2, pd.get_dummies(labels_500),\n    validation_data=(X_valid, y_valid),\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    verbose=True)\n\nstop = time.time()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-14T16:03:48.110876Z","iopub.execute_input":"2022-02-14T16:03:48.111424Z","iopub.status.idle":"2022-02-14T16:03:56.87081Z","shell.execute_reply.started":"2022-02-14T16:03:48.111387Z","shell.execute_reply":"2022-02-14T16:03:56.870079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Learning curves**","metadata":{}},{"cell_type":"code","source":"# Convert to dataframe\nhistory_df = pd.DataFrame(history.history)\n\n# Subplots\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,4))\n\n# Plot loss metric\nplt.subplot(1,2,1)\nax=history_df.reset_index().loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\", ax=axes[0])\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'])\n\n# Plot accuracy metric\nplt.subplot(1,2,2)\nax=history_df.reset_index().loc[:, ['categorical_accuracy', 'val_categorical_accuracy']].plot(title=\"Accuracy\", ax=axes[1])\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:03:56.872298Z","iopub.execute_input":"2022-02-14T16:03:56.872561Z","iopub.status.idle":"2022-02-14T16:03:57.388291Z","shell.execute_reply.started":"2022-02-14T16:03:56.872528Z","shell.execute_reply":"2022-02-14T16:03:57.387579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluation**","metadata":{}},{"cell_type":"code","source":"# Predictions\npreds=np.argmax(model.predict(X_valid), axis=1)\n\n# Confidence\nconf=np.max(model.predict(X_valid), axis=1)\n\n# Final accuracy and time\nscore5=accuracy_score(np.argmax(y_valid.values, axis=1), preds)\ntime5=np.round(stop-start,1)\nprint(f'Final accuracy on validation set:{np.round(100*score5,1)}%')\nprint(f'Training time: {time5} secs')","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:04:20.475448Z","iopub.execute_input":"2022-02-14T16:04:20.475707Z","iopub.status.idle":"2022-02-14T16:04:21.22568Z","shell.execute_reply.started":"2022-02-14T16:04:20.47568Z","shell.execute_reply":"2022-02-14T16:04:21.224929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot predictions**","metadata":{}},{"cell_type":"code","source":"# Plot some model predictions\nplt.figure(figsize=(15,4))\nplt.suptitle('Model predictions', fontsize=20, y=1.05)\n\n# Subplot\nfor i in range(20):\n    img = X_valid[i];\n    ax=plt.subplot(2, 10, i+1)\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.set_title(f'Pred:{preds[i]} \\n Conf:{np.round(100*conf[i],1)}', fontdict = {'fontsize':14})\n    plt.imshow(img, cmap='gray')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:04:43.411967Z","iopub.execute_input":"2022-02-14T16:04:43.41222Z","iopub.status.idle":"2022-02-14T16:04:44.786966Z","shell.execute_reply.started":"2022-02-14T16:04:43.412193Z","shell.execute_reply":"2022-02-14T16:04:44.786128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"code","source":"# Summary of results\nssize=[33600, 10, 10, 500, 500]\ndistillation=['No','No','Yes','No','Yes']\nscores=np.round(100*np.array([score1, score2, score3, score4, score5]),1)\ntimes=[time1, time2, time3, time4, time5]\n\n# Dataframe\nresults=pd.DataFrame({'Support size': ssize, 'Distillation': distillation, 'Training time (s)': times, 'Accuracy (%)': scores})\nresults","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:05:54.455478Z","iopub.execute_input":"2022-02-14T16:05:54.455744Z","iopub.status.idle":"2022-02-14T16:05:54.47033Z","shell.execute_reply.started":"2022-02-14T16:05:54.455715Z","shell.execute_reply":"2022-02-14T16:05:54.469388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Distillation managed to **reduce the training time by a factor of 10** whilst retaining a **relatively high accuracy**. \n* The learning curves show distillation helps prevent against overfitting. \n* These results are based on a simple CNN architecture. Higher accuracies can be achieved with the right model - see the [blog](https://ai.googleblog.com/2021/12/training-machine-learning-models-more.html).","metadata":{"execution":{"iopub.status.busy":"2022-02-11T17:50:24.052661Z","iopub.execute_input":"2022-02-11T17:50:24.053506Z","iopub.status.idle":"2022-02-11T17:50:24.058738Z","shell.execute_reply.started":"2022-02-11T17:50:24.053468Z","shell.execute_reply":"2022-02-11T17:50:24.057559Z"}}}]}