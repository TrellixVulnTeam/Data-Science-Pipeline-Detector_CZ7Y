{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"The purpose of this notebook is to build CNN's for digit classification using the famous MNIST dataset. This is one of those classical examples in computer vision that is important in its own right but also incredibly interesting to learn from. Applications of such algorithms include reading bank cheques for example. It is therefore clear why we need to achieve incredibly high accuracy in our algorithms.  ","metadata":{}},{"cell_type":"markdown","source":"# Libraries","metadata":{"_kg_hide-input":false,"_kg_hide-output":false}},{"cell_type":"code","source":"# Core\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set(style='darkgrid', font_scale=1.4)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom keras.utils.vis_utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:42:48.18951Z","iopub.execute_input":"2022-02-13T11:42:48.190135Z","iopub.status.idle":"2022-02-13T11:42:53.900767Z","shell.execute_reply.started":"2022-02-13T11:42:48.190032Z","shell.execute_reply":"2022-02-13T11:42:53.899896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reproducibility**","metadata":{}},{"cell_type":"code","source":"# Random seeds\ndef set_seed(seed=0):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\nset_seed()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:42:53.902724Z","iopub.execute_input":"2022-02-13T11:42:53.903035Z","iopub.status.idle":"2022-02-13T11:42:53.91216Z","shell.execute_reply.started":"2022-02-13T11:42:53.902995Z","shell.execute_reply":"2022-02-13T11:42:53.910063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"# Training data\ntrain_data=pd.read_csv('../input/digit-recognizer/train.csv')\n\n# Test data (scale to be in [0,1])\ntest_data=pd.read_csv('../input/digit-recognizer/test.csv')/255\n\n# Dimensions\nprint('Training dataframe dimensions:',train_data.shape)\nprint('Test dataframe dimensions:',test_data.shape)\n\n# First 5 entries of training data\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:42:53.914119Z","iopub.execute_input":"2022-02-13T11:42:53.914381Z","iopub.status.idle":"2022-02-13T11:42:59.486925Z","shell.execute_reply.started":"2022-02-13T11:42:53.914351Z","shell.execute_reply":"2022-02-13T11:42:59.486127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Check for null values**","metadata":{}},{"cell_type":"code","source":"# Missing values values\nprint('Number of null values in training set:',train_data.isnull().sum().sum())\nprint('')\nprint('Number of null values in test set:',test_data.isnull().sum().sum())","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-13T11:42:59.488228Z","iopub.execute_input":"2022-02-13T11:42:59.488517Z","iopub.status.idle":"2022-02-13T11:42:59.581907Z","shell.execute_reply.started":"2022-02-13T11:42:59.488478Z","shell.execute_reply":"2022-02-13T11:42:59.580972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preview first few images**","metadata":{}},{"cell_type":"code","source":"# Figure size\nplt.figure(figsize=(9,9))\n\n# Subplot \nfor i in range(9):\n    img = np.asarray(train_data.iloc[i+18,1:].values.reshape((28,28))/255);\n    ax=plt.subplot(3, 3, i+1)\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.title.set_text(f'{train_data.iloc[i+18,0]}')\n    plt.imshow(img, cmap='gray')\n    \nplt.show()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-13T11:42:59.584398Z","iopub.execute_input":"2022-02-13T11:42:59.58476Z","iopub.status.idle":"2022-02-13T11:43:00.112679Z","shell.execute_reply.started":"2022-02-13T11:42:59.58472Z","shell.execute_reply":"2022-02-13T11:43:00.11197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Explore label distribution**","metadata":{}},{"cell_type":"code","source":"# Figure size\nplt.figure(figsize=(10,5))\n\n# Countplot\nsns.countplot(x='label', data=train_data)\nplt.title('Distribution of labels in training set')","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-13T11:43:00.11393Z","iopub.execute_input":"2022-02-13T11:43:00.114269Z","iopub.status.idle":"2022-02-13T11:43:00.3991Z","shell.execute_reply.started":"2022-02-13T11:43:00.114227Z","shell.execute_reply":"2022-02-13T11:43:00.39838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Labels and features**","metadata":{}},{"cell_type":"code","source":"# Labels\ny=train_data.label\n\n# Scale features to be in [0,1]\nX=train_data.drop('label', axis=1)/255\n\n# Delete to save memory\ndel train_data","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:43:00.400486Z","iopub.execute_input":"2022-02-13T11:43:00.400931Z","iopub.status.idle":"2022-02-13T11:43:00.59805Z","shell.execute_reply.started":"2022-02-13T11:43:00.400893Z","shell.execute_reply":"2022-02-13T11:43:00.597263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reshape data**","metadata":{}},{"cell_type":"code","source":"# Reshape (-1 means unspecified)\nX = X.values.reshape(-1, 28, 28, 1)\n\n# Save test data index for submission\ntest_index = test_data.index\n\n# Reshape\ntest_data = test_data.values.reshape(-1, 28, 28, 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:43:00.599383Z","iopub.execute_input":"2022-02-13T11:43:00.599649Z","iopub.status.idle":"2022-02-13T11:43:00.606174Z","shell.execute_reply.started":"2022-02-13T11:43:00.599615Z","shell.execute_reply":"2022-02-13T11:43:00.605273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"markdown","source":"Data Augmentation is a clever trick that uses your existing training set to create additional 'fake' data by applying small transformations at every epoch. This doesn't change the size of your training set, it just modifies each image slightly at every epoch so the network becomes for robust over many epochs.","metadata":{}},{"cell_type":"markdown","source":"**Visualise augmentations**","metadata":{}},{"cell_type":"code","source":"# Data Augmentation\ndatagen = ImageDataGenerator(\n    rotation_range = 18,           # 18 degrees\n    zoom_range=0.2,                # 20 %\n    fill_mode='constant',          # edge pixels\n    cval=0                         # fill value\n)\n\naug = datagen.flow(X[42].reshape(-1, 28, 28, 1))\n\n# Plot using a for loop\nfig, axes = plt.subplots(2, 8, figsize = (15, 4))\nplt.suptitle('Random Rotation & Random Zoom', fontsize=20, y=1.05)\naxes = axes.ravel()\n\nfor i in range(16):\n    \n    aug_img = next(aug)[0]\n    axes[i].imshow(aug_img, cmap = 'gray')\n    axes[i].axis('off')\n    \nplt.show()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-13T12:30:02.121075Z","iopub.execute_input":"2022-02-13T12:30:02.121349Z","iopub.status.idle":"2022-02-13T12:30:03.274626Z","shell.execute_reply.started":"2022-02-13T12:30:02.121316Z","shell.execute_reply":"2022-02-13T12:30:03.273908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll actually use keras' preprocessing library instead of ImageDataGenerator. This is because the latter works on a CPU whereas the former works on a GPU so this will be faster.","metadata":{}},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# Define model\ndef build_model():\n    model = keras.Sequential([\n\n        # Data Augmentation\n        preprocessing.RandomRotation(factor=0.05, fill_mode='constant'),     # 18 degrees\n        preprocessing.RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2), fill_mode='constant'),  # 20%\n\n        # Convolutional layer 1\n        layers.Conv2D(filters=64, kernel_size=5, strides=1, padding='same', input_shape=[28,28,1], activation='relu'),\n        layers.MaxPool2D(pool_size=2, padding='same'),\n        layers.Dropout(rate=0.3),\n\n        # Convolutional layer 2\n        layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'),\n        layers.MaxPool2D(pool_size=4, padding='same'),\n        layers.Dropout(rate=0.3),\n        layers.Flatten(),\n\n        # Hidden layer 3\n        layers.Dense(units=256, activation='relu'),\n        layers.Dropout(rate=0.4),\n\n        # Output layer (softmax returns a probability distribution)\n        layers.Dense(units=10, activation='softmax')\n    ])\n\n    # Define optimizer, loss function and accuracy metric\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['sparse_categorical_accuracy'])\n    \n    return model","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-13T11:43:02.296501Z","iopub.execute_input":"2022-02-13T11:43:02.297354Z","iopub.status.idle":"2022-02-13T11:43:02.306575Z","shell.execute_reply.started":"2022-02-13T11:43:02.297304Z","shell.execute_reply":"2022-02-13T11:43:02.305732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Early stopping**","metadata":{}},{"cell_type":"code","source":"# Define early stopping callback on validation loss\nearly_stopping = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=20,\n    restore_best_weights=True,\n)\n\n# Reduce learning rate when validation loss plateaus\nreduce_lr = callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=5\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:43:02.308185Z","iopub.execute_input":"2022-02-13T11:43:02.308466Z","iopub.status.idle":"2022-02-13T11:43:02.315405Z","shell.execute_reply.started":"2022-02-13T11:43:02.308427Z","shell.execute_reply":"2022-02-13T11:43:02.314711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross validation","metadata":{}},{"cell_type":"code","source":"FOLDS = 10\nEPOCHS = 200\nBATCH_SIZE = 500\n\ntest_preds = np.zeros((1, 1))\nscores = []\ntimes = []\nhistory_df = pd.DataFrame()\n\ncv = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=0)\n\nfor fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n    # Start timer\n    start = time.time()\n    \n    # get training and validation sets\n    X_train, X_valid = X[train_idx], X[val_idx]\n    y_train, y_valid = y[train_idx], y[val_idx]\n\n    # Build and train model\n    model = build_model()\n    fold_history = model.fit(\n        X_train,\n        y_train,\n        validation_data=(X_valid, y_valid),\n        epochs=EPOCHS,\n        batch_size=BATCH_SIZE,\n        #callbacks=[early_stopping, reduce_lr],\n        verbose=False\n    )\n    \n    history_df = history_df.append(pd.DataFrame(fold_history.history))\n    \n    # Make predictions and measure accuracy\n    y_pred = np.argmax(model.predict(X_valid), axis=1)\n    score = accuracy_score(y_valid, y_pred)\n    scores.append(score)\n    \n    # Store predictions\n    test_preds = test_preds + model.predict(test_data)\n    \n    # Stop timer\n    stop = time.time()\n    times.append((stop - start)/60)\n    \n    # Print accuracy and time\n    print(f'Fold {fold} - Accuracy: {score}, Time: {round((stop - start)/60,1)} mins')\n    \nprint('')\nprint(f'Mean Accuracy: {np.mean(scores)}')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-13T11:43:02.316942Z","iopub.execute_input":"2022-02-13T11:43:02.317422Z","iopub.status.idle":"2022-02-13T11:45:04.899584Z","shell.execute_reply.started":"2022-02-13T11:43:02.317383Z","shell.execute_reply":"2022-02-13T11:45:04.898832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot fold accuracy**","metadata":{}},{"cell_type":"code","source":"# Figure size\nplt.figure(figsize=(10,5))\n\n# Line plot\nplt.plot(scores, label='scores')\nplt.plot(np.mean(scores)*np.ones(len(scores)), c='black', label='mean')\n\n# Aesthetics\nplt.title('Fold accuracy')\nplt.xlabel('Fold')\nplt.ylabel('Accuracy')\nplt.ylim([0.99,1])\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:45:04.901188Z","iopub.execute_input":"2022-02-13T11:45:04.901691Z","iopub.status.idle":"2022-02-13T11:45:05.18298Z","shell.execute_reply.started":"2022-02-13T11:45:04.901637Z","shell.execute_reply":"2022-02-13T11:45:05.182246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot fold time**","metadata":{}},{"cell_type":"code","source":"# Figure size\nplt.figure(figsize=(10,5))\n\n# Line plot\nplt.plot(times, label='times', c='orange')\nplt.plot(np.mean(times)*np.ones(len(times)), c='black', label='mean')\n\n# Aesthetics\nplt.title('Fold time')\nplt.xlabel('Fold')\nplt.ylabel('Time (mins)')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:45:05.185507Z","iopub.execute_input":"2022-02-13T11:45:05.185732Z","iopub.status.idle":"2022-02-13T11:45:05.621087Z","shell.execute_reply.started":"2022-02-13T11:45:05.185704Z","shell.execute_reply":"2022-02-13T11:45:05.620253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot learning curves**","metadata":{}},{"cell_type":"code","source":"for i in range(FOLDS):\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,4))\n    plt.suptitle('Fold '+str(i+1), fontsize=20)\n    \n    plt.subplot(1,2,1)\n    ax=history_df.reset_index().loc[EPOCHS*i+1:EPOCHS*(i+1)-1, ['loss', 'val_loss']].plot(title=\"Cross-entropy\", ax=axes[0])\n    plt.xlabel('Epoch')\n    \n    plt.subplot(1,2,2)\n    ax=history_df.reset_index().loc[EPOCHS*i+1:EPOCHS*(i+1)-1, ['sparse_categorical_accuracy', 'val_sparse_categorical_accuracy']].plot(title=\"Accuracy\", ax=axes[1])\n    plt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:45:05.625434Z","iopub.execute_input":"2022-02-13T11:45:05.627391Z","iopub.status.idle":"2022-02-13T11:45:11.242801Z","shell.execute_reply.started":"2022-02-13T11:45:05.62735Z","shell.execute_reply":"2022-02-13T11:45:11.24212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Soft voting**","metadata":{}},{"cell_type":"code","source":"# Soft voting to ensemble predictions\ntest_preds = np.argmax(test_preds, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:45:11.245659Z","iopub.execute_input":"2022-02-13T11:45:11.24635Z","iopub.status.idle":"2022-02-13T11:45:11.251369Z","shell.execute_reply.started":"2022-02-13T11:45:11.246308Z","shell.execute_reply":"2022-02-13T11:45:11.250495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot predictions**","metadata":{}},{"cell_type":"code","source":"# Plot some model predictions\nplt.figure(figsize=(15,3.5))\nplt.suptitle('Model predictions', fontsize=20, y=1.05)\n\n# Subplot\nfor i in range(20):\n    img = test_data[i];\n    ax=plt.subplot(2, 10, i+1)\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.title.set_text(f'Pred:{test_preds[i]}')\n    plt.imshow(img, cmap='gray')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:45:11.252682Z","iopub.execute_input":"2022-02-13T11:45:11.253177Z","iopub.status.idle":"2022-02-13T11:45:12.449497Z","shell.execute_reply.started":"2022-02-13T11:45:11.253138Z","shell.execute_reply":"2022-02-13T11:45:12.448756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# Save predictions to file\noutput = pd.DataFrame({'ImageId': test_index+1,\n                       'Label': test_preds})\n\n# Check format\noutput.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:45:12.4505Z","iopub.execute_input":"2022-02-13T11:45:12.450755Z","iopub.status.idle":"2022-02-13T11:45:12.463122Z","shell.execute_reply.started":"2022-02-13T11:45:12.450723Z","shell.execute_reply":"2022-02-13T11:45:12.462333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T11:45:12.465378Z","iopub.execute_input":"2022-02-13T11:45:12.465588Z","iopub.status.idle":"2022-02-13T11:45:12.51786Z","shell.execute_reply.started":"2022-02-13T11:45:12.465563Z","shell.execute_reply":"2022-02-13T11:45:12.517087Z"},"trusted":true},"execution_count":null,"outputs":[]}]}