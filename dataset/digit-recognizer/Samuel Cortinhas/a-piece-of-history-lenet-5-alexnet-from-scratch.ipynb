{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"In this notebook we will **motivate** and **implement from scratch** two **Convolutional Neural Networks (CNNs)** that had big impacts on the field of Deep Learning. Namely, we will look at **LeNet-5** (Yann LeCunn et al., 1989), which is considered one of the first CNNs ever and also **AlexNet** (Alex Krizhevsky et al., 2012), which won the 2012 ImageNet competition by an impressive marging and introduced many techniques that are considered **state of the art** even today (e.g. dropout, maxpooling, relu, etc). \n\nThese networks offer a glimpse into the history of computer vision, including the **early trends** and **challenges**. Limited computational resources in particular have led to the **rapid innovation** we've seen in the last few decades. ","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:22:27.100707Z","iopub.execute_input":"2022-06-07T15:22:27.101332Z","iopub.status.idle":"2022-06-07T15:22:27.137762Z","shell.execute_reply.started":"2022-06-07T15:22:27.101206Z","shell.execute_reply":"2022-06-07T15:22:27.136208Z"}}},{"cell_type":"markdown","source":"### Architectures","metadata":{}},{"cell_type":"markdown","source":"<center>\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/960px-Comparison_image_neural_networks.svg.png\" width=\"520\" height=\"520\">\n</center>","metadata":{}},{"cell_type":"markdown","source":"By todays standards these models are relatively **simplistic**, being only 5 or 8 layers deep. In comparison, many high end CNNs nowadays have **over 100 layers**. To understand these models we need to understand what each layer does.","metadata":{}},{"cell_type":"markdown","source":"# CNN layers","metadata":{}},{"cell_type":"markdown","source":"### Convolutional layer","metadata":{}},{"cell_type":"markdown","source":"<center>\n<img src=\"https://www.researchgate.net/profile/Hiromu-Yakura/publication/323792694/figure/fig1/AS:615019968475136@1523643595196/Outline-of-the-convolutional-layer.png\" width=\"220\" height=\"220\">\n</center>","metadata":{}},{"cell_type":"markdown","source":"Convolutional layers are the main **building blocks** of CNNs. They work by taking the **dot product** with a set of **filters** and a **sliding window** of the input image. The result is a set of local **features**, like edges and constrast, that can be helpful in describing the images. The learnable parameters are only the **weights** contained in the filters and due to their small size, these layers can be implemented quite **effeciently**. ","metadata":{}},{"cell_type":"markdown","source":"### Pooling layer","metadata":{}},{"cell_type":"markdown","source":"<center>\n<img src=\"https://www.researchgate.net/profile/Imran-Ali-12/publication/340812216/figure/fig4/AS:928590380138496@1598404607456/Pooling-layer-operation-oproaches-1-Pooling-layers-For-the-function-of-decreasing-the.png\" width=\"280\" height=\"280\">\n</center>","metadata":{}},{"cell_type":"markdown","source":"The primary function of the pooling layer is to **downsample** the image sizes, e.g. from 64x64 to 32x32. It works by partitioning the image into squares and applying a **non-linear transformation** over thoses squares. The most common types of pooling are **average pooling**, where the average is taken of each square, and **max pooling**, where the maximum is taken of each square.","metadata":{}},{"cell_type":"markdown","source":"### Activation layer","metadata":{}},{"cell_type":"markdown","source":"<center>\n<img src=\"https://www.researchgate.net/profile/Junxi-Feng/publication/335845675/figure/fig3/AS:804124836765699@1568729709680/Commonly-used-activation-functions-a-Sigmoid-b-Tanh-c-ReLU-and-d-LReLU.ppm\" width=\"520\" height=\"520\">\n</center>","metadata":{}},{"cell_type":"markdown","source":"This can be considered either part of the previous layer or as a layer of its own. Activation functions apply a **non-linear transformation** to the previous later, which enable the model to **learn more complex relationships**. Common activation functions are the **Rectified Linear Unit (ReLU)**, hyperbolic tan (tanh) and sigmoid. For the final layer, **softmax** can be used to produce predicted class probabilities.","metadata":{}},{"cell_type":"markdown","source":"### Dense layer","metadata":{}},{"cell_type":"markdown","source":"<center>\n<img src=\"https://www.researchgate.net/profile/Alex-Kost-2/publication/336607800/figure/fig4/AS:814973764767744@1571316295028/Visualization-of-a-fully-connected-layer-Taken-from-Hollemans-72.ppm\" width=\"220\" height=\"220\">\n</center>","metadata":{}},{"cell_type":"markdown","source":"Dense or **fully connected** layers are the standard layers in a neural network, where every neuron in the previous layer is connected to the current layer through weights and biases. ","metadata":{}},{"cell_type":"markdown","source":"### Dropout","metadata":{}},{"cell_type":"markdown","source":"<center>\n<img src=\"https://miro.medium.com/max/1044/1*iWQzxhVlvadk6VAJjsgXgg.png\" width=\"420\" height=\"420\">\n</center>","metadata":{}},{"cell_type":"markdown","source":"Dropout is a clever way to **prevent** your model from **overfitting** the training data by **randomly 'turning off'** each neuron **independently** with some probability p. The result is that the model cannot rely on any particular neuron and instead has to make predictions using several different neurons. ","metadata":{}},{"cell_type":"markdown","source":"**Putting the pieces together**","metadata":{}},{"cell_type":"markdown","source":"Now that we understand all the different components of a CNN, let's code it up from scratch. We will use the **keras sequential model** as this is probably the **easiest** way to do it.","metadata":{}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"# Core\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style='darkgrid', font_scale=1.4)\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport gc\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom keras.utils.vis_utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2022-06-07T19:58:48.977752Z","iopub.execute_input":"2022-06-07T19:58:48.978153Z","iopub.status.idle":"2022-06-07T19:58:56.421766Z","shell.execute_reply.started":"2022-06-07T19:58:48.97812Z","shell.execute_reply":"2022-06-07T19:58:56.420728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reproducibility**","metadata":{}},{"cell_type":"code","source":"# Set random seeds\ndef set_seed(seed=0):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\nset_seed()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T19:58:56.423447Z","iopub.execute_input":"2022-06-07T19:58:56.424107Z","iopub.status.idle":"2022-06-07T19:58:56.429998Z","shell.execute_reply.started":"2022-06-07T19:58:56.424072Z","shell.execute_reply":"2022-06-07T19:58:56.429169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LeNet-5 ","metadata":{}},{"cell_type":"markdown","source":"[LeNet-5](https://en.wikipedia.org/wiki/LeNet) is a 5 layer CNN made up of **2 convolutional layers** with average pooling followed by **3 fully connected layers**. \n\n*Notes:*\n\n* It is interesting to note that at the time the perfered **activation functions** were all smooth (e.g. sigmoid, tanh, etc). It was not until later (~2010) that ReLU took over as the prefered activation function we see today. \n\n* Furthermore, **average pooling** wasn't used for any significant reason other than to reduce the size of the network to be able to train it in a reasonable time. **Maxpooling** was quickly found to produce better results and provide additional properties like translation invariance. \n\n* Finally, observe the pattern that as you go **deeper** into the network, the **image sizes** tend to **shrink** and the number of **channels**/filters tends to **increase**. This pattern is still favoured today. \n\nWe will code it using a keras sequential model for the task of handwritten **digit recognition** via the MNIST dataset as it was originally designed for. ","metadata":{}},{"cell_type":"code","source":"# 5 layer CNN\ndef build_LeNet5(input_shape=(28,28,1)):\n    # Sequential model\n    model = keras.Sequential([\n\n    # Input shape\n    keras.Input(shape=input_shape),    # shape=(28,28,1)\n    \n    # Layer 1\n    layers.Conv2D(filters=6, kernel_size=(5,5), padding='same', activation='sigmoid'),          # shape=(28,28,6)\n    layers.AveragePooling2D(pool_size=(2,2), strides=(2,2), padding='valid'),                   # shape=(14,14,6)\n    \n    # Layer 2\n    layers.Conv2D(filters=16, kernel_size=(5,5), padding='valid', activation='sigmoid'),        # shape=(10,10,16)\n    layers.AveragePooling2D(pool_size=(2,2), strides=(2,2), padding=\"valid\"),                   # shape=(5,5,16)\n    \n    # Layer 3\n    layers.Flatten(),                                    # shape=(400,1)\n    layers.Dense(units=120, activation='sigmoid'),       # shape=(120,1)\n    \n    # Layer 4\n    layers.Dense(units=84, activation='sigmoid'),        # shape=(84,1)\n    \n    # Layer 5\n    layers.Dense(units=10, activation='softmax')         # shape=(10,1)\n    ])\n    \n    # Compile model (SGD = stochastic gradient descent)\n    model.compile(optimizer='SGD',\n                  loss='categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-07T19:58:58.518469Z","iopub.execute_input":"2022-06-07T19:58:58.51904Z","iopub.status.idle":"2022-06-07T19:58:58.528209Z","shell.execute_reply.started":"2022-06-07T19:58:58.519002Z","shell.execute_reply":"2022-06-07T19:58:58.527525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model summary\nmodel=build_LeNet5()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T19:59:57.863094Z","iopub.execute_input":"2022-06-07T19:59:57.863509Z","iopub.status.idle":"2022-06-07T19:59:57.931267Z","shell.execute_reply.started":"2022-06-07T19:59:57.863457Z","shell.execute_reply":"2022-06-07T19:59:57.930017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AlexNet","metadata":{}},{"cell_type":"markdown","source":"[AlexNet](https://en.wikipedia.org/wiki/AlexNet) provided a breakthrough moment in Deep Learning by showing the world the power of CNNs. After Alex won the ImageNet competition he presented his work to leading researches at a conference and wrote what some call the **most influential** [paper](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) in the field of computer vision, which so far has **over 100,000 citations**. \n\n*Notes:*\n\n* Many **improvements** have been made compared to LeNet-5. **ReLU** is the activation used, which makes training much faster. **Maxpooling** is being used instead of average pooling. And **dropout** has been introduced, a type of regularisation which allows the model to go deeper without overfitting.\n* We still observe the pattern that as you go **deeper** the **image sizes decrease** and the number of **channels increase**. \n\nThe original AlexNet was trained to classify images to one of **1000 classes**. For this demonstration we will restrict the problem to **CIFAR-10**, i.e. where there are only **10 classes**, so that training doesn't take too long. ","metadata":{}},{"cell_type":"code","source":"# 8 layer CNN\ndef build_AlexNet(input_shape=(224,224,3)):\n    # Sequential model\n    model = keras.Sequential([\n\n    # Input shape\n    keras.Input(shape=input_shape),    # shape=(224,224,3)\n    \n    # Layer 1\n    layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),          # shape=(54,54,96)\n    layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),                       # shape=(26,26,96)\n    \n    # Layer 2\n    layers.Conv2D(filters=256, kernel_size=(5,5), padding='same', activation='relu'),        # shape=(26,26,256)\n    layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding=\"valid\"),                    # shape=(12,12,256)\n    \n    # Layer 3\n    layers.Conv2D(filters=384, kernel_size=(3,3), padding='same', activation='relu'),        # shape=(12,12,384)\n        \n    # Layer 4\n    layers.Conv2D(filters=384, kernel_size=(3,3), padding='same', activation='relu'),        # shape=(12,12,384)\n        \n    # Layer 5\n    layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'),        # shape=(12,12,256)\n    layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding=\"valid\"),                    # shape=(5,5,256)\n        \n    # Layer 6\n    layers.Flatten(),                                     # shape=(6400,1)\n    layers.Dense(units=4096, activation='relu'),          # shape=(4096,1)\n    layers.Dropout(rate=0.5),\n    \n    # Layer 7\n    layers.Dense(units=4096, activation='relu'),          # shape=(4096,1)\n    layers.Dropout(rate=0.5),\n    \n    # Layer 8\n    layers.Dense(units=10, activation='softmax')        # shape=(10,1) --> original was (1000,1)\n    ])\n    \n    # Compile model (SGD = stochastic gradient descent)\n    model.compile(optimizer='SGD',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['sparse_categorical_accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-07T20:00:16.731339Z","iopub.execute_input":"2022-06-07T20:00:16.731736Z","iopub.status.idle":"2022-06-07T20:00:16.746316Z","shell.execute_reply.started":"2022-06-07T20:00:16.731704Z","shell.execute_reply":"2022-06-07T20:00:16.745374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model summary\nmodel=build_AlexNet()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T20:00:17.147337Z","iopub.execute_input":"2022-06-07T20:00:17.148301Z","iopub.status.idle":"2022-06-07T20:00:17.629544Z","shell.execute_reply.started":"2022-06-07T20:00:17.148262Z","shell.execute_reply":"2022-06-07T20:00:17.628511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MNIST","metadata":{}},{"cell_type":"markdown","source":"MNIST is a **database** of 10's of thousands of **handwritten digits**. It is also **historic** because it was created in 1998, a time where obtaining large labelled datasets for **supervised learning** was very **difficult**. It is sometimes described as the **Titinic** dataset of **computer vision**. ","metadata":{}},{"cell_type":"code","source":"# Training data\nmnist_train=pd.read_csv('../input/digit-recognizer/train.csv')\n\n# Test data (scale to be in [0,1])\nmnist_test=pd.read_csv('../input/digit-recognizer/test.csv')/255\n\n# Dimensions\nprint('Training dataframe dimensions:', mnist_train.shape)\nprint('Test dataframe dimensions:', mnist_test.shape)\n\n# First 5 entries of training data\nmnist_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:40:34.973821Z","iopub.execute_input":"2022-06-07T15:40:34.974418Z","iopub.status.idle":"2022-06-07T15:40:40.047215Z","shell.execute_reply.started":"2022-06-07T15:40:34.974383Z","shell.execute_reply":"2022-06-07T15:40:40.046412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preview first few images**","metadata":{}},{"cell_type":"code","source":"# Figure size\nplt.figure(figsize=(9,9))\n\n# Subplot \nfor i in range(9):\n    img = np.asarray(mnist_train.iloc[i+18,1:].values.reshape((28,28))/255);\n    ax=plt.subplot(3, 3, i+1)\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.title.set_text(f'{mnist_train.iloc[i+18,0]}')\n    plt.imshow(img, cmap='gray')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:40:40.048462Z","iopub.execute_input":"2022-06-07T15:40:40.049066Z","iopub.status.idle":"2022-06-07T15:40:40.369404Z","shell.execute_reply.started":"2022-06-07T15:40:40.049028Z","shell.execute_reply":"2022-06-07T15:40:40.368486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Labels and features**","metadata":{}},{"cell_type":"code","source":"# Labels\ny=mnist_train.label\n\n# One-hot encoding of labels\ny=pd.get_dummies(y)\n\n# Scale features to be in [0,1]\nX=mnist_train.drop('label', axis=1)/255\n\n# Delete to save memory\ndel mnist_train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:40:40.370821Z","iopub.execute_input":"2022-06-07T15:40:40.371176Z","iopub.status.idle":"2022-06-07T15:40:40.740725Z","shell.execute_reply.started":"2022-06-07T15:40:40.371124Z","shell.execute_reply":"2022-06-07T15:40:40.739974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Split data**","metadata":{}},{"cell_type":"code","source":"# Train-valid split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:40:40.741946Z","iopub.execute_input":"2022-06-07T15:40:40.742477Z","iopub.status.idle":"2022-06-07T15:40:40.965406Z","shell.execute_reply.started":"2022-06-07T15:40:40.742439Z","shell.execute_reply":"2022-06-07T15:40:40.964589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reshape data**","metadata":{}},{"cell_type":"code","source":"# Reshape (-1 means unspecified)\nX = X.values.reshape(-1, 28, 28, 1)\n\n# Reshape\nmnist_test = mnist_test.values.reshape(-1, 28, 28, 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:40:40.96679Z","iopub.execute_input":"2022-06-07T15:40:40.96718Z","iopub.status.idle":"2022-06-07T15:40:40.972031Z","shell.execute_reply.started":"2022-06-07T15:40:40.967144Z","shell.execute_reply":"2022-06-07T15:40:40.97112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Split data**","metadata":{}},{"cell_type":"code","source":"# Train-valid split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:40:40.974644Z","iopub.execute_input":"2022-06-07T15:40:40.975012Z","iopub.status.idle":"2022-06-07T15:40:41.356865Z","shell.execute_reply.started":"2022-06-07T15:40:40.974975Z","shell.execute_reply":"2022-06-07T15:40:41.356072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train model**","metadata":{}},{"cell_type":"code","source":"# Build model\nmodel = build_LeNet5()\n\n# Early stopping\nearly_stopping = keras.callbacks.EarlyStopping(\n    patience=10,\n    min_delta=0.0001,\n    restore_best_weights=True,\n)\n\n# Train model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=32,\n    epochs=200,\n    callbacks=[early_stopping],\n    verbose=True\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-07T15:40:41.358207Z","iopub.execute_input":"2022-06-07T15:40:41.358541Z","iopub.status.idle":"2022-06-07T15:52:06.765172Z","shell.execute_reply.started":"2022-06-07T15:40:41.358505Z","shell.execute_reply":"2022-06-07T15:52:06.764316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Learning curves**","metadata":{}},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\nhistory_df.loc[:, ['categorical_accuracy', 'val_categorical_accuracy']].plot(title=\"Accuracy\")\n\nprint('Final accuracy on validation set:', history_df.loc[len(history_df)-1,'val_categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:52:06.766597Z","iopub.execute_input":"2022-06-07T15:52:06.76704Z","iopub.status.idle":"2022-06-07T15:52:07.166384Z","shell.execute_reply.started":"2022-06-07T15:52:06.767004Z","shell.execute_reply":"2022-06-07T15:52:07.165518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notice how the train and valid metrics are basically on top of each other. This means the model is **generalising very well** whilst achieving **high accuracy**. This is an example of a model with **low bias** and **low variance** - impressive! ","metadata":{}},{"cell_type":"markdown","source":"**Test set predictions**","metadata":{}},{"cell_type":"code","source":"# Predictions\npreds = model.predict(mnist_test)\n\n# Confidence\nconf = np.max(preds, axis=1)\n\n# Retrieve most likely classes\npred_classes = np.argmax(preds, axis=1)\n\n# Plot some model predictions\nplt.figure(figsize=(15,4))\nplt.suptitle('Model predictions', fontsize=20, y=1.05)\n\n# Subplot\nfor i in range(20):\n    img = mnist_test[i].reshape((28,28))/255;\n    ax=plt.subplot(2, 10, i+1)\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.set_title(f'Pred:{pred_classes[i]} \\n Conf:{np.round(100*conf[i],1)}', fontdict = {'fontsize':14})\n    plt.imshow(img, cmap='gray')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:52:07.16769Z","iopub.execute_input":"2022-06-07T15:52:07.168117Z","iopub.status.idle":"2022-06-07T15:52:09.358428Z","shell.execute_reply.started":"2022-06-07T15:52:07.168079Z","shell.execute_reply":"2022-06-07T15:52:09.357526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Clear memory**","metadata":{}},{"cell_type":"code","source":"# Clear memory\ndel mnist_test, X, y, X_train, X_valid, y_train, y_valid, model, history, history_df, preds, conf, pred_classes\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:54:57.871573Z","iopub.execute_input":"2022-06-07T15:54:57.872092Z","iopub.status.idle":"2022-06-07T15:54:58.082752Z","shell.execute_reply.started":"2022-06-07T15:54:57.872049Z","shell.execute_reply":"2022-06-07T15:54:58.081976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CIFAR-10","metadata":{}},{"cell_type":"markdown","source":"CIFAR-10 is a **large dataset** of thousands of **32x32 colour images** in **10 different classes**. It is often used as a **benchmark** for scientific research in computer vision.","metadata":{}},{"cell_type":"code","source":"# Load dataset\n(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n\n# Define the 10 class names\nclass_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:55:06.112441Z","iopub.execute_input":"2022-06-07T15:55:06.112792Z","iopub.status.idle":"2022-06-07T15:55:12.367744Z","shell.execute_reply.started":"2022-06-07T15:55:06.112763Z","shell.execute_reply":"2022-06-07T15:55:12.366815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Scale pixels**","metadata":{}},{"cell_type":"code","source":"# Scale to lie in [0,1]\nX_train = X_train / 255\nX_test = X_test / 255","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:55:13.970402Z","iopub.execute_input":"2022-06-07T15:55:13.971219Z","iopub.status.idle":"2022-06-07T15:55:14.477032Z","shell.execute_reply.started":"2022-06-07T15:55:13.971175Z","shell.execute_reply":"2022-06-07T15:55:14.476145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Split data**","metadata":{}},{"cell_type":"code","source":"# Train-valid split (subset to speed up training)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, stratify=y_train, train_size=0.16, test_size=0.04, random_state=0)\n\n# Reduce test set (10%)\nX_test = X_test[:1000]\ny_test = y_test[:1000]\n\n# Print shape\nprint('X_train shape', X_train.shape)\nprint('X_valid shape', X_valid.shape)\nprint('X_test shape', X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:55:19.11903Z","iopub.execute_input":"2022-06-07T15:55:19.119791Z","iopub.status.idle":"2022-06-07T15:55:19.541843Z","shell.execute_reply.started":"2022-06-07T15:55:19.119743Z","shell.execute_reply":"2022-06-07T15:55:19.541005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use tf dataset API\ntrain_ds=tf.data.Dataset.from_tensor_slices((X_train, y_train))\nvalid_ds=tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\ntest_ds=tf.data.Dataset.from_tensor_slices((X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:55:24.026774Z","iopub.execute_input":"2022-06-07T15:55:24.027145Z","iopub.status.idle":"2022-06-07T15:55:24.331694Z","shell.execute_reply.started":"2022-06-07T15:55:24.027099Z","shell.execute_reply":"2022-06-07T15:55:24.330876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preview first few images**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(30,15))\nfor i,(image,label) in enumerate(train_ds.take(18)):\n    ax=plt.subplot(3,6,i+1)\n    plt.imshow(image)\n    plt.title(class_names[label.numpy()[0]], fontsize=24)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:55:28.88939Z","iopub.execute_input":"2022-06-07T15:55:28.889848Z","iopub.status.idle":"2022-06-07T15:55:31.165227Z","shell.execute_reply.started":"2022-06-07T15:55:28.889804Z","shell.execute_reply":"2022-06-07T15:55:31.164015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data pipeline**","metadata":{}},{"cell_type":"code","source":"# Resize images\ndef resize_image(image, label):\n    image=tf.image.resize(image, (224,224))  # upscale to work with AlexNet\n    return image, label\n\n# Apply transformations\ntrain_ds=(train_ds.map(resize_image)\n          .shuffle(buffer_size = 8000)\n          .batch(batch_size=32,drop_remainder=True)\n          )\n\nvalid_ds=(valid_ds.map(resize_image)\n          #.shuffle(buffer_size = 2000)\n          .batch(batch_size=32,drop_remainder=True)\n          )\n\ntest_ds=(test_ds.map(resize_image)\n         #.shuffle(buffer_size = 1000)\n         .batch(batch_size=32,drop_remainder=True)\n         )","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:55:39.439605Z","iopub.execute_input":"2022-06-07T15:55:39.439952Z","iopub.status.idle":"2022-06-07T15:55:39.510524Z","shell.execute_reply.started":"2022-06-07T15:55:39.439919Z","shell.execute_reply":"2022-06-07T15:55:39.50978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train model**","metadata":{}},{"cell_type":"code","source":"# Build model\nmodel = build_AlexNet()\n\n# Early stopping\nearly_stopping = keras.callbacks.EarlyStopping(\n    patience=5,\n    min_delta=0.0001,\n    restore_best_weights=True,\n)\n\n# Train model\nhistory = model.fit(\n    train_ds,\n    validation_data=valid_ds,\n    epochs=100,\n    #callbacks=[early_stopping],\n    verbose=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:55:49.226149Z","iopub.execute_input":"2022-06-07T15:55:49.226913Z","iopub.status.idle":"2022-06-07T15:56:24.481125Z","shell.execute_reply.started":"2022-06-07T15:55:49.226871Z","shell.execute_reply":"2022-06-07T15:56:24.480323Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Learning curves**","metadata":{}},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\nhistory_df.loc[:, ['sparse_categorical_accuracy', 'val_sparse_categorical_accuracy']].plot(title=\"Accuracy\")\n\nprint('Final accuracy on validation set:', history_df.loc[len(history_df)-1,'val_sparse_categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-06-07T15:56:24.482688Z","iopub.execute_input":"2022-06-07T15:56:24.4835Z","iopub.status.idle":"2022-06-07T15:56:24.875767Z","shell.execute_reply.started":"2022-06-07T15:56:24.483464Z","shell.execute_reply":"2022-06-07T15:56:24.874993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This time we can see some **overfitting** occuring. This is likely because the model has many **learnable parameters** (~50 million!) and **little regularisation**. That being said the performance is still quite good considering CIFAR-10 is a challenging dataset to well on. \n\nA simple **improvement** would be to use **data augmentation** to artificially 'create' more training data. This usually helps a model generalise better to unseen data.","metadata":{}},{"cell_type":"markdown","source":"**Test set predictions**","metadata":{}},{"cell_type":"code","source":"# Predictions\npreds = model.predict(test_ds)\n\n# Confidence\nconf = np.max(preds, axis=1)\n\n# Retrieve most likely classes\npred_classes = np.argmax(preds, axis=1)\npred_names = []\nfor index, i in enumerate(pred_classes):\n    pred_names.append(class_names[i])\n\n# Plot some model predictions\nplt.figure(figsize=(30,18))\nplt.suptitle('Model predictions', fontsize=40, y=1.05)\n\n# Subplot\nfor i,(image,label) in enumerate(test_ds.take(1)):\n    for j in range(18):\n        ax=plt.subplot(3,6,j+1)\n        plt.imshow(image[j])\n        plt.title(f'Pred:{pred_names[j]} \\n Conf:{np.round(100*conf[j],1)}', fontsize=24)\n        plt.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T16:01:54.186351Z","iopub.execute_input":"2022-06-07T16:01:54.186709Z","iopub.status.idle":"2022-06-07T16:01:57.232094Z","shell.execute_reply.started":"2022-06-07T16:01:54.18668Z","shell.execute_reply":"2022-06-07T16:01:57.230624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"In this notebook, we looked at two **famous and important CNNs** in detail and **implemented** them from scratch using the keras framework. Even though these models are **relatively simple** by todays standards, they still achieve very **impressive performance**. The ideas introduced in these models had and continue to have a **profound impact** on the field of computer vision.","metadata":{}},{"cell_type":"markdown","source":"**Acknowledgments**\n\n* [AlexNet CNN Architecture on Tensorflow (beginner)](https://www.kaggle.com/code/vortexkol/alexnet-cnn-architecture-on-tensorflow-beginner) by [Ananta Raj](https://www.kaggle.com/vortexkol).\n* [Convolutional Neural Networks](https://www.coursera.org/learn/convolutional-neural-networks) by [Andrew NG](https://en.wikipedia.org/wiki/Andrew_Ng).","metadata":{}},{"cell_type":"markdown","source":"Thanks for reading!","metadata":{}}]}