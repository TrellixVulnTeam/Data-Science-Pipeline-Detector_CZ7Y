{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-20T16:31:00.138326Z","iopub.execute_input":"2021-10-20T16:31:00.1388Z","iopub.status.idle":"2021-10-20T16:31:00.153758Z","shell.execute_reply.started":"2021-10-20T16:31:00.138711Z","shell.execute_reply":"2021-10-20T16:31:00.152798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Flatten\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\nfrom tensorflow.keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:00.155316Z","iopub.execute_input":"2021-10-20T16:31:00.155819Z","iopub.status.idle":"2021-10-20T16:31:01.982852Z","shell.execute_reply.started":"2021-10-20T16:31:00.15578Z","shell.execute_reply":"2021-10-20T16:31:01.982099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data\ntrain_data = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nsubmission_data = pd.read_csv(\"/kaggle/input/digit-recognizer/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:01.984273Z","iopub.execute_input":"2021-10-20T16:31:01.98454Z","iopub.status.idle":"2021-10-20T16:31:06.65814Z","shell.execute_reply.started":"2021-10-20T16:31:01.984503Z","shell.execute_reply":"2021-10-20T16:31:06.657415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View the training data\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:06.660666Z","iopub.execute_input":"2021-10-20T16:31:06.660935Z","iopub.status.idle":"2021-10-20T16:31:06.681023Z","shell.execute_reply.started":"2021-10-20T16:31:06.6609Z","shell.execute_reply":"2021-10-20T16:31:06.680251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View the test data\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:06.682452Z","iopub.execute_input":"2021-10-20T16:31:06.683023Z","iopub.status.idle":"2021-10-20T16:31:06.70078Z","shell.execute_reply.started":"2021-10-20T16:31:06.682981Z","shell.execute_reply":"2021-10-20T16:31:06.699991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape, test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:06.701863Z","iopub.execute_input":"2021-10-20T16:31:06.702181Z","iopub.status.idle":"2021-10-20T16:31:06.707387Z","shell.execute_reply.started":"2021-10-20T16:31:06.702143Z","shell.execute_reply":"2021-10-20T16:31:06.706502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get labels and features\nfeatures = train_data.iloc[:, 1:].values\nlabels = train_data.iloc[:, 0].values\nfeatures = features.reshape(-1, 28, 28, 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:06.708725Z","iopub.execute_input":"2021-10-20T16:31:06.709158Z","iopub.status.idle":"2021-10-20T16:31:06.718214Z","shell.execute_reply.started":"2021-10-20T16:31:06.709122Z","shell.execute_reply":"2021-10-20T16:31:06.717046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for loading the QMNIST Dataset\ndef unpickle(file):\n    import pickle\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:06.719916Z","iopub.execute_input":"2021-10-20T16:31:06.720102Z","iopub.status.idle":"2021-10-20T16:31:06.729356Z","shell.execute_reply.started":"2021-10-20T16:31:06.72008Z","shell.execute_reply":"2021-10-20T16:31:06.728518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the QMNIST Dataset\nqmnist = unpickle(\"/kaggle/input/qmnist-the-extended-mnist-dataset-120k-images/MNIST-120k\")","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:06.730973Z","iopub.execute_input":"2021-10-20T16:31:06.731614Z","iopub.status.idle":"2021-10-20T16:31:06.869256Z","shell.execute_reply.started":"2021-10-20T16:31:06.731575Z","shell.execute_reply":"2021-10-20T16:31:06.868475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# So it is stored in a dictionary. We gotta get the data and put it in a dataframe\nqmnist_data = np.array(qmnist[\"data\"])\nqmnist_data = qmnist_data.reshape(-1, 28, 28, 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:06.871546Z","iopub.execute_input":"2021-10-20T16:31:06.872061Z","iopub.status.idle":"2021-10-20T16:31:06.913941Z","shell.execute_reply.started":"2021-10-20T16:31:06.872022Z","shell.execute_reply":"2021-10-20T16:31:06.913094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the QMNIST labels\nqmnist_labels = np.array(qmnist[\"labels\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:06.915653Z","iopub.execute_input":"2021-10-20T16:31:06.915954Z","iopub.status.idle":"2021-10-20T16:31:06.920584Z","shell.execute_reply.started":"2021-10-20T16:31:06.915915Z","shell.execute_reply":"2021-10-20T16:31:06.919538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now lets get the mnist data as well\nfrom tensorflow import keras\nmnist = keras.datasets.mnist\n(X_train_mnist, y_train_mnist), (X_val_mnist, y_val_mnist) = mnist.load_data()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:06.922252Z","iopub.execute_input":"2021-10-20T16:31:06.922827Z","iopub.status.idle":"2021-10-20T16:31:07.198311Z","shell.execute_reply.started":"2021-10-20T16:31:06.922789Z","shell.execute_reply":"2021-10-20T16:31:07.19757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qmnist_labels = qmnist_labels.reshape(-1,)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:07.203524Z","iopub.execute_input":"2021-10-20T16:31:07.203738Z","iopub.status.idle":"2021-10-20T16:31:07.209419Z","shell.execute_reply.started":"2021-10-20T16:31:07.203713Z","shell.execute_reply":"2021-10-20T16:31:07.208705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(qmnist_data.shape, X_train_mnist.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:07.212527Z","iopub.execute_input":"2021-10-20T16:31:07.21275Z","iopub.status.idle":"2021-10-20T16:31:07.219801Z","shell.execute_reply.started":"2021-10-20T16:31:07.212724Z","shell.execute_reply":"2021-10-20T16:31:07.218616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_val_mnist.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:07.22121Z","iopub.execute_input":"2021-10-20T16:31:07.221513Z","iopub.status.idle":"2021-10-20T16:31:07.228726Z","shell.execute_reply.started":"2021-10-20T16:31:07.221473Z","shell.execute_reply":"2021-10-20T16:31:07.228058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(qmnist_labels.shape, y_train_mnist.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:07.22998Z","iopub.execute_input":"2021-10-20T16:31:07.230312Z","iopub.status.idle":"2021-10-20T16:31:07.23672Z","shell.execute_reply.started":"2021-10-20T16:31:07.230271Z","shell.execute_reply":"2021-10-20T16:31:07.235899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets combine the QMNIST and Traditional mnist and dataset pre-loaded for this competition\n\n# 1. Combine train and val sets from traditional mnist\nX_mnist = np.concatenate((X_train_mnist, X_val_mnist))\ny_mnist = np.concatenate((y_train_mnist, y_val_mnist))\nX_mnist = X_mnist.reshape(-1,28,28,1)\n\n# 2. Combine the qmnist and traditional mnist\nX_train_full = np.concatenate((qmnist_data, X_mnist))\ny_train_full = np.concatenate((qmnist_labels, y_mnist))\n\n#3. Combine X_train and the Features array to get final datasets\n#X_train_full = np.concatenate((X_train, features))\n#y_train_full = np.concatenate((y_train, labels))","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:07.238029Z","iopub.execute_input":"2021-10-20T16:31:07.238755Z","iopub.status.idle":"2021-10-20T16:31:07.322882Z","shell.execute_reply.started":"2021-10-20T16:31:07.2387Z","shell.execute_reply":"2021-10-20T16:31:07.322093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the data shapes:\nprint(\"Training Data shape: \", X_train_full.shape, y_train_full.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:07.325179Z","iopub.execute_input":"2021-10-20T16:31:07.325622Z","iopub.status.idle":"2021-10-20T16:31:07.33218Z","shell.execute_reply.started":"2021-10-20T16:31:07.325586Z","shell.execute_reply":"2021-10-20T16:31:07.33117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View a few images\n\nfigure = plt.figure(figsize = (15,15))\n\nfor i in range(0, 9, 1):\n    ax = figure.add_subplot(3, 3, i+1)\n    image = plt.imshow(X_train_full[i], cmap = \"binary\")\n    ax.set_title(y_train_full[i])","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:07.333892Z","iopub.execute_input":"2021-10-20T16:31:07.334163Z","iopub.status.idle":"2021-10-20T16:31:08.584494Z","shell.execute_reply.started":"2021-10-20T16:31:07.334128Z","shell.execute_reply":"2021-10-20T16:31:08.583805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = X_train_full.shape[1:]\nprint(input_shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:08.585592Z","iopub.execute_input":"2021-10-20T16:31:08.586382Z","iopub.status.idle":"2021-10-20T16:31:08.591223Z","shell.execute_reply.started":"2021-10-20T16:31:08.58632Z","shell.execute_reply":"2021-10-20T16:31:08.590486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape, Dropout\n\nmodel = Sequential()\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), activation = \"relu\", input_shape = input_shape))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), activation = \"relu\"))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), activation = \"relu\"))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), activation = \"relu\"))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(units = 128, activation = \"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units = 256, activation = \"relu\"))\nmodel.add(Dense(units= 512, activation = \"relu\"))\nmodel.add(Dense(units = 10, activation = \"softmax\"))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:08.592627Z","iopub.execute_input":"2021-10-20T16:31:08.593094Z","iopub.status.idle":"2021-10-20T16:31:09.595405Z","shell.execute_reply.started":"2021-10-20T16:31:08.593059Z","shell.execute_reply":"2021-10-20T16:31:09.59463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.distplot(y_train_full)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffle the data\n#from sklearn.utils import shuffle\n\n#X_train_full, y_train_full = shuffle(X_train_full, y_train_full, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:09.596672Z","iopub.execute_input":"2021-10-20T16:31:09.59693Z","iopub.status.idle":"2021-10-20T16:31:09.601974Z","shell.execute_reply.started":"2021-10-20T16:31:09.596893Z","shell.execute_reply":"2021-10-20T16:31:09.601277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ny_train_full = to_categorical(y_train_full ,num_classes=10)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:09.603179Z","iopub.execute_input":"2021-10-20T16:31:09.603527Z","iopub.status.idle":"2021-10-20T16:31:09.618689Z","shell.execute_reply.started":"2021-10-20T16:31:09.603489Z","shell.execute_reply":"2021-10-20T16:31:09.618015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and validation sets\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size = 0.25, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:09.619762Z","iopub.execute_input":"2021-10-20T16:31:09.620014Z","iopub.status.idle":"2021-10-20T16:31:09.741039Z","shell.execute_reply.started":"2021-10-20T16:31:09.619979Z","shell.execute_reply":"2021-10-20T16:31:09.740248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training Set Shapes: \", X_train.shape, y_train.shape)\nprint(\"Validation Set Shapes: \", X_val.shape, y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:09.74218Z","iopub.execute_input":"2021-10-20T16:31:09.74273Z","iopub.status.idle":"2021-10-20T16:31:09.750109Z","shell.execute_reply.started":"2021-10-20T16:31:09.742686Z","shell.execute_reply":"2021-10-20T16:31:09.749336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Preprocessing\n# Add some image augmentation to better improve the generalization of the model\n\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1/255.0,\n    rotation_range=20,\n    width_shift_range=0.20,\n    height_shift_range=0.20,\n    shear_range=15,\n    zoom_range=0.10,\n    horizontal_flip= True,\n    vertical_flip= True\n)\n\nval_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1/255.0\n)\n\ntrain_generator = train_datagen.flow(\n    X_train,\n    y_train, \n    batch_size=256\n)\n\nvalidation_generator = val_datagen.flow(\n    X_val,\n    y_val, \n    batch_size=64\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:09.751346Z","iopub.execute_input":"2021-10-20T16:31:09.75219Z","iopub.status.idle":"2021-10-20T16:31:09.90398Z","shell.execute_reply.started":"2021-10-20T16:31:09.75215Z","shell.execute_reply":"2021-10-20T16:31:09.903171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nfrom tensorflow.keras.optimizers import Adam\nmodel.compile(loss = \"categorical_crossentropy\", optimizer = Adam(learning_rate = 0.0001), metrics = [\"Accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-20T16:31:09.905142Z","iopub.execute_input":"2021-10-20T16:31:09.905948Z","iopub.status.idle":"2021-10-20T16:31:09.920443Z","shell.execute_reply.started":"2021-10-20T16:31:09.905911Z","shell.execute_reply":"2021-10-20T16:31:09.919664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop = EarlyStopping(patience = 10, restore_best_weights = True)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T17:38:16.193963Z","iopub.execute_input":"2021-10-20T17:38:16.194231Z","iopub.status.idle":"2021-10-20T17:38:16.198923Z","shell.execute_reply.started":"2021-10-20T17:38:16.1942Z","shell.execute_reply":"2021-10-20T17:38:16.198217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cool lets train the model\nhistory = model.fit(train_generator, epochs = 100, validation_data = validation_generator, callbacks = [early_stop],verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T17:38:19.12096Z","iopub.execute_input":"2021-10-20T17:38:19.121522Z","iopub.status.idle":"2021-10-20T17:51:36.397962Z","shell.execute_reply.started":"2021-10-20T17:38:19.121482Z","shell.execute_reply":"2021-10-20T17:51:36.397224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View the Training Performance:\npd.DataFrame(history.history).plot(figsize = (10,10))\nplt.grid(True)\nplt.gca().set_ylim(0, 1.5)\nplt.title(\"Mnist Model Performance\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T17:54:20.017666Z","iopub.execute_input":"2021-10-20T17:54:20.017947Z","iopub.status.idle":"2021-10-20T17:54:23.765881Z","shell.execute_reply.started":"2021-10-20T17:54:20.017915Z","shell.execute_reply":"2021-10-20T17:54:23.765234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_train, features_val, labels_train, labels_val = train_test_split(features, labels, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T17:54:38.810255Z","iopub.execute_input":"2021-10-20T17:54:38.810903Z","iopub.status.idle":"2021-10-20T17:54:39.190055Z","shell.execute_reply.started":"2021-10-20T17:54:38.810862Z","shell.execute_reply":"2021-10-20T17:54:39.189293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                 factor=0.1,\n                                                 patience=5,\n                                                 min_lr=0.000001,\n                                                 verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T17:54:42.674182Z","iopub.execute_input":"2021-10-20T17:54:42.674486Z","iopub.status.idle":"2021-10-20T17:54:42.679419Z","shell.execute_reply.started":"2021-10-20T17:54:42.674445Z","shell.execute_reply":"2021-10-20T17:54:42.678572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = Adam(learning_rate = 0.0001), metrics = [\"accuracy\"])\nhistory_2 = model.fit(features_train, labels_train, epochs = 100,  validation_data = (features_val, labels_val), callbacks = [reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2021-10-20T17:54:58.517969Z","iopub.execute_input":"2021-10-20T17:54:58.518235Z","iopub.status.idle":"2021-10-20T18:03:21.293408Z","shell.execute_reply.started":"2021-10-20T17:54:58.518205Z","shell.execute_reply":"2021-10-20T18:03:21.292563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View the Training Performance:\npd.DataFrame(history_2.history).plot(figsize = (10,10))\nplt.grid(True)\nplt.gca().set_ylim(0, 1.5)\nplt.title(\"Mnist Model Performance Training Round 2\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T18:03:21.565481Z","iopub.execute_input":"2021-10-20T18:03:21.566511Z","iopub.status.idle":"2021-10-20T18:03:21.829866Z","shell.execute_reply.started":"2021-10-20T18:03:21.566472Z","shell.execute_reply":"2021-10-20T18:03:21.829202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate model\nfinal_loss, final_acc = model.evaluate(features_val,  labels_val, verbose=2)\nprint(\"Model accuracy: \", final_acc, \", model loss: \", final_loss)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T18:03:55.687132Z","iopub.execute_input":"2021-10-20T18:03:55.687532Z","iopub.status.idle":"2021-10-20T18:03:56.394776Z","shell.execute_reply.started":"2021-10-20T18:03:55.687494Z","shell.execute_reply":"2021-10-20T18:03:56.394043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions\ntest_data = np.array(test_data)\ntest_data = test_data.reshape(28000, 28, 28, 1)\npredictions = model.predict(test_data)\npredictions = np.argmax(predictions, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T18:55:50.035197Z","iopub.execute_input":"2021-10-20T18:55:50.035862Z","iopub.status.idle":"2021-10-20T18:55:51.676227Z","shell.execute_reply.started":"2021-10-20T18:55:50.035807Z","shell.execute_reply":"2021-10-20T18:55:51.675495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(predictions))","metadata":{"execution":{"iopub.status.busy":"2021-10-20T18:55:54.627291Z","iopub.execute_input":"2021-10-20T18:55:54.627566Z","iopub.status.idle":"2021-10-20T18:55:54.634292Z","shell.execute_reply.started":"2021-10-20T18:55:54.627536Z","shell.execute_reply":"2021-10-20T18:55:54.633435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a submission\nsubmission = pd.DataFrame({'ImageId': range(1, len(predictions) + 1), \"Label\": predictions})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T18:55:57.857617Z","iopub.execute_input":"2021-10-20T18:55:57.85835Z","iopub.status.idle":"2021-10-20T18:55:57.911039Z","shell.execute_reply.started":"2021-10-20T18:55:57.858299Z","shell.execute_reply":"2021-10-20T18:55:57.910382Z"},"trusted":true},"execution_count":null,"outputs":[]}]}