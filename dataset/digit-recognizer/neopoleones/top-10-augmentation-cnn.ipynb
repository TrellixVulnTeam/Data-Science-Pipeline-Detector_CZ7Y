{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pytorch is consuming so much ram, so, I've selected the tensorflow\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as ts\nimport tensorflow.keras as ks\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\n\npd.set_option('display.max_columns', 784)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:33:16.760619Z","iopub.execute_input":"2022-06-16T07:33:16.761772Z","iopub.status.idle":"2022-06-16T07:33:23.462634Z","shell.execute_reply.started":"2022-06-16T07:33:16.761657Z","shell.execute_reply":"2022-06-16T07:33:23.4618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Normalizing and reshaping the dataset","metadata":{}},{"cell_type":"code","source":"df_path         = '../input/digit-recognizer/'\nim_shape = (28, 28, 1)\n\nout_df = pd.read_csv(df_path + 'sample_submission.csv')\nout_df.set_index('ImageId', inplace = True)\n\ndef prepare_data(df: pd.DataFrame, train = False):\n    x_train = y_train = None\n    \n    if train:\n        y_train = df['label']\n        y_train = to_categorical(y_train, num_classes = 10)\n        x_train = df.drop('label', axis=1, inplace=False)\n    else:\n        x_train = df\n    \n    # There is no semantic loss but convolutions **cores** will contain sane numbers\n    x_train = x_train / 255\n    \n    # (rows, 28, 28, 1) \n    x_train = x_train.values.reshape(-1, *im_shape)\n    \n    return x_train, y_train\n\nx_test, _        = prepare_data(pd.read_csv(df_path + 'test.csv'))\nx_train, y_train = prepare_data(pd.read_csv(df_path + 'train.csv'),  train=True)\n\nx_train_splitted, x_test_splitted, y_train_splitted, y_test_splitted = train_test_split(\n    x_train, y_train, test_size = 0.2\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:33:23.464195Z","iopub.execute_input":"2022-06-16T07:33:23.464861Z","iopub.status.idle":"2022-06-16T07:33:29.135615Z","shell.execute_reply.started":"2022-06-16T07:33:23.464822Z","shell.execute_reply":"2022-06-16T07:33:29.134773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Creating CNN model using the keras api","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\n# augmentation setup\nmnist_datagen = ImageDataGenerator(\n        samplewise_center              = False, \n        featurewise_std_normalization  = False,  \n        samplewise_std_normalization   = False,  \n        zca_whitening                  = True,  \n        horizontal_flip                = False,  \n        vertical_flip                   = False,\n    \n        rotation_range                 = 10,  \n        width_shift_range              = 0.1,  \n        height_shift_range             = 0.1, \n)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:35:17.871239Z","iopub.execute_input":"2022-06-16T07:35:17.871891Z","iopub.status.idle":"2022-06-16T07:35:17.877445Z","shell.execute_reply.started":"2022-06-16T07:35:17.87184Z","shell.execute_reply":"2022-06-16T07:35:17.876378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# learning options\nepoch_count = 150\nprefered_batch_size  = 256\n\nmodel_options = {\n    'optimizer': 'adam',\n    'metrics':   'accuracy',                  \n    'loss':      'categorical_crossentropy'  # awesome loss-function for multiclass classification\n}\nlrelu = lambda x: ks.layers.LeakyReLU(alpha = 0.01)(x)\n\n# C part (2 convolutions|MaxPools(2x2))\nconv_setup = {\n    'kernel_size': 3,\n    'strides':     1,               # we are getting them using kernel(size 5) with step 1\n    'activation': 'relu'\n}\n\nlr_model = ks.Sequential()\n# -----------------------------------------------------------------  # C1\nlr_model.add(ks.layers.Conv2D(\n    filters     = 64,               # 32 feature maps*\n    input_shape = im_shape,\n    **conv_setup\n))\nlr_model.add(ks.layers.BatchNormalization())\n\nlr_model.add(ks.layers.Conv2D(\n    filters     = 64,\n    **conv_setup\n))\nlr_model.add(ks.layers.BatchNormalization())\n\nlr_model.add(ks.layers.MaxPool2D()) # pool size is 2x2 by default\nlr_model.add(ks.layers.Dropout(0.4))\n\n# -----------------------------------------------------------------  # C2\nlr_model.add(ks.layers.Conv2D(\n    filters     = 128,\n    **conv_setup\n))\nlr_model.add(ks.layers.BatchNormalization())\n\nlr_model.add(ks.layers.Conv2D(\n    filters     = 128,\n    **conv_setup\n))\nlr_model.add(ks.layers.BatchNormalization())\n\nlr_model.add(ks.layers.MaxPool2D())\nlr_model.add(ks.layers.Dropout(0.4))\n\n# -----------------------------------------------------------------  # Classifier part\nlr_model.add(ks.layers.Flatten())   # 2d -> 1d(256 units)\nlr_model.add(ks.layers.Dense(\n    1024, activation = 'swish'\n))\nlr_model.add(ks.layers.Dropout(0.4))\nlr_model.add(ks.layers.BatchNormalization())\n\n# -----------------------------------------------------------------  # Output layer\nlr_model.add(ks.layers.Dense(\n    10, activation='softmax'        # 10 classes\n))\n\n# Assembly model\nlr_model.compile(**model_options)\nlr_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:40:36.693434Z","iopub.execute_input":"2022-06-16T07:40:36.693802Z","iopub.status.idle":"2022-06-16T07:40:36.824994Z","shell.execute_reply.started":"2022-06-16T07:40:36.693772Z","shell.execute_reply":"2022-06-16T07:40:36.824073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train our model\nlr_model.fit_generator(\n    mnist_datagen.flow(x_train_splitted, y_train_splitted, batch_size = prefered_batch_size),\n    verbose = 1,\n    epochs = 100,\n    steps_per_epoch= x_train_splitted.shape[0] // prefered_batch_size,\n    validation_data = (x_test_splitted, y_test_splitted),    \n)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:40:43.412325Z","iopub.execute_input":"2022-06-16T07:40:43.412687Z","iopub.status.idle":"2022-06-16T07:55:33.419827Z","shell.execute_reply.started":"2022-06-16T07:40:43.412659Z","shell.execute_reply":"2022-06-16T07:55:33.416448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict classes\ny_preds = lr_model.predict(x_test)\ny_preds_classified = np.argmax(y_preds, axis=1)\ny_preds_classified[:10]","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:55:39.200044Z","iopub.execute_input":"2022-06-16T07:55:39.200907Z","iopub.status.idle":"2022-06-16T07:55:40.935638Z","shell.execute_reply.started":"2022-06-16T07:55:39.200852Z","shell.execute_reply":"2022-06-16T07:55:40.934909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# upload results \nout_df['Label'] = y_preds_classified\nout_df.to_csv('outer.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:55:42.536997Z","iopub.execute_input":"2022-06-16T07:55:42.537624Z","iopub.status.idle":"2022-06-16T07:55:42.597371Z","shell.execute_reply.started":"2022-06-16T07:55:42.537591Z","shell.execute_reply":"2022-06-16T07:55:42.596632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}