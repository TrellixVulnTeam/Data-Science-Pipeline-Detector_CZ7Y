{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **0. Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport random\nimport time\nimport os\nimport copy\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nimport torchvision\nimport torchvision.transforms as transform\nfrom torchvision.utils import make_grid\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **1. Data Loading**\n**Open the data in the pandas table**","metadata":{}},{"cell_type":"code","source":"train_pd = pd.read_csv('../input/digit-recognizer/train.csv')\ntrain_pd.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now we know that there are only 10 classes from 0 to 9**","metadata":{}},{"cell_type":"code","source":"sorted(train_pd.label.unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's see what the pictures look like**","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(10,8))\n\ni = 0\nfor row in range(3):\n  for col in range(4):\n    axs[row][col].imshow(train_pd.iloc[i, 1:].values.reshape(28,28), cmap='gray')\n    axs[row][col].set_title(str(train_pd.iloc[i, 0]), fontsize=20)\n    axs[row][col].axis('off')\n    i+=1\n\nplt.suptitle('Data Samples', fontsize=30)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **2. Data preparation**","metadata":{}},{"cell_type":"markdown","source":"**Here we can see that there is no strong imbalance, so it is not worth fighting it**","metadata":{}},{"cell_type":"code","source":"train_samplesize = pd.DataFrame({str(x): train_pd['label'].value_counts()[x] for x in range(10)}, index=[0])\n\nsns.barplot(data=train_samplesize).set_title('Training Set Data Imbalance', fontsize=20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sometimes the data is normalized in advance, but as you can see in the graph, this is not the case, so the data will have to be normalized**","metadata":{}},{"cell_type":"code","source":"def plotHist(img):\n  img = train_pd.iloc[img, 1:].values.reshape(28,28)\n  plt.figure(figsize=(10,5))\n  plt.subplot(1,2,1)\n  plt.imshow(img, cmap='gray')\n  plt.axis('off')\n  histo = plt.subplot(1,2,2)\n  histo.set_ylabel('Count')\n  histo.set_xlabel('Pixel Intensity')\n  plt.hist(img.flatten(), bins=10, lw=0, color='r', alpha=0.5)\n\nplotHist(2021)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's write our own dataset so that we can apply augmentations**","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n  def __init__(self, features, labels, Transform):\n    self.x = features\n    self.y = labels\n    self.transform = Transform\n\n  def __len__(self):\n    return len(self.x)\n\n  def __getitem__(self, index):\n    return self.transform(self.x[index]), self.y[index]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Before calling the class, you need to prepare the data, that is, break the dataframe into features and labels, make a reshape, and convert it to tensors. All this is done by the function below**","metadata":{}},{"cell_type":"code","source":"def GetDf(df, Transform):\n  x_features = df.iloc[:, 1:].values\n  y_labels = df.label.values\n  x_features = x_features.reshape(-1, 1, 28, 28)\n  x_features = np.uint8(x_features)\n  x_features = torch.from_numpy(x_features)\n  y_labels = torch.from_numpy(y_labels)\n  return MyDataset(x_features, y_labels, Transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Augmentation. There is nothing unusual here, I would just like to draw your attention to the fact that we are converting images to three-channel images, since they will be fed to the input models that were pre-trained on three-channel images**","metadata":{}},{"cell_type":"code","source":"transformer = {\n '0': transform.Compose([\n                           transform.ToPILImage(),\n                           transform.Resize(94),\n                           transform.Grayscale(num_output_channels=3), \n                           transform.ToTensor(),\n                           transform.Normalize(\n                                    [0.13097111880779266, 0.13097111880779266, 0.13097111880779266],\n                                    [0.30848443508148193, 0.30848443508148193, 0.30848443508148193])\n]),\n\n    '1': transform.Compose([\n                           transform.ToPILImage(),\n                           transform.Resize(94),\n                           transform.Grayscale(num_output_channels=3),\n                           transform.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n                           transform.RandomRotation(5),\n                           transform.RandomAffine(degrees=11, translate=(0.1,0.1), scale=(0.8,0.8)),\n                           transform.ToTensor(),\n                           transform.Normalize(\n                                    [0.13097111880779266, 0.13097111880779266, 0.13097111880779266],\n                                    [0.30848443508148193, 0.30848443508148193, 0.30848443508148193])\n]),\n    'val': transform.Compose([\n                           transform.ToPILImage(),\n                           transform.Resize(94),\n                           transform.Grayscale(num_output_channels=3),\n                           transform.ToTensor(),\n                           transform.Normalize(\n                                  [0.13141274452209473, 0.13141274452209473, 0.13141274452209473],\n                                  [0.30904173851013184, 0.30904173851013184, 0.30904173851013184])\n    ])\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exampleset = GetDf(train_pd, Transform=transform.Compose([\n                           transform.ToPILImage(),\n                           transform.Grayscale(num_output_channels=3),\n                           transform.ToTensor()\n    ]))\n\nx, y = next(iter(torch.utils.data.DataLoader(exampleset)))\n\nchannels = ['Red', 'Green', 'Blue']\ncmaps = [plt.cm.Reds_r, plt.cm.Greens_r, plt.cm.Blues_r]\n\nfig, ax = plt.subplots(1, 4, figsize=(15, 10))\n\nfor i, axs in enumerate(fig.axes[:3]):\n    axs.imshow(x[0][i,:,:], cmap=cmaps[i])\n    axs.set_title(f'{channels[i]} Channel')\n    axs.set_xticks([])\n    axs.set_yticks([])\n    \nax[3].imshow(x[0].permute(1,2,0), cmap='gray')\nax[3].set_title('Three Channels')\nax[3].set_xticks([])\nax[3].set_yticks([]);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3. Training and Test**\n**I will use an ensemble of pre-trained models, the idea is this: I first train only the classifier on 10 epochs, then unfreeze the network and train all together for another 10 epochs. After that, the model makes predictions on the test data**","metadata":{}},{"cell_type":"code","source":"# Get the device\nuse_cuda = torch.cuda.is_available()\nprint(use_cuda)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This is a custom dataset for the test part of the data**","metadata":{}},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, features,transform=transform.Compose([\n                              transform.ToPILImage(),\n        transform.Resize(94),\n        transform.Grayscale(num_output_channels=3),\n                              transform.ToTensor(),\n                              transform.Normalize(\n                                  [0.13141274452209473, 0.13141274452209473, 0.13141274452209473],\n                                  [0.30904173851013184, 0.30904173851013184, 0.30904173851013184])\n    ])):\n        self.features = features.values.reshape((-1,28,28)).astype(np.uint8)\n        self.targets = None\n        self.transform=transform\n        \n    def __len__(self):\n        return (self.features.shape[0])\n    \n    def __getitem__(self, idx):\n        return self.transform(self.features[idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's write a function that will create its own datasets for each model**","metadata":{}},{"cell_type":"code","source":"def create_dataloaders(seed, test_size=0.1, df=train_pd, batch_size=50):\n    \n    # Create training set and validation set\n    train_data, valid_data = train_test_split(df,\n                                              test_size=test_size,\n                                              random_state=seed)\n    \n    # Create Datasets\n    train_dataset_0 = GetDf(train_data, Transform=transformer['0'])\n    train_dataset_1 = GetDf(train_data, Transform=transformer['1'])\n    \n    train_dataset = ConcatDataset([train_dataset_0, train_dataset_1])\n\n    valid_dataset = GetDf(valid_data, Transform=transformer['val'])\n    \n    # Create Dataloaders\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, num_workers=4)\n\n    train_size = len(train_dataset)\n    val_size = len(valid_dataset)\n\n    return train_loader, valid_loader, train_size, val_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Here we will save the history to make a visualization at the end**","metadata":{}},{"cell_type":"code","source":"losses = {'train':[], 'val':[]}\naccuracies = {'train':[], 'val':[]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train function structure:\n\n1. **Classifier Training**\n1. **Network-wide Training**\n1. **Predictions**","metadata":{}},{"cell_type":"code","source":"def train(seed, epochs, model):\n\n  # Train and valid dataloaders\n  print('Creating new dataloaders...')\n    \n  train_loader, valid_loader, train_size, val_size = create_dataloaders(seed=seed)\n\n  loaders = {'train': train_loader, 'val': valid_loader}\n\n  dataset_sizes = {'train': train_size, 'val': val_size}\n\n  print('Creating a model {}...'.format(seed))\n\n  model.to(device)  \n  criterion = nn.CrossEntropyLoss()\n  if seed==2 or seed==3:\n    optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n  else:\n    optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n#   scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=3, verbose=True)\n\n  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)\n  since = time.time()\n  best_model = copy.deepcopy(model.state_dict())\n  best_acc = 0.0\n  for epoch in range(epochs):\n    for phase in ['train', 'val']:\n      if phase == 'train':\n        model.train()\n      else:\n        model.eval()\n      \n      running_loss = 0.0\n      running_corrects = 0.0\n\n      for inputs, labels in loaders[phase]:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        with torch.set_grad_enabled(phase=='train'):\n          outp = model(inputs)\n          _, pred = torch.max(outp, 1)\n          loss = criterion(outp, labels)\n        \n          if phase == 'train':\n            loss.backward()\n            optimizer.step()\n            \n\n        running_loss += loss.item()*inputs.size(0)\n        running_corrects += torch.sum(pred == labels.data)\n\n#       if phase == 'train':\n#           acc = 100. * running_corrects.double() / dataset_sizes[phase]\n#           scheduler.step(acc)\n\n      epoch_loss = running_loss / dataset_sizes[phase]\n      epoch_acc = running_corrects.double()/dataset_sizes[phase]\n      losses[phase].append(epoch_loss)\n      accuracies[phase].append(epoch_acc)\n      if phase == 'train':\n        print('Epoch: {}/{}'.format(epoch+1, epochs))\n      print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n    \n      if phase == 'val':\n        print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n        print('=='*31)\n      if phase == 'val' and epoch_acc > best_acc:\n        best_acc = epoch_acc\n        best_model = copy.deepcopy(model.state_dict())\n    scheduler.step() \n  time_elapsed = time.time() - since\n  print('CLASSIFIER TRAINING TIME {}m {}s'.format(time_elapsed//60, time_elapsed%60))\n  print('=='*31)\n\n\n  model.load_state_dict(best_model)\n\n  for param in model.parameters():\n        param.requires_grad=True\n\n  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)  \n#   scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=3, verbose=True)\n  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)\n  for epoch in range(epochs):\n    for phase in ['train', 'val']:\n      if phase == 'train':\n        model.train()\n      else:\n        model.eval()\n      \n      running_loss = 0.0\n      running_corrects = 0.0\n\n      for inputs, labels in loaders[phase]:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        with torch.set_grad_enabled(phase=='train'):\n          outp = model(inputs)\n          _, pred = torch.max(outp, 1)\n          loss = criterion(outp, labels)\n        \n          if phase == 'train':\n            loss.backward()\n            optimizer.step()\n        \n        running_loss += loss.item()*inputs.size(0)\n        running_corrects += torch.sum(pred == labels.data)\n\n#       if phase == 'train':\n#         acc = 100. * running_corrects.double() / dataset_sizes[phase]\n#         scheduler.step(acc)\n\n      epoch_loss = running_loss / dataset_sizes[phase]\n      epoch_acc = running_corrects.double()/dataset_sizes[phase]\n      losses[phase].append(epoch_loss)\n      accuracies[phase].append(epoch_acc)\n      if phase == 'train':\n        print('Epoch: {}/{}'.format(epoch+1, epochs))\n      print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n    \n      if phase == 'val':\n        print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n        print('=='*31)    \n      if phase == 'val' and epoch_acc > best_acc:\n        best_acc = epoch_acc\n        best_model = copy.deepcopy(model.state_dict())\n    scheduler.step() \n  time_elapsed = time.time() - since\n  print('ALL NET TRAINING TIME {}m {}s'.format(time_elapsed//60, time_elapsed%60))\n  print('=='*31)\n\n  model.load_state_dict(best_model)\n    \n  model.eval() # Evaluation mode -> Turn off dropout\n  test_pred = torch.LongTensor()\n    \n  if use_cuda:\n    test_pred = test_pred.cuda()\n        \n  with torch.no_grad(): # Turn off gradients for prediction, saves memory and computations\n    for features in test_loader:\n        \n        if use_cuda:\n            features = features.cuda()\n\n            # Get the softmax probabilities\n        outputs = model(features)\n            # Get the prediction of the batch\n        _, predicted = torch.max(outputs, 1)\n            # Concatenate the prediction\n        test_pred = torch.cat((test_pred, predicted), dim=0)\n    \n  model_name = 'model_' + str(seed + 1)\n  ensemble_df[model_name] = test_pred.cpu().numpy()\n  print('Prediction Saved! \\n') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Uploading models**","metadata":{}},{"cell_type":"code","source":"densenet121_0 = torchvision.models.densenet121(pretrained=True)\nfor param in densenet121_0.parameters():\n  param.requires_grad=False\n\ndensenet121_0.classifier = nn.Linear(in_features=densenet121_0.classifier.in_features, out_features=10, bias=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"densenet121_1 = torchvision.models.densenet121(pretrained=True)\nfor param in densenet121_1.parameters():\n  param.requires_grad=False\n\ndensenet121_1.classifier = nn.Linear(in_features=densenet121_1.classifier.in_features, out_features=10, bias=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"googlenet = torchvision.models.googlenet(pretrained=True)\nfor param in googlenet.parameters():\n  param.grad_requires = False\n\ngooglenet.fc = nn.Linear(in_features=googlenet.fc.in_features, out_features=10, bias=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet101 = torchvision.models.resnet101(pretrained=True)\nfor param in resnet101.parameters():\n  param.grad_requires = False\n\nresnet101.fc = nn.Linear(in_features=resnet101.fc.in_features, out_features=10, bias=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg19_bn = torchvision.models.vgg19_bn(pretrained=True)\nfor param in vgg19_bn.parameters():\n  param.grad_requires = False\n\nvgg19_bn.classifier[6] = nn.Linear(4096, 10, bias=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Launching training**","metadata":{}},{"cell_type":"code","source":"# Create test_loader\nsubmit_df = pd.read_csv('../input/digit-recognizer/sample_submission.csv')\ntest_df = pd.read_csv('../input/digit-recognizer/test.csv')\ntest_dataset = TestDataset(test_df)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nensemble_df = submit_df.copy()\n\nnum_models = 5\nnum_epochs = 10\n\nmodels = [densenet121_0, densenet121_1, googlenet, resnet101, vgg19_bn]\n\nfor seed in range(num_models):\n   train(seed=seed, epochs=num_epochs, model=models[seed])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **4. Submit Preparing**","metadata":{}},{"cell_type":"code","source":"ensemble_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final prediction\nfinal_pred = ensemble_df.iloc[:,2:].mode(axis=1).iloc[:,0]\nsubmit_df.Label = final_pred.astype(int)\nsubmit_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a submission file\nsubmit_df.to_csv('submission0.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **5. Learning Visualization**","metadata":{}},{"cell_type":"markdown","source":"**As you can see, the idea of defrosting feature extractor worked and we see a sharp increase in accuracy**","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(5, 2, figsize=(15, 15))\nmodelname = ['DenseNet_0', 'DenseNet_1', 'GooglNet', 'ResNet101', 'VGG16 with BN']\n\nepochs=10\n\ni=0\n\nfor row in range(5):\n\n  epoch_list = list(range(1,epochs*2+1))\n\n  ax[row][0].plot(epoch_list, accuracies['train'][i:20+i], label='Train Accuracy')\n  ax[row][0].plot(epoch_list, accuracies['val'][i:20+i], label='Validation Accuracy')\n  ax[row][0].set_xticks(np.arange(0, epochs*2+1, 5))\n  ax[row][0].set_ylabel('Accuracy Value')\n  ax[row][0].set_xlabel('Epoch')\n  ax[row][0].set_title('Accuracy {}'.format(modelname[row]))\n\n  ax[row][1].plot(epoch_list, losses['train'][i:20+i], label='Train Loss')\n  ax[row][1].plot(epoch_list, losses['val'][i:20+i], label='Validation Loss')\n  ax[row][1].set_xticks(np.arange(0, epochs*2+1, 5))\n  ax[row][1].set_ylabel('Loss Value')\n  ax[row][1].set_xlabel('Epoch')\n  ax[row][1].set_title('Loss {}'.format(modelname[row]))\n  fig.tight_layout()\n  fig.subplots_adjust(top=1.5, wspace=0.3)\n  i+=20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***I am always happy to receive any feedback. What do you think can be changed and what can be removed?***","metadata":{}}]}