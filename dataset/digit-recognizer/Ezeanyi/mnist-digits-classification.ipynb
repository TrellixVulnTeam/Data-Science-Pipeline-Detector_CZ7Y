{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nThis kernel will explore the basics of image processing using a basic convolutional neural network running on tensor backend with keras as the programming interface. The MNIST image digits, popular as a beginner image data for introductory image processing will be used to train a convnet and make predictions.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1.0 Data exploration\nLoad and explore data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#load libraries for data manipulation and visualization\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n# warnings\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data sets consist of grayscale image data in pixels in a structured format with each column representing a pixel of the image data.\n* The training set has 42000 samples while the test set has 28000 samples\n* The training set has 785 features while the test set has 784 features\n* The training set has an extra variable 'label' which is the target variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the train and test data sets\ntrain = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nprint('Number of Training Samples = {}'.format(train.shape[0]))\nprint('Number of Test Samples = {}\\n'.format(test.shape[0]))\nprint('Training X Shape = {}'.format(train.shape))\nprint('Training y Shape = {}\\n'.format(train['label'].shape[0]))\nprint('Test X Shape = {}'.format(test.shape))\nprint('Test y Shape = {}\\n'.format(test.shape[0]))\nprint('Index of Train Set:\\n', train.columns)\nprint('Index of Test Set:\\n', test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check datatypes\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The datatypes label to pixel783 consist of numeric integer64 values. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample of data\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lp = sb.countplot(train['label'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The label consist of 10 numeric values that are representations of digit images 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9. The challenge is a multi-class classification of image data given its pixel values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for missing values\nmissing_train = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\nmissing_train = missing_train[missing_train > 0] * 100\nprint(\"There are {} train features with  missing values :\".format(missing_train.shape[0]))\nmissing_test = (test.isnull().sum()/test.isnull().count()).sort_values(ascending=False)\nmissing_test= missing_test[missing_test > 0] * 100\nprint(\"There are {} test features with  missing values :\".format(missing_test.shape[0]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.0 Recompose pixel digits to image data\nThe data sets are given as pixel digits, the image data can be reconstructed from the pixel digits. 784 pixels suggest the image is of size lenght 28 and width 28.(i.e. 28 x 28 = 784 pixels). ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_image(train_image, train_label, index):\n    image_shaped = train_image.values.reshape(28,28)\n    plt.subplot(4, 6, index+1)\n    plt.imshow(image_shaped, cmap=plt.cm.gray)\n    plt.title(label)\n\n\nplt.figure(figsize=(18, 8))\nsample_image = train.sample(24).reset_index(drop=True)\nfor index, row in sample_image.iterrows():\n    label = row['label']\n    image_pixels = row.drop('label')\n    show_image(image_pixels, label, index)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.0 Data preparation\nA convnet takes as input tensors in this format (sample, image_height, image_width, image_channels), hence we will configure the convnet to process inputs of size (28, 28, 1) where the channel is 1 representing a grayscale image. A coloured image in RGB colour format will have a channel value of 3.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The image values are transformed into a float32 array with values between 0 and 1 suitable for neural nets processing by dividing with 255.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\n# prepare training and test sets\nX = train.drop(columns=['label']).values.reshape((train.shape[0],28,28,1))\nX_train = X.astype('float32') / 255\ny = to_categorical(train['label'])\nX_test = test.values.reshape((test.shape[0],28,28,1))\nX_test = X_test.astype('float32') / 255\n\n# prepare training and validation sets\ntrain_images, test_images, train_labels, test_labels = train_test_split(X, y,\n                                                test_size=0.1, random_state=0)\ntrain_images = train_images.astype('float32') / 255\ntest_images = test_images.astype('float32') / 255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.0 Modeling\nDefine a small convnet model, compile and evaluate model, evaluate model on test data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Defining a Small Convnet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining a small convnet\nimport tensorflow.keras.models as models\nimport tensorflow.keras.layers as layers\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n# adding a classifier on top of the convnet\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(32, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2 Compile and Evaluate Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\ncallbacks = [\n    EarlyStopping(patience=10, verbose=1),\n    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n    ModelCheckpoint('model.h5', verbose=1, save_best_only=True, save_weights_only=True)\n]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# model training \nmodel.compile(optimizer='rmsprop',\n   loss='categorical_crossentropy',\n   metrics=['acc'])\nhistory = model.fit(train_images,\n   train_labels,\n   epochs=20,\n   batch_size=64,\n   callbacks=callbacks,\n   validation_data=(test_images, test_labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model acheived a validation accuracy of 98.9%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.3 Evaluate Model on Test Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)\nresults = np.argmax(predictions, axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Sample of Predictions","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18, 8))\nsample_test = test.head(24)\nfor index, image_pixels in sample_test.iterrows():\n    label = results[index]\n    show_image(image_pixels, label, index)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating submission file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"solution = pd.read_csv(\"/kaggle/input/digit-recognizer/sample_submission.csv\")\nsolution['Label'] = results\nsolution.to_csv('solution.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}