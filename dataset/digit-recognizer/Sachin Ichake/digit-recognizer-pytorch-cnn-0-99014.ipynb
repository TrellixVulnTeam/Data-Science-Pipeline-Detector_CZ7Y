{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn \nfrom tqdm import tqdm \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport torch.optim as optim \nfrom torch.utils.data import DataLoader \nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nimport torch.nn.functional as F\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS =30 \nBATCH_SIZE=512\nTEST_BATCH_SIZE=64\nTRAIN_FILE = '../input/digit-recognizer/train.csv'\nTEST_FILE='../input/digit-recognizer/test.csv'\nSUBMIT_FILE = '../input/digit-recognizer/sample_submission.csv'\nMODEL_PATH = '/kaggle/working/model.pt'\nSUBMITTION_FILE ='/kaggle/working/submission.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass DigitDataset():\n    def __init__(self,pixels, labels):\n        self.pixels= pixels\n        self.labels=labels\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self,index):\n        pixels = self.pixels[index]\n        labels = self.labels[index]\n#         channel, height and width \n        pixels= pixels.reshape((1, 28,28))\n        \n        return { 'pixels' : torch.tensor(pixels, dtype = torch.float),\n                'labels': torch.tensor(labels,dtype = torch.long)            \n        } \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DigitModel(nn.Module):\n    def __init__(self):\n        super(DigitModel,self).__init__()\n#         in channel, out channel, kernel , stride \n        self.conv1 = nn.Conv2d(1,32,5,1,padding=2) \n        self.conv2 = nn.Conv2d(32,32,5,1,padding=2)\n#         self.bn1 = nn.BatchNorm2d(32)\n        self.maxp1 = nn.MaxPool2d(kernel_size = 2, stride=2)\n        self.conv3 = nn.Conv2d(32,64,3,1,padding=1) \n        self.conv4 = nn.Conv2d(64,64,3,1,padding=1) \n#         self.bn2 = nn.BatchNorm2d(64)\n        self.maxp2 = nn.MaxPool2d(kernel_size = 2, stride=2)\n        self.fc1 = nn.Linear(3136,1568)\n        self.fc2 = nn.Linear(1568,10)\n        self.dr1 = nn.Dropout(0.25)  \n        self.dr2 = nn.Dropout(0.50)  \n       \n    def forward(self,x):\n        \n        # Convolution 1\n        x = F.relu(self.conv1(x))\n        \n        # Convolution 2\n        x = self.maxp1(F.relu(self.conv2(x)))\n        x = self.dr1(x)        \n        \n        # Convolution 3\n        x = F.relu(self.conv3(x))\n        x = self.maxp2(F.relu(self.conv4(x)))\n        x = self.dr1(x)\n        \n        # Flatten \n        x = torch.flatten(x,1)          \n        \n        # FC 1\n        x = F.relu(self.fc1(x)) \n        x = self.dr2(x)\n        \n        # FC 2\n        x = self.fc2(x)\n        x = F.log_softmax(x,dim=1)\n        return x\n         \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(TRAIN_FILE).reset_index(drop=True)\ndf_testing = pd.read_csv(TEST_FILE).reset_index(drop=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check columns\ndf_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the null value \ndf_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head() \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_train.loc[:,df_train.columns != 'label'].values/255\ny = df_train.label.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, df_test,df_train_label,df_test_label = train_test_split(X,y, test_size =0.1,random_state=24)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n%matplotlib inline\nfrom torchvision.utils import make_grid\n\nrandom_select = np.random.randint(100,size = 9)\ngrid = make_grid(torch.Tensor(df_train[random_select].reshape((-1, 28, 28))).unsqueeze(1), nrow=9)\nplt.rcParams['figure.figsize'] =(16,2)\nplt.imshow(grid.numpy().transpose((1,2,0)))\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = DigitDataset(df_train,df_train_label)\ntest_dataset = DigitDataset(df_test,df_test_label)\ntrain_dataloader = DataLoader(train_dataset,batch_size =BATCH_SIZE,num_workers=4)\ntest_dataloader = DataLoader(test_dataset,batch_size =BATCH_SIZE,num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\")\nmodel = DigitModel()\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\ncriterian = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_fn(model,criterian,data_loader,device,optimizer):\n    model.train()\n    running_loss =0.0\n    \n    for bi , d in tqdm(enumerate(data_loader), total=len(data_loader)):\n        pixels = d['pixels']\n        labels = d['labels']\n        pixels= pixels.to(device,dtype=torch.float)\n        labels= labels.to(device,dtype=torch.long)\n        optimizer.zero_grad()\n        outputs  = model(pixels)\n        loss = criterian(outputs,labels)\n#         loss = F.nll_loss(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        if bi % 100 == 99:    # print every 2000 mini-batches\n            print('loss: %.3f' %\n                  (running_loss / 2000))\n            running_loss = 0.0\n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_fn(data_loader, model, optimizer, device):\n    model.eval()\n    fin_labels=[]\n    fin_outputs = []\n    lossdetails =[]\n    with torch.no_grad():\n        for bi, d in tqdm(enumerate(data_loader),total =len(data_loader)):\n                        \n            pixels = d[\"pixels\"]\n            labels = d [\"labels\"]\n            pixels= pixels.to(device,dtype=torch.float)\n            labels= labels.to(device,dtype=torch.long)\n            \n            \n            outputs = model(pixels)\n            pred = outputs.argmax(dim=1, keepdim=True) \n            \n            fin_labels.extend(labels.tolist())\n            fin_outputs.extend(pred.tolist())\n    return fin_outputs, fin_labels\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_accuracy =0 \nfor epoch in range(EPOCHS):\n    train_fn(model,criterian,train_dataloader,device,optimizer)\n    outputs, labels = eval_fn(test_dataloader,model,optimizer,device)\n    \n    accuracy = accuracy_score(labels, outputs)\n    \n    if accuracy > best_accuracy:\n        print(f\"Epoch = {epoch} : Accuracy Score = {accuracy}\")\n#         torch.save(model.state_dict(), MODEL_PATH)\n        best_accuracy = accuracy\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(TEST_FILE).reset_index(drop=True)\nX = df_test.values/255.\ndf_test['label'] = -1\ny = df_test.label.values\ntest_dataset = DigitDataset(X,y)\ntest_dataloader = DataLoader(test_dataset,batch_size =16,num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npredictions = []\nmodel.eval()\nfor bi , d in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n    pixels = d[\"pixels\"]\n    labels = d [\"labels\"]\n    pixels = pixels.to(device,dtype =torch.float)\n    labels = labels.to(device,dtype =torch.float)\n    \n    outputs = model(pixels)\n    pred = outputs.argmax(dim=1, keepdim=True)   \n    predictions.extend(pred.tolist())\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nsubmission = pd.read_csv(SUBMIT_FILE)\nsubmission.head()\nsubmission['Label'] = [int(pred[0]) for pred in  predictions]\n# accuracy = metrics.f1_score(submission['Label'].values, predictions,average='macro')*100\n# print(accuracy)\nsubmission.to_csv('/kaggle/working/submit_new.csv', index=False)\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}