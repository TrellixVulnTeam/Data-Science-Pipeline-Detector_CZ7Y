{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"section-top\"></a>\n# Table of Contents\n* [Introduction](#section-intro)\n* [1. Basic Processing, Data Preparation](#section-one)\n* [2. Visualizing Images](#section-two)\n* [3. Simple Model](#section-three)\n* [4. Simple Model with Data Augmentation](#section-four)\n    * [4.1 Data Augmentation](#section-four-one)\n    * [4.2 Feed Model with Augmented Data](#section-four-two)\n\n\n* [5. Adding few Layers](#section-five)\n* [6. Final Model](#section-six)\n* [7. Interpreting Results and Error Analysis](#section-seven)\n    * [7.1 Confusion Matrix](#section-seven-one)\n    * [7.2 Error Analysis](#section-seven-two)\n\n\n\n* [Conclusion](#section-conc)\n* [Readings, Resources](#section-read)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-intro\"></a>\n# Introduction\nIn this notebook, I will build a CNN network layer by layer. Visualize observations and results. Try something and see results. It is deep learning, enjoy it.","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport gc\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n\nimport tensorflow as tf\nfrom keras.utils.vis_utils import plot_model\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten, BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-11T00:25:57.226315Z","iopub.execute_input":"2021-11-11T00:25:57.227071Z","iopub.status.idle":"2021-11-11T00:26:02.785925Z","shell.execute_reply.started":"2021-11-11T00:25:57.226943Z","shell.execute_reply":"2021-11-11T00:26:02.784991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\nlen(tf.config.list_physical_devices('GPU'))","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:26:02.787923Z","iopub.execute_input":"2021-11-11T00:26:02.788228Z","iopub.status.idle":"2021-11-11T00:26:02.965707Z","shell.execute_reply.started":"2021-11-11T00:26:02.788197Z","shell.execute_reply":"2021-11-11T00:26:02.964939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Setting seed for reproducibility\n\nhttps://www.kaggle.com/lbronchal/keras-gpu-cpu-reproducibility-test","metadata":{}},{"cell_type":"code","source":"seed = 666\ntf.random.set_seed(seed)\nnp.random.seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)                      \nrandom.seed(666)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:26:02.967538Z","iopub.execute_input":"2021-11-11T00:26:02.968112Z","iopub.status.idle":"2021-11-11T00:26:02.976281Z","shell.execute_reply.started":"2021-11-11T00:26:02.968073Z","shell.execute_reply":"2021-11-11T00:26:02.975255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[take me to the top](#section-top)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n\n# 1. Basic Processing, Data Preparation","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n\nprint(f\"Training observations {train.shape[0]}, Test observations {test.shape[0]} \\n\")\n\ntrain.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:26:04.296594Z","iopub.execute_input":"2021-11-11T00:26:04.297371Z","iopub.status.idle":"2021-11-11T00:26:09.337111Z","shell.execute_reply.started":"2021-11-11T00:26:04.297326Z","shell.execute_reply":"2021-11-11T00:26:09.336279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have quitely balanced dataset, nice.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (8, 4))\n\nsns.countplot(data = train, x = \"label\", ax = ax, color = \"#101820\")\n\nax.set_title(\"Countplot for Train Labels\")\n\nsns.despine()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:26:09.338754Z","iopub.execute_input":"2021-11-11T00:26:09.341193Z","iopub.status.idle":"2021-11-11T00:26:09.729545Z","shell.execute_reply.started":"2021-11-11T00:26:09.341153Z","shell.execute_reply":"2021-11-11T00:26:09.728856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X = train.drop(\"label\", axis = 1)\ntrain_y = train[\"label\"]\n\ndel train\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:26:09.730782Z","iopub.execute_input":"2021-11-11T00:26:09.731282Z","iopub.status.idle":"2021-11-11T00:26:09.966012Z","shell.execute_reply.started":"2021-11-11T00:26:09.731239Z","shell.execute_reply":"2021-11-11T00:26:09.962699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Converting images to gray scale. It helps to converge CNN quickly.","metadata":{}},{"cell_type":"code","source":"train_X = train_X / 255\nX_test = test / 255\n\ndel test\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:26:09.970852Z","iopub.execute_input":"2021-11-11T00:26:09.971128Z","iopub.status.idle":"2021-11-11T00:26:10.316091Z","shell.execute_reply.started":"2021-11-11T00:26:09.971083Z","shell.execute_reply":"2021-11-11T00:26:10.315223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 784 pixel data, it means 28*28 pixel images.","metadata":{}},{"cell_type":"code","source":"print(f\"Training data shape: {train_X.shape} \\nTest data shape: {X_test.shape}\")\n\ntrain_X = train_X.values.reshape(-1, 28, 28, 1)\nX_test = X_test.values.reshape(-1, 28, 28, 1)\n\nprint(f\"Training data shape after rescaling: {train_X.shape} \\nTest data shape after rescaling: {X_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:26:10.317541Z","iopub.execute_input":"2021-11-11T00:26:10.3181Z","iopub.status.idle":"2021-11-11T00:26:10.329805Z","shell.execute_reply.started":"2021-11-11T00:26:10.318062Z","shell.execute_reply":"2021-11-11T00:26:10.32888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Converting label to one hot vectors.","metadata":{}},{"cell_type":"code","source":"train_y = to_categorical(train_y, num_classes = 10)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:26:10.331247Z","iopub.execute_input":"2021-11-11T00:26:10.334706Z","iopub.status.idle":"2021-11-11T00:26:10.343062Z","shell.execute_reply.started":"2021-11-11T00:26:10.334665Z","shell.execute_reply":"2021-11-11T00:26:10.339775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can see 100 images from training set from below.","metadata":{}},{"cell_type":"markdown","source":"[take me to the top](#section-top)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n\n# 2. Visualizing Images","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(1, figsize = (8, 8))\nfig.suptitle(\"Training Set Images (Sample)\")\n\nfor i in range(100):\n    \n    plt.subplot(10, 10, i + 1)\n    plt.imshow(train_X[i], cmap = plt.cm.binary)\n    plt.axis(\"off\")\n    \nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:26:10.345583Z","iopub.execute_input":"2021-11-11T00:26:10.346116Z","iopub.status.idle":"2021-11-11T00:26:14.4494Z","shell.execute_reply.started":"2021-11-11T00:26:10.346062Z","shell.execute_reply":"2021-11-11T00:26:14.448084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can see 100 images from test set from below. A couple of them is really hard to detectable, isn't it?","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(1, figsize = (8, 8))\nfig.suptitle(\"Test Set Images (Sample)\")\n\nfor i in range(100):\n    \n    plt.subplot(10, 10, i + 1)\n    plt.imshow(X_test[i], cmap = plt.cm.binary)\n    plt.axis(\"off\")\n    \nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:26:14.450442Z","iopub.execute_input":"2021-11-11T00:26:14.45068Z","iopub.status.idle":"2021-11-11T00:26:19.016572Z","shell.execute_reply.started":"2021-11-11T00:26:14.450649Z","shell.execute_reply":"2021-11-11T00:26:19.015705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating validation set with 10% of training data. It is enough.\n\nI also set stratify parameter for equally distributed labels.","metadata":{}},{"cell_type":"markdown","source":"[take me to the top](#section-top)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n\n# 3. Simple Model","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(train_X, \n                                                  train_y, \n                                                  test_size = 0.1, \n                                                  random_state = 666, \n                                                  stratify = train_y)\n\nprint(f\"Training set shape: {X_train.shape} \\nValidation set shape: {X_val.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:26:19.019531Z","iopub.execute_input":"2021-11-11T00:26:19.019889Z","iopub.status.idle":"2021-11-11T00:26:20.003026Z","shell.execute_reply.started":"2021-11-11T00:26:19.019846Z","shell.execute_reply":"2021-11-11T00:26:20.002097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, I will create a simple CNN model to see what we need. After looking first results, I will add some layers or doing something.\n\nFor first model, I will just use two convolutional layer with 32 filter, 3 kernel size with relu activation. Then, max pooling with (2, 2) pool size.","metadata":{}},{"cell_type":"code","source":"def simple_model():\n    \n    model = Sequential(\n        [\n            Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\", input_shape = (28, 28, 1)),\n            Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\"),\n            MaxPool2D(pool_size = (2, 2)),\n            \n            Flatten(),\n            Dense(units = 10, activation = \"softmax\")\n        ]\n    )\n    \n    model.compile(loss = \"categorical_crossentropy\", metrics = \"accuracy\", optimizer = \"adam\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:26:20.004607Z","iopub.execute_input":"2021-11-11T00:26:20.004876Z","iopub.status.idle":"2021-11-11T00:26:20.010925Z","shell.execute_reply.started":"2021-11-11T00:26:20.00484Z","shell.execute_reply":"2021-11-11T00:26:20.010199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = simple_model()\nmodel.summary()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-11T00:26:20.012313Z","iopub.execute_input":"2021-11-11T00:26:20.012828Z","iopub.status.idle":"2021-11-11T00:26:22.34488Z","shell.execute_reply.started":"2021-11-11T00:26:20.012789Z","shell.execute_reply":"2021-11-11T00:26:22.344082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Simple Model Architecture\\n\")\nplot_model(model, to_file = \"simple_model.png\", show_shapes = True, show_layer_names = True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:26:22.346301Z","iopub.execute_input":"2021-11-11T00:26:22.346747Z","iopub.status.idle":"2021-11-11T00:26:23.216759Z","shell.execute_reply.started":"2021-11-11T00:26:22.346708Z","shell.execute_reply":"2021-11-11T00:26:23.215884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    X_train, y_train, \n    validation_data = (X_val, y_val),\n    epochs = 10, batch_size = 64\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-11T00:26:23.21878Z","iopub.execute_input":"2021-11-11T00:26:23.219287Z","iopub.status.idle":"2021-11-11T00:27:04.942821Z","shell.execute_reply.started":"2021-11-11T00:26:23.219245Z","shell.execute_reply":"2021-11-11T00:27:04.942038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay, we have overfitting situation. We have high balance. To solve it, we can get more data. Data augmentation is one of the most important techniques for this situation, since we are working on image data.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n\nsns.lineplot(x = range(10), y = history.history[\"loss\"], ax = axes[0], label = \"Training Loss\")\nsns.lineplot(x = range(10), y = history.history[\"val_loss\"], ax = axes[0], label = \"Validation Loss\")\n\nsns.lineplot(x = range(10), y = history.history[\"accuracy\"], ax = axes[1], label = \"Training Accuracy\")\nsns.lineplot(x = range(10), y = history.history[\"val_accuracy\"], ax = axes[1], label = \"Validation Accuracy\")\naxes[0].set_title(\"Loss\"); axes[1].set_title(\"Accuracy\")\n\nsns.despine()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:27:04.944502Z","iopub.execute_input":"2021-11-11T00:27:04.944803Z","iopub.status.idle":"2021-11-11T00:27:05.418286Z","shell.execute_reply.started":"2021-11-11T00:27:04.94475Z","shell.execute_reply":"2021-11-11T00:27:05.417506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can create new images with using ImageDataGenerator class from Keras.\n\nIt takes an image, rotates, shifts, zooms etc.\n\nBut we have to be careful. We are working with number images and some augmentations could hurt our model. For example, if we use flipping, we get meaningles images, and for some numbers i.e. 6 and 9, it will cause a problem.","metadata":{}},{"cell_type":"markdown","source":"[take me to the top](#section-top)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n\n# 4. Simple Model with Data Augmentation","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-four-one\"></a>\n\n## 4.1 Data Augmentation","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range = 0.1,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    zoom_range = 0.15,\n    horizontal_flip = False, \n    vertical_flip = False\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:27:05.420062Z","iopub.execute_input":"2021-11-11T00:27:05.420822Z","iopub.status.idle":"2021-11-11T00:27:05.433493Z","shell.execute_reply.started":"2021-11-11T00:27:05.420746Z","shell.execute_reply":"2021-11-11T00:27:05.432575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At the top, we can see a random original image from training set.\n\nAt the bottom, we have its 30 copies with some rotation, shifting, etc.","metadata":{}},{"cell_type":"code","source":"sample_image = 12345\n\nplt.imshow(X_train[sample_image], cmap = plt.cm.binary)\nplt.title(\"Original Image\")\nplt.axis(\"off\"); plt.show()\n\naug = datagen.flow(X_train[sample_image].reshape(-1, 28, 28, 1), batch_size = 1)\n\nfig, axes = plt.subplots(3, 10, figsize = (15, 6))\naxes = axes.ravel()\n\nfor i in range(30):  \n    \n    aug_img = next(aug)[0]\n    axes[i].imshow(aug_img, cmap = plt.cm.binary)\n    axes[i].axis(\"off\")\n    \nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:27:05.436409Z","iopub.execute_input":"2021-11-11T00:27:05.442895Z","iopub.status.idle":"2021-11-11T00:27:07.474906Z","shell.execute_reply.started":"2021-11-11T00:27:05.442856Z","shell.execute_reply":"2021-11-11T00:27:07.474211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-four-two\"></a>\n\n## 4.2 Feed Model with Augmented Data","metadata":{}},{"cell_type":"code","source":"del model\n\n_ = gc.collect()\ntf.keras.backend.clear_session()\n\nmodel = simple_model()\n\nmodel.summary()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:27:07.476061Z","iopub.execute_input":"2021-11-11T00:27:07.476637Z","iopub.status.idle":"2021-11-11T00:27:07.713676Z","shell.execute_reply.started":"2021-11-11T00:27:07.476596Z","shell.execute_reply":"2021-11-11T00:27:07.712912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, I will use same model with augmented dataset. Let's examine it and then see what we will do.","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    datagen.flow(X_train, y_train, batch_size = 64),\n    epochs = 10, validation_data = (X_val, y_val),\n    steps_per_epoch = X_train.shape[0] // 64\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-11T00:27:07.715083Z","iopub.execute_input":"2021-11-11T00:27:07.715427Z","iopub.status.idle":"2021-11-11T00:30:06.960924Z","shell.execute_reply.started":"2021-11-11T00:27:07.715387Z","shell.execute_reply":"2021-11-11T00:30:06.960009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n\nsns.lineplot(x = range(10), y = history.history[\"loss\"], ax = axes[0], label = \"Training Loss\")\nsns.lineplot(x = range(10), y = history.history[\"val_loss\"], ax = axes[0], label = \"Valiidation Loss\")\n\nsns.lineplot(x = range(10), y = history.history[\"accuracy\"], ax = axes[1], label = \"Training Accuracy\")\nsns.lineplot(x = range(10), y = history.history[\"val_accuracy\"], ax = axes[1], label = \"Validation Accuracy\")\naxes[0].set_title(\"Loss\"); axes[1].set_title(\"Accuracy\")\n\nsns.despine()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:30:06.96259Z","iopub.execute_input":"2021-11-11T00:30:06.962884Z","iopub.status.idle":"2021-11-11T00:30:07.374738Z","shell.execute_reply.started":"2021-11-11T00:30:06.962845Z","shell.execute_reply":"2021-11-11T00:30:07.37401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay, our model didn't learn well, high bias. We use 10 epochs, we can increase that. Or, We can create bigger network and then we will look at what did happened.","metadata":{}},{"cell_type":"markdown","source":"I just add 2 convolutional layer with 64 filters, max pooling again and 0.3 dropout. We still have a simple model.","metadata":{}},{"cell_type":"markdown","source":"[take me to the top](#section-top)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-five\"></a>\n\n# 5. Adding few Layers","metadata":{}},{"cell_type":"code","source":"def simple_extra_layers():\n\n    model = Sequential(\n        [\n            Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\", input_shape = (28, 28, 1)),\n            Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\"),\n            MaxPool2D(pool_size = (2, 2)),\n\n            Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"),\n            Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"),\n            MaxPool2D(pool_size = (2, 2)),   \n            Dropout(0.3),\n\n            Flatten(),\n            Dense(units = 10, activation = \"softmax\")\n        ]\n    )\n\n    model.compile(loss = \"categorical_crossentropy\", metrics = \"accuracy\", optimizer = \"adam\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:30:07.377928Z","iopub.execute_input":"2021-11-11T00:30:07.378647Z","iopub.status.idle":"2021-11-11T00:30:07.386353Z","shell.execute_reply.started":"2021-11-11T00:30:07.378605Z","shell.execute_reply":"2021-11-11T00:30:07.385422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\n\n_ = gc.collect()\ntf.keras.backend.clear_session()\n\nmodel = simple_extra_layers()\n\nmodel.summary()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:30:07.387625Z","iopub.execute_input":"2021-11-11T00:30:07.38798Z","iopub.status.idle":"2021-11-11T00:30:07.671537Z","shell.execute_reply.started":"2021-11-11T00:30:07.387904Z","shell.execute_reply":"2021-11-11T00:30:07.670707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Adding a few extra layers to Simple Model\\n\")\n\nplot_model(model, to_file = \"few_extra_layers_model.png\", show_shapes = True, show_layer_names = True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:30:07.672907Z","iopub.execute_input":"2021-11-11T00:30:07.673191Z","iopub.status.idle":"2021-11-11T00:30:07.885004Z","shell.execute_reply.started":"2021-11-11T00:30:07.673135Z","shell.execute_reply":"2021-11-11T00:30:07.884118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    datagen.flow(X_train, y_train, batch_size = 64),\n    epochs = 10, validation_data = (X_val, y_val),\n    steps_per_epoch = X_train.shape[0] // 64\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-11T00:30:07.886749Z","iopub.execute_input":"2021-11-11T00:30:07.88762Z","iopub.status.idle":"2021-11-11T00:33:16.650947Z","shell.execute_reply.started":"2021-11-11T00:30:07.887573Z","shell.execute_reply":"2021-11-11T00:33:16.650156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n\nsns.lineplot(x = range(len(history.history[\"loss\"])), y = history.history[\"loss\"], ax = axes[0], label = \"Training Loss\")\nsns.lineplot(x = range(len(history.history[\"loss\"])), y = history.history[\"val_loss\"], ax = axes[0], label = \"Validation Loss\")\n\nsns.lineplot(x = range(len(history.history[\"accuracy\"])), y = history.history[\"accuracy\"], ax = axes[1], label = \"Training Accuracy\")\nsns.lineplot(x = range(len(history.history[\"accuracy\"])), y = history.history[\"val_accuracy\"], ax = axes[1], label = \"Validation Accuracy\")\naxes[0].set_title(\"Loss\"); axes[1].set_title(\"Accuracy\")\n\nsns.despine()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:33:16.652563Z","iopub.execute_input":"2021-11-11T00:33:16.652854Z","iopub.status.idle":"2021-11-11T00:33:17.08546Z","shell.execute_reply.started":"2021-11-11T00:33:16.652815Z","shell.execute_reply":"2021-11-11T00:33:17.084561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"High bias problem remains. If we increase epoch number, this problem could be solved. Or adding more layers, for example Batch Normalization can be helpful for converging faster.","metadata":{}},{"cell_type":"markdown","source":"[take me to the top](#section-top)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-six\"></a>\n\n# 6. Final Model","metadata":{}},{"cell_type":"markdown","source":"I just add BatchNormalization after convolutional layers and also, two fully connected layers (128 - 64 units) with batch normalization added before the output layer.","metadata":{}},{"cell_type":"code","source":"def final_model():\n\n    model = Sequential(\n        [\n            Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\", input_shape = (28, 28, 1)),\n            BatchNormalization(),\n            Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\"),\n            BatchNormalization(),\n            MaxPool2D(pool_size = (2, 2)),\n\n            Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"),\n            BatchNormalization(),\n            Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"),\n            BatchNormalization(),\n            MaxPool2D(pool_size = (2, 2)),   \n            Dropout(0.3),\n            \n            Flatten(),\n            Dense(units = 128, activation = \"relu\"),\n            BatchNormalization(),\n            Dense(units = 64, activation = \"relu\"),\n            BatchNormalization(),\n            Dense(units = 10, activation = \"softmax\")\n        ]\n    )\n\n    model.compile(loss = \"categorical_crossentropy\", metrics = \"accuracy\", optimizer = \"adam\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:33:17.086817Z","iopub.execute_input":"2021-11-11T00:33:17.087217Z","iopub.status.idle":"2021-11-11T00:33:17.096641Z","shell.execute_reply.started":"2021-11-11T00:33:17.08717Z","shell.execute_reply":"2021-11-11T00:33:17.095932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\n\n_ = gc.collect()\ntf.keras.backend.clear_session()\n\nmodel = final_model()\nmodel.summary()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:33:17.098392Z","iopub.execute_input":"2021-11-11T00:33:17.099236Z","iopub.status.idle":"2021-11-11T00:33:17.478912Z","shell.execute_reply.started":"2021-11-11T00:33:17.099117Z","shell.execute_reply":"2021-11-11T00:33:17.478092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Final Model Archtitecture\\n\")\n\nplot_model(model, to_file = \"final_model.png\", show_shapes = True, show_layer_names = True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:33:17.480133Z","iopub.execute_input":"2021-11-11T00:33:17.480404Z","iopub.status.idle":"2021-11-11T00:33:17.755961Z","shell.execute_reply.started":"2021-11-11T00:33:17.480366Z","shell.execute_reply":"2021-11-11T00:33:17.754982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we use more epochs, some callbacks will help us to prevent overfitting problem.\n\nReduceLROnPPlateau, reduces learning rate during training. It monitors a metric or loss, if results are not going well, it reduces learning rate.\n\nEarlyStopping, stops training if validation score doesn't improve. Important for prevent overfitting.\n\nCheckpoint, saves model when validation score improves.","metadata":{}},{"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(\n    monitor = \"val_accuracy\", \n    patience = 3,\n    verbose = 1, \n    factor = 0.5, \n    min_lr = 0.0000001\n)\n\nearly_stopping = EarlyStopping(\n    monitor = \"val_accuracy\",\n    patience = 10,\n    verbose = 1,\n    mode = \"max\",\n)\n\ncheckpoint = ModelCheckpoint(\n    monitor = \"val_accuracy\",\n    filepath = \"mnist_cnn.{epoch:02d}-{val_accuracy:.6f}.hdf5\",\n    verbose = 1,\n    save_best_only = True, \n    save_weights_only = True\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:33:17.758314Z","iopub.execute_input":"2021-11-11T00:33:17.758625Z","iopub.status.idle":"2021-11-11T00:33:17.765052Z","shell.execute_reply.started":"2021-11-11T00:33:17.758582Z","shell.execute_reply":"2021-11-11T00:33:17.763751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    datagen.flow(X_train, y_train, batch_size = 64),\n    epochs = 100, batch_size = 64, validation_data = (X_val, y_val),\n    steps_per_epoch = X_train.shape[0] // 64,\n    callbacks=[reduce_lr, early_stopping, checkpoint]\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-11T00:33:17.766792Z","iopub.execute_input":"2021-11-11T00:33:17.76715Z","iopub.status.idle":"2021-11-11T00:42:53.014982Z","shell.execute_reply.started":"2021-11-11T00:33:17.767105Z","shell.execute_reply":"2021-11-11T00:42:53.013699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\n\n_ = gc.collect()\ntf.keras.backend.clear_session()\n\nmodel = final_model()\nmodel.load_weights(\"./mnist_cnn.24-0.996429.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:43:08.923737Z","iopub.execute_input":"2021-11-11T00:43:08.923993Z","iopub.status.idle":"2021-11-11T00:43:21.288284Z","shell.execute_reply.started":"2021-11-11T00:43:08.923963Z","shell.execute_reply":"2021-11-11T00:43:21.287454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n\nsns.lineplot(x = range(len(history.history[\"loss\"])), y = history.history[\"loss\"], ax = axes[0], label = \"Training Loss\")\nsns.lineplot(x = range(len(history.history[\"loss\"])), y = history.history[\"val_loss\"], ax = axes[0], label = \"Validation Loss\")\n\nsns.lineplot(x = range(len(history.history[\"accuracy\"])), y = history.history[\"accuracy\"], ax = axes[1], label = \"Training Accuracy\")\nsns.lineplot(x = range(len(history.history[\"accuracy\"])), y = history.history[\"val_accuracy\"], ax = axes[1], label = \"Validation Accuracy\")\naxes[0].set_title(\"Loss\"); axes[1].set_title(\"Accuracy\")\n\nsns.despine()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:43:21.290042Z","iopub.execute_input":"2021-11-11T00:43:21.290326Z","iopub.status.idle":"2021-11-11T00:43:21.697597Z","shell.execute_reply.started":"2021-11-11T00:43:21.290286Z","shell.execute_reply":"2021-11-11T00:43:21.696881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nice, there is no problem. But now, let's look at the predictions.","metadata":{}},{"cell_type":"markdown","source":"[take me to the top](#section-top)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-seven\"></a>\n\n# 7. Interpreting Results and Error Analysis","metadata":{}},{"cell_type":"code","source":"val_preds = np.argmax(model.predict(X_val), axis = 1)\ntrain_preds = np.argmax(model.predict(X_train), axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:43:31.508431Z","iopub.execute_input":"2021-11-11T00:43:31.509251Z","iopub.status.idle":"2021-11-11T00:43:34.834551Z","shell.execute_reply.started":"2021-11-11T00:43:31.509201Z","shell.execute_reply":"2021-11-11T00:43:34.833717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-seven-one\"></a>\n\n## 7.1 Confusion Matrix","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize = (18, 6))\n\ncm_train = confusion_matrix(np.argmax(y_train, axis = 1), train_preds)\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm_train)\ndisp.plot(cmap = plt.cm.Blues, ax = axes[0])\n\ncm_val = confusion_matrix(np.argmax(y_val, axis = 1), val_preds)\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm_val)\ndisp.plot(cmap = plt.cm.Blues, ax = axes[1])\n\naxes[0].set_title(\"Training Set\"); axes[1].set_title(\"Validation Set\")\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:43:34.836035Z","iopub.execute_input":"2021-11-11T00:43:34.836304Z","iopub.status.idle":"2021-11-11T00:43:36.219886Z","shell.execute_reply.started":"2021-11-11T00:43:34.836268Z","shell.execute_reply":"2021-11-11T00:43:36.219088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at confusion matrix. Two things are noticeable. There is a confusion between 4-9 and 1-7.\n\nWe can see this problem both sets. \n\nOne more thing. I want to know how the model fails at 4-9. Let's look at images that the model predict wrong.","metadata":{}},{"cell_type":"markdown","source":"[take me to the top](#section-top)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-seven-two\"></a>\n\n## 7.2 Error Analysis","metadata":{}},{"cell_type":"code","source":"errors = (val_preds - np.argmax(y_val, axis = 1) != 0)\n\npred_error = val_preds[errors]\nobserved_error = np.argmax(y_val, axis = 1)[errors]\nimage_error = X_val[errors]\nlen(pred_error)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:43:42.06158Z","iopub.execute_input":"2021-11-11T00:43:42.06233Z","iopub.status.idle":"2021-11-11T00:43:42.070644Z","shell.execute_reply.started":"2021-11-11T00:43:42.062287Z","shell.execute_reply":"2021-11-11T00:43:42.069539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(1, figsize=(10, 10))\nfig.suptitle(\"Errors in Validation\")\n\nrows = int(len(pred_error) ** 0.5) - 1\ncols = int(len(pred_error) / rows) + 1\n\nfor i in range(len(pred_error)):\n    \n    plt.subplot(rows, cols, i + 1)\n    plt.imshow(image_error[i], cmap = plt.cm.binary)\n    plt.axis(\"off\")\n    plt.title(f\"True Value: {observed_error[i]} \\nPrediction: {pred_error[i]}\")\n    \nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:43:43.396748Z","iopub.execute_input":"2021-11-11T00:43:43.397366Z","iopub.status.idle":"2021-11-11T00:43:44.196654Z","shell.execute_reply.started":"2021-11-11T00:43:43.397326Z","shell.execute_reply":"2021-11-11T00:43:44.195868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"errors = (train_preds - np.argmax(y_train, axis = 1) != 0)\n\ntrain_pred_error = train_preds[errors]\ntrain_observed_error = np.argmax(y_train, axis = 1)[errors]\ntrain_image_error = X_train[errors]\nlen(train_pred_error)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:43:44.588444Z","iopub.execute_input":"2021-11-11T00:43:44.588717Z","iopub.status.idle":"2021-11-11T00:43:44.59851Z","shell.execute_reply.started":"2021-11-11T00:43:44.588685Z","shell.execute_reply":"2021-11-11T00:43:44.597646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(1, figsize = (15, 10))\nfig.suptitle(\"Errors in Training\")\n\nrows = int(len(train_pred_error) ** 0.5) - 1\ncols = int(len(train_pred_error) / rows) + 1\n\nfor i in range(len(train_pred_error)):\n    \n    plt.subplot(rows, cols, i + 1)\n    plt.imshow(train_image_error[i], cmap = plt.cm.binary)\n    plt.axis(\"off\")\n    plt.title(f\"True Value: {train_observed_error[i]} \\nPrediction: {train_pred_error[i]}\")\n    \nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-11T00:43:48.231063Z","iopub.execute_input":"2021-11-11T00:43:48.231325Z","iopub.status.idle":"2021-11-11T00:43:49.822877Z","shell.execute_reply.started":"2021-11-11T00:43:48.231295Z","shell.execute_reply":"2021-11-11T00:43:49.821637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hard to detect for human eyes.","metadata":{}},{"cell_type":"markdown","source":"[take me to the top](#section-top)","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")\n\npreds = np.argmax(model.predict(X_test), axis = 1)\nsubmission[\"Label\"] = preds\nsubmission.to_csv(\"cnn.csv\",index = False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-11-11T00:43:54.50315Z","iopub.execute_input":"2021-11-11T00:43:54.503692Z","iopub.status.idle":"2021-11-11T00:43:56.69917Z","shell.execute_reply.started":"2021-11-11T00:43:54.503634Z","shell.execute_reply":"2021-11-11T00:43:56.698412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[take me to the top](#section-top)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-conc\"></a>\n\n# Conclusion","metadata":{}},{"cell_type":"markdown","source":"In machine learning - deep learning, I think, the most important think is to know what you do. If you have knowledge about how they work, you can code it without much effort. Try lots of things, fail, add or change something, fail, try different idea, fail. Finally, you can success.\n\nIt is like a computer game.","metadata":{}},{"cell_type":"markdown","source":"[take me to the top](#section-top)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-read\"></a>\n\n# Readings, Resources","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6?rvi=1\n\nhttps://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist\n\nhttps://www.kaggle.com/lbronchal/keras-gpu-cpu-reproducibility-test\n\n\nAndrew NG's Deep Learning course is as good as his Machine Learning course. If you need theory, you should look at it.\n\nhttps://keras.io/examples/vision/\n\nFinally, I want to say that, Keras has one of the best documentations that I read. You should take a look at. It will motivate you.","metadata":{}},{"cell_type":"markdown","source":"[take me to the top](#section-top)","metadata":{}}]}