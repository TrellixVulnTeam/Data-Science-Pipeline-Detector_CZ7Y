{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Digit Recognizer Submission\nThe code starts with the imports and data handling/preprocessing.","metadata":{}},{"cell_type":"code","source":"# Set-up code partially from \"Deep Neural Network Keras Way\" notebook\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tensorflow import keras\nfrom keras import layers\nfrom sklearn.model_selection import train_test_split\nfrom keras import  backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\n# read train and test sets\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\nprint(train.shape)\ntest= pd.read_csv(\"../input/digit-recognizer/test.csv\")\nprint(test.shape)\n\n# set up training and testing data\nX_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\ny_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\nX_test = test.values.astype('float32')\n\nX_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n\nfor i in range(6, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-16T02:08:00.943844Z","iopub.execute_input":"2021-06-16T02:08:00.944174Z","iopub.status.idle":"2021-06-16T02:08:05.042745Z","shell.execute_reply.started":"2021-06-16T02:08:00.944144Z","shell.execute_reply":"2021-06-16T02:08:05.04176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Preprocessing (from the aforementioned notebook)\nmean_px = X_train.mean().astype(np.float32)\nstd_px = X_train.std().astype(np.float32)\n\ndef standardize(x): \n    return (x-mean_px)/std_px\n\nfrom keras.utils.np_utils import to_categorical\ny_train= to_categorical(y_train)\nnum_classes = y_train.shape[1]\nnum_classes","metadata":{"execution":{"iopub.status.busy":"2021-06-16T02:08:05.044657Z","iopub.execute_input":"2021-06-16T02:08:05.045035Z","iopub.status.idle":"2021-06-16T02:08:05.143306Z","shell.execute_reply.started":"2021-06-16T02:08:05.044997Z","shell.execute_reply":"2021-06-16T02:08:05.14204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fix random seed for reproducibility\nseed = 43\nnp.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T02:08:07.183367Z","iopub.execute_input":"2021-06-16T02:08:07.18369Z","iopub.status.idle":"2021-06-16T02:08:07.188226Z","shell.execute_reply.started":"2021-06-16T02:08:07.183662Z","shell.execute_reply":"2021-06-16T02:08:07.187311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Model\nI am using a convolutional neural network with the following architecture:\n\n1. InputLayer(28, 28, 1)\n2. Preprocessing\n3. Conv2D(kernel_size=3, filters=32, activation='relu')\n4. BatchNormalization\n5. Conv2D(kernel_size=3, filters=64, activation='relu')\n6. BatchNormalization\n7. Conv2D(kernel_size=5, filters=128, activation='relu')\n8. BatchNormalization\n9. Conv2D(kernel_size=5, filters=128, activation='relu')\n10. MaxPool2D\n11. BatchNormalization\n12. Flatten\n13. Dense(units=1024,activation='relu')\n14. Dense(units=10, activation='softmax')","metadata":{}},{"cell_type":"code","source":"# Function for the model\ndef my_model():\n# Building the model\n    model = keras.Sequential([\n        layers.InputLayer(input_shape=[28,28,1]),\n        preprocessing.RandomContrast(0.2),\n        preprocessing.RandomTranslation(height_factor=0.1,width_factor=0.1),\n        layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n        layers.BatchNormalization(axis=1),\n        layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n        layers.BatchNormalization(axis=1),\n        layers.Conv2D(filters=128, kernel_size=5, activation='relu'),\n        layers.BatchNormalization(axis=1),\n        layers.Conv2D(filters=128, kernel_size=5, activation='relu'),\n        layers.MaxPool2D(),\n        layers.BatchNormalization(axis=1),\n        layers.Flatten(),\n        layers.Dense(units=1024,activation='relu'),\n        layers.Dense(units=10, activation='softmax')\n    ])\n\n    # Compiling the model with 'adam' optimizer,\n    # \"categorical_crossentropy\" loss, and \"accuracy\" metric\n    model.compile(\n        optimizer='adam',\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-16T03:17:52.027359Z","iopub.execute_input":"2021-06-16T03:17:52.027693Z","iopub.status.idle":"2021-06-16T03:17:52.037509Z","shell.execute_reply.started":"2021-06-16T03:17:52.027664Z","shell.execute_reply":"2021-06-16T03:17:52.036826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepares data for training\nfrom sklearn.model_selection import train_test_split\nX = X_train\ny = y_train\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T03:25:31.592938Z","iopub.execute_input":"2021-06-16T03:25:31.593243Z","iopub.status.idle":"2021-06-16T03:25:31.601604Z","shell.execute_reply.started":"2021-06-16T03:25:31.593215Z","shell.execute_reply":"2021-06-16T03:25:31.600848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model with Early Stopping\ncallback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\nmodel = my_model()\nhistory=model.fit(\n    X_train, y_train,\n    validation_data = (X_val, y_val),\n    epochs=50,\n    callbacks=[callback]\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T03:25:33.264002Z","iopub.execute_input":"2021-06-16T03:25:33.264304Z","iopub.status.idle":"2021-06-16T03:25:39.637589Z","shell.execute_reply.started":"2021-06-16T03:25:33.264275Z","shell.execute_reply":"2021-06-16T03:25:39.636895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This model trains to a maximum validation accuracy of about 97%.\n\nNow the model will be trained on the whole training data for final submission.","metadata":{}},{"cell_type":"code","source":"# train final model with all of the training data\ncallback_final = keras.callbacks.EarlyStopping(monitor='loss', patience=10, verbose=1, restore_best_weights=True)\nfinal_model= my_model()\nhistory=final_model.fit(X, y, epochs=50, callbacks=[callback_final])","metadata":{"execution":{"iopub.status.busy":"2021-06-16T03:25:47.8705Z","iopub.execute_input":"2021-06-16T03:25:47.870839Z","iopub.status.idle":"2021-06-16T03:25:55.364086Z","shell.execute_reply.started":"2021-06-16T03:25:47.870811Z","shell.execute_reply":"2021-06-16T03:25:55.363177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final submission\npredictions = model.predict(X_test, verbose=0)\npredictions_final = predictions.argmax(axis=1)\nprint(predictions_final)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions_final)+1)),\n                         \"Label\": predictions_final})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)\nprint(\"Finished uploading submission file to csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-16T03:42:09.682041Z","iopub.execute_input":"2021-06-16T03:42:09.68237Z","iopub.status.idle":"2021-06-16T03:42:11.346179Z","shell.execute_reply.started":"2021-06-16T03:42:09.682317Z","shell.execute_reply":"2021-06-16T03:42:11.34525Z"},"trusted":true},"execution_count":null,"outputs":[]}]}