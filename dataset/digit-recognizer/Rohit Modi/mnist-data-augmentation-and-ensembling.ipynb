{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nprint(os.listdir(\"../input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense,BatchNormalization, Dropout\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\nimport csv\nimport gc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will assess the working of neural nets on the MNIST digits dataset using three approaches :\n1. **Using the standard neural network architecture.**\n2. **Using the convolutional neural network architecture.**\n3. **Adding Data Augmentation and then using the convolutional neural network architecture.**"},{"metadata":{},"cell_type":"markdown","source":"First we need to load and process the data, as the data provided in not in form of images but rather in form of a dataframe. Lets check what data is provided in the dataframe."},{"metadata":{"trusted":true,"_uuid":"c686efb084f88e02a22c3dd707816fbb4b16a249"},"cell_type":"code","source":"# defining data directory paths\ntrain_dir = \"../input/train.csv\"\ntest_dir = \"../input/test.csv\"\n\ndf = pd.read_csv(train_dir)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The dataframe contains image labels defining which class the particular image belongs to, also the columns ranging pixel0 - pixel738 contains a value for that particular pixel.\n* The image is of the size 28x28"},{"metadata":{},"cell_type":"markdown","source":"**Defining Labels :** extracting labels from dataframe -> converting to numpy array -> converting to one-hot format.\n"},{"metadata":{"trusted":true,"_uuid":"76b5c27be96220b05954c57f26047df582fb6110"},"cell_type":"code","source":"labels = df[\"label\"].values.tolist() # extracting labels from the database and converting it into a list\nlabels = np.array(labels)\n\nn_classes = len(set(labels)) # defining number of classes\n\nlabels = keras.utils.to_categorical(labels) # converting the labels to one-hot format","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training data :** Extracting from dataframe -> converting to list -> numpy array -> scaling into range 0-1."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df.drop([\"label\"], axis = 1) # extracting the image data\ndata = df_train.values.tolist() # converting image data to list\ndata = np.array(data)\ndata = data.astype('float32')/255.0 # converting data into range 0-1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting an image from each class to get insight on image data.\nPlotting 5 images from each class"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"dataframes_i = []\nfor i in range(10):\n    tempdf = None\n    tempdf = df[df[\"label\"]==i].drop([\"label\"], axis = 1)\n    temp = tempdf.values.tolist()\n    dataframes_i.append(temp[0:5])\n    \nfig = plt.figure(figsize = (8,20)) #defining figure\ndef plot_images(image, index):\n    fig.add_subplot(10,5, index)\n    plt.axis(\"on\")\n    plt.tick_params(left = False, bottom=False, labelbottom=False, labelleft = False,)\n    plt.imshow(image, cmap = 'Greys')\n    return\n\nindex = 1\nfor i in dataframes_i:\n    for j in i:\n        x = np.array(j)\n        x = x.reshape(28,28)\n        plot_images(x, index)\n        index += 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking shape of training data and labels"},{"metadata":{"trusted":true,"_uuid":"3140ad671af8d5fc64532b78647a487744478e23"},"cell_type":"code","source":"print(\"Training data shape = \" + str(data.shape))\nprint(\"Training labels shape = \" + str(labels.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Defining Standard Neural Network** : \nNow that we have the training data and labels we will define a simple neural network."},{"metadata":{"trusted":true,"_uuid":"7c5ef6683de35441945a2afb95e8f9cf2f1e941d"},"cell_type":"code","source":"gen_model = Sequential()\ngen_model.add(Dense(784, activation = 'relu', input_shape = (784,)))\ngen_model.add(Dense(512, activation = 'relu'))\ngen_model.add(Dense(264, activation = 'relu'))\ngen_model.add(Dense(10, activation = 'softmax'))\nprint(\"STANDARD NEURAL NETWORK MODEL :-\")\ngen_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1fd515d01a1668fbcd326cc5010b9792c893e75"},"cell_type":"code","source":"gen_model.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adadelta(), metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2a19f908cfc3738166b1c1d388304934ff4ae84"},"cell_type":"code","source":"gen_model_hist = gen_model.fit(data, labels, batch_size = 32, epochs = 5, validation_split = 0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now plotting the training and validation accuracy plots :"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(gen_model_hist.history[\"acc\"])\nplt.plot(gen_model_hist.history[\"val_acc\"])\nplt.title(\"Training vs Validation Accuracy\")\nplt.legend([\"Training\",\"Validation\"], loc = 'lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"del gen_model, gen_model_hist\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CONVOLUTIONAL NEURAL NETWORK**"},{"metadata":{},"cell_type":"markdown","source":"Now we will use the convolutional neural network architecture to train the model, for this we need to modify our data as :\n* reshaping the training data into (n, 28, 28, 1) as there is only one channel and image is of size 28x28."},{"metadata":{"trusted":true,"_uuid":"bd9a2c23683e28639199c092eafcbd067b3e8035"},"cell_type":"code","source":"X_train_cnn = data.reshape(len(data), 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Defining the CNN model :**"},{"metadata":{"trusted":true,"_uuid":"c3b3994b90bb52716d45b8de585dc3563295b402"},"cell_type":"code","source":"cnn_model = Sequential()\ncnn_model.add(Conv2D(32, kernel_size = [3,3], activation = 'relu', input_shape = (28,28,1)))\ncnn_model.add(Conv2D(64, kernel_size = [3,3], activation = 'relu'))\ncnn_model.add(BatchNormalization())\ncnn_model.add(MaxPool2D(pool_size = [2,2], strides = 2))\ncnn_model.add(Conv2D(128, kernel_size = [3,3], activation = 'relu'))\ncnn_model.add(MaxPool2D(pool_size = [2,2], strides = 2))\ncnn_model.add(Flatten())\ncnn_model.add(Dense(512, activation = 'relu'))\ncnn_model.add(Dense(10, activation = 'softmax'))\nprint(\"CONVOLUTIONAL NEURAL NETWORK MODEL :-\")\ncnn_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compiling and fitting the data in the model."},{"metadata":{"trusted":true,"_uuid":"229bbe39d2fb559fb28c5f94f52ec8917d58205b","scrolled":true},"cell_type":"code","source":"cnn_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\ncnn_model_hist = cnn_model.fit(X_train_cnn, labels, batch_size = 32, epochs = 6, validation_split = 0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the model metrics:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(cnn_model_hist.history[\"acc\"])\nplt.plot(cnn_model_hist.history[\"val_acc\"])\nplt.title(\"Training vs Validation Accuracy (CNN Model)\")\nplt.legend([\"Training\",\"Validation\"], loc = 'lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"del cnn_model, cnn_model_hist\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9630c19733feaa4d9d444bf3a066219ec0366649"},"cell_type":"markdown","source":"**ADDING DATA AUGMENTATION AND ENSEMBLING MODELS:**"},{"metadata":{},"cell_type":"markdown","source":"Now we will train 7 different classifiers on the cnn architecture and then use them for preditions.\n1. We will build 7 different models.\n2. Train those models on different splits of data.\n3. Use those models for predictions as : we take the mode from the predictions."},{"metadata":{},"cell_type":"markdown","source":"As we are adding the data augmentation and training models several times, this process will take some time."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_aug = ImageDataGenerator(featurewise_center = False,\n                             samplewise_center = False,\n                             featurewise_std_normalization = False,\n                             samplewise_std_normalization = False,\n                             zca_whitening = False,\n                             rotation_range = 10,\n                             zoom_range = 0.1,\n                             width_shift_range = 0.1,\n                             height_shift_range = 0.1,\n                             horizontal_flip = False,\n                             vertical_flip = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining several models\nmodels_ensemble = []\nfor i in range(7):\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size = [3,3], activation = 'relu', input_shape = (28,28,1)))\n    model.add(Conv2D(64, kernel_size = [3,3], activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size = [2,2], strides = 2))\n    model.add(Conv2D(128, kernel_size = [3,3], activation = 'relu'))\n    model.add(MaxPool2D(pool_size = [2,2], strides = 2))\n    model.add(Flatten())\n    model.add(Dense(512, activation = 'relu'))\n    model.add(Dense(10, activation = 'softmax'))\n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    models_ensemble.append(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining training routine\nmodel_histories = []\ni = 1\nfor model in models_ensemble:\n    xtrain, xtest, ytrain, ytest = train_test_split(X_train_cnn, labels, test_size = 0.07)\n    print(\"Model \" +str(i)+ \" : \",end=\"\")\n    model_history = model.fit_generator(data_aug.flow(xtrain, ytrain, batch_size = 64), epochs = 1, verbose = 1, validation_data = (xtest, ytest), steps_per_epoch = xtrain.shape[0])\n    model_histories.append(model_history)\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we will use all our models to make predictions**\n* Make predictions from one model -> add to list -> repeat for all models -> then we will find the mode of predictions -> use it as final prediction."},{"metadata":{"trusted":true,"_uuid":"d1bac8d4acaed8dbfb4e66704e3c4a6a3e92c686"},"cell_type":"code","source":"# import and preprocess test data\ntestdata = pd.read_csv(test_dir)\ntestdata = testdata.values.tolist()\ntestdata = np.array(testdata)\ntestdata_reshaped = testdata.reshape(testdata.shape[0], 28, 28, 1)\ntestdata_reshaped = testdata_reshaped.astype('float')/255.0\n\ndef make_predictions_final_model(curr_model):\n    prediction_array = curr_model.predict_on_batch(testdata_reshaped)\n    predictions = [np.argmax(i) for i in prediction_array]\n    return predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Firstly we will make predictions on each model and then save it into lists, this will create 5 different prediction lists.\n* Then we will use these lists to make new list exclusively for each image which will contain predictions from each model.\n* Finally we will find the mode from each list and then append it to a new list which will be the final predictions for our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_ensemble = [] \n\n# Make predictions using seperate models\nfor model in models_ensemble:\n    curr_predictions = make_predictions_final_model(model)\n    predictions_ensemble.append(curr_predictions)\n\nprediction_per_image = []\n# Make a list of predictions for a particular image \nfor i in range(len(predictions_ensemble[0])):\n    temppred = [predictions_ensemble[0][i], predictions_ensemble[1][i], predictions_ensemble[2][i], predictions_ensemble[3][i], predictions_ensemble[4][i], predictions_ensemble[5][i], predictions_ensemble[6][i]]\n    prediction_per_image.append(temppred)\n    \n# Find the maximum occuring element in the array (list)\nprediction_per_image = np.array(prediction_per_image)\nmodes = stats.mode(prediction_per_image, axis = 1)\n\n# append the modes to the final prediction list\nfinal_predictions = []      \nfor i in modes[0]:\n    final_predictions.append(i[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating the output csv file."},{"metadata":{"trusted":true,"_uuid":"7f662fa8ee0d86345f235740fabc1303f645c459"},"cell_type":"code","source":"final_csv = []\ncsv_title = ['ImageId', 'Label']\nfinal_csv.append(csv_title)\nfor i in range(len(final_predictions)):\n    image_id = i + 1\n    label = final_predictions[i]\n    temp = [image_id, label]\n    final_csv.append(temp)\n\nprint(len(final_csv))\n\nwith open('submission_csv_aug.csv', 'w') as file:\n    writer = csv.writer(file)\n    writer.writerows(final_csv)\nfile.close()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}