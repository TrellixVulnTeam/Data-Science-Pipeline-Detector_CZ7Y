{"cells":[{"metadata":{},"cell_type":"markdown","source":"# COMPONENTS OF THIS PROJECT\n### 1- Introduction\n\n### 1- Data exploration\n\n### 2- Convolutional neural networks\n\n### 3- CNN model evaluation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1- Introduction:\n\nIn this competition, the goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. 10 digits are represented in this dataset [0 1 2 3 4 5 6 7 8 9 ]. We will try to preprocess the images and the labels and then feed the convolutional neural nets with those preprocessed images to classify them. The output will be the prediction of the digit represented in the image.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.datasets import mnist\nimport keras.utils.np_utils as ku\nimport keras.models as models\nimport keras.layers as layers\nfrom keras import regularizers\nimport numpy.random as nr\n\nimport keras\nfrom keras.layers import Dropout\nfrom keras.optimizers import rmsprop, Adam\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport warnings\nwarnings.simplefilter(action='ignore')\n\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We start by opening our train and test datasets","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest=pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The table shows the 784 pixels of the pictures with the digits. We will need some preprocessing to reshape and scale the values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ## 1.1 Target and features\n\n\nWe set the target and the features:\n* Target: Labels\n* Features: train set without labels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"target=train['label']\ntrain.drop('label',axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.countplot(target, color='crimson')\nplt.title('The distribution of the digits in the dataset', weight='bold', fontsize='18')\nplt.xticks(weight='bold', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have here the distribution of the digits in this dataset. They are all equally represented. We don't have any class imbalance here so we can go forward with our preprocessing.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ### 1.2 Standardize the values","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Models created with Keras, and most other deep learning frameworks, operate on floating point numbers. The gray scale pixel values of the images are coded as integers in the range  {0,255}\n\n* These pixel values must be coerced to floating point and then standardized to be in a range  {0.0,1.0}\n\n* As is the case for training many machine learning models, it is best to use standardized values for training deep neural networks.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train/255\ntest=test/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train=train.values.reshape(-1,28,28,1)\nTest=test.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### 1.3 Data visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here is a glimpse of what we will be dealing with:\n\n* Images of handwritten Digits from 0 to 9 \n* We will feed those images to the CNN in order to learn and predict the test images.\n* ** We have below an example of 60 digit images from this dataset**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nfor i in range(60):\n    plt.subplot(6,10,i+1)\n    plt.imshow(Train[i].reshape((28,28)),cmap='binary')\n    plt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### 1.4 Encoding target:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The labels are coded as integers corresponding to the digit in the image. We use One Hot Encoding to encode each label","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Target=ku.to_categorical(target, num_classes=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The shape of the labels before One Hot Encoding\",target.shape)\nprint(\"The shape of the labels after One Hot Encoding\",Target.shape)\nprint(\"We have 10 columns for the 10 digits\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of the first image with label: '1' after OHE\")\nprint(Target[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After reshaping the features and encoding the labels, we split them to train and test sets\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ### 1.5 Split: Train/Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test=train_test_split(Train, Target, test_size=0.10, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2 Convolutional neural networks","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n> ## 2.1 Model parameters:\n>### Regularization:\n\n>> #### l2 Regularization\nWe will use l2 regularization, l2 regularization applies a penalty proportional to the l2 or Euclidean norm of the model weights to the loss function (Also called Ridge regression in sklearn).\n\n> #### Dropout\nWe will also apply dropout regularization to train our CNN. We'll  define a neural network with a dropout layer with  𝑝=0.5 (Half of the nodes are dropped).\n\n>### Activation functions\n>>* The **ReLu** function:  rectilinear activation function is used for the hidden units.\n\n>>* The **softmax** activation function is used for multi-class classifiers (Classification of 10 digits)\n\n>### Padding\nThe coverage of the convolution opertor can be expanded by zero padding in the spatial dimenstion. With the zero padding added, the convolution operator covers the entire spatial dimension of the input tensor. \n\n>>* We add zero padding to convolutional layers with the parameter **padding = same**. It adds zero padding\n\n>### CNN Architecture\n* A multi-layer convolutional neural network to create a **feature map.**\n> * **Con2D** is used to build feature maps from the data\n> * **MaxPooling** is used to reduce dimensionality. In MaxPooling, the output value is just the maximum of the input values in each patch (for ex. The maximum pixel in a span of 3 pixels).\n* A fully-connected hidden layer to perform the **classification.**\n* An output layer to **identify the digits**.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ## 2.1 Building the model:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> **1 CNN model: Without Batch normalization**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nn=models.Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Add some convolutional layers to extract features = Feature map\n\nnn.add(layers.Conv2D(16, (3, 3), padding = 'same', activation = 'relu', input_shape = (28, 28, 1)))\nnn.add(layers.MaxPooling2D((2, 2)))\nnn.add(layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu', input_shape = (28, 28, 1)))\nnn.add(layers.MaxPooling2D((2, 2)))\nnn.add(layers.Conv2D(64, (3, 3), padding = 'same', activation = 'relu'))\nnn.add(layers.MaxPooling2D((2, 2)))\nnn.add(layers.Conv2D(64, (3, 3), padding = 'same', activation = 'relu'))\nnn.add(layers.MaxPooling2D((2, 2)))\n\n\n## latten the output of the convolutional layers so that fully connected network can be applied\nnn.add(layers.Flatten())\n\n## Finally, fully connected layers to classify the digits using the extracted features\nnn.add(layers.Dense(64, activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\nnn.add(Dropout(0.5))\nnn.add(layers.Dense(64, activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\nnn.add(Dropout(0.5))\nnn.add(layers.Dense(10, activation = 'softmax'))\n\nnn.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **2 CNN model: With Batch normalization**\n* Batch normalization is used to increase the stability of a neural network, batch normalization normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation.\n* It reduces overfitting because it has a slight regularization effects. Similar to dropout, it adds some noise to each hidden layer’s activations. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nn1=models.Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Add some convolutional layers to extract features = Feature map\nnn1=models.Sequential()\nnn1.add(layers.Conv2D(16, (3, 3), padding = 'same', activation = 'relu', input_shape = (28, 28, 1)))\nnn1.add(BatchNormalization())\nnn1.add(layers.MaxPooling2D((2, 2)))\nnn1.add(layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu', input_shape = (28, 28, 1)))\nnn1.add(BatchNormalization())\nnn1.add(layers.MaxPooling2D((2, 2)))\nnn1.add(BatchNormalization())\nnn1.add(layers.Conv2D(64, (3, 3), padding = 'same', activation = 'relu'))\nnn1.add(BatchNormalization())\nnn1.add(layers.MaxPooling2D((2, 2)))\n\n## latten the output of the convolutional layers so that fully connected network can be applied\nnn1.add(layers.Flatten())\n\n## Finally, fully connected layers to classify the digits using the extracted features\nnn1.add(layers.Dense(64, activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\nnn1.add(Dropout(0.5))\nnn1.add(layers.Dense(64, activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\nnn1.add(Dropout(0.5))\nnn1.add(layers.Dense(10, activation = 'softmax'))\n\nnn1.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optimization:\n\nWe will use **RMSprop**:\n* RMSprop accumulates a measure of the squared gradient to change the learning rate. An exponential decay is applied to the accumulated squared gradient to ensure that more recent experience dominates the learning rate.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nn1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Early stopping** terminates the training of the neural network model at an epoch before it becomes over-fit. We set the patience to epochs=5\n * The first callback, EarlyStopping, is for the early stopping method.\n * The second call back checkpoints or saves the current model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = 'my_model_file.hdf5' # define where the model is saved\ncallbacks_list = [\n        keras.callbacks.EarlyStopping(\n            monitor = 'val_loss', # Use accuracy to monitor the model\n            patience = 5 # Stop after 5 steps with lower accuracy\n        ),\n        keras.callbacks.ModelCheckpoint(\n            filepath = filepath, # file where the checkpoint is saved\n            monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n            save_best_only = True)]# Only save model if it is the best","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">### 2.3 Data augmentation:\n\nIn order to avoid overfitting, we generate new images out of the existing images with some changes (rotation, zoom, width and height shift)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        rotation_range=15,\n        zoom_range = 0.15,\n        width_shift_range=0.15,\n        height_shift_range=0.15)\ndatagen.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">### 2.4 Training the model:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> **(Check the output button for the training description)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history = nn.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n                              epochs = 25, validation_data = (x_test,y_test),\n                              steps_per_epoch=len(x_train) / 128, \n                              callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history2 = nn1.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n                              epochs = 25, validation_data = (x_test,y_test),\n                              steps_per_epoch=len(x_train) / 128, verbose=1,\n                              callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Early Stopping terminated the training at 29 epochs (Check the output of the cell above)**. The model reached 99% accuracy in the 27th epoch but didn't improve afterwards.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":">### 2.5 Digits prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted = nn.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted2 = nn1.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3 CNN Model Evaluation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":">### 3.1 Loss and accuracy","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.style.use('seaborn')\nsns.set_style('whitegrid')\nfig = plt.figure(figsize=(15,10))\n#First Model\nax1 = plt.subplot2grid((2,2),(0,0))\ntrain_loss = history.history['loss']\ntest_loss = history.history['val_loss']\nx = list(range(1, len(test_loss) + 1))\nplt.plot(x, test_loss, color = 'cyan', label = 'Test loss')\nplt.plot(x, train_loss, label = 'Training losss')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Model 1: Loss vs. Epoch',weight='bold', fontsize=18)\nax1 = plt.subplot2grid((2,2),(0,1))\ntrain_acc = history.history['accuracy']\ntest_acc = history.history['val_accuracy']\nx = list(range(1, len(test_acc) + 1))\nplt.plot(x, test_acc, color = 'cyan', label = 'Test accuracy')\nplt.plot(x, train_acc, label = 'Training accuracy')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Model 1: Accuracy vs. Epoch', weight='bold', fontsize=18)  \n\n#Second Model\n\nax1 = plt.subplot2grid((2,2),(1,0))\ntrain_loss = history2.history['loss']\ntest_loss = history2.history['val_loss']\nx = list(range(1, len(test_loss) + 1))\nplt.plot(x, test_loss, color = 'cyan', label = 'Test loss')\nplt.plot(x, train_loss, label = 'Training losss')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Model 2: Loss vs. Epoch',weight='bold', fontsize=18)\n\nax1 = plt.subplot2grid((2,2),(1,1))\ntrain_acc = history2.history['accuracy']\ntest_acc = history2.history['val_accuracy']\nx = list(range(1, len(test_acc) + 1))\nplt.plot(x, test_acc, color = 'cyan', label = 'Test accuracy')\nplt.plot(x, train_acc, label = 'Training accuracy')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Model 2: Accuracy vs. Epoch', weight='bold', fontsize=18)  \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Model 1**: The train/test accuracy and loss results look good. Our model didn't overfit.\n* **Model 2**: Batch normalization reduced overfitting.\n* Next, we check the confusion matrix to see the mistakes done by the classifier","execution_count":null},{"metadata":{},"cell_type":"markdown","source":">### 3.2 Confusion matrix","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ny_class = np.argmax(predicted, axis = 1) \n\ny_check = np.argmax(y_test, axis = 1) \n\ncmatrix = confusion_matrix(y_check, y_class)\n\nplt.figure(figsize=(15,8))\nplt.title('Confusion matrix of the test/predicted digits ', weight='bold', fontsize=18)\nsns.heatmap(cmatrix,annot=True,cmap=\"Reds\",fmt=\"d\",cbar=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Good news! Just few misclassified digits, we can see that most of the mistakes are between digits that are kind of similar \n\n>### 3.3 Examples of misclassied digits:\n\n* Here we have 36 misclassified digits:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#We use np.argmax with y_test and predicted values: transform them from 10D vector to 1D\nclass_y = np.argmax(y_test,axis = 1) \nclass_num=np.argmax(predicted, axis=1)\n#Detect the errors\nerrors = (class_num - class_y != 0)\n#Localize the error images\npredicted_er = predicted[errors]\ny_test_er = y_test[errors]\nx_test_er = x_test[errors]\n\n                \n#Plot the misclassified numbers\nplt.figure(figsize=(15,9))\n\nfor i in range(30):\n    plt.subplot(5,6,i+1)\n    plt.imshow(x_test_er[i].reshape((28,28)),cmap='binary')\n    plt.title( np.argmax(predicted_er[i]), size=13, weight='bold', color='red')\n    plt.axis(\"off\")\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have the predicted values in red colors along with the misclassified images. What's interesting here is that the error is more from the humans than from the machine, some digits are written in an uncomprehensive way, it's difficult even for us to read some of these handwritings. I would have guessed the same as the machine in many of these cases.\n\n* The digits shown in the section \"**1.3 Data visualization**\" are readable and clear in comparison to these misclassified digits. We plot them again in the figure below to notice the difference.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\n\nfor i in range(30):\n    plt.subplot(5,6,i+1)\n    plt.imshow(Train[i].reshape((28,28)),cmap='binary')\n    plt.axis(\"off\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Effectively, the misclassified digit are not clear in comparison with the rest of the digits. We reached a 99% accuracy and it could have been higher if the misclassified digits were written in a comprehensive way.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4 Submission","execution_count":null},{"metadata":{},"cell_type":"markdown","source":">Finally, we are done with our analysis. We fit the models on the test data\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final = nn.predict(Test)\nfinal = np.argmax(final,axis = 1)\nfinal = pd.Series(final, name=\"Label\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">Create our CSV file and submit to competition","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,len(Test)+1),name = \"ImageId\"),final],axis = 1)\n\nsubmission.to_csv(\"CNN_digit_recognizer.csv\", index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}