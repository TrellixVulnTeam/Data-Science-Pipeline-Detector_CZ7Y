{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd_train = pd.read_csv('../input/digit-recognizer/train.csv')\n\n\nx_train = pd_train.drop(['label'], axis=1)\ny_train = pd_train['label']\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nx_train_vis = np.array(x_train).reshape(x_train.shape[0], 28, 28)\n\nfig, axis = plt.subplots(1, 4, figsize=(20, 10))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(x_train_vis[i], cmap='binary')\n    digit = y_train[i]\n    ax.set(title = f\"Real Number is {digit}\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = x_train / 255.0\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.2, shuffle=True, stratify=y_train, random_state=26)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import np_utils\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import Dropout, Flatten,Activation , Dense","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(X_train).reshape(-1,28,28,1)\nX_val = np.array(X_val).reshape(-1,28,28,1)\nY_train = np_utils.to_categorical(np.array(Y_train))\nY_val = np_utils.to_categorical(np.array(Y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This step is data augmentation. In order to prevent overfitting of the model, we do some adjustment to the training image\n#so that it dosent over fit\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.01, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ntrain_gen = datagen.flow(X_train, Y_train, batch_size=32)\ntest_gen = datagen.flow(X_val, Y_val, batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\n\n#model.add(Lambda(standardize,input_shape=(28,28,1)))    \nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=(28,28,1)))\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())    \n\nmodel.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\n    \nmodel.add(Flatten())\nmodel.add(Dense(512,activation=\"relu\"))\n    \nmodel.add(Dense(10,activation=\"softmax\"))\n    \nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = './model_out.h5'\ncheckpointer = ModelCheckpoint(\n    filepath=model_path,\n    monitor='val_accuracy',\n    verbose=1,\n    mode='max',\n    save_best_only=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(train_gen, \n                              epochs = 100, \n                              validation_data = test_gen,\n                              callbacks = [checkpointer])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing resuming training from saved model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel = load_model('model_out.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_2 = model.fit_generator(train_gen, \n                              initial_epoch = 100,\n                              epochs = 200, \n                              validation_data = test_gen,\n                              callbacks = [checkpointer])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Doing the submission stuff","metadata":{}},{"cell_type":"code","source":"pd_test = pd.read_csv('../input/digit-recognizer/test.csv')\nx_test = pd_test\nx_test = x_test/255.0\nX_test = np.array(x_test).reshape(-1,28,28,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('./model_out.h5')\ny_pred = model.predict(X_test)\ny_pred = np.argmax(y_pred,1)\npd_submit = pd.read_csv('../input/digit-recognizer/sample_submission.csv')\npd_submit['Label'] = y_pred\npd_submit.to_csv('submit.csv', header=True, index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trying out different CNN model (Modified LeNet-5)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation, BatchNormalization\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport math","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd_train = pd.read_csv('../input/digit-recognizer/train.csv')\n\n\nx_train = pd_train.drop(['label'], axis=1)\ny_train = pd_train['label']\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nx_train_vis = np.array(x_train).reshape(x_train.shape[0], 28, 28)\n\nfig, axis = plt.subplots(1, 4, figsize=(20, 10))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(x_train_vis[i], cmap='binary')\n    digit = y_train[i]\n    ax.set(title = f\"Real Number is {digit}\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = x_train / 255.0\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.2, shuffle=True, stratify=y_train, random_state=26)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import np_utils\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import Dropout, Flatten,Activation , Dense","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(X_train).reshape(-1,28,28,1)\nX_val = np.array(X_val).reshape(-1,28,28,1)\nY_train = np_utils.to_categorical(np.array(Y_train))\nY_val = np_utils.to_categorical(np.array(Y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This step is data augmentation. In order to prevent overfitting of the model, we do some adjustment to the training image\n#so that it dosent over fit\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.01, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ntrain_gen = datagen.flow(X_train, Y_train, batch_size=32)\ntest_gen = datagen.flow(X_val, Y_val, batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def LeNet5v2(input_shape=(28,28,1), classes = 10):\n    \"\"\"\n    Implementation of a modified LeNet-5.\n    Only those layers with learnable parameters are counted in the layer numbering.\n    \n    Arguments:\n    input_shape -- shape of the images of the dataset\n    classes -- integer, number of classes\n\n    Returns:\n    model -- a Model() instance in Keras\n    \"\"\"\n    \n    model = Sequential([\n        \n    # Layer 1\n    Conv2D(filters = 32, kernel_size = 5, strides = 1, activation = 'relu', input_shape=(28,28,1), kernel_regularizer=l2(0.0005), name = 'convolution_1'),\n    \n    # Layer 2\n    Conv2D(filters = 32, kernel_size = 5, strides = 1, name = 'convolution_2', use_bias=False),\n    \n    # Layer 3    \n    BatchNormalization(name = 'batchnorm_1'),\n        \n    # -------------------------------- #  \n    Activation(\"relu\"),\n    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_1'),\n    Dropout(0.25, name = 'dropout_1'),\n    # -------------------------------- #  \n        \n    # Layer 3\n    Conv2D(filters = 64, kernel_size = 3, strides = 1, activation = 'relu', kernel_regularizer=l2(0.0005), name = 'convolution_3'),\n        \n    # Layer 4\n    Conv2D(filters = 64, kernel_size = 3, strides = 1, name = 'convolution_4', use_bias=False),\n        \n    # Layer 5\n    BatchNormalization(name = 'batchnorm_2'),\n        \n    # -------------------------------- #  \n    Activation(\"relu\"),\n    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_2'),\n    Dropout(0.25, name = 'dropout_2'),\n    Flatten(name = 'flatten'),\n    # -------------------------------- #  \n        \n    # Layer 6\n    Dense(units = 256, name = 'fully_connected_1', use_bias=False),\n        \n    # Layer 7\n    BatchNormalization(name = 'batchnorm_3'),\n    \n    # -------------------------------- #  \n    Activation(\"relu\"),\n    # -------------------------------- #  \n        \n    # Layer 8\n    Dense(units = 128, name = 'fully_connected_2', use_bias=False),\n        \n    # Layer 9\n    BatchNormalization(name = 'batchnorm_4'),\n        \n    # -------------------------------- #  \n    Activation(\"relu\"),\n    # -------------------------------- #  \n        \n    # Layer 10\n    Dense(units = 84, name = 'fully_connected_3', use_bias=False),\n        \n    # Layer 11\n    BatchNormalization(name = 'batchnorm_5'),\n        \n    # -------------------------------- #  \n    Activation(\"relu\"),\n    Dropout(0.25, name = 'dropout_3'),\n    # -------------------------------- #  \n\n    # Output\n    Dense(units = 10, activation = 'softmax', name = 'output')\n        \n    ])\n    \n    model._name = 'LeNet5v2'\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LeNet5Model = LeNet5v2(input_shape = (28, 28, 1), classes = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LeNet5Model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"variable_learning_rate  = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001, verbose=1)\n\nmodel_path = './model_out.h5'\ncheckpointer = ModelCheckpoint( filepath=model_path, monitor='val_accuracy', verbose=1, mode='max', save_best_only=True)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LeNet5Model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = LeNet5Model.fit_generator(train_gen, epochs = 100, callbacks = [variable_learning_rate , checkpointer], validation_data = test_gen)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"variable_learning_rate  = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n\nmodel_path = './model_out_loss.h5'\ncheckpointer = ModelCheckpoint( filepath=model_path, monitor='val_loss', verbose=1, mode='min', save_best_only=True)\n\nmodel_path_2 = './model_out.h5'\ncheckpointer_2 = ModelCheckpoint( filepath=model_path_2, monitor='val_accuracy', verbose=1, mode='max', save_best_only=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd_test = pd.read_csv('../input/digit-recognizer/test.csv')\nx_test = pd_test\nx_test = x_test/255.0\nX_test = np.array(x_test).reshape(-1,28,28,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel = load_model('./model_out.h5')\ny_pred = model.predict(X_test)\ny_pred = np.argmax(y_pred,1)\npd_submit = pd.read_csv('../input/digit-recognizer/sample_submission.csv')\npd_submit['Label'] = y_pred\npd_submit.to_csv('submit.csv', header=True, index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}