{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PyTorch CNN for Digit Recognition\n\nThis kernel provides a simple CNN approach, in order to classify the digit images provided in this dataset.\n\nFirst, we import the relevant libraries and modules and load the data into two dataframes.","metadata":{}},{"cell_type":"code","source":"import itertools\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom matplotlib.colors import LinearSegmentedColormap\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\n\n# Data Loading\ntraindf = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntestdf = pd.read_csv(\"../input/digit-recognizer/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:48:48.954015Z","iopub.execute_input":"2022-04-10T22:48:48.954424Z","iopub.status.idle":"2022-04-10T22:48:57.166733Z","shell.execute_reply.started":"2022-04-10T22:48:48.954325Z","shell.execute_reply":"2022-04-10T22:48:57.165959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we perform some basic re-definitions.","metadata":{}},{"cell_type":"code","source":"traindf.rename(columns={'label' : 'Digit'}, inplace=True)\nfor i in range(traindf.shape[1]-1):\n    traindf.rename(columns={'pixel'+str(i) : 'Pixel '+str(i+1)}, inplace=True)\ntestdf.rename(columns={'label' : 'Digit'}, inplace=True)\nfor i in range(traindf.shape[1]-1):\n    testdf.rename(columns={'pixel'+str(i) : 'Pixel '+str(i+1)}, inplace=True)\n\n# Load the required data into numpy arrays\ny = traindf['Digit'].to_numpy().astype(int)\nX = traindf.iloc[:,1:].values\nX_final_test = testdf.values\nprint('All data have been loaded into numpy arrays.')\n\nX = np.reshape(X, (X.shape[0], 28, 28))\nX_final_test = np.reshape(X_final_test, (X_final_test.shape[0], 28, 28))","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:49:00.283004Z","iopub.execute_input":"2022-04-10T22:49:00.283933Z","iopub.status.idle":"2022-04-10T22:49:01.235179Z","shell.execute_reply.started":"2022-04-10T22:49:00.28389Z","shell.execute_reply":"2022-04-10T22:49:01.234139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At this point we define a custom dataset class in order to form datasets using the data, which are then split into training/validation/testing sub-datasets and loaded into PyTorch DataLoaders.","metadata":{}},{"cell_type":"code","source":"class CustomDatasetNN(Dataset):\n    def __init__(self, feats, labels):\n        self.feats = feats\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.feats)\n\n    def __getitem__(self, item):\n        img = self.feats[item]\n        tensoring = transforms.ToTensor()\n        normalizer = transforms.Normalize((0.1307,), (0.3081,))\n\n        img = tensoring(img).float()\n        img = normalizer(img)\n        return img, self.labels[item]\n\nbatch_size = 300    \n\nmodel_debug = True # Set to False when the code is ready to be deployed for the final predictions\nif model_debug:\n    # Take 60% for training\n    X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n    # Split the remaining 15% for validation and 25% for testing\n    X_test, X_val, y_test, y_val = train_test_split(X_rest, y_rest, test_size=0.375, random_state=42, stratify=y_rest)\n    \n    test_data = CustomDatasetNN(X_test,y_test)\n    test_loader = DataLoader(test_data,batch_size=batch_size,shuffle=True)\nelse:\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n\ntrain_data = CustomDatasetNN(X_train,y_train)\nval_data = CustomDatasetNN(X_val,y_val)\ntrain_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\nval_loader = DataLoader(val_data,batch_size=batch_size,shuffle=True)\n\ny_final_test = np.zeros(X_final_test.shape[0]) # Dummy array\nfinal_data = CustomDatasetNN(X_final_test,y_final_test)\nfinal_loader = DataLoader(final_data,batch_size=1,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:49:03.280186Z","iopub.execute_input":"2022-04-10T22:49:03.280432Z","iopub.status.idle":"2022-04-10T22:49:03.728757Z","shell.execute_reply.started":"2022-04-10T22:49:03.280404Z","shell.execute_reply":"2022-04-10T22:49:03.727885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before moving on to the CNN model, we provide some auxiliary functions useful for some visualizations during the model's debugging, where we use our own test set.","metadata":{}},{"cell_type":"code","source":"# Auxiliary Functions\n\nimport seaborn as sns\nsns.set(style = \"darkgrid\") # Personal preference\n\ndef CustomCmap(from_rgb,to_rgb):\n\n    # from color r,g,b\n    r1,g1,b1 = from_rgb\n\n    # to color r,g,b\n    r2,g2,b2 = to_rgb\n\n    cdict = {'red': ((0, r1, r1),\n                   (1, r2, r2)),\n           'green': ((0, g1, g1),\n                    (1, g2, g2)),\n           'blue': ((0, b1, b1),\n                   (1, b2, b2))}\n\n    cmap = LinearSegmentedColormap('custom_cmap', cdict)\n    return cmap\n\nmycmap = CustomCmap([1.0, 1.0, 1.0], [72/255, 99/255, 147/255])\nmycmap_r = CustomCmap([72/255, 99/255, 147/255], [1.0, 1.0, 1.0])\n\nmycol = (72/255, 99/255, 147/255)\nmycomplcol = (129/255, 143/255, 163/255)\n\ndef plot_cm(cfmatrix,title,classes):\n    fig, ax1 = plt.subplots(1,1) #, figsize=(5,5)\n\n    for ax,cm in zip([ax1],[cfmatrix]):\n        im = ax.imshow(cm, interpolation='nearest', cmap=mycmap)\n        divider = make_axes_locatable(ax)\n        cax = divider.append_axes(\"right\", size=\"5%\", pad=.2)\n        plt.colorbar(im, cax=cax) #, ticks=[-1,-0.5,0,0.5,1]\n        ax.set_title(title,fontsize=14)\n        tick_marks = np.arange(len(classes))\n        ax.set_xticks(tick_marks)\n        ax.set_xticklabels(classes, rotation=90)\n        ax.set_yticks(tick_marks)\n        ax.set_yticklabels(classes)\n\n        fmt = 'd'\n        thresh = cm.max() / 2.\n\n        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n            ax.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n        ax.set_ylabel('True label',fontsize=14)\n        ax.set_xlabel('Predicted label',fontsize=14)\n\n    plt.savefig(title+'.pdf', bbox_inches='tight')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:49:05.998909Z","iopub.execute_input":"2022-04-10T22:49:05.999157Z","iopub.status.idle":"2022-04-10T22:49:06.070147Z","shell.execute_reply.started":"2022-04-10T22:49:05.99913Z","shell.execute_reply":"2022-04-10T22:49:06.069451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following corresponds to the CNN setup.","metadata":{}},{"cell_type":"code","source":"class CNNBackbone(nn.Module):\n    def __init__(self, input_height, input_width, conv_channels, kernels, maxpools, lin_channels, dropout, batchnorm):\n        \"\"\"\n        Agrs:\n            input_height (int):\n                image height in pixels\n            input_width (int):\n                image width in pixels\n            conv_channels (list):\n                contains the input and output channels for each\n                convolutional layer, therefore using a total of\n                len(channels)-1 convolutional layers\n            kernels (list):\n                contains the kernel sizes to be considered per\n                convolution. Must have length len(channels)-1\n            maxpools (list):\n                contains the MaxPool2d kernel sizes to be considered\n                per convolution. Must have length len(channels)-1\n            lin_channels (list):\n                contains the output channels for each linear layer\n                following the convolutions, therefore using a total of\n                len(lin_channels) linear layers.\n                Note that the last element must be equal to the number\n                of classes to be determined.\n            classes (int):\n                number of output features\n            dropout (float):\n                dropout probability, 0 <= dropout <= 1\n            batchnorm (bool):\n                boolean parameter to control whether batch normalization\n                is applied or not.\n        \"\"\"\n        super(CNNBackbone, self).__init__()\n        self.num_conv_layers = len(kernels)\n        self.batchnorm = batchnorm\n        \n        seq = []\n        for i in range(self.num_conv_layers):\n            seq.append(nn.Conv2d(in_channels=conv_channels[i], \n                                 out_channels=conv_channels[i+1],\n                                 kernel_size=kernels[i], stride=1, padding=1))\n            seq.append(nn.ReLU())\n            if self.batchnorm:\n                seq.append(nn.BatchNorm2d(num_features=conv_channels[i+1],track_running_stats=False))\n            seq.append(nn.MaxPool2d(kernel_size=maxpools[i]))\n            \n        # Flatten the output of the final convolution layer\n        seq.append(nn.Flatten())\n        \n        convolutions = nn.Sequential(*seq)\n        \n        # Calculation of first linear layer dimensions\n        # We build an empty tensor of appropriate size and let him go through\n        # the above sequence, in order to calculate the output's size automatically\n        first_lin = convolutions(torch.empty(1,conv_channels[0],input_height,input_width)).size(-1)\n        \n        self.num_lin_layers = len(lin_channels)\n        for i in range(self.num_lin_layers):\n            if i == self.num_lin_layers-1:\n                seq.append(nn.Linear(lin_channels[i-1], lin_channels[i]))\n                break\n            elif i == 0:\n                seq.append(nn.Linear(first_lin, lin_channels[i]))\n            else:\n                seq.append(nn.Linear(lin_channels[i-1], lin_channels[i]))\n            seq.append(nn.ReLU())\n            seq.append(nn.Dropout(dropout))\n                \n        self.fitter = nn.Sequential(*seq)\n\n    def forward(self, x):\n        \"\"\"CNN forward\n        Args:\n            x (torch.Tensor):\n                [B, S, F] Batch size x sequence length x feature size\n                padded inputs\n        Returns:\n            torch.Tensor: [B, O] Batch size x CNN output size cnn outputs\n        \"\"\"\n        out = self.fitter(x)\n        return out\n    \ndef load_backbone_from_checkpoint(model, checkpoint_path):\n    model.load_state_dict(torch.load(checkpoint_path))\n    \n# adapted code from this repository: https://github.com/Bjarten/early-stopping-pytorch\nclass EarlyStopping:\n    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(f'Validation loss increase spotted. Early stopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss\n\ndef training_loop(model, train_dataloader, optimizer, device=\"cuda\"):\n    model.train()\n    batch_losses = []\n            \n    for batch in train_dataloader:\n        x_batch, y_batch = batch\n                \n        # Move to device\n        x_batch, y_batch = x_batch.float().to(device), y_batch.type(torch.LongTensor).to(device)\n                \n        # Clear the previous gradients first\n        optimizer.zero_grad()\n        \n        # forward pass\n        yhat = model(x_batch) # No unpacking occurs in CNNs\n        \n        # loss calculation\n        loss = loss_function(yhat, y_batch)\n        \n        # Backward pass\n        loss.backward()\n        \n        # Update weights\n        optimizer.step()\n        \n        batch_losses.append(loss.data.item())\n        \n    train_loss = np.mean(batch_losses)\n\n    return train_loss\n\n\ndef validation_loop(model, val_dataloader, device=\"cuda\"):\n    \n    model.eval()\n    batch_losses = []\n    \n    for batch in val_dataloader:\n        x_batch, y_batch = batch\n                \n        # Move to device\n        x_batch, y_batch = x_batch.float().to(device), y_batch.type(torch.LongTensor).to(device)\n        \n        yhat = model(x_batch) # No unpacking occurs in CNNs\n        \n        loss = loss_function(yhat, y_batch)\n        \n        batch_losses.append(loss.data.item())\n        \n    val_loss = np.mean(batch_losses)\n\n    return val_loss # Return validation_loss and anything else you need\n\n\ndef train(model, train_dataloader, val_dataloader, optimizer, epochs, device=\"cuda\", patience=-1, verbose_ct=100):\n\n    train_losses = []\n    val_losses = []\n    print(f\"Initiating CNN training.\")\n    model_path = f'CNN.pt'\n    checkpoint_path = 'checkpoint.pt'\n        \n    if patience != -1:\n        early_stopping = EarlyStopping(patience=patience, verbose=False, path=checkpoint_path)\n\n    for epoch in range(epochs):\n        \n        # Training loop\n        train_loss = training_loop(model, train_dataloader, optimizer, device)    \n        train_losses.append(train_loss)\n\n        # Validation loop\n        with torch.no_grad():\n\n            val_loss = validation_loop(model, val_dataloader, device)\n            val_losses.append(val_loss)\n\n        if patience != -1:\n            early_stopping(val_loss, model)\n\n            if early_stopping.early_stop:\n                print(\"Patience limit reached. Early stopping and going back to last checkpoint.\")\n                break\n\n        if epoch % verbose_ct == 0:        \n            print(f\"[{epoch+1}/{epochs}] Training loss: {train_loss:.4f}\\t Validation loss: {val_loss:.4f}.\")\n\n    if patience != -1 and early_stopping.early_stop == True:\n        load_backbone_from_checkpoint(model,checkpoint_path)        \n\n    torch.save(model.state_dict(), model_path)\n\n    print(f\"CNN training finished.\\n\")\n    \n    return train_losses, val_losses\n    \ndef evaluate(model, test_dataloader, device=\"cuda\"):\n    model.eval()\n    predictions = []\n    labels = []\n    \n    with torch.no_grad():\n        for batch in test_dataloader:\n            \n            x_batch, y_batch = batch\n                \n            # Move to device\n            x_batch, y_batch = x_batch.float().to(device), y_batch.type(torch.LongTensor).to(device)\n            \n            yhat = model(x_batch) # No unpacking occurs in CNNs\n            \n            # Calculate the index of the maximum argument\n            yhat_idx = torch.argmax(yhat, dim=1)\n            \n            predictions.append(yhat_idx.cpu().numpy())\n            labels.append(y_batch.cpu().numpy())\n    \n    return predictions, labels  # Return the model predictions\n\n# Small code to plot losses after training\ndef plot_losses(train_losses,val_losses,title):\n    plt.plot(train_losses, label=\"Training loss\", color=mycol)\n    plt.plot(val_losses, label=\"Validation loss\", color=mycomplcol)\n    plt.legend(loc='best')\n    plt.ylabel('Mean Loss')\n    plt.xlabel('Epochs')\n    plt.title(f\"Loss graph during the process of training the CNN.\")\n    plt.savefig(title, bbox_inches='tight')\n    plt.show() \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:49:07.757897Z","iopub.execute_input":"2022-04-10T22:49:07.75843Z","iopub.status.idle":"2022-04-10T22:49:07.843895Z","shell.execute_reply.started":"2022-04-10T22:49:07.758387Z","shell.execute_reply":"2022-04-10T22:49:07.843044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we run the model in order to make predictions.","metadata":{}},{"cell_type":"code","source":"input_height, input_width = 28, 28\nconv_channels = [1,4,16,32,64]\nkernels = [3,3,3,3]\nmaxpools = [2,2,2,2]\nlin_channels = [128,64,10]\ndropout = 0.2\nlearning_rate = 0.0001\nweight_decay = 1e-6\npatience = 10\nverbose_ct = 1\n\nepochs = 2500\n\nmodel = CNNBackbone(input_height = input_height, input_width = input_width,\n                    conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,\n                    lin_channels = lin_channels, dropout = dropout, batchnorm=True)\nmodel.to(device)\nloss_function = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n\n# Train the model\nt_losses, v_losses = train(model, train_loader, val_loader, optimizer, epochs,\n                           device=device, patience=patience, verbose_ct = verbose_ct)\n\n# Plot the loss diagram\nplot_losses(t_losses, v_losses, 'CNN_Training_Loss.pdf')\n\nif model_debug:\n    # Evaluate the model\n    predictions, labels = evaluate(model, test_loader, device=device)\n\n    y_true = np.concatenate(labels, axis=0)\n    y_pred = np.concatenate(predictions, axis=0)\n\n    print(classification_report(y_true, y_pred))\nelse:\n    # Final Predictions\n    predictions, labels = evaluate(model, final_loader, device=device)\n\n    y_pred = np.concatenate(predictions, axis=0)\n    x_idx = np.arange(X_final_test.shape[0])+1\n    \n    final_df = pd.DataFrame({'ImageId':x_idx, 'Label':y_pred})\n    final_df.to_csv('submission.csv', index=False)\n    print('Submission file is ready.')","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:49:10.320814Z","iopub.execute_input":"2022-04-10T22:49:10.321257Z","iopub.status.idle":"2022-04-10T22:51:18.035421Z","shell.execute_reply.started":"2022-04-10T22:49:10.321221Z","shell.execute_reply":"2022-04-10T22:51:18.034651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}