{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","file_extension":".py","version":"3.6.3","nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python"}},"nbformat":4,"cells":[{"source":"CNN classifier for handwritten digits of the MNIST dataset. The dataset consists of 42000 images of size 28x28 = 784 pixels (one color number) including the corresponding labels from 0,..,9. The basic architecture of the NN is given by:\n\n- Layer: input = [42000,784]\n- Layer: Conv1 -> ReLu -> MaxPool: [.,14,14,32] \n- Layer: Conv2 -> ReLu -> MaxPool: [.,7,7,64]\n- Layer: FC -> ReLu: [.,1024]\n- Layer: FC -> ReLu: [.,10]\n\nUsing a split of 95%/5% on the labeled data this implementation, trained on 40000 training images for 8 epochs with suitable hyperparameters, achieves a 99.45% accuracy on the validation set of 2000 images.\n\n## Libraries and Settings","cell_type":"markdown","metadata":{"_cell_guid":"ae26a5da-aab9-47a2-b7dd-644778615a16","_uuid":"8abac6e9d07e55338b420f9789904bc957f8fa0c"}},{"execution_count":null,"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm # cm = colormap\nimport tensorflow as tf\n%matplotlib inline\nimport os;\nimport itertools\n\ndir_logs = os.getcwd()+'/logs'; # directory to save models\nval_set_size = 2000; # validation set size \n\n#display parent directory and working directory\nprint(os.path.dirname(os.getcwd())+':', os.listdir(os.path.dirname(os.getcwd())));\nprint(os.getcwd()+':', os.listdir(os.getcwd()));","cell_type":"code","metadata":{"_cell_guid":"8fc7ff0a-f896-485a-9628-2f4c639942d0","_uuid":"420cf9cf5d64f79d38869ba265edfd759f1e4865"},"outputs":[]},{"source":"## Data Preprocessing","cell_type":"markdown","metadata":{"_cell_guid":"e1bd0032-cf12-45cd-840d-bbe8b36b8383","_uuid":"15744e6161356ffdfaba3da0eb55c469f187a246"}},{"execution_count":null,"source":"## read training and validation data [42000,785] dataframe\n\nif os.path.isfile('../input/train.csv'):\n    data = pd.read_csv('../input/train.csv') # on kaggle \n    print('train.csv loaded: data({0[0]},{0[1]})'.format(data.shape))\nelif os.path.isfile('data/train.csv'):\n    data = pd.read_csv('data/train.csv') # on local environment\n    print('train.csv loaded: data({0[0]},{0[1]})'.format(data.shape))\nelse:\n    print('Error: train.csv not found')","cell_type":"code","metadata":{"_cell_guid":"1c4dc51a-add1-410d-a586-58e934d0afd5","_uuid":"cd465ec1f9f87cfe2432ad669e81bf142aac1352"},"outputs":[]},{"execution_count":null,"source":"## look at data and split into training and validation sets\n\n# extract images\nimages = data.iloc[:,1:].values # (42000,784) array\nimages = images.astype(np.float) # convert from int64 to float\nimages = np.multiply(images, 1.0 / 255.0) # convert from [0:255] to [0.0:1.0]\nimage_size = images.shape[1] # = 784\nimage_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8) # = 28\n\n# extract image labels\nlabels_flat = data.iloc[:,0].values\nlabels_count = np.unique(labels_flat).shape[0]; # number of different labels = 10\n\n#plot some images and labels\nplt.figure(figsize=(15,2))\nfor i in range(0,10):\n    plt.subplot(2,10,1+i)\n    plt.title(labels_flat[i])\n    plt.imshow(images[i].reshape(image_width,image_height),cmap=cm.binary)\n    \n# convert class labels from scalars to one-hot vectors e.g. 1 => [0 1 0 0 0 0 0 0 0 0]\ndef dense_to_one_hot(labels_dense, num_classes):\n    num_labels = labels_dense.shape[0]\n    index_offset = np.arange(num_labels) * num_classes\n    labels_one_hot = np.zeros((num_labels, num_classes))\n    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n    return labels_one_hot\n\n# labels in one hot representation\nlabels = dense_to_one_hot(labels_flat, labels_count).astype(np.uint8)\n#labels = labels.astype(np.uint8)\n\n# split data into training & validation\ntrain_images = images[val_set_size:]\ntrain_labels = labels[val_set_size:]\nval_images = images[:val_set_size]\nval_labels = labels[:val_set_size]\n\nprint('images({0[0]},{0[1]}),'.format(images.shape),'labels_flat({0[0]})'.format(labels_flat.shape))\nprint('train_images({0[0]},{0[1]})'.format(train_images.shape),'labels({0[0]},{0[1]})'.format(labels.shape),'val_images({0[0]},{0[1]})'.format(val_images.shape),'val_labels({0[0]},{0[1]})'.format(val_labels.shape))\nprint ('image_size = {0}, image_width = {1}, image_height = {2}, labels_count = {3}'.format(image_size,image_width,image_height,labels_count))\n","cell_type":"code","metadata":{"_cell_guid":"64f637d5-34c4-49ea-a743-fbc1b2cd917b","_uuid":"4021b771e17a5f9787c9b71ad5c6733c92ec860c"},"outputs":[]},{"source":"## TensorFlow Graph","cell_type":"markdown","metadata":{"_cell_guid":"1eff9850-60ba-4f02-8de7-941865a8d91c","_uuid":"21a49993c6e32b06ca3cb76a76d4c688ac15a161"}},{"execution_count":null,"source":"#tf.set_random_seed(1)\n#np.random.seed(1)\n\n# weight and bias initialization\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape) #  positive bias\n    return tf.Variable(initial)\n\n# 2D convolution\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\n# max pooling\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n# variables for input and output \nx = tf.placeholder('float', shape=[None, image_size])\ny_ = tf.placeholder('float', shape=[None, labels_count])\n\n# 1. layer: convolution + max pooling\nimage = tf.reshape(x, [-1,28,28,1]) # (.,784) => (.,28,28,1)\nW_conv1 = weight_variable([5, 5, 1, 32]) # (5,5,1,32)\nb_conv1 = bias_variable([32]) # (32)\nh_conv1 = tf.nn.relu(conv2d(image, W_conv1) + b_conv1) # => (.,28,28,32)\nh_pool1 = max_pool_2x2(h_conv1) # => (.,14,14,32)\n\n# 2. layer: convolution + max pooling\nW_conv2 = weight_variable([5, 5, 32, 64])\nb_conv2 = bias_variable([64])\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # => (.,14,14,64)\nh_pool2 = max_pool_2x2(h_conv2) # => (.,7,7,64)\n\n# 3.layer: fully connected\nW_fc1 = weight_variable([7*7*64,1024])\nb_fc1 = bias_variable([1024])\nh_pool2_flat = tf.reshape(h_pool2, [-1,7*7*64]) # (.,7,7,64) => (.,3136)\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) # => (.,1024)\n\n# dropout\ntf_keep_prob = tf.placeholder('float')\nh_fc1_drop = tf.nn.dropout(h_fc1, tf_keep_prob)\n\n# 4.layer: fully connected\nW_fc2 = weight_variable([1024, labels_count])\nb_fc2 = bias_variable([labels_count])\ny = tf.matmul(h_fc1_drop, W_fc2) + b_fc2 # => (.,10)\n\n# cost function\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n\n# optimisation function\nglobal_step = tf.Variable(0, trainable=False)\ntf_learn_rate = tf.placeholder(dtype='float', name=\"tf_learn_rate\")\ntrain_step = tf.train.AdamOptimizer(tf_learn_rate).minimize(cross_entropy)\n\n# evaluation\ncorrect_prediction = tf.equal(tf.argmax(tf.nn.softmax(y),1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n\n# prediction function\npredict = tf.argmax(tf.nn.softmax(y),1) # [0.1, 0.9, 0.2, 0.1, 0.1 0.3, 0.5, 0.1, 0.2, 0.3] => 1\n\n# function: to get the next mini batch\ndef next_batch(batch_size):\n    global train_images, train_labels, index_in_epoch;\n    assert batch_size <= num_examples\n \n    start = index_in_epoch\n    index_in_epoch += batch_size\n    \n    if index_in_epoch > num_examples:\n        perm = np.arange(num_examples) \n        np.random.shuffle(perm) # shuffle the data\n        train_images = train_images[perm]\n        train_labels = train_labels[perm]\n        start = 0 # start next epoch\n        index_in_epoch = batch_size\n        \n    end = index_in_epoch\n    return train_images[start:end], train_labels[start:end]","cell_type":"code","metadata":{"_cell_guid":"d3bedd5b-c40d-46a7-8e7e-19af7f2a5773","collapsed":true,"_uuid":"57d7213a23ff15c677946c5ee3c81b04579c87ec"},"outputs":[]},{"source":"## Training and Validation","cell_type":"markdown","metadata":{"_cell_guid":"e2b7c61e-88bb-40dd-bde0-5ec1977d8365","_uuid":"180614885e56beb180592796a1267c0fbcab30ac"}},{"execution_count":null,"source":"## set parameters\n\nsess = tf.InteractiveSession() # start TensorFlow session\nsess.run(tf.global_variables_initializer()) # initialize global variables\n\n# variables and parameters\nnum_examples = train_images.shape[0];\nindex_in_epoch = 0;\ntrain_acc, val_acc, train_loss, val_loss = np.array([]),np.array([]),np.array([]),np.array([]);  \nlog_step = 50; # log results each step\nepoch_no = 8; # no of epochs \n\n# test hyperparameters\nmb_size_range = [50]; # mini batch size\nkeep_prob_range = [0.5]; # dropout regularization with keeping probability\nlearn_rate_range = [10*1e-4, 5*1e-4, 2.5*1e-4, 1*1e-4, 0.5*1e-4, 0.25*1e-4, 0.1*1e-4, \n                    0.05*1e-4, 0.025*1e-4, 0.01*1e-4];\nlearn_rate_step = 1.0; # change learning rate each learn_rate_step in epochs","cell_type":"code","metadata":{"_cell_guid":"96416e2d-9d37-408a-b690-812a7328e7fb","collapsed":true,"_uuid":"767d03d478b0a3a5a6cf97751db20ddd054de78c"},"outputs":[]},{"execution_count":null,"source":"## training model\n\nfor mb_size,keep_prob in itertools.product(mb_size_range,keep_prob_range):\n    mb_no = int(np.floor(epoch_no*num_examples/mb_size)); # no of mini batches\n    learn_rate_step = int(np.floor(learn_rate_step*num_examples/mb_size)); # steps in batches\n    print('epoch_no = %.0f, mb_size = %.0f, keep_prob = %.2f'%(epoch_no,mb_size,keep_prob))\n    learn_rate_pos = -1;\n    \n    for i in range(0,mb_no+1):\n        \n        if (i%learn_rate_step == 0) and ((learn_rate_pos+1) < len(learn_rate_range)):\n            learn_rate_pos+=1;\n            learn_rate = learn_rate_range[learn_rate_pos]  # adapt learn_rate\n            print('set current learn rate to: %.6f'%learn_rate)\n        \n        #learn_rate = 0.001*1e-4;\n        \n        batch_xs, batch_ys = next_batch(mb_size) #get new batch\n        \n        if i > 0:\n             sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, \n                                                tf_keep_prob: keep_prob, \n                                                tf_learn_rate: learn_rate})\n        if i%log_step == 0 or i == mb_no:\n            train_loss = np.append(train_loss, sess.run(cross_entropy, feed_dict={x:train_images[0:2000], y_:train_labels[0:2000], tf_keep_prob:1.0}));\n            train_acc = np.append(train_acc, accuracy.eval(feed_dict={x:train_images[0:2000], y_:train_labels[0:2000], tf_keep_prob:1.0}));      \n            if val_set_size > 0:\n                train_loss = np.append(train_loss, sess.run(cross_entropy, feed_dict={x:train_images[0:val_set_size], y_:train_labels[0:val_set_size], tf_keep_prob:1.0}));\n                train_acc = np.append(train_acc, accuracy.eval(feed_dict={x:train_images[0:val_set_size], y_:train_labels[0:val_set_size], tf_keep_prob:1.0}));      \n                val_loss = np.append(val_loss, sess.run(cross_entropy, feed_dict={x:val_images, y_: val_labels, tf_keep_prob: 1.0}));\n                val_acc = np.append(val_acc, accuracy.eval(feed_dict={x: val_images, y_: val_labels,tf_keep_prob: 1.0}));                                  \n            else: \n                val_loss = [0]; val_acc = [0];\n            print('%.2f epoch: train/val loss = %.4f/%.4f , train/val acc = %.4f/%.4f'%(i*mb_size/num_examples,train_loss[-1],val_loss[-1],train_acc[-1], val_acc[-1]))\n\n    # save model\n    #if not os.path.exists(dir_logs): # check if directory for logs exists\n    #    os.makedirs(dir_logs)\n    #np.savez(dir_logs+'/model.npz', \n    #        learn_rate = learn_rate, keep_prob = keep_prob, mb_size = mb_size, log_step = log_step,\n    #        W_conv1 = np.asarray(W_conv1.eval()), b_conv1 = np.asarray(b_conv1.eval()), W_conv2 = np.asarray(W_conv2.eval()),\n    #        b_conv2 = np.asarray(b_conv2.eval()), W_fc1 = np.asarray(W_fc1.eval()), b_fc1 = np.asarray(b_fc1.eval()),\n    #        W_fc2 = np.asarray(W_fc2.eval()), b_fc2 = np.asarray(b_fc2.eval()),\n    #        train_loss = train_loss, val_loss = val_loss, train_acc = train_acc,\n    #        val_acc = val_acc, val_loss_final = val_loss_final, val_acc_final = val_acc_final);\n\n    #close session\n    #sess.close();\n","cell_type":"code","metadata":{"_cell_guid":"2ca5e137-2767-4261-ac20-65d86042e856","_uuid":"98c599d07113cfa8bfee30244e31655400737184"},"outputs":[]},{"execution_count":null,"source":"'''\n## load model\n\n#print(dir_logs + ': ' + str(os.listdir(dir_logs)))\nprint('load '+ dir_logs + '/model.npz')\nnpzFile = np.load(dir_logs+'/model.npz');\n#print(npzFile.files);\nlearn_rate = npzFile['learn_rate'];\nkeep_prob = npzFile['keep_prob'];\nmb_size = npzFile['mb_size'];\nlog_step = npzFile['log_step'];\ntrain_loss = npzFile['train_loss'];\nval_loss = npzFile['val_loss'];\ntrain_acc = npzFile['train_acc'];\nval_acc = npzFile['val_acc'];\nval_loss_final = npzFile['val_loss_final'];\nval_acc_final = npzFile['val_acc_final'];\n\nsess = tf.InteractiveSession() # start TensorFlow session\n#sess.run(tf.global_variables_initializer()) # initialiue global variables\nW_conv1.load(npzFile['W_conv1'], session=sess)\nb_conv1.load(npzFile['b_conv1'], session=sess)\nW_conv2.load(npzFile['W_conv2'], session=sess)\nb_conv2.load(npzFile['b_conv2'], session=sess)\nW_fc1.load(npzFile['W_fc1'], session=sess)\nb_fc1.load(npzFile['b_fc1'], session=sess)\nW_fc2.load(npzFile['W_fc2'], session=sess)\nb_fc2.load(npzFile['b_fc2'], session=sess)\n'''","cell_type":"code","metadata":{"_cell_guid":"ec43e6f6-51f7-4590-96d4-7e45bad659ec","_uuid":"5d8fd8ba7e1bd518979de953f41594fc924ff2de"},"outputs":[]},{"execution_count":null,"source":"## confusion matrix\ny_predict = sess.run(tf.argmax(y,1), feed_dict={x: val_images,tf_keep_prob: 1.0});\ny_target = sess.run(tf.argmax(val_labels,1));\nprint('confusion matrix:')\nprint(sess.run(tf.contrib.metrics.confusion_matrix(predictions = y_predict, labels = y_target)))","cell_type":"code","metadata":{"_cell_guid":"083ed09c-7e93-49e5-ae28-eccc9282d20f","collapsed":true,"_uuid":"55718aab0eed2d5894f5df7764645c5c24f9f605"},"outputs":[]},{"execution_count":null,"source":"## final loss, accuracy \n\nval_loss_final = sess.run(cross_entropy, feed_dict={x: val_images,y_: val_labels, tf_keep_prob: 1.0});        \nval_acc_final = accuracy.eval(feed_dict={x: val_images, y_: val_labels, tf_keep_prob: 1.0})\nprint('final: val_loss = %.4f, val_acc = %.4f'%(val_loss_final,val_acc_final))\n\nplt.figure(figsize=(10, 5));\nplt.subplot(1,2,1);\nplt.plot(np.arange(0,len(train_acc))*log_step*mb_size/num_examples, train_acc,'-b', label='Training')\nplt.plot(np.arange(0,len(val_acc))*log_step*mb_size/num_examples, val_acc,'-g', label='Validation')\nplt.legend(loc='lower right', frameon=False)\nplt.ylim(ymax = 1.1, ymin = 0.0)\nplt.ylabel('accuracy')\nplt.xlabel('epoch');\n\nplt.subplot(1,2,2)\nplt.plot(np.arange(0,len(train_loss))*log_step*mb_size/num_examples, train_loss,'-b', label='Training')\nplt.plot(np.arange(0,len(val_loss))*log_step*mb_size/num_examples, val_loss,'-g', label='Validation')\nplt.legend(loc='lower right', frameon=False)\nplt.ylim(ymax = 3.0, ymin = 0.0)\nplt.ylabel('loss')\nplt.xlabel('epoch');","cell_type":"code","metadata":{"_cell_guid":"7e351ab9-f9dc-41d1-80ee-802b1c8a9114","collapsed":true,"_uuid":"6541c6ca89fd856531b2f0280cbe78d91da87183"},"outputs":[]},{"execution_count":null,"source":"## visualize weights\n\nW_conv1_vis = W_conv1.eval();\nprint('W_conv1: min = ' + str(np.min(W_conv1_vis)) + ' max = ' + str(np.max(W_conv1_vis))\n      + ' mean = ' + str(np.mean(W_conv1_vis)) + ' std = ' + str(np.std(W_conv1_vis)))\nW_conv1_vis = np.reshape(W_conv1_vis,(5,5,1,4,8))\nW_conv1_vis = np.transpose(W_conv1_vis,(3,0,4,1,2))\nW_conv1_vis = np.reshape(W_conv1_vis,(20,40,1))\nplt.gca().set_xticks(np.arange(-0.5, 40, 5), minor = True);\nplt.gca().set_yticks(np.arange(-0.5, 20, 5), minor = True);\nplt.grid(which = 'minor', color='b', linestyle='-', linewidth=1)\nplt.title('W_conv1 ' + str(W_conv1.shape))\nplt.colorbar(plt.imshow(W_conv1_vis[:,:,0], cmap=cm.binary));\nplt.show();\n\nW_conv2_vis = W_conv2.eval();\nprint('W_conv2: min = ' + str(np.min(W_conv2_vis)) + ' max = ' + str(np.max(W_conv2_vis))\n      + ' mean = ' + str(np.mean(W_conv2_vis)) + ' std = ' + str(np.std(W_conv2_vis)))\nW_conv2_vis = np.reshape(W_conv2_vis,(5,5,4,8,64))\nW_conv2_vis = np.transpose(W_conv2_vis,(2,0,3,1,4))\nW_conv2_vis = np.reshape(W_conv2_vis,(4*5,8*5,8,8))\nW_conv2_vis = np.transpose(W_conv2_vis,(2,0,3,1))\nW_conv2_vis = np.reshape(W_conv2_vis,(8*4*5,8*8*5))\nplt.figure(figsize=(15,10))\nplt.gca().set_xticks(np.arange(-0.5, 320, 40), minor = True);\nplt.gca().set_yticks(np.arange(-0.5, 160, 20), minor = True);\nplt.grid(which = 'minor', color='b', linestyle='-', linewidth=1)\nplt.title('W_conv2 ' + str(W_conv2.shape))\nplt.colorbar(plt.imshow(W_conv2_vis[:,:], cmap=cm.binary));\n\n#b_conv1_vis = b_conv1.eval();\n#print('b_conv1 = ',b_conv1_vis)\n#b_conv2_vis = b_conv2.eval();\n#print('b_conv2 = ',b_conv2_vis)","cell_type":"code","metadata":{"_cell_guid":"add9e626-e259-4b3f-82ef-078778113782","collapsed":true,"_uuid":"5532356d3a392b9d76205c02cdc17d92fdfe2481"},"outputs":[]},{"execution_count":null,"source":"## visualize activations\n\nIMG_NO = 10;\nfeed_dict = {x: train_images[IMG_NO:IMG_NO+1], tf_keep_prob: 1.0}\n\n# original image\nplt.figure(figsize=(15,10))\nplt.subplot(2,3,1)\nplt.title('prediction: %d'%predict.eval(feed_dict = feed_dict))\nplt.imshow(train_images[IMG_NO].reshape(image_width,image_height),cmap=cm.binary);\n\n# 1. convolution\nh_conv1_vis = h_conv1.eval(feed_dict = feed_dict);\nplt.subplot(2,3,2)\nplt.title('h_conv1 ' + str(h_conv1_vis.shape))\nh_conv1_vis = np.reshape(h_conv1_vis,(-1,28,28,4,8))\nh_conv1_vis = np.transpose(h_conv1_vis,(0,3,1,4,2))\nh_conv1_vis = np.reshape(h_conv1_vis,(-1,4*28,8*28))\nplt.imshow(h_conv1_vis[0], cmap=cm.binary);\n\n# 1. max pooling\nh_pool1_vis = h_pool1.eval(feed_dict = feed_dict);\nplt.subplot(2,3,3)\nplt.title('h_pool1 ' + str(h_pool1_vis.shape))\nh_pool1_vis = np.reshape(h_pool1_vis,(-1,14,14,4,8))\nh_pool1_vis = np.transpose(h_pool1_vis,(0,3,1,4,2))\nh_pool1_vis = np.reshape(h_pool1_vis,(-1,4*14,8*14))\nplt.imshow(h_pool1_vis[0], cmap=cm.binary);\n\n# 2. convolution\nh_conv2_vis = h_conv2.eval(feed_dict = feed_dict);\nplt.subplot(2,3,4)\nplt.title('h_conv2 ' + str(h_conv2_vis.shape))\nh_conv2_vis = np.reshape(h_conv2_vis,(-1,14,14,8,8))\nh_conv2_vis = np.transpose(h_conv2_vis,(0,3,1,4,2))\nh_conv2_vis = np.reshape(h_conv2_vis,(-1,8*14,8*14))\nplt.imshow(h_conv2_vis[0], cmap=cm.binary);\n\n# 2. max pooling\nh_pool2_vis = h_pool2.eval(feed_dict = feed_dict);\nplt.subplot(2,3,5)\nplt.title('h_pool2 ' + str(h_pool2_vis.shape))\nh_pool2_vis = np.reshape(h_pool2_vis,(-1,7,7,8,8))\nh_pool2_vis = np.transpose(h_pool2_vis,(0,3,1,4,2))\nh_pool2_vis = np.reshape(h_pool2_vis,(-1,8*7,8*7))\nplt.imshow(h_pool2_vis[0], cmap=cm.binary);\n\n# 3. FC layer\nh_fc1_vis = h_fc1.eval(feed_dict = feed_dict);\nplt.subplot(2,3,6)\nplt.title('h_fc1 ' + str(h_fc1_vis.shape))\nh_fc1_vis = np.reshape(h_fc1_vis,(-1,32,32))\nplt.imshow(h_fc1_vis[0], cmap=cm.binary);\nplt.show()\n\n# 4. FC layer\nh_fc2_vis = y.eval(feed_dict = feed_dict);\nnp.set_printoptions(precision=2)\nprint('h_fc2 = ', h_fc2_vis)","cell_type":"code","metadata":{"_cell_guid":"ab004898-a7ec-4e89-9be2-503db6e24d66","collapsed":true,"_uuid":"3f169ddac4c3639ba734f67048ba41b775d68094"},"outputs":[]},{"source":"## Testing","cell_type":"markdown","metadata":{"_cell_guid":"069e66b4-fb6c-4a55-9dd0-5f0d23717388","_uuid":"176c76821d5518569b5e33569dd127fd91039cc4"}},{"execution_count":null,"source":"# read test data from CSV file \nif os.path.isfile('../input/test.csv'):\n    test_data = pd.read_csv('../input/test.csv') # on kaggle \n    print('test.csv loaded: test_data({0[0]},{0[1]})'.format(test_data.shape))\nelif os.path.isfile('data/test.csv'):\n    test_data = pd.read_csv('data/test.csv') # on local environment\n    print('test.csv loaded: test_data({0[0]},{0[1]})'.format(test_data.shape))\nelse:\n    print('Error: test.csv not found')\n    \ntest_images = test_data.iloc[:,0:].values # (28000,784) array\ntest_images = test_images.astype(np.float)\ntest_images = np.multiply(test_images, 1.0 / 255.0) # convert from [0:255] => [0.0:1.0]\nprint('read: test_images({0[0]},{0[1]})'.format(test_images.shape));\n\n\n# using mini batches is more resource efficient\npredicted_labels = np.zeros(test_images.shape[0])\nBATCH_SIZE = 1000;\nfor i in range(0,int(test_images.shape[0]/BATCH_SIZE)):\n    predicted_labels[i*BATCH_SIZE:(i+1)*BATCH_SIZE] = predict.eval(feed_dict={x: test_images[i*BATCH_SIZE:(i+1)*BATCH_SIZE], tf_keep_prob: 1.0})\nprint('compute predicted_labels({0})'.format(len(predicted_labels)))\n\n# save predictions\nnp.savetxt('submission.csv', \n           np.c_[range(1,len(test_images)+1),predicted_labels], \n           delimiter=',', \n           header = 'ImageId,Label', \n           comments = '', \n           fmt='%d')\n\nprint('saved: submission.csv');","cell_type":"code","metadata":{"_cell_guid":"2286dd81-8199-44ab-a119-1f7d5470b757","scrolled":true,"collapsed":true,"_uuid":"dd5c3638434505b4491ddd8c804bf53e9d20dfa6"},"outputs":[]},{"execution_count":null,"source":"# look at test images and predicted labels\nplt.figure(figsize=(10,15))\nfor j in range(0,5):\n    for i in range(0,10):\n        plt.subplot(10,10,j*10+i+1)\n        plt.title('%d'%predicted_labels[j*10+i])\n        plt.imshow(test_images[j*10+i].reshape(28,28),cmap=cm.binary)\n","cell_type":"code","metadata":{"_cell_guid":"7689a5ba-fdd8-4dcd-ab67-23fc2e3bf0fa","collapsed":true,"_uuid":"85b4ef639e68901b701d9281fcd65933f699c05a"},"outputs":[]},{"execution_count":null,"source":"sess.close()","cell_type":"code","metadata":{"_cell_guid":"c906dec2-00ac-4c25-9b79-cdc5e1d6e496","collapsed":true,"_uuid":"1f39c8494c0e34ea4eecc5941a67c7f3a9443d11"},"outputs":[]}],"nbformat_minor":1}