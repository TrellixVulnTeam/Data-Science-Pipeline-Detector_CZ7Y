{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DIGIT MNIST Classification Ensemble(KOR, ENG)\n\nToday I learning about CNN Ensemble(Bagging). It is very amazting performance about accuracy.<br>\n**Ensemble(Bagging) technique is a method of solving a diffcult problem using the collective intelligence of several people rather than one expert.**<br>\n(but i think this model is Geneius of several people!!)<br>\n**This NoteBook Guideline is easy to understand for anyone. I hope it helps many people.**<br>\nI will also add the link referenced below, so it will be more useful if you check it out!<br>\n**If you have any question. plz comment!! and Don't forget Upvote!**\n<hr>\n금일 CNN을 앙상블 기법의 적용원리에 대하여 학습하였습니다.<br>이 Notebook은 쉽게 이해할 수 있게 작성되어 있으며,\n개인적인 바램이지만, 많은 사람들이 쉽게 이해하였으면 좋겠습니다.<br>\n추가로 하단에 참조했으면 하는 링크를 달아두었으니, 내용을 확인하시면 조금 더 도움될 것입니다.\n\n\n# Contents\n- **Load Data and Preprocessing Data**\n- **Check Values Count**\n- **Create Model**\n- **Learning Ensemble(Very Importance)**\n- **Visualization about Loss and Accuracy**\n- **Reference Link**\n","metadata":{}},{"cell_type":"markdown","source":"# Load Data and Preprocessing Data\n- **train_data compose label and pixel value.**\n    - **train_data Pixel be transformation of 28*28**\n    - **Pixel value normalization**\n    - **label data drop and make train_label**\n        - **(KOR) 28*28 사이즈로 변형 및 정규화 과정을 거치며, label 셋을 따로 만들어 줍니다.**\n</br>\n</br>\n- **test_data**\n    - **Pixel be transformation of 28*28**\n    - **Pixel value normalization**    \n        - **(KOR) 28*28 사이즈로 변환만 해주면 됩니다.**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Conv2D, Activation, Dense, Input, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Flatten, MaxPooling2D, GlobalAveragePooling2D, LeakyReLU\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nwarnings.filterwarnings(action='ignore')\n%matplotlib inline\n\ntrain_df = pd.read_csv('../input/digit-recognizer/train.csv')\ntest_df = pd.read_csv('../input/digit-recognizer/test.csv')\n\ntrain_label = train_df['label']\ntrain_label = to_categorical(train_label)\ntrain_data = (train_df.iloc[:, 1:].values.astype('float32') / 255.0 ).reshape(-1, 28, 28, 1)\ntest_data = (test_df.iloc[:,:].values.astype('float32') / 255.0 ).reshape(-1, 28, 28, 1)\n\nprint('train_df shape : ',train_data.shape, 'train_label : ',train_label.shape, 'test_data : ',test_data.shape)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-01-19T05:22:54.274807Z","iopub.execute_input":"2022-01-19T05:22:54.275159Z","iopub.status.idle":"2022-01-19T05:22:56.52346Z","shell.execute_reply.started":"2022-01-19T05:22:54.275044Z","shell.execute_reply":"2022-01-19T05:22:56.522146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check values count\n- **Let's Check evenly the distribution of the label data**","metadata":{}},{"cell_type":"code","source":"count = pd.value_counts(train_df['label'].values)\ncount.plot.bar(figsize=(10,8), fontsize=15)","metadata":{"execution":{"iopub.execute_input":"2022-01-18T11:47:40.497196Z","iopub.status.busy":"2022-01-18T11:47:40.496753Z","iopub.status.idle":"2022-01-18T11:47:40.705548Z","shell.execute_reply":"2022-01-18T11:47:40.704928Z","shell.execute_reply.started":"2022-01-18T11:47:40.497157Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Ensemble Model\n- Please note that I will comment below Code!!!","metadata":{}},{"cell_type":"code","source":"# Build CNN(Convolutional Neural Network)\noptimizer = RMSprop(learning_rate=0.0025,\n                    rho=0.9,\n                    momentum=0.1,\n                    epsilon=1e-07,\n                    centered=True,\n                    name='RMSprop')\n\nnets = 15                # Number of Reapeat\nmodel = [0] *nets        # Making Ensemble Model List\n\n\nfor i in range(nets):\n    model[i] = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)),\n        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n        \n        tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n        \n        tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n\n        tf.keras.layers.MaxPooling2D(2, 2),\n        tf.keras.layers.Dropout(0.25),\n\n        tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n        \n        tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n        \n        tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n\n        tf.keras.layers.MaxPooling2D(2,2),\n        tf.keras.layers.Dropout(0.25),    \n\n        tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n        \n        tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n\n        tf.keras.layers.MaxPooling2D(2,2),\n        tf.keras.layers.Dropout(0.25),\n\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(256),\n        tf.keras.layers.LeakyReLU(alpha=0.1),\n\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(10, activation='softmax')\n    ])\n    \n    model[i].compile(loss='categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-01-18T14:30:48.496322Z","iopub.status.idle":"2022-01-18T14:30:48.496616Z","shell.execute_reply":"2022-01-18T14:30:48.496487Z","shell.execute_reply.started":"2022-01-18T14:30:48.496467Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if you want see model summary()\n# model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Learning Ensemble for Bagging\n<img src = 'https://blog.kakaocdn.net/dn/PC6mD/btrh2i38SMg/VtEFCCGAyvknFrTVkZQ76K/img.webp'></src>","metadata":{}},{"cell_type":"code","source":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n\ndatagen = ImageDataGenerator(\n        rotation_range=10,  \n        zoom_range = 0.10,  \n        width_shift_range=0.1, \n        height_shift_range=0.1)\n\nhistory = [0] * nets\nepochs = 45\nfor j in range(nets):\n    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(train_data, train_label, test_size = 0.1, stratify = train_label)\n    \n    history[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n        epochs = epochs, steps_per_epoch = X_train2.shape[0]//64,  \n        validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=0)\n    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n        j+1,epochs,max(history[j].history['accuracy']),max(history[j].history['val_accuracy']) ))","metadata":{"execution":{"iopub.execute_input":"2022-01-18T14:34:10.39149Z","iopub.status.busy":"2022-01-18T14:34:10.391236Z","iopub.status.idle":"2022-01-18T14:34:20.00754Z","shell.execute_reply":"2022-01-18T14:34:20.004031Z","shell.execute_reply.started":"2022-01-18T14:34:10.391462Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization about Loss and Accuracy","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(2,1)\nax[0].plot(history[14].history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history[14].history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\nax[0].grid(color='black', linestyle='-', linewidth=0.25)\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history[14].history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history[14].history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax[1].grid(color='black', linestyle='-', linewidth=0.25)\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ENSEMBLE PREDICTIONS AND SUBMIT\nresults = np.zeros( (test_data.shape[0],10) ) \nfor j in range(nets):\n    results = results + model[j].predict(test_data)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submission.csv\",index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reference Link\n<hr>\n   - It's very useful kernel!!(I recommand below kernel)\n   \n- reference link : https://www.kaggle.com/benanakca/kannada-mnist-cnn-tutorial-with-app-top-2\n- reference link : https://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist/notebook\n","metadata":{}},{"cell_type":"markdown","source":"# Upvote!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}