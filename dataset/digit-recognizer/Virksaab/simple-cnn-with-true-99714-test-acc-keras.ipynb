{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom tensorflow import keras\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPool2D\nfrom keras.layers.core import Lambda\nfrom keras.layers.core import Dense\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import  Sequential\nfrom keras.preprocessing import image\nfrom keras.optimizers import Adam\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# create the training & test sets\ntrain = pd.read_csv(\"../input/train.csv\")\ntest= pd.read_csv(\"../input/test.csv\")\nprint(\"Train size:{}\\nTest size:{}\".format(train.shape, test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a72a139b2ee67e973da8b9aff69d521c7f92c7c"},"cell_type":"markdown","source":"### <span style=\"color:red\">NOTE</span>: *Train colms are 785, where test colms are 784 because first colm is the Labels colm*. Let's see:"},{"metadata":{"_uuid":"fffa55d72d43b67149954f564bfcadb689cd9c49","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# The output variable is an integer from 0 to 9. \n#This is a multiclass classification problem.\ntrain['label']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"230e792d329957f635908dd75e832b37b1f71090"},"cell_type":"markdown","source":"### <span style=\"color:red\">Split Labels and images</span> and <span style=\"color:green\">convert data from pandas dataframe to numpy array </span>:\n***pd.dataframe.values*** is used to convert dataframe in numpy array\n"},{"metadata":{"_uuid":"47f70f4f088da8530cc90ada23648c85a41ec780","collapsed":true,"trusted":true},"cell_type":"code","source":"X_train = train.drop(['label'], axis=1).values.astype('float32') # all pixel values\ny_train = train['label'].values.astype('int32') # only labels i.e targets digits\nX_test = test.values.astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2912006255d46d2c075f9ac8c48433a459fd1ec"},"cell_type":"markdown","source":"## Data Visualization:\nLets look at some  images from data set with their labels."},{"metadata":{"_uuid":"6ed12c7791e91c75850325dea892b58dd5d230c5","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"#Convert train datset to (num_images, img_rows, img_cols) format \nX_train = X_train.reshape(X_train.shape[0], 28, 28)\nfor j,i in enumerate(range(15,20)):\n    plt.subplot(1,5,j+1)\n    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n    plt.axis('off')\n    plt.title(y_train[i]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38578b80ecde9423d0be67f4c5d80e4c58e79a39"},"cell_type":"markdown","source":"### <span style=\"color:red\">Change dimensions for CNN</span> and <span style=\"color:green\">expand 1 more dimension to store channels</span>:\nCNN layers takes data shape as (num_images, img_rows, img_cols, n_channels)"},{"metadata":{"_uuid":"1d993d422e90ed1e9bb862f0c1bdf8bc3b759605","trusted":true,"collapsed":true},"cell_type":"code","source":"X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28,1)\nprint(\"Train size:{}\\nTest size:{}\".format(X_train.shape, X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17ceca6f21240e4687b82b380eb4ac62345d606e"},"cell_type":"markdown","source":"## Data preprocessing:\n---\n### 1. <span style=\"color:red\">Feature Standardization:</span>\n* It is important preprocessing step.\n* It is used to centre the data around **zero mean and unit variance**."},{"metadata":{"_uuid":"d20d79bd9eebc8e4180fe900c006c7708579f61a","collapsed":true,"trusted":true},"cell_type":"code","source":"mean_px = X_train.mean().astype(np.float32)\nstd_px = X_train.std().astype(np.float32)\ndef standardize(x): \n    return (x-mean_px)/std_px","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d3c41529d65b7283c2f253b5b57bb8a92fd604b"},"cell_type":"markdown","source":"### 2. <span style=\"color:red\">One Hot encoding of labels:</span>\n---\n* A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. \n* In this case, the nth digit will be represented as a vector which is 1 in the nth dimension. \n    * For example, 3 would be [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]."},{"metadata":{"_uuid":"e07d5d0bbda198d5da44adf1c4a78d66e5537c40","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"y_train = to_categorical(y_train)\nprint(\"Number of classes:{}\".format(y_train.shape[1]))\nprint(\"This is 3 (starting from zero):{}\".format(y_train[9])) #starting from zero","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ddb59d655c223a45c0efe910455ac025b57e966"},"cell_type":"markdown","source":"# CNN Model Structure:"},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"eaf86e3fd745f97f8fdb77e3d38ed2e9d4499759","collapsed":true,"trusted":true},"cell_type":"code","source":"model = Sequential([\n    Lambda(standardize, input_shape=(28,28,1)),\n    Conv2D(32,(3,3), activation='relu'),\n    BatchNormalization(axis=1),\n    Dropout(.5),\n    Conv2D(32,(3,3), activation='relu'),\n    BatchNormalization(axis=1),\n    MaxPool2D(),\n    Conv2D(64,(3,3), activation='relu'),\n    BatchNormalization(axis=1),\n    Dropout(.5),\n    Conv2D(64,(3,3), activation='relu'),\n    MaxPool2D(),\n    Flatten(),\n    BatchNormalization(),\n    Dropout(.5),\n    Dense(512, activation='relu'),\n    BatchNormalization(),\n    Dropout(.5),\n    Dense(10, activation='softmax')\n    ])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b73a3db36562e5d108b35efc04e9b4a62b451a2"},"cell_type":"markdown","source":"# Data Augmentation: <small>(important step)</small>\n* Data augmentation means increasing the number of data points. \n* In terms of images, it may mean that increasing the number of images in the dataset. \n* In terms of traditional row/column format data, it means increasing the number of rows or objects.\n\n<span style=\"color:orange\">But why?</span>\n\nThe answer to why is simple:\n* We do not have large amount of data.\n* The more the data, the better our CNN model will be, in principle.\n\n<span style=\"color:orange\">OK, cool. How to do it?</span>\n\nIn images, you can:\n* rotate the original image, \n* change lighting conditions, \n* crop it differently, etc.\n\n<span style=\"color:red\">NOTE</span>: be careful about your choice of data augmentation.\n\n**Keras provides easy way for Data Augmentation:**\n"},{"metadata":{"_uuid":"0ba5d53db3ad14b45d797293befb8fe9315acc45","collapsed":true,"trusted":true},"cell_type":"code","source":"gen = image.ImageDataGenerator(rotation_range=10, \n                               width_shift_range=0.10, \n                               shear_range=0.5,\n                               height_shift_range=0.10, \n                               zoom_range=0.10\n                              )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa8c7cf5a5a2077b31519c3413794e5ff09b2e78"},"cell_type":"markdown","source":"## Set rest of the things:"},{"metadata":{"_uuid":"302a786f74cd3468e278467f4d1421a4bdb3ee95","collapsed":true,"trusted":true},"cell_type":"code","source":"# Complile keras model\nmodel.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n# Learning Rate\nmodel.optimizer.lr=0.001\n# Get data batches\nbatches = gen.flow(X_train, y_train, batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2ba30178914dc772dd31e91afca490093df0e17"},"cell_type":"markdown","source":"### <span style=\"color:red\">NOTE:</span>\nNo evaluation is performed here.\nHmm. <span style=\"color:orange\">Why?</span>\n\nYou need all the images in the training set to train because data is already limited and for better accuracy.\n"},{"metadata":{"_uuid":"37d4f0b205997abfc83cb0c066eb581a149a75ce"},"cell_type":"markdown","source":"## Start training:\n**10 epochs -> test acc: .99542**\n\n**15 epochs -> test acc: .99714**\n\nI'm gonna run the  training for epochs=1 because it'll take too long to run here.. \n\nBut, don't worry i'm not lying, you'll get .99714 accuracy on test set after training.\n\n(May be accuracy fluctuate a little because of random weights initialization, but i'll be around .997xx). \n\nHonestly, my GTX 1060 6GB (~10mins/epoch) is better than kaggle's Tesla K80 (~28mins/epoch).\nRun the below cell to train."},{"metadata":{"_uuid":"3fca86d5a524d6ff443307ed9b14d2cd8ca3f525","trusted":true,"collapsed":true},"cell_type":"code","source":"# We can create plots from the history object returned by fit_generator() or fit ()\nhistory = model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1) # change epochs=15","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14a7316bd334fb032b02ae722d5ba2ad201e3503"},"cell_type":"markdown","source":"## Time to test our work:"},{"metadata":{"_uuid":"c60ef964a78411684ef3365ab140933e0bc05ada","collapsed":true,"trusted":true},"cell_type":"code","source":"predictions = model.predict_classes(X_test, verbose=0)\n# Setting submission file according to Competition guidelines\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                          \"Label\": predictions})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8dd4ca3c72c63fca7d1567e94424f158ca31b9b","collapsed":true},"cell_type":"markdown","source":"### That's it. \nFork this notebook and download and run it on your pc.\n### <span style=\"color:purple\">If you like this kernel, please upvote :)</span>"},{"metadata":{"_uuid":"ac56423959f3fb76d028fc36a60f746d080a6db1","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}