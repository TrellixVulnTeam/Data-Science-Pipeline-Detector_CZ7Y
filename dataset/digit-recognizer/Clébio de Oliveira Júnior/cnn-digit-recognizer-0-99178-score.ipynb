{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Digit Recognizer using CNN\n---"},{"metadata":{},"cell_type":"markdown","source":"## Importing\n---"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Functions\n___"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"np.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def doSubmission(y_pred):\n    test_Id = np.arange(1, y_pred.size+1, dtype=np.int)\n    \n    pred_dict = {\"ImageId\": test_Id, \"Label\": y_pred}\n    df = pd.DataFrame(pred_dict)\n    df.to_csv(\"sample_submission.csv\", index=False, index_label=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df_train.label.to_numpy() # transforming into numpy array\n\nX = df_train.drop(columns=[\"label\"]).to_numpy(np.float64)\nX /= 255.0 #normalizing to improve the model learning","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_totrain = X.reshape(X.shape[0], 28, 28, 1) #a complete data base to train the model for prediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it's time to separate into train and test database. "},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_cat = to_categorical(y, 10)\ny_train_cat = to_categorical(y_train, 10)\ny_test_cat = to_categorical(y_test, 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = df_test.to_numpy(np.float64)\ntest = test.reshape(test.shape[0], 28, 28, 1)\ntest /= 255.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building the Convolution Neural Network\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convNeuralNetwork(filters=256, kernel_size=(3, 3), pool_size=(2, 2), units=128, dropout=0.2):\n    cnn = Sequential()\n    \n    cnn.add(Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), \n                   input_shape=(28, 28, 1), activation=\"relu\", padding=\"same\"))\n    cnn.add(MaxPool2D(pool_size=pool_size, padding=\"same\"))\n\n    cnn.add(Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1),\n                   activation=\"relu\", padding=\"same\"))\n    cnn.add(MaxPool2D(pool_size=pool_size, padding=\"same\"))\n    \n    cnn.add(Flatten())\n            \n    cnn.add(Dense(units=units, activation=\"relu\"))\n    cnn.add(Dropout(dropout))\n            \n    cnn.add(Dense(units=units, activation=\"relu\"))\n    cnn.add(Dropout(dropout))\n            \n    cnn.add(Dense(units=10, activation=\"softmax\"))\n    \n    cnn.compile(optimizer=\"adamax\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    \n    return cnn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model to Test\n\nIt's important to see if the model is not underfiting or overfiting"},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, \n                               restore_best_weights=True)\n\ncnn = convNeuralNetwork(filters=2048, units=1024)\ncnn_hist = cnn.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat), \n                   epochs=50, batch_size=256, callbacks=[early_stopping])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cnn_hist.history[\"accuracy\"]\nval_accuracy = cnn_hist.history[\"val_accuracy\"]\n\nplt.plot(accuracy, \"o-\", label=\"Accuracy\")\nplt.plot(val_accuracy, \"o-\", label=\"Val Accuracy\")\n\nplt.legend(loc=\"best\")\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = cnn_hist.history[\"loss\"]\nval_loss = cnn_hist.history[\"val_loss\"]\n\nplt.plot(loss, \"o-\", label=\"Loss\")\nplt.plot(val_loss, \"o-\", label=\"Val Loss\")\n\nplt.legend(loc=\"best\")\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor=\"loss\", patience=10, restore_best_weights=True)\nmodel_checkpoint = ModelCheckpoint(filepath=\"./\", monitor=\"loss\", verbose=1,\n                                   save_best_only=True, save_weights_only=True)\n\nmodel = convNeuralNetwork(filters=2048, units=1024)\nmodel_hist = model.fit(X_totrain, y_cat, batch_size=256, epochs=50, \n                       callbacks=[early_stopping, model_checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = model_hist.history[\"accuracy\"]\n\nplt.plot(accuracy, \"o-\", label=\"Accuracy\")\nplt.legend(loc=\"best\")\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = model_hist.history[\"loss\"]\n\nplt.plot(accuracy, \"o-\", label=\"Loss\")\nplt.legend(loc=\"best\")\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(test).argmax(1)\n\ndoSubmission(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}