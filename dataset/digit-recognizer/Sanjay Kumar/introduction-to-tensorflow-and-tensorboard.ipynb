{"cells":[{"metadata":{"_cell_guid":"c8bff5c1-891d-4ee6-b6c1-f23b507aa550","_uuid":"98c16a5150b22b6d9c598f4e3ba1578b8c82f6a3"},"cell_type":"markdown","source":"# Introduction to Tensorflow,  and Tensorboard\nBuild a Convolutional Neural Network with Tensorflow.\nThe Notebook consists 4 parts:\n  -  Data Preprocessing\n  -  Defining CNN architecture \n  -  Training the Model\n  -  Visualising Tensorboard Graph and Scalars\n\n## CNN Overview\n<img src=\"https://static1.squarespace.com/static/54856bade4b0c4cdfb17e3c0/t/58278379f7e0ab81d3e68c5a/1478984571373/\"  title=\"Convolutional Neural Network\" />\n[Convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN, or ConvNet) is a class of deep, feed-forward artificial neural networks that has successfully been applied to analyzing visual imagery.\n\n\n  \n## Dataset Introduction\nThe Dataset used here is  MNIST handwritten digits. The dataset contains 42000 examples for training and 28,000 examples for testing. \n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/MnistExamples.png/220px-MnistExamples.png\"  title=\"MNIST DataSet\" />\n\n## Importing Libraries\n"},{"metadata":{"_cell_guid":"ae71302c-4198-45d4-af82-a4e929716425","_uuid":"0f038b2c78b2530b6a53ea89422dfbdc7bd6282e","trusted":false,"collapsed":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom tensorflow.python.keras import utils\nfrom tensorflow.python.keras.preprocessing import image\nimport plotly\nimport plotly.graph_objs as go\nimport seaborn as sns\nfrom IPython.display import Image\nimport matplotlib.cm as cm\nimport numpy as np\n%matplotlib inline\nplotly.offline.init_notebook_mode(True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3a263a81-134d-47a7-954e-2f1f4e44529d","_uuid":"99b3a5e451e925214304b914607903fa14ae85e9"},"cell_type":"markdown","source":"## Loading the Data\nWe read data provided in csv format. The train.csv file contains 42000 rows and 785 columns. Each row represents an image of a handwritten digit and a label with the value of this digit."},{"metadata":{"_cell_guid":"e5a1f82c-3ea9-4850-a1f4-1c687919cdcc","_uuid":"509cf978c19005a79e69533151ecf6e8610cb2d1","trusted":false,"collapsed":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8233fafe-d442-41ca-9a9d-618c5856a139","_uuid":"f81176155d710f9080a9391a5fddeafe6a68b8f4"},"cell_type":"markdown","source":"__Checking for null or missing data using pandas inbuilt function__"},{"metadata":{"_cell_guid":"55239e5b-90ab-4023-bc50-226f92a6fb10","_uuid":"411e5394e11e5aff697bfc52720377b96ef0795b","trusted":false,"collapsed":true},"cell_type":"code","source":"train.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b7c129c7-7e14-4951-b993-3401c51d5209","_uuid":"abc8fa140cea7b1f73547dfa9c8e22adae06ce1d","trusted":false,"collapsed":true},"cell_type":"code","source":"test.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"66210ade-9747-49cf-be26-455f197fd9c3","_uuid":"c3251c494a60824621e1a72c16bf2476f113961e"},"cell_type":"markdown","source":"The given data is pretty clean and does not have any null or missing value.\n\n\n## Seperating Labels from features"},{"metadata":{"_cell_guid":"05073053-372d-491e-ab86-e6a5867ee1e4","collapsed":true,"_uuid":"1a4efe4446f273c44842055f2301aedceaca2b50","trusted":false},"cell_type":"code","source":"labels = train['label']\ntrain = train.drop(['label'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"10685162-4e39-4362-8b4e-35dd78cad444","_uuid":"62bd0844aef23ba14fb2f591a49acce1cdd4858b"},"cell_type":"markdown","source":"## Countplot for Labels"},{"metadata":{"_cell_guid":"4e06d185-fd87-494c-a9b4-8697ae6e4d84","_uuid":"b9b5ce88dfe211f9a8bf4f04c59ddf9216e6c024","trusted":false,"collapsed":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(15,7))\nsns.countplot(labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"38e54e63-c582-43d9-8524-167c1181c496","_uuid":"b238128beb2cb69bf605d8e856b00a4dcbc041ab"},"cell_type":"markdown","source":"We can see that we have almost balanced labels for each class.\n\n## Viewing some example"},{"metadata":{"_cell_guid":"2b7bc5c5-825c-4455-b75f-d1b880ec3861","scrolled":true,"_uuid":"dd2c9c7276276ff35e98df2f52b735e97cd65e13","trusted":false,"collapsed":true},"cell_type":"code","source":"def show_img(img):\n    img = img.values.reshape(28,28)\n    plt.imshow(img,cmap=cm.binary)\n\nshow_img(train.iloc[80])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9144ce3e-25c8-4ead-bccc-d9f771ae776b","_uuid":"3089c630cde9c75d8e9a42fb74fdaf135a8d52de"},"cell_type":"markdown","source":"## Normalisation\nWe perform a grayscale normalization to reduce the effect of illumination's differences.\nMoreover the CNN converg faster on [0..1] data than on [0..255]."},{"metadata":{"_cell_guid":"439422ec-485e-496c-869f-607527d9a620","collapsed":true,"_uuid":"0f489ad3642788a5b284559a09a12f62111bacaa","trusted":false},"cell_type":"code","source":"train /= 255.0\ntest /= 255.0","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bc6903e0-afbb-412f-b845-57cdbfc1de2d","_uuid":"856109e5fa82d306481326e3a1540b3a1e3f2611"},"cell_type":"markdown","source":"\n## Reshaping Array\nReshaping the array for input to CNN. Initial it was given in 1-d array format (784), so it is changed in 3-d array of shape (28 $*$ 28 $*$ 1) because CNN takes 3-d input."},{"metadata":{"_cell_guid":"3c85e7dc-b199-4cbc-9766-6b57c213b553","collapsed":true,"_uuid":"d9992d36321c94958e64bd233c7837230e05f2d9","trusted":false},"cell_type":"code","source":"train = train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d57f6e61-e319-42aa-a943-e79e9e6e0952","_uuid":"4606f869a14f634478eae602bbe999e7ae5051ad"},"cell_type":"markdown","source":"## Changing labels to one-hot vectors\n\nThe given labels are in numerical format (0-9), we convert it into one hot vectors.\n\ne.g for 5 we get our one hot vector as  [0,0,0,0,0,1,0,0,0,0]"},{"metadata":{"_cell_guid":"0b07984d-ee37-42a2-9162-ce54bb768fd8","collapsed":true,"_uuid":"aa8927c7d689a04ef24425da339c4f920755722c","trusted":false},"cell_type":"code","source":"labels = utils.to_categorical(labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"443f0a83-4a10-48a6-bb71-e26ae2cf6552","_uuid":"d823b98c1f2fe1195489858b487224fca03e36a5"},"cell_type":"markdown","source":"## Splitting Data for training and Validation\n\nUsing train_test_split function from sklearn we divide our data into training and validation dataset in ratio of 0.1."},{"metadata":{"_cell_guid":"1cb1f968-ba71-4dd8-9666-1e1a71f60625","collapsed":true,"_uuid":"e5a934516ec7da9699679d39bb0ad555904453e8","trusted":false},"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(train, labels, test_size = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6be26511-02d9-43de-bc16-837ba6f789d8","_uuid":"3c53330e4327ccbd3cfff2f4f2d59f4ce2c257eb"},"cell_type":"markdown","source":"## Defining Convolution and max pool function\nWe define our convolution block with zero padding and strides/step = 1.The activation function used here is relu.In general relu is used as activation function because it is a very simple non linear function and it reduces calculation.\nMax pooling is used for downsampling of the data. 2x2 max-pooling splits the image into square 2-pixel blocks and only keeps maximum value for each of those blocks."},{"metadata":{"_cell_guid":"f80cdbb6-1393-4d1c-9ed1-1cf8beb06309","collapsed":true,"_uuid":"5e4014da25f9cb615b170af4767dd8d55dbae496","trusted":false},"cell_type":"code","source":"def conv2d(x, W, b, strides=1):\n    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)\n\n\ndef maxpool2d(x, k=2):\n    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n                          padding='SAME')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"45cb2505-00d9-4a4a-af15-3675df7d5a53","_uuid":"673f52e122dc812a6fb243a924fc388db7557db1"},"cell_type":"markdown","source":"## Defining the tensorflow graph\nThe model architecture depends upon the problem. In this problem we have to identify the digit. The digit is identified just by looking at it's shape. Shape is a very low level feature in CNN. In general the first few layers of CNN identifies shapes of input. So we define a very shallow CNN model instead of going for a deep CNN model. \n\nModel architecture :\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Layer &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Output Shape\n  -  Input &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(28$*$28$*$1)\n  -  Conv1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (28$*$28$*$32)&nbsp;&nbsp;&nbsp; (32 are the number of feature maps) \n  -  Maxpool &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(14$*$14$*$32) &nbsp;&nbsp;(Reduces the dimensions to half it's previous value)\n  -  Conv2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (14$*$14$*$64) (64 are the number of feature maps of 2nd Conv layer)\n  -  Maxpool &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (7$*$7$*$64) \n  -  Fully-connected layer &nbsp;&nbsp;&nbsp; (1024) \n  -  Dropout &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (1024)\n  -  Softmax Layer &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (10) (10 Output Classes)\n\n## Dropout\n[Dropout](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5) is a regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data. It is a very efficient way of performing model averaging with neural networks.It removes some nodes from the network at each training stage. Each of the nodes is either kept in the network with probability keep_prob or dropped with probability 1 - keep_prob. After the training stage is over the nodes are returned to the NN with their original weights.\n\n## Learining Rate and Optimizer\n\nThe learninig rate used here is [exponential decay](https://www.tensorflow.org/api_docs/python/tf/train/exponential_decay). It decays after 10,000 steps. Initial rate is taken as 0.001.\n\n\nThe optimizer is [Adam](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) with standard value of Beta1 $=$ 0.9 and Beta2 $=$ 0.999.\n"},{"metadata":{"_cell_guid":"5a49417f-572a-400a-9050-3a7a52e90030","collapsed":true,"_uuid":"c13b59f3f449d07f1ad5637403546e3258b17a60","trusted":false},"cell_type":"code","source":"batch_size = 16\npatch_size = 5\nimage_size = 28\nnum_labels = 10\nnum_channels = 1\ngraph = tf.Graph()\nwith graph.as_default():\n    global_step = tf.Variable(0, trainable=False)\n  \n        # Input data.\n    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n    tf_valid_dataset = tf.constant(X_val, dtype=tf.float32)\n    tf_test_dataset = tf.placeholder(tf.float32, shape=(None, image_size, image_size, num_channels))\n  \n        # Variables.\n    layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, 32], stddev=0.1))\n    layer1_biases = tf.Variable(tf.zeros([32]))\n    \n    layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, 32, 64], stddev=0.1))\n    layer2_biases = tf.Variable(tf.constant(1.0, shape=[64]))\n    \n    layer3_weights = tf.Variable(tf.truncated_normal([7*7*64, 1024], stddev=0.1))\n    layer3_biases = tf.Variable(tf.constant(1.0, shape=[1024]))\n\n    layer4_weights = tf.Variable(tf.truncated_normal([1024, num_labels], stddev=0.1))\n    layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n  \n    # Model.\n    def model(data, dropout):\n        conv1 = conv2d(data, layer1_weights, layer1_biases)\n        conv1 = maxpool2d(conv1, k=2)\n        conv2 = conv2d(conv1, layer2_weights, layer2_biases)\n        conv2 = maxpool2d(conv2, k=2)\n        fullyconnected1 = tf.reshape(conv2, [-1, layer3_weights.get_shape().as_list()[0]])\n        fullyconnected1 = tf.add(tf.matmul(fullyconnected1, layer3_weights), layer3_biases)\n        fullyconnected1 = tf.nn.relu(fullyconnected1)\n        fullyconnected1 = tf.nn.dropout(fullyconnected1, dropout)\n        output = tf.add(tf.matmul(fullyconnected1, layer4_weights), layer4_biases)\n        return output\n  \n    # Training computation.\n    logits = model(tf_train_dataset, 0.75)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels, logits=logits))\n\n    learning_rate = tf.train.exponential_decay(0.001, global_step=global_step,\n                                           decay_steps = 4000, decay_rate = 0.96, staircase=False)\n    \n    # Optimizer.\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, beta2=0.999).minimize(loss, global_step= global_step)\n    # Predictions for the training, validation, and test data.\n    \n    train_prediction = tf.nn.softmax(logits)\n    valid_prediction = tf.nn.softmax(model(tf_valid_dataset, 1))\n    test_prediction = tf.nn.softmax(model(tf_test_dataset, 1))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ebb64e19-a533-4c81-ada2-8cfda6d4c3ce","_uuid":"60b69e02236604a8d348d74efa1424eed8603388"},"cell_type":"markdown","source":"## Defining the accuracy function"},{"metadata":{"_cell_guid":"eb8d2eef-a5a1-4623-b95e-bb38b742ab4c","collapsed":true,"_uuid":"391dbd2958784fbb397425ce9715d8049f4dcb35","trusted":false},"cell_type":"code","source":"def accuracy(predictions, labels):\n    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n          / predictions.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"224a236b-2f56-4269-8c4d-8367f2a3fb99","_uuid":"e7032eb9405036e1e61f17b63868357a6f811b59"},"cell_type":"markdown","source":"## Training the Tensorflow graph"},{"metadata":{"_cell_guid":"2771b541-e7d6-42c8-8b36-7830faa1bee9","_uuid":"063ad6520d2ba1ed2e0b740b0d8b1bf737522ac7","trusted":false,"collapsed":true},"cell_type":"code","source":"num_steps = 9001\nvalid_accuracy_list = []\ntrain_accuracy_list = []\nstep = []\nloss_list = []\nlearning_rate_list = []\nwith tf.Session(graph=graph) as sess:\n    tf.global_variables_initializer().run()\n    summary_writer = tf.summary.FileWriter('./logg',\n                                      sess.graph)\n    print('Initialized')\n    for global_step in range(num_steps):\n        offset = (global_step * batch_size) % (Y_train.shape[0] - batch_size)\n        batch_data = X_train[offset:(offset + batch_size), :, :, :]\n        batch_labels = Y_train[offset:(offset + batch_size), :]\n        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n        _, l, predictions,lr = sess.run(\n            [optimizer, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n        loss_list.append(l)\n        learning_rate_list.append(lr)\n        if (global_step % 1000 ==0):\n            valid_accuracy = accuracy(valid_prediction.eval(), Y_val)\n            train_accuracy = accuracy(predictions, batch_labels)\n            print('Minibatch loss at step %d: %f' % (global_step, l))\n            print('Minibatch accuracy: %.1f%%' % train_accuracy)\n            print('Validation accuracy: %.1f%%' % valid_accuracy)\n            valid_accuracy_list.append(valid_accuracy)\n            train_accuracy_list.append(train_accuracy)\n            step.append(global_step)\n    output = []\n    for i in range(28):\n        batch_test = test[i*1000:(i+1)*1000 , :]\n        output.append(sess.run([test_prediction], feed_dict={tf_test_dataset:batch_test}))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"52e91203-433c-42a0-8daa-77296b679cd6","_uuid":"8a6d906d3321a9781eaad9a35667a010edd67353"},"cell_type":"markdown","source":"\n## Plotting Training Loss  , Learning Rate , Training and Validation Accuracy \n"},{"metadata":{"_cell_guid":"157a21b2-3199-4f38-84fd-6753479a5994","_uuid":"08dbd43cbcb25138ca794372bd454ba0c1177a42","trusted":false,"collapsed":true},"cell_type":"code","source":"trace1 = go.Scatter(\n    y = loss_list\n)\nlayout = go.Layout(\n    title='Loss',\n    xaxis=dict(\n        title='Step',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    ),\n    yaxis=dict(\n        title='loss',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    )\n)\ndata = [trace1]\nfig = go.Figure(data=data, layout=layout)\nplotly.offline.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6323bd5d-5aec-42da-b729-93ddf6b88193","_uuid":"499c0299a8b4a50f58cf6cea9abcb2984e5cdd44","trusted":false,"collapsed":true},"cell_type":"code","source":"trace1 = go.Scatter(\n    y = learning_rate_list\n)\nlayout = go.Layout(\n    title='Learning Rate',\n    xaxis=dict(\n        title='Step',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    ),\n    yaxis=dict(\n        title='Learninig rate',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    )\n)\ndata = [trace1]\nfig = go.Figure(data=data, layout=layout)\nplotly.offline.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cc277db2-07ac-4a3f-b148-4720e20742c2","_uuid":"301c66963fb6cf0d8dc9c5eb48ae88cbbab2d722","trusted":false,"collapsed":true},"cell_type":"code","source":"trace1 = go.Scatter(\n    x = step,\n    y = train_accuracy_list,\n    name = 'Training Accuracy'\n)\ntrace2 = go.Scatter(\n    x = step,\n    y = valid_accuracy_list,\n    name = 'Validation Accuracy'\n)\ndata = [trace1, trace2]\n\nplotly.offline.iplot(data)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"67c01921-e50c-4e5d-9c5a-aee0f74aa4e2","_uuid":"b0a80ae95eb0714c8a67a4db46a58edd964c661f"},"cell_type":"markdown","source":"## Tensorboard Visuals\n\n\n__The tensorboard visuals can be obtained from running the notebook on local pc and running command 'tensorboard --logdir ./logg' __ \n\n## Tensorboard Graph\n__Download the graph to view it properly.__\n\nDownload Link https://drive.google.com/open?id=1rsd5jRuswWQ4tOCU-5Xw9UvVjBrb_5TZ\n\n<img src=\"https://lh3.googleusercontent.com/JBBK6hApwwfd6Heo24kLsBrI5NSs1b2DP843mbvueI0saI3l-fEbbKgvlbDGpKM2qVw45k8p7PQJ0Fnk1QBM=w1366-h678-rw\"  title=\"Convolutional Neural Network\" />"},{"metadata":{"_cell_guid":"95fffada-6cd7-41f8-9d32-36ccf9a453cb","collapsed":true,"_uuid":"7c9806e01c5c430ed549210e8677581473fd5d16","trusted":false},"cell_type":"code","source":"submission = []\nfor i in range(28):\n    for j in range(1000):\n        submission.append(np.argmax(output[i][0][j]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f3afd629-503a-4566-ad0f-55fb6396e2a7","collapsed":true,"_uuid":"37ede72a04a284f44d22657e7f50d951ea7c23ac","trusted":false},"cell_type":"code","source":"submission = pd.Series(submission, name=\"Label\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fdc4e1ac-56e3-454a-b728-35b80ff60cc2","_uuid":"45a6dcf1c6cdbd7e9e909acaa5f60b5fe18ce631","trusted":false,"collapsed":true},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),submission],axis = 1)\n\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"28dd9a4c-fb11-4001-95c0-49db18222c97","_uuid":"1da85467c1ee38095e40771f4d96f729351e37bd","trusted":false,"collapsed":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c5d23170-6160-47d2-866c-f50ce97d9ecb","_uuid":"4774d3949f24d7bbc93390a0caf9412bcde9a33a"},"cell_type":"markdown","source":"Thanks for reading the notebook . Any suggestion would be apprec"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}