{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 align = \"center\">Deep Learning - Prediction of Handwritten Digits</h1>\n\n![](https://wallpaperbat.com/img/109996-machine-learning-wallpaper.jpg)\n\n# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Introduction</p></div>\nThe main motivation behind creating this kernel was so I could explore more about the field of <strong>deep learning</strong>. In this kernel I'll try to explain some of the concepts I learnt and how they can be applied for our problem statement of identifying digits. We will explore neural networks in Python and then try to implement them using <strong>TensorFlow</strong> and <strong>Keras</strong>.\n\n### What is Tensorflow ?\n\nTensorFlow is a free and open-source software library for machine learning and artificial intelligence. It can be used across a range of tasks but has a particular focus on training and inference of deep neural networks.\n\n<img src = \"https://149695847.v2.pressablecdn.com/wp-content/uploads/2019/06/tf_logo_social.png\" width = \"250\">\n\n### What is Keras ?\n\nKeras is a deep learning API written in Python, running on top of the machine learning platform `TensorFlow`. It was developed with a focus on enabling fast experimentation.\n\n<img src = \"https://miro.medium.com/max/600/1*DKu_54iqz6C-p6ndo7rO3g.png\" width = \"200\" height = \"200\">\n\n# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Imports</p></div>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\n\nfrom IPython.display import YouTubeVideo\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.models import Model\nfrom keras.callbacks import ReduceLROnPlateau\n\nimport cv2\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:15:33.375444Z","iopub.execute_input":"2022-05-31T16:15:33.375767Z","iopub.status.idle":"2022-05-31T16:15:33.385612Z","shell.execute_reply.started":"2022-05-31T16:15:33.375736Z","shell.execute_reply":"2022-05-31T16:15:33.384522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">The Basics</p></div>\n<div class=\"alert alert-info\">\nBefore we can start classifying our digits, lets try and understand some of the most basic things about deep learning.\n<ul>\n    <li>What is a Tensor ?</li>\n    <li>What is a Neural Network ?</li>\n    <li>The Perceptron</li>\n</ul>\n</div>\n\n# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">What is a Tensor ?</p></div>\n**`Tensor`**: I've seen many complex definitions of tensors on Google and this was the simplest one I could find. A tensor is a container which can house data in N dimensions.\n\n<img src = \"https://qph.fs.quoracdn.net/main-qimg-8a42228263b908bec0de477a66c0f83e\" width = 350 height = 400>\n\nSome of the common terms associated with `tensors` are:\n - `Rank`: It is defined as the number of dimensions of that tensor.\n - `Shape`: It represents the size of the each dimension.\n - `Data-type`: Type of data contained in the tensor, such as `int32`, `int64`, `float32`, `float64`, etc.\n\nLets take a look at creating tensors and then explore some of the operations we can perform with them.","metadata":{}},{"cell_type":"code","source":"# 1D tensor\na = tf.constant([0, 1, 2, 3])\nprint(a, '\\n')\n\n# 2D tensor\nb = tf.constant([[0, 1],\n                [2, 3],\n                [4, 5]])\nprint(b, '\\n')\n\n# 3D tensor\nc = tf.constant([[[0, 1, 2, 3, 4],\n                   [5, 6, 7, 8, 9]],\n                  [[10, 11, 12, 13, 14],\n                   [15, 16, 17, 18, 19]],\n                  [[20, 21, 22, 23, 24],\n                   [25, 26, 27, 28, 29]]])\nprint(c)","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-31T16:15:34.432014Z","iopub.execute_input":"2022-05-31T16:15:34.432412Z","iopub.status.idle":"2022-05-31T16:15:34.444744Z","shell.execute_reply.started":"2022-05-31T16:15:34.43237Z","shell.execute_reply":"2022-05-31T16:15:34.443965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we try to visualize the 3D tensor the break down would look like this:\n\n<img src = \"https://www.tensorflow.org/guide/images/tensor/3-axis_front.png\" width = 300>\n\nHigher dimensional tensors might be a bit tough to understand through code, so lets look at a visualization of what they look like:\n\n<img src = \"https://www.cc.gatech.edu/~san37/img/dl/tensor.png\" width = 500 height = 500>\n\n# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Tensor Operations</p></div>\n\nLet's take a look at a few operations that can be performed using `tensors`","metadata":{}},{"cell_type":"code","source":"# add two tensors\nprint(tf.add(5, 5), '\\n')\n\n# square the tensor\nprint(tf.square(10), '\\n')\n\n# adds all the tensors\nprint(tf.reduce_sum([5, 10, 100]), '\\n')\n\nt1 = tf.constant([[4, 5],\n                 [9, 10]])\nt2 = tf.constant([[3, 1],\n                 [15, 8]])\n\n# add 'n' tensors \nprint(tf.math.add_n([t1, t2, t2]), '\\n')\n\n# subtract the tensors\nprint(tf.subtract(t1, t2), '\\n')\n\nt3 = tf.constant([[1.5, 8],\n                 [16, 20]])\nt4 = tf.constant([[3.0, 4],\n                 [10, 25]])\n\n# multiply tensors\nprint(tf.multiply(t3, t4), '\\n')\n\n# divide the tensors\nprint(tf.divide(t3, t4), '\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:15:35.507196Z","iopub.execute_input":"2022-05-31T16:15:35.507605Z","iopub.status.idle":"2022-05-31T16:15:35.527375Z","shell.execute_reply.started":"2022-05-31T16:15:35.507563Z","shell.execute_reply":"2022-05-31T16:15:35.526378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">What is a Neural Network ?</p></div>\n\nNeural Networks (NNs) are one of the most important aspects of deep learning. [Neural Networks are a set of algorithms inspired by neurons in the human brain.](https://purnasaigudikandula.medium.com/a-beginner-intro-to-neural-networks-543267bda3c8)\n\nApart from this blog post, I found a few YouTube videos that explain what a neural network is. Definitely worth checking them out !!","metadata":{}},{"cell_type":"code","source":"YouTubeVideo('aircAruvnKk', width = 700, height = 500)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-31T16:15:36.727527Z","iopub.execute_input":"2022-05-31T16:15:36.728174Z","iopub.status.idle":"2022-05-31T16:15:36.935124Z","shell.execute_reply.started":"2022-05-31T16:15:36.728132Z","shell.execute_reply":"2022-05-31T16:15:36.934484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n    A few more helpful videos on this topic:\n    <ul>\n        <li><a href='https://www.youtube.com/watch?v=IHZwWFHWa-w'>How Neural Networks Learn ?</a></li>\n        <li><a href='https://www.youtube.com/watch?v=Ilg3gGewQ5U&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=3'>Backpropogation</a></li>\n        <li><a href='https://www.youtube.com/watch?v=tIeHLnjs5U8&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=4'>Math Behind Backpropogation</a></li>\n    </ul>\n</div>\n\n# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">The Perceptron</p></div>\n\nA perceptron is the basic unit of a neural network. It has only 1 layer. A perceptron consists of input values, weights, a bias, a weighted sum and activation function. This is what a **Perceptron** looks like:\n<img src = \"https://cdn-images-1.medium.com/max/624/1*1Fvs7xlgf1p_D_EZmm5_vg.png\" width = 600>\n\nIt might seem a bit intimidating at first so lets break it down it smaller parts and understand what each part of a <i>Perceptron</i> really means.\n> - `Weights`: In simple terms weights decide how much influence the input will have on the output.\n> - `Bias`: Basically it is a constant value. Bias allows you to shift the activation function by adding a constant. \n> - `Weighted Sum`: It can be expressed according to this formula:<br>\n<img src = \"https://miro.medium.com/max/875/1*sA1AswVFReH7M6zAoBGFzg.png\" width = 300>\n> - `Activation Function`: An Activation Function decides whether a neuron should be activated or not. Some of the most popular activation functions are:\n    <ol>\n        <li><b>Sigmoid</b>: It is especially used for models where we have to predict the probability as an output. Since probability of anything exists only between               the range of 0 and 1, sigmoid is a good choice.\n            <img src = \"https://miro.medium.com/max/970/1*Xu7B5y9gp0iL5ooBj7LtWw.png\" width = 500>\n        </li>\n        <li><b>ReLU (Rectified Linear Unit) </b>: It will output the input directly if it is positive, otherwise, it will output zero. This is what it looks like:-\n            <p><img src = \"https://analyticsindiamag.com/wp-content/uploads/2018/01/relu-activation-function-1.png\" width = 500></p>\n        </li>\n        <li><b>Leaky ReLU</b>: It is a type of activation function based on a ReLU, that has a small slope for negative values instead of a flat slope.\n            <p><img src = \"https://www.researchgate.net/profile/Stefano-Romanazzi/publication/325226633/figure/fig9/AS:627667623768071@1526659031098/Plot-of-the-                                 LeakyReLU-function.png\" width = 500></p>\n        </li>\n        <li><b>Tanh</b>: The function takes any real value as input and outputs values in the range -1 to 1.<br>\n            <img src = \"https://www.researchgate.net/publication/340644173/figure/fig2/AS:880423089491969@1586920630956/3a-Graph-of-the-tanh-function-3b-Graph-of-gradient-of-tanh-function.ppm\" width = 450>\n        </li>\n    </ol>\n    \n# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Feed Forward Neural Networks (FFNN)</p></div>\nIn a feed forward neural network information flows only in **one direction**. It is one of the simplest forms of a neural network. It is a **Multi-Layered Perceptron (MLP)** as it is composed of multiple perceptrons. The opposite of a Feed Forward Neural Network is a **Recurrent Neural Network**, in which certain pathways are cycled.\n\n<img src = \"https://miro.medium.com/proxy/1*By-gx36gxOgfXa37zZCbSw.png\">\n\nData enters at the inputs and passes through the network, layer by layer until it arrives at the output. During normal operation there is no feedback between the layers of the neural network.\n\nThe FFNN is the above example has the following architecture:\n> - 1 input layer with 4 neurons that accept inputs `x1`, `x2`, `x3` and `x4`\n> - 1<sup>st</sup> hidden layer with 4 neurons\n> - 2<sup>nd</sup> hidden layer with 5 neurons\n> - 3<sup>rd</sup> hidden layer with 6 neurons\n> - 4<sup>th</sup> hidden layer with 4 neurons\n> - 5<sup>th</sup> hidden layer with 3 neurons\n> - 1 output layer with 3 ouputs `y1`, `y2` and `y3`\n\nSince every neuron in a layer is connected to every other neuron in the next layer it is a <i>Fully Connected Neural Network (FCNN)</i>.\n\n**Note**: Any neural network with more than 1 hidden layer is considered to be a **<i>Deep Neural Network</i>**.\n\n# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Recurrent Neural Networks (RNN)</p></div>\nRecurrent Neural Networks (RNNs) are a type of neural networks where the **output from the previous step is fed as input to the current step**. Most neural networks such as feedforward neural networks, have no memory of the input they received just one moment ago. For example, if you provide a feedforward neural network with the sequence of letters `WISDOM` when it gets to `D` it has already forgotten that it just read the letter `S`. No matter how much you train it, it will always struggle to guess the most likely next character `O`. Recurrent networks, on the other hand, remember what they’ve just encountered.\n\n<img src = \"https://www.researchgate.net/publication/338672883/figure/fig1/AS:864764884422656@1583187423806/The-comparison-between-Recurrent-Neural-Network-RNN-and-Feed-Forward-Neural-Network.jpg\" height = 550 width = 550>\n\nRNNs assign a <i>matrix of weights</i> to their multiple inputs, then apply a function to those weights to determine a single output. The weights are applied not only to their present inputs, but also to their inputs from a moment ago.\n\nRNNs work on the principle of **Backpropogation Throught Time (BPTT)**. The goal of **backpropagation** is to <i>modify the weights</i> of a neural network in order to minimize the error. BPTT extends the tweaking process to include the weight of **`T-1`** input values responsible for each unit’s memory of the prior moment.\n\n<img src = \"https://miro.medium.com/max/1200/1*chs1MCz2rCK4_dFRLnUEIg.png\">\n\nThe 2 most commons problems associated with RNNs are:\n> - <ol>\n    <li><b>Vanishing Gradients</b>: As the backpropagation algorithm moves backwards from the output layer towards the input layer, the gradients often get smaller and smaller and approach zero which eventually leaves the weights of the initial layers nearly unchanged. As a result, <b>gradient descent never converges to the optimum</b>. This is known as the <i>vanishing gradients</i> problem.</li>\n    <li><b>Exploding Gradients</b>: In some cases, the gradients keep on getting larger and larger as the backpropagation algorithm progresses. This, in turn, causes very large weight updates and causes <b>gradient descent to diverge</b>. This is known as the <i>exploding gradients</i> problem.</li> \n\n# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">MNIST Dataset</p></div>\nThe MNIST (Modified National Institute of Standards and Technology) dataset for deep learning is like Titanic for machine learning. It is one of the simplest and easiest datasets to get started with deep learning and neural networks.","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:15:37.921711Z","iopub.execute_input":"2022-05-31T16:15:37.922523Z","iopub.status.idle":"2022-05-31T16:15:37.929991Z","shell.execute_reply.started":"2022-05-31T16:15:37.92248Z","shell.execute_reply":"2022-05-31T16:15:37.928612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Taking a look at our data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\nprint(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:15:38.976255Z","iopub.execute_input":"2022-05-31T16:15:38.976944Z","iopub.status.idle":"2022-05-31T16:15:41.733674Z","shell.execute_reply.started":"2022-05-31T16:15:38.976879Z","shell.execute_reply":"2022-05-31T16:15:41.732759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets take a look at missing values in the MNIST dataset","metadata":{}},{"cell_type":"code","source":"print(train_df.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:15:41.95397Z","iopub.execute_input":"2022-05-31T16:15:41.954292Z","iopub.status.idle":"2022-05-31T16:15:42.006269Z","shell.execute_reply.started":"2022-05-31T16:15:41.954256Z","shell.execute_reply":"2022-05-31T16:15:42.00533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fortunately there are no missing values present in the dataset.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nax = sns.countplot(x = 'label', data = train_df)\nplt.title('Class Count', fontsize = 20)\nplt.xlabel('Labels', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x() + 0.25, p.get_height() + 10))","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:15:43.016742Z","iopub.execute_input":"2022-05-31T16:15:43.017197Z","iopub.status.idle":"2022-05-31T16:15:43.333612Z","shell.execute_reply.started":"2022-05-31T16:15:43.017164Z","shell.execute_reply":"2022-05-31T16:15:43.332493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The number of images for each class is relatively similar. A huge class imbalance does not exist in the dataset, however there is a minor class imbalance that does exist.","metadata":{}},{"cell_type":"code","source":"X = train_df.drop(columns = ['label']).values.astype('float32')\ny = train_df['label'].values\nprint(X, '\\n')\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:15:44.377383Z","iopub.execute_input":"2022-05-31T16:15:44.378414Z","iopub.status.idle":"2022-05-31T16:15:44.670984Z","shell.execute_reply.started":"2022-05-31T16:15:44.378361Z","shell.execute_reply":"2022-05-31T16:15:44.670064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Splitting the Data</p></div>\nLets split our dataset using the `train_test_split` function. We set the `test_size` to 10 % of our dataset.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, stratify = y, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:15:45.878892Z","iopub.execute_input":"2022-05-31T16:15:45.879226Z","iopub.status.idle":"2022-05-31T16:15:46.449296Z","shell.execute_reply.started":"2022-05-31T16:15:45.879192Z","shell.execute_reply":"2022-05-31T16:15:46.44835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets take a look at the shape of `X_train`","metadata":{}},{"cell_type":"code","source":"print(X_train, '\\n')\nprint(X_train.shape)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-31T16:15:47.409295Z","iopub.execute_input":"2022-05-31T16:15:47.409577Z","iopub.status.idle":"2022-05-31T16:15:47.415489Z","shell.execute_reply.started":"2022-05-31T16:15:47.409548Z","shell.execute_reply":"2022-05-31T16:15:47.41481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The number of rows = 42000 - 0.1 * 42000 = 37800<br>\nThe number of columns = 784","metadata":{}},{"cell_type":"code","source":"X_train[0]","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-31T16:15:48.51456Z","iopub.execute_input":"2022-05-31T16:15:48.514895Z","iopub.status.idle":"2022-05-31T16:15:48.530931Z","shell.execute_reply.started":"2022-05-31T16:15:48.51486Z","shell.execute_reply":"2022-05-31T16:15:48.529895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_train)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:15:49.282334Z","iopub.execute_input":"2022-05-31T16:15:49.282664Z","iopub.status.idle":"2022-05-31T16:15:49.288992Z","shell.execute_reply.started":"2022-05-31T16:15:49.282607Z","shell.execute_reply":"2022-05-31T16:15:49.288079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`y_train` is a single list with 37800 entries","metadata":{}},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Traditional Machine Learning for Digit Classification</p></div>\nBefore we can start applying Deep Learning and Neural Networks for classifying the digits, lets take a look at the performance of some popular **Machine Learning Algorithms**. Lets compare the accuracy of the machine learning methods with each other and then with the CNN we train to anaylze which model works best on the given data.\n\n### KNN","metadata":{}},{"cell_type":"code","source":"neighbors_and_accuracy = {}\nn_neighbors = [i for i in range(1, 20, 2)]\n\nfor i in n_neighbors:\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(X_train, y_train)\n    print(f'For n_neighbors = {i}')\n    score = knn.score(X_test, y_test)\n    print(f'Score = {score}')\n    neighbors_and_accuracy.update({i: score})\nprint('--------------------------')\n\nsorted_dict = dict(sorted(neighbors_and_accuracy.items(), key = lambda x: x[1], reverse = True))\nprint(f'Best Neighbors = {list(sorted_dict.keys())[0]}')\nprint(f'Best Score = {list(sorted_dict.values())[0]}')\n\nfinal_knn = KNeighborsClassifier(n_neighbors = list(sorted_dict.keys())[0])\nfinal_knn.fit(X_train, y_train)\ny_pred = final_knn.predict(X_test)\ncm_final_knn = confusion_matrix(y_test, y_pred)\n\nplt.figure(figsize = (15, 10))\nsns.heatmap(cm_final_knn, cmap = 'Blues', annot = True, annot_kws = {'size': 12})\nplt.title('Confusion Matrix for KNN', fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:15:53.007243Z","iopub.execute_input":"2022-05-31T16:15:53.007831Z","iopub.status.idle":"2022-05-31T16:17:30.563881Z","shell.execute_reply.started":"2022-05-31T16:15:53.007794Z","shell.execute_reply":"2022-05-31T16:17:30.562989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"dtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\ny_pred = dtc.predict(X_test)\nacc_dtc = dtc.score(X_test, y_test)\nprint(f'Score = {acc_dtc}')\ncm_dtc = confusion_matrix(y_test, y_pred)\n\nplt.figure(figsize = (15, 10))\nsns.heatmap(cm_dtc, cmap = 'Blues', annot = True, annot_kws = {'size': 12})\nplt.title('Confusion Matrix for the Decision Tree Classifier', fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:17:30.566033Z","iopub.execute_input":"2022-05-31T16:17:30.566611Z","iopub.status.idle":"2022-05-31T16:17:42.766371Z","shell.execute_reply.started":"2022-05-31T16:17:30.566564Z","shell.execute_reply":"2022-05-31T16:17:42.765247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"best_score = 0\n\nfor i in range(100, 600, 100):\n    rfc = RandomForestClassifier(n_estimators = i, random_state = 0)\n    rfc.fit(X_train, y_train)\n    print(f'For n_estimators = {i}')\n    score = rfc.score(X_test, y_test)\n    if(score > best_score):\n        best_score = score\n        best_estimator = i\n    print(f'Score = {score}')\n    \nprint('--------------------------')\nprint('Best estimators = {}'.format(best_estimator))\nprint('Best Score = {}'.format(best_score))\n\nimproved_rfc = RandomForestClassifier(n_estimators = best_estimator, random_state = 0)\nimproved_rfc.fit(X_train, y_train)\ny_pred = improved_rfc.predict(X_test)\nacc_improved_rfc = improved_rfc.score(X_test, y_test)\ncm_improved_rfc = confusion_matrix(y_test, y_pred)\n\nplt.figure(figsize = (15, 10))\nsns.heatmap(cm_improved_rfc, cmap = 'Blues', annot = True, annot_kws = {'size': 12})\nplt.title('Confusion Matrix for the Random Forest Classifier', fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:17:45.966395Z","iopub.execute_input":"2022-05-31T16:17:45.966773Z","iopub.status.idle":"2022-05-31T16:26:10.110542Z","shell.execute_reply.started":"2022-05-31T16:17:45.966736Z","shell.execute_reply":"2022-05-31T16:26:10.109522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this case traditional machine learning models give a decent accuracy in the range of 96%. If we want to get a better result then we need to try Deep Learning using Convolutional Neural Networks. Most CNNs are able to give 98% to 99% accuracy on the dataset.","metadata":{}},{"cell_type":"code","source":"X_train = X_train.reshape(X_train.shape[0], 28, 28)\nX_test = X_test.reshape(X_test.shape[0], 28, 28)\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:26:10.112786Z","iopub.execute_input":"2022-05-31T16:26:10.113798Z","iopub.status.idle":"2022-05-31T16:26:10.12101Z","shell.execute_reply.started":"2022-05-31T16:26:10.113745Z","shell.execute_reply":"2022-05-31T16:26:10.119873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Visualizing the Images</p></div>\n\nLets take a look at the what the images of our dataset actually look like","metadata":{}},{"cell_type":"code","source":"def show_random_images(color1, color2, color3, color4):\n    \n    '''Randomly prints images from the dataset with different color maps'''\n\n    random_list = []\n    for i in range(0, 4):\n        random_number = random.randint(0, 37800)\n        random_list.append(random_number)\n\n    fig, axes = plt.subplots(2, 2, figsize = (10, 10))\n\n    axes[0, 0].imshow(X_train[random_list[0]], cmap = color1)\n    axes[0, 0].set_title('Label = ' + str(y_train[random_list[0]]))\n    axes[0, 0].axis('off')\n\n    axes[0, 1].imshow(X_train[random_list[1]], cmap = color2)\n    axes[0, 1].set_title('Label = ' + str(y_train[random_list[1]]))\n    axes[0, 1].axis('off')\n\n    axes[1, 0].imshow(X_train[random_list[2]], cmap = color3)\n    axes[1, 0].set_title('Label = ' + str(y_train[random_list[2]]))\n    axes[1, 0].axis('off')\n\n    axes[1, 1].imshow(X_train[random_list[3]], cmap = color4)\n    axes[1, 1].set_title('Label = ' + str(y_train[random_list[3]]))\n    axes[1, 1].axis('off')\n\n    plt.show()\n\nshow_random_images('Greens', 'YlOrBr', 'gist_heat', 'winter')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-31T16:26:16.529877Z","iopub.execute_input":"2022-05-31T16:26:16.530191Z","iopub.status.idle":"2022-05-31T16:26:16.824429Z","shell.execute_reply.started":"2022-05-31T16:26:16.530159Z","shell.execute_reply":"2022-05-31T16:26:16.822518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_multiple_images(train_or_test, caption, title):\n    \n    '''Displays the first 25 images of the dataset'''\n\n    r = 5\n    c = 5 \n\n    fig = plt.figure(figsize = (10, 10))\n\n    for i in range(r * c): \n        fig.add_subplot(r, c, i + 1)\n        plt.imshow(train_or_test[i]) \n        plt.title(caption + ' = ' + str(title[i]))\n        plt.axis(\"off\")\n        \ndisplay_multiple_images(X_train, 'Label', y_train)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-31T16:26:16.866688Z","iopub.execute_input":"2022-05-31T16:26:16.867039Z","iopub.status.idle":"2022-05-31T16:26:17.935694Z","shell.execute_reply.started":"2022-05-31T16:26:16.867003Z","shell.execute_reply":"2022-05-31T16:26:17.934689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def images_and_pixels(image, ax):\n    \n    '''Displays a random image along with its pixel values'''\n    \n    ax.imshow(image, cmap = 'PuBu')\n    width, height = image.shape\n    threshold = image.max() / 2.5\n    \n    for x in range(width):\n        for y in range(height):\n            ax.annotate(str(round(image[x][y],2)), \n                        xy = (y,x),\n                        horizontalalignment = 'center',\n                        verticalalignment = 'center',\n                        color = 'white' if image[x][y] < threshold else 'black')\n\nfig = plt.figure(figsize = (10,10)) \nax = fig.add_subplot(111)\nrandom_number = random.randint(0, 37800)\n\nimages_and_pixels(X_train[random_number], ax)\n\nplt.title('Label = ' + str(y_train[random_number]), fontsize = 20)\nplt.axis('off')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-31T16:26:17.937845Z","iopub.execute_input":"2022-05-31T16:26:17.938216Z","iopub.status.idle":"2022-05-31T16:26:22.107431Z","shell.execute_reply.started":"2022-05-31T16:26:17.93817Z","shell.execute_reply":"2022-05-31T16:26:22.106602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reshaping and normalizing `X_train` and `X_test`","metadata":{}},{"cell_type":"code","source":"X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_train = X_train / 255.0\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\nX_test = X_test / 255.0\nprint(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:26:22.108891Z","iopub.execute_input":"2022-05-31T16:26:22.109148Z","iopub.status.idle":"2022-05-31T16:26:22.268045Z","shell.execute_reply.started":"2022-05-31T16:26:22.109115Z","shell.execute_reply":"2022-05-31T16:26:22.267348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Data Augmentation</p></div>\n\nData augmentation helps us expand the size of our dataset and provide more data to the model for training. It helps us apply different transformations to the original image, which results in multiple transformed copies of the same image.\n\n**Note**: If augmented data was passed to the machine learning models we created above, the accuracy could improve. The reason I am applying augmentation after the training the models, is because the ML models cannot go past a certain level of accuracy even after augmentations like the CNN can. The augmented data that we generate using `ImageDataGenerator` is passed to the CNN for training. ","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n                zoom_range = 0.1,\n                width_shift_range = 0.1,\n                height_shift_range = 0.1)\ndatagen.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:26:40.057526Z","iopub.execute_input":"2022-05-31T16:26:40.057836Z","iopub.status.idle":"2022-05-31T16:26:40.144254Z","shell.execute_reply.started":"2022-05-31T16:26:40.057807Z","shell.execute_reply":"2022-05-31T16:26:40.14287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">CNN (Convolutional Neural Network)</p></div>\n\nA convolutional neural network is a class of deep neural networks, most commonly applied to analyze visual imagery. This is what a CNN looks like:\n\n<img src = \"https://miro.medium.com/max/1400/1*0NwaOkzvom6YpMZoIgWTiQ.png\">\n\nSome of the common terms associated with it are:\n\n> - `Convolution`: It is the first layer to extract features from an input image. It preserves the relationship between pixels by learning image features using small squares of input data. It is a mathematical operation that takes two inputs:\n    - An image matrix\n    - Filter (or kernel)\n> - `Filter`: It is also called a `kernel`. Filters detect spatial patterns such as edges in an image by detecting the change in intensity values of the image. The values of the filters are learned automatically by the neural network through the training process.\n    <p><img src = \"https://miro.medium.com/max/826/1*4yv0yIH0nVhSOv3AkLUIiw.png\"></p>  \n> - `Feature Map`: This is also called the `Activation Map`. It is the result of the multiplication of the `image matrix` and the `filter`.\n    <p><img src = \"https://miro.medium.com/max/536/1*MrGSULUtkXc0Ou07QouV8A.gif\"></p>\n> - `Kernel Size`: It is the size of the `kernel` or the `filter`.\n> - `Stride`: It is the number of pixels shifted over the input image.\n    <p><img src = \"https://miro.medium.com/max/1400/1*ulfFYH5HbWpLTIfuebj5mQ.gif\" width = 300 height = 300></p>\n    In the above example the image size is 5 x 5, the kernel size is 3 x 3 and the stride is 1.\n> - `Padding`: It extends the area of the image which is processed by the CNN. Adding padding to the image processed by the CNN allows for a more accurate analysis of the images.\n    <p><img src = \"https://upload.wikimedia.org/wikipedia/commons/0/04/Convolution_arithmetic_-_Padding_strides.gif\" width = 300 height = 300></p>\n> - `Max Pooling`: In `max pooling` the kernel extracts the maximum value of the area it convolves. It is <i>advisable</i> to perform `max pooling` when it is possible to extract some features from our image. It is not recommended to perform this operation in the initial stages of the CNN as the kernels would still be in the process of extracting edges and gradients.\n    <p><img src = \"https://lh5.googleusercontent.com/jOohqE8T9IYqkir1OzJN2vRdeykH1yGnwEy9oWK85EWf2aP-jg10YZt_3yaVDeCZVS9713QDACk0l1iYX5e5EfE2CUqbSLVaq5UBeGL91a92v3ZMRyb4FLobxjN5pDh4RBc1pT-8\" width = 450 height = 450></p>\n> - `Batch Normalization`: This allows every layer of the network to do learning more independently. It is used to normalize the output of the previous layers.\n> - `Dropout`: This is a technique where randomly selected neurons are ignored during training. They are <i>dropped out</i> randomly. The effect is that the network becomes less sensitive to the specific weights of the neurons. This helps the network **generalize better** and makes it less likely to overfit the data.","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n            keras.Input(shape = (28, 28, 1)),\n            layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n            layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n            layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n            layers.MaxPooling2D(),\n            layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n            layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n            layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n            layers.MaxPooling2D(),\n            layers.Conv2D(128, 3, padding = 'same', activation = 'relu'),\n            layers.Conv2D(128, 3, padding = 'same', activation = 'relu'),\n            layers.Conv2D(128, 3, padding = 'same', activation = 'relu'),\n            layers.Flatten(),\n            layers.Dropout(0.20),\n            layers.Dense(128, activation = 'relu'),\n            layers.Dense(10, activation = 'softmax'),\n])\n\nmodel.compile(\n        loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n        optimizer = keras.optimizers.Adam(lr = 1e-4),\n        metrics = ['acc'],\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:26:41.97756Z","iopub.execute_input":"2022-05-31T16:26:41.977969Z","iopub.status.idle":"2022-05-31T16:26:42.504673Z","shell.execute_reply.started":"2022-05-31T16:26:41.977931Z","shell.execute_reply":"2022-05-31T16:26:42.50361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have now defined our custom CNN model architecture, but what the **<i>heck</i>** does all this even mean?\n> - `Sequential` in Keras allows you to create models layer-by-layer for most problems. It is limited in that it does not allow you to create models that share layers or have multiple inputs or outputs.\n> - `Input` is used to accept the images in our dataset as the input. The shape has to be in the form of `width x height x channel`. Here the width = height = 28 and the number of channels = 1 since it is a black and white image. If we wanted to train the model for a colored images we would have set number of channels to 3.  \n> - `Conv2D` is the Convolutional layer of our CNN. Once we understand the parameters of the first `Conv2D` layer it will become easy to understand the other convolutional layers as well. The first convolutional layer has:\n> > - `filters` = 32\n> > - `kernel_size` = 3\n> > - `padding = same`: It applies padding to the input image so that the input image gets fully covered by the filter and the specified stride. If the `stride` = 1 then the layer's output will have the same spatial dimensions as its input\n> > - `activation = 'relu'` is the activation function for the layer of the CNN\n> - `MaxPooling2D` as we saw earlier is used to help the kernel extract the maximum value of the area it convolves.\n> - `Flatten` helps you <i>flatten</i> the multi-dimension inputs into a single dimension.\n> - `Dropout`: A Dropout of `0.20` means that 20 % of randomly selected neurons are ignored during training. They are <i>dropped out</i> randomly.  \n> - `Dense` is the fully connected neural network layer. The first `Dense` layer has `units` = 128. This is the same as the number of neurons. It also has the `relu` activation function. It performs the following operation:\n> > - `output = activation(dot(input, kernel) + bias)`\n\nOnce we have defined the architecture to our CNN we have to `compile` the model. In our case our model is compiled having the following parameters:\n> - `loss`: The purpose of loss functions is to compute the quantity that a model should seek to minimize during training. We use `SparseCategoricalCrossentropy` when there are 2 or more classes in our dataset. You can take a look at the different types of loss functions provided by Keras over [here](https://keras.io/api/losses/).\n> - `optimizer`: We use the `Adam` optimizer which is an <i>ADAptive Moment (ADAM) Estimation Algorithm</i>. We set `lr = 1e-4`. The **learning rate** is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated.\n> - `metrics` are functions that are used to judge the perfomance of the model. The `acc` metric computes the accuracy rates across all the predictions.\n\nKeras provies a way to looks at the summary of the model using `model.summary()`. The summary is textual and includes information about the layers and their order in the model, the output shape of each layer and the number of parameters (weights) in each layer.","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:26:43.747057Z","iopub.execute_input":"2022-05-31T16:26:43.747363Z","iopub.status.idle":"2022-05-31T16:26:43.761473Z","shell.execute_reply.started":"2022-05-31T16:26:43.747333Z","shell.execute_reply":"2022-05-31T16:26:43.760325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Learning Rate Reduction</p></div>\n\nModels often benefit by reducing the learning rate once learning stagnates. `ReduceLROnPlateau` monitors a particular quantity (in this case `val_acc`) and if no improvement is seen for a `patience` number of epochs, the learning rate is reduced. `ReduceLROnPlateau` accepts the following parameters:\n> - `monitor`: Quantity to be monitored\n> - `patience`: Number of epochs with no improvement, after which learning rate will be reduced.\n> - `verbose`: Set `verbose = 0` if you don't want message updates (quiet). Set `verbose = 1` to get message updates.\n> - `factor`: Factor by which learning rate will be reduced. The formula is : `new_lr = lr * factor`\n> - `min_lr`: Lower bound on the learning rate","metadata":{}},{"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor = 'val_acc', patience = 3, verbose = 1, factor = 0.5, min_lr = 0.00001)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:26:45.896993Z","iopub.execute_input":"2022-05-31T16:26:45.8973Z","iopub.status.idle":"2022-05-31T16:26:45.902746Z","shell.execute_reply.started":"2022-05-31T16:26:45.897271Z","shell.execute_reply":"2022-05-31T16:26:45.902001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Training the CNN</p></div>\n\nAfter deciding a CNN architecture, <i>**training**</i> your model is the most important part. Lets take a look at some of the parameters of the `.fit` function:\n> - `X_train` and `y_train` are the training data\n> - `batch_size` is the number of samples processed before the model is updated.\n> - `epochs`: An epoch means training the neural network with all the training data for one cycle.\n> - `validation_data` is the data on which we evaluate the loss and metrics at the end of each epoch.\n> - `steps_per_epoch`: It is used to define how many batches of samples to use in 1 epoch.\n> - `callbacks`: These are functions or blocks of code which are executed during a specific instant while training a deep learning model. In this case we have `reduce_lr` as the callback.","metadata":{}},{"cell_type":"code","source":"classifier = model.fit_generator(datagen.flow(X_train, y_train, batch_size = 64), \n                                 epochs = 50, \n                                 validation_data = (X_test, y_test), \n                                 verbose = 1,\n                                 steps_per_epoch = X_train.shape[0] // 64,\n                                 callbacks = [reduce_lr])","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-07T01:39:44.59584Z","iopub.execute_input":"2022-04-07T01:39:44.59612Z","iopub.status.idle":"2022-04-07T01:55:18.812688Z","shell.execute_reply.started":"2022-04-07T01:39:44.596089Z","shell.execute_reply":"2022-04-07T01:55:18.811578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Visualizing CNN Layers</p></div>\nLets visualize the layers of our model and take a look at what our CNN is learning.","metadata":{}},{"cell_type":"code","source":"def CNN_layer_visualizer():\n    \n    layer_names = [layer.name for layer in model.layers]\n    layer_outputs = [layer.output for layer in model.layers]\n    \n    activation_model = Model(inputs = model.input, outputs = layer_outputs)\n    input = X_train[random_number]\n    activations = activation_model.predict(input.reshape(-1, 28, 28, 1) / 255.0)\n    \n    for number in range(len(layer_names) - 4):\n        fig = plt.figure(figsize = (22, 3))\n        for img in range(30):\n            ax = fig.add_subplot(2, 15, img + 1)\n            ax = plt.imshow(activations[number][0, :, :, img], cmap = 'afmhot')\n            main_title = fig.suptitle(str(layer_names[number]), fontsize = 20)\n            plt.xticks([])\n            plt.yticks([])\n            fig.subplots_adjust(wspace = 0.05, hspace = 0.05)\n            \nCNN_layer_visualizer()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T01:55:24.561873Z","iopub.execute_input":"2022-04-07T01:55:24.562164Z","iopub.status.idle":"2022-04-07T01:55:41.919655Z","shell.execute_reply.started":"2022-04-07T01:55:24.562134Z","shell.execute_reply":"2022-04-07T01:55:41.91858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Model Performance</p></div>\n\nTo understand the performance of our model we create 2 graphs:\n> - Accuracy vs Epochs \n> - Loss vs Epochs","metadata":{}},{"cell_type":"code","source":"def model_performance_graphs():\n    \n    fig, axes = plt.subplots(1, 2, figsize = (15, 8))\n\n    axes[0].plot(classifier.epoch, classifier.history['acc'], label = 'acc')\n    axes[0].plot(classifier.epoch, classifier.history['val_acc'], label = 'val_acc')\n    axes[0].set_title('Accuracy vs Epochs', fontsize = 20)\n    axes[0].set_xlabel('Epochs', fontsize = 15)\n    axes[0].set_ylabel('Accuracy', fontsize = 15)\n    axes[0].legend()\n\n    axes[1].plot(classifier.epoch, classifier.history['loss'], label = 'loss')\n    axes[1].plot(classifier.epoch, classifier.history['val_loss'], label=\"val_loss\")\n    axes[1].set_title(\"Loss Curve\",fontsize=18)\n    axes[1].set_xlabel(\"Epochs\",fontsize=15)\n    axes[1].set_ylabel(\"Loss\",fontsize=15)\n    axes[1].legend()\n\n    plt.show()\n    \nmodel_performance_graphs()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-07T01:55:45.161305Z","iopub.execute_input":"2022-04-07T01:55:45.161909Z","iopub.status.idle":"2022-04-07T01:55:45.999442Z","shell.execute_reply.started":"2022-04-07T01:55:45.161873Z","shell.execute_reply":"2022-04-07T01:55:45.994532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluating the performance of our model on the training set","metadata":{}},{"cell_type":"code","source":"model.evaluate(X_train, y_train, batch_size = 64, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T01:55:46.87491Z","iopub.execute_input":"2022-04-07T01:55:46.875217Z","iopub.status.idle":"2022-04-07T01:55:50.464287Z","shell.execute_reply.started":"2022-04-07T01:55:46.875179Z","shell.execute_reply":"2022-04-07T01:55:50.463283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluating the performance of our model on the testing set","metadata":{}},{"cell_type":"code","source":"model.evaluate(X_test, y_test, batch_size = 64, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T01:55:50.46664Z","iopub.execute_input":"2022-04-07T01:55:50.466953Z","iopub.status.idle":"2022-04-07T01:55:50.830074Z","shell.execute_reply.started":"2022-04-07T01:55:50.466909Z","shell.execute_reply":"2022-04-07T01:55:50.828977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Making the predictions using our trained model","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\nmake_prediction = (((test_df.values).reshape(-1, 28, 28, 1)) / 255.0)\nfinal_labels = model.predict(make_prediction)\nfinal_labels = np.argmax(final_labels, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T01:56:43.190014Z","iopub.execute_input":"2022-04-07T01:56:43.19031Z","iopub.status.idle":"2022-04-07T01:56:48.19586Z","shell.execute_reply.started":"2022-04-07T01:56:43.190277Z","shell.execute_reply":"2022-04-07T01:56:48.19484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets see how well our predictions match up with the images from `test_df`","metadata":{}},{"cell_type":"code","source":"display_multiple_images(test_df.values.reshape(-1, 28, 28, 1), 'Prediction', final_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T01:57:13.048021Z","iopub.execute_input":"2022-04-07T01:57:13.049962Z","iopub.status.idle":"2022-04-07T01:57:14.479839Z","shell.execute_reply.started":"2022-04-07T01:57:13.04991Z","shell.execute_reply":"2022-04-07T01:57:14.478741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_labels","metadata":{"execution":{"iopub.status.busy":"2022-04-07T01:57:49.271527Z","iopub.execute_input":"2022-04-07T01:57:49.271861Z","iopub.status.idle":"2022-04-07T01:57:49.280734Z","shell.execute_reply.started":"2022-04-07T01:57:49.271827Z","shell.execute_reply":"2022-04-07T01:57:49.279481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Confusion Matrix</p></div>\nLets try to visualize how accurate our model is using a confusion matrix","metadata":{}},{"cell_type":"code","source":"y_pred = np.argmax(model.predict(X_test), axis = 1)\nplt.figure(figsize = (15, 10))\nsns.heatmap(confusion_matrix(y_test, y_pred), cmap = 'Blues', annot = True, annot_kws = {'size': 12})\nplt.title('Confusion Matrix for the CNN', fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T01:57:52.727877Z","iopub.execute_input":"2022-04-07T01:57:52.728508Z","iopub.status.idle":"2022-04-07T01:57:54.481726Z","shell.execute_reply.started":"2022-04-07T01:57:52.72847Z","shell.execute_reply":"2022-04-07T01:57:54.480806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Building 10 CNNs</p></div>\n\nInstead of using only 1 CNN, let's try to use 10 CNNs with the same architecture and then combine their results.","metadata":{}},{"cell_type":"code","source":"n = 10\nnew_models = [0] * n\n\nfor i in range(n):\n    new_models[i] = keras.Sequential([\n                        keras.Input(shape = (28, 28, 1)),\n                        layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n                        layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n                        layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n                        layers.MaxPooling2D(),\n                        layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n                        layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n                        layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n                        layers.MaxPooling2D(),\n                        layers.Conv2D(128, 3, padding = 'same', activation = 'relu'),\n                        layers.Conv2D(128, 3, padding = 'same', activation = 'relu'),\n                        layers.Conv2D(128, 3, padding = 'same', activation = 'relu'),\n                        layers.Flatten(),\n                        layers.Dropout(0.20),\n                        layers.Dense(128, activation = 'relu'),\n                        layers.Dense(10, activation = 'softmax'),\n    ])\n\n    new_models[i].compile(\n                  loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n                  optimizer = keras.optimizers.Adam(lr = 1e-4),\n                  metrics = ['acc'],\n            )","metadata":{"execution":{"iopub.status.busy":"2022-04-07T01:58:04.670857Z","iopub.execute_input":"2022-04-07T01:58:04.671412Z","iopub.status.idle":"2022-04-07T01:58:05.282563Z","shell.execute_reply.started":"2022-04-07T01:58:04.671366Z","shell.execute_reply":"2022-04-07T01:58:05.281321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is the <i>**training**</i> phase of all 10 CNNs. It shows the number of epochs for each model and prints the final results after each model finishes training on 50 epochs. Since we are training 10 CNNs together it takes a <i>long time to run</i>. Feel free to try increasing the number of CNNs to 15 or even 20, **if you have enough GPU time left**.\n\n**Note**: I would <strong><i>not recommend</i></strong> running the cell below if you are trying to conserve GPU time. If only Kaggle had higher GPU limits.....","metadata":{}},{"cell_type":"code","source":"history = [0] * n\nfor i in range(n):\n    history[i] = new_models[i].fit_generator(datagen.flow(X_train, y_train, batch_size = 64), \n                                   epochs = 50, \n                                   validation_data = (X_test, y_test), \n                                   verbose = 1,\n                                   steps_per_epoch = X_train.shape[0] // 64,\n                                   callbacks = [reduce_lr])\n    print('Model {model_number}: Epochs = {epochs}: Training Accuracy = {training_accuracy}: Validation Accuracy = {validation_accuracy}'.format(model_number = i + 1,\n                                                                                                                                                epochs = 50,\n                                                                                                                                                training_accuracy = max(history[i].history['acc']),\n                                                                                                                                                validation_accuracy = max(history[i].history['val_acc'])))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-07T01:58:09.909112Z","iopub.execute_input":"2022-04-07T01:58:09.909394Z","iopub.status.idle":"2022-04-07T03:14:30.335471Z","shell.execute_reply.started":"2022-04-07T01:58:09.909362Z","shell.execute_reply":"2022-04-07T03:14:30.333832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Performance of 10 CNNs</p></div>\n\nTo understand how all 10 of our CNNs trained we need to look the performance accuracy of each CNN against the number of epochs (50) they were trained on.","metadata":{}},{"cell_type":"code","source":"model_nos = ['Model: ' + str(i + 1) for i in range(0, 10)]\nplt.figure(figsize = (15, 10))\nfor i in range(n):\n    plt.plot(history[i].history['val_acc'])\nplt.title('CNN Accuracy', fontsize = 20)\nplt.legend(model_nos, loc = 'lower right')\nplt.xlabel('Epochs', fontsize = 15)\nplt.ylabel('Accuracy',  fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T03:24:44.313922Z","iopub.execute_input":"2022-04-07T03:24:44.314538Z","iopub.status.idle":"2022-04-07T03:24:44.613264Z","shell.execute_reply.started":"2022-04-07T03:24:44.314501Z","shell.execute_reply":"2022-04-07T03:24:44.612276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Ensemble 10 CNNs</p></div>\nEnsembling is the process by which multiple models can be combined to solve a particular problem. We combine the results of all the 10 CNNs trained by us and then make the predictions on the test data.","metadata":{}},{"cell_type":"code","source":"new_final_labels = np.zeros((test_df.shape[0], 10))\nfor i in range(n):\n    new_final_labels = new_final_labels + new_models[i].predict(make_prediction)\nnew_final_labels = np.argmax(new_final_labels, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T03:25:25.162406Z","iopub.execute_input":"2022-04-07T03:25:25.162735Z","iopub.status.idle":"2022-04-07T03:25:40.457216Z","shell.execute_reply.started":"2022-04-07T03:25:25.162674Z","shell.execute_reply":"2022-04-07T03:25:40.456066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Taking a look at how our predictions match up to the actual images","metadata":{}},{"cell_type":"code","source":"display_multiple_images(test_df.values.reshape(-1, 28, 28, 1), 'Prediction', new_final_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T03:25:40.488596Z","iopub.execute_input":"2022-04-07T03:25:40.489467Z","iopub.status.idle":"2022-04-07T03:25:41.925525Z","shell.execute_reply.started":"2022-04-07T03:25:40.489419Z","shell.execute_reply":"2022-04-07T03:25:41.924566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Confusion Matrix for 10 Ensembled CNNs</p></div>\n\nLet's see how good our 10 ensembled CNNs are:","metadata":{}},{"cell_type":"code","source":"y_pred = np.zeros((X_test.shape[0], 10))\nfor i in range(n):\n    y_pred = y_pred + new_models[i].predict(X_test)\ny_pred = np.argmax(y_pred, axis = 1)\nplt.figure(figsize = (15, 10))\nsns.heatmap(confusion_matrix(y_test, y_pred), cmap = 'Blues', annot = True, annot_kws = {'size': 12})\nplt.title('Confusion Matrix for 10 Ensembled CNNs', fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T03:28:54.381918Z","iopub.execute_input":"2022-04-07T03:28:54.382267Z","iopub.status.idle":"2022-04-07T03:28:57.263678Z","shell.execute_reply.started":"2022-04-07T03:28:54.382233Z","shell.execute_reply":"2022-04-07T03:28:57.262635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">Creating the Submission File</p></div>","metadata":{}},{"cell_type":"code","source":"submission_df = pd.DataFrame()\nimage_id = [i for i in range(1, 28001)]\nsubmission_df['ImageId'] = image_id\nsubmission_df['Label'] = new_final_labels\nsubmission_df.to_csv('submission.csv', index = False)\nsubmission_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T03:26:59.29931Z","iopub.execute_input":"2022-04-07T03:26:59.29959Z","iopub.status.idle":"2022-04-07T03:26:59.38616Z","shell.execute_reply.started":"2022-04-07T03:26:59.299558Z","shell.execute_reply":"2022-04-07T03:26:59.385108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style = \"color:white; display:fill; border-radius:10px; background-color:#9A9A9A; letter-spacing:0.5px; overflow:hidden\"><p style = \"padding:20px; color:white; overflow:hidden; margin:0; font-size:110%\">References</p></div>\n\n> - https://www.kaggle.com/code/cdeotte/25-million-images-0-99757-mnist/notebook\n> - https://www.kaggle.com/code/cdeotte/how-to-choose-cnn-architecture-mnist\n> - https://www.kaggle.com/code/anktplwl91/visualizing-what-your-convnet-learns/notebook\n> - https://www.kaggle.com/code/aishwarya2210/prediction-of-digits-from-handwritten-images\n> - https://www.kaggle.com/code/andradaolteanu/how-i-taught-myself-deep-learning-vanilla-nns\n> - https://www.kaggle.com/code/andradaolteanu/convolutional-neural-nets-cnns-explained\n> - https://www.kaggle.com/code/andradaolteanu/pytorch-rnns-and-lstms-explained-acc-0-99\n> - https://www.kaggle.com/code/kimchanyoung/mnist-classifier-baseline-for-starter-99-4\n","metadata":{}}]}