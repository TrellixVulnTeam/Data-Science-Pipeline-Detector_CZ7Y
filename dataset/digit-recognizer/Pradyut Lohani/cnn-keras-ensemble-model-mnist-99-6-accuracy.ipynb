{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MNIST Digit Recognizer\n**\"Hello World\"**.\nThis notebook will help in understanding the basics of Computer Vision and design a CNN model to identify hand written numbers with high accuracy. Special thanks to **Chris Deotte** for his notebook https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Reading and Cleaning","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Training Dataset\ntrain=pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\nprint(\"Training Dataset Shape:\",train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Testing Dataset\ntest=pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\nprint('Test Dataset Shape:',test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extracting the dependent and independent variables\ny=train['label'].values #To be predicted\nx=train.drop('label',axis=1).values #Independent Variables\nprint('Variables Shape:',x.shape)\nprint('Labels Shape:',y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Displaying some images from the dataset\nimport matplotlib.pyplot as plt\nx=x.reshape(x.shape[0],28,28)\nfig=plt.figure(figsize=(12,5))\nfor i in range(30):\n    plt.subplot(3,10,i+1)\n    plt.axis('off')\n    plt.imshow(x[i],cmap=plt.cm.binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reshaping and Normalization\nfrom keras.utils.np_utils import to_categorical\n\n#Reshape images to input into CNN layers as a 4D Tensor\nx=x.reshape(-1,28,28,1)\ntest=test.values.reshape(-1,28,28,1)\n#Normalization\nx=x/255\ntest=test/255\n#One Hot Encoding the labels\ny=to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Augmentation to increase number of input images\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen=ImageDataGenerator(\n    rotation_range=10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    zoom_range=0.2,\n    fill_mode='nearest'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CNN Ensemble Models\n#To learn about deep learning ensemble models:\n# https://machinelearningmastery.com/ensemble-methods-for-deep-learning-neural-networks/\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,Dropout,Dense,GlobalAveragePooling2D,MaxPool2D,Flatten,BatchNormalization\n\nensem=10\nmodel=[0]*ensem\nfor i in range(ensem):\n    model[i]=Sequential()\n    model[i].add(Conv2D(filters=32,kernel_size=(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n    model[i].add(BatchNormalization())\n    model[i].add(Conv2D(filters=32,kernel_size=(3,3),padding='same',activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Conv2D(filters=32,kernel_size=(3,3),padding='same',activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(MaxPool2D(2,2))\n    model[i].add(Dropout(0.2))\n\n    model[i].add(Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(MaxPool2D(2,2))\n    model[i].add(Dropout(0.2))\n\n    model[i].add(GlobalAveragePooling2D())\n    model[i].add(Dense(128,activation='relu'))\n    model[i].add(Dropout(0.2))\n    model[i].add(Dense(10,activation='softmax'))\n    \n    model[i].compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\ncallback=tf.keras.callbacks.EarlyStopping(monitor='accuracy',min_delta=0,patience=5,mode='auto',restore_best_weights=True,verbose=0)\nlrs=tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n\nhistory=[0]*ensem\nfor i in range(ensem):\n    train_x,valid_x,train_y,valid_y=train_test_split(x,y,test_size=0.2)\n    history[i]=model[i].fit_generator(train_datagen.flow(train_x,train_y,batch_size=128),\n                      epochs=100,\n                      steps_per_epoch=train_x.shape[0]//128,\n                      verbose=0,\n                      validation_data=(valid_x,valid_y),\n                      validation_steps=valid_x.shape[0]//128,\n                      callbacks=[callback,lrs])\n    print('Model {}: Epochs=100, Train_Accuracy:{}, Val_Accuracy:{}'.format(i+1,max(history[i].history['accuracy']),max(history[i].history['val_accuracy'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Models Accuracy\nimport matplotlib.pyplot as plt\n\nstyles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\nnames=['Model {}'.format(i) for i in range(ensem)]\nplt.figure(figsize=(15,5))\nfor i in range(ensem):\n    plt.plot(history[i].history['val_accuracy'],linestyle=styles[i])\nplt.title('Models accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('# Epoch')\nplt.legend(names, loc='lower right')\naxes = plt.gca()\naxes.set_ylim([0.8,1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* All the models follow a similar trend for Validation Accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the loss and accuracy for the first model.\n#All the modesl follow a similar trend\n\ndef plot_model(history):\n    fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,4))\n    fig.suptitle('Model Accuracy and Loss')\n\n    ax1.plot(history[0].history['accuracy'])\n    ax1.plot(history[0].history['val_accuracy'])\n    ax1.title.set_text('Accuracy')\n    ax1.set_ylabel('Accuracy')\n    ax1.set_xlabel('Epoch')\n    ax1.legend(['Train','Valid'],loc=4)\n\n    ax2.plot(history[0].history['loss'])\n    ax2.plot(history[0].history['val_loss'])\n    ax2.title.set_text('Loss')\n    ax2.set_ylabel('Loss')\n    ax2.set_xlabel('Epoch')\n    ax2.legend(['Train','Valid'],loc=1)\n\n    fig.show()\n\nplot_model(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification Report and Confusion Matrix for the first model\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\n#Predicting values from the validation dataset and one hot encoding the predicted and true labels\ny_pred=model[0].predict(valid_x)\ny_pred_classes=np.argmax(y_pred, axis=1)\ny_true=np.argmax(valid_y, axis=1)\n\n#Classification Report\nprint('Classification Report')\nreport=classification_report(y_true, y_pred_classes)\nprint(report)\n\n#Computuing and Plotting Confusion Matrix\nconfusion_mtx=confusion_matrix(y_true, y_pred_classes)\nf,ax=plt.subplots(figsize=(16,8))\nsns.heatmap(confusion_mtx,annot=True,fmt='')\nplt.xlabel(\"Predicted\",size=12)\nplt.ylabel(\"True\",size=12)\nplt.title(\"Confusion Matrix\",size=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the values are correctly predicted with high precision\n* Highest error rate is between 7-2 and 4-9","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction=np.zeros((test.shape[0],10)) \nfor i in range(ensem):\n    prediction=prediction+model[i].predict(test)\nprediction=np.argmax(prediction,axis = 1)\nprediction=pd.Series(prediction,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name=\"ImageId\"),prediction],axis=1)\nsubmission.to_csv(\"digit_recognizer.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hope this helps üòÑ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Thank You üôè","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}