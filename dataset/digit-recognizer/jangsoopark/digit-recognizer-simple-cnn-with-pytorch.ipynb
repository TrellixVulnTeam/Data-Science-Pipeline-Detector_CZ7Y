{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-19T19:19:14.464698Z","iopub.execute_input":"2022-02-19T19:19:14.465039Z","iopub.status.idle":"2022-02-19T19:19:14.476667Z","shell.execute_reply.started":"2022-02-19T19:19:14.464986Z","shell.execute_reply":"2022-02-19T19:19:14.475965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Training Dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\n\n\ndata_root = '/kaggle/input'\n\ntrain_set = np.loadtxt(os.path.join(data_root, 'digit-recognizer/train.csv'), delimiter=',', skiprows=1, dtype=np.float32)\nprint(train_set.shape)\n\nlabels, images = train_set[:, 0, np.newaxis], train_set[:, 1:]\nprint(labels.shape)\nprint(images.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:19:14.481642Z","iopub.execute_input":"2022-02-19T19:19:14.482131Z","iopub.status.idle":"2022-02-19T19:19:32.421747Z","shell.execute_reply.started":"2022-02-19T19:19:14.482094Z","shell.execute_reply":"2022-02-19T19:19:32.420984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize Training Samples","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nnum_train_set, _ = labels.shape\n\nidxs = np.arange(num_train_set)\n\nnp.random.shuffle(idxs)\n\nh, w = 10, 10\n\nfig, ax = plt.subplots(h, w, figsize=(20, 20))\nfor i in range(h):\n    for j in range(w):\n        idx = idxs[i * h + j]\n        number = labels[idx, 0].astype(np.uint8)\n        ax[i, j].set_title(f'label: {number}')\n        ax[i, j].imshow(images[idx, :].reshape((28, 28)), cmap='gray')\n        ax[i, j].axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:19:32.423234Z","iopub.execute_input":"2022-02-19T19:19:32.423717Z","iopub.status.idle":"2022-02-19T19:19:36.60723Z","shell.execute_reply.started":"2022-02-19T19:19:32.423679Z","shell.execute_reply":"2022-02-19T19:19:36.606483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define the operations for CNN","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nimport collections\n\n_activations = {\n    'relu': nn.ReLU,\n    'relu6': nn.ReLU6,\n    'leaky_relu': nn.LeakyReLU\n}\n\n\nclass BaseBlock(nn.Module):\n\n    def __init__(self):\n        super(BaseBlock, self).__init__()\n        self._layer: nn.Sequential\n\n    def forward(self, x):\n        return self._layer(x)\n\n\nclass DenseBlock(BaseBlock):\n\n    def __init__(self, shape, **params):\n        super(DenseBlock, self).__init__()\n        in_dims, out_dims = shape\n        _seq = collections.OrderedDict([\n            ('dense', nn.Linear(in_dims, out_dims)),\n        ])\n        _act_name = params.get('activation')\n        if _act_name:\n            _seq.update({_act_name: _activations[_act_name](inplace=True)})\n\n        self._layer = nn.Sequential(_seq)\n\n        w_init = params.get('w_init', None)\n        idx = list(dict(self._layer.named_children()).keys()).index('dense')\n        if w_init:\n            w_init(self._layer[idx].weight)\n        b_init = params.get('b_init', None)\n        if b_init:\n            b_init(self._layer[idx].bias)\n\n\nclass Conv2DBlock(BaseBlock):\n\n    def __init__(self, shape, stride, padding='same', **params):\n        super(Conv2DBlock, self).__init__()\n\n        h, w, in_channels, out_channels = shape\n        _seq = collections.OrderedDict([\n            ('conv', nn.Conv2d(in_channels, out_channels, kernel_size=(h, w), stride=stride, padding=padding))\n        ])\n\n        _bn = params.get('batch_norm')\n        if _bn:\n            _seq.update({'bn': nn.BatchNorm2d(out_channels)})\n\n        _act_name = params.get('activation')\n        if _act_name:\n            _seq.update({_act_name: _activations[_act_name](inplace=True)})\n\n        _max_pool = params.get('max_pool')\n        if _max_pool:\n            _kernel_size = params.get('max_pool_size', 2)\n            _stride = params.get('max_pool_stride', _kernel_size)\n            _seq.update({'max_pool': nn.MaxPool2d(kernel_size=_kernel_size, stride=_stride)})\n\n        self._layer = nn.Sequential(_seq)\n\n        w_init = params.get('w_init', None)\n        idx = list(dict(self._layer.named_children()).keys()).index('conv')\n        if w_init:\n            w_init(self._layer[idx].weight)\n        b_init = params.get('b_init', None)\n        if b_init:\n            b_init(self._layer[idx].bias)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:19:36.609852Z","iopub.execute_input":"2022-02-19T19:19:36.610356Z","iopub.status.idle":"2022-02-19T19:19:36.99681Z","shell.execute_reply.started":"2022-02-19T19:19:36.610308Z","shell.execute_reply":"2022-02-19T19:19:36.996027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define the model","metadata":{}},{"cell_type":"markdown","source":"|    layer    | Input  |   Conv 1   |   Conv 2   |   Conv 3   |   Conv 4   |   Dense 5    |  Dense 6   |  Dense 7   |  Dense 8   |\n| :---------: | ------ | :--------: | :--------: | :--------: | :--------: | :----------: | :--------: | :--------: | :--------: |\n|  channels   | 3      |     16     |     32     |     64     |    128     |     512      |     256    |      64    |     10     |\n| weight size | -      |   3 x 3    |   3 x 3    |   3 x 3    |   3 x 3    |  1152 x 512  |  512 x 256 |  256 x 64  |   64 x 10  |\n|   pooling   | -      | 2 x 2 - s2 | 2 x 2 - s2 | 2 x 2 - s2 | 2 x 2 - s2 |      -       |      -     |      -     |      -     |\n|   padding   | -      |     2      |     2      |     2      |     2      |      -       |      -     |      -     |      -     |\n|   dropout   | -      |     -      |     -      |     -      |     -      |      -       |      -     |      -     |      -     |\n| activation  | linear |    ReLU    |    ReLU    |    ReLU    |    ReLU    |     ReLU     |     ReLU   |     ReLU   |   Linear   |","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\n\n\nclass Network(nn.Module):\n    \n    def __init__(self, **params):\n        super(Network, self).__init__()\n        \n        self.classes = params.get('classes', 10)\n        self.channels = params.get('channels', 1)\n        \n        self._layer = nn.Sequential(\n            Conv2DBlock(\n                shape=[3, 3, self.channels, 16], stride=1, padding='same', activation='relu', max_pool=True\n            ),\n            Conv2DBlock(\n                shape=[3, 3, 16, 32], stride=1, padding='same', activation='relu', max_pool=True\n            ),\n            Conv2DBlock(\n                shape=[3, 3, 32, 64], stride=1, padding='same', activation='relu', max_pool=True\n            ),\n            Conv2DBlock(\n                shape=[3, 3, 64, 128], stride=1, padding='same', activation='relu', max_pool=False\n            ),\n            nn.Flatten(),\n            \n            DenseBlock(shape=[1152, 512], activation='relu'),\n            DenseBlock(shape=[512, 256], activation='relu'),\n            nn.Dropout(p=params.get('dropout_rate', 0.9)),\n            DenseBlock(shape=[256, 64], activation='relu'),\n            DenseBlock(shape=[64, self.classes])\n        )\n\n    def forward(self, x):\n        return self._layer(x)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:19:36.998311Z","iopub.execute_input":"2022-02-19T19:19:36.998545Z","iopub.status.idle":"2022-02-19T19:19:37.010421Z","shell.execute_reply.started":"2022-02-19T19:19:36.99851Z","shell.execute_reply":"2022-02-19T19:19:37.009657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Dimension Test","metadata":{}},{"cell_type":"code","source":"net = Network()\nsample_input = torch.tensor(images[0, :].reshape(1, 1, 28, 28))\noutput = net(sample_input)\nprint(output.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:19:37.01153Z","iopub.execute_input":"2022-02-19T19:19:37.011796Z","iopub.status.idle":"2022-02-19T19:19:37.038077Z","shell.execute_reply.started":"2022-02-19T19:19:37.011743Z","shell.execute_reply":"2022-02-19T19:19:37.03739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Wrapper","metadata":{}},{"cell_type":"code","source":"\nclass Model(object):\n    def __init__(self, **params):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.net = Network(\n            classes=params.get('classes', 10),\n            channels=params.get('channels', 1),\n            dropout_rate=params.get('dropout_rate', 0.9)\n        )\n        self.net.to(self.device)\n\n        self.lr = params.get('lr', 1e-4)\n        self.lr_step = params.get('lr_step', None)\n        self.lr_decay = params.get('lr_decay', None)\n        self.lr_scheduler = None\n\n        self.momentum = params.get('momentum', 0.9)\n        self.weight_decay = params.get('weight_decay', 0)\n        \n        self.grad_clip = params.get('grad_clip', None)\n        self.adjustable_grad_clip = params.get('adjustable_grad_clip', False)\n        \n        self.criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n        self.optimizer = torch.optim.SGD(\n            self.net.parameters(),\n            lr=self.lr,\n            momentum=self.momentum,\n            weight_decay=self.weight_decay\n        )\n\n        if self.lr_decay:\n            self.lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n                optimizer=self.optimizer,\n                milestones=self.lr_step,\n                gamma=self.lr_decay\n            )\n\n    def optimize(self, x, y):\n        p = self.net(x.to(self.device))\n        loss = self.criterion(p, y.to(self.device))\n\n        self.optimizer.zero_grad()\n        loss.backward()\n\n        if self.grad_clip:\n            torch.nn.utils.clip_grad_norm_(\n                self.net.parameters(),\n                self.grad_clip / self.lr if self.adjustable_grad_clip else self.grad_clip)\n            \n        self.optimizer.step()\n        return loss.item()\n\n    @torch.no_grad()\n    def inference(self, x):\n        return self.net(x.to(self.device))\n\n    def save(self, path):\n        torch.save(self.net.state_dict(), path)\n\n    def load(self, path):\n        self.net.load_state_dict(torch.load(path))\n        self.net.eval()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:19:37.039286Z","iopub.execute_input":"2022-02-19T19:19:37.039529Z","iopub.status.idle":"2022-02-19T19:19:37.054587Z","shell.execute_reply.started":"2022-02-19T19:19:37.039496Z","shell.execute_reply":"2022-02-19T19:19:37.053596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Loader","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n\n\nclass Dataset(torch.utils.data.Dataset):\n\n    def __init__(self, path, name='digit-recognizer', ratio=0.9, is_train=False, transform=None):\n        self.is_train = is_train\n        self.name = name\n        self.ratio = ratio\n        \n        self.images = []\n        self.labels = []\n\n        self.transform = transform\n        self._load_data(path)\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        _image = self.images[idx]\n        _label = self.labels[idx]\n\n        if self.transform:\n            _image = Image.fromarray(_image)\n            _image = self.transform(_image)\n\n        return _image, _label\n\n    def _load_data(self, path):\n        mode = 'train' if self.is_train else 'test'\n\n        data = np.loadtxt(os.path.join(path, f'{self.name}/train.csv'), delimiter=',', skiprows=1, dtype=np.float32)\n        num_dataset, _ = data.shape\n        num_train = int(num_dataset * self.ratio)\n        \n        if self.is_train:\n            self.labels, self.images = data[: num_train, 0], data[: num_train, 1:]\n            \n        else:\n            self.labels, self.images = data[num_train:, 0], data[num_train: , 1:]\n            \n        self.images = self.images.reshape(-1, 28, 28)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:19:37.05606Z","iopub.execute_input":"2022-02-19T19:19:37.056505Z","iopub.status.idle":"2022-02-19T19:19:37.068646Z","shell.execute_reply.started":"2022-02-19T19:19:37.056467Z","shell.execute_reply":"2022-02-19T19:19:37.067932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n@torch.no_grad()\ndef validation(m, ds):\n    num_data = 0\n    corrects = 0\n\n    # Test loop\n    m.net.eval()\n    _softmax = torch.nn.Softmax(dim=1)\n    for i, data in enumerate(ds):\n        images, labels = data\n        \n        predictions = m.inference(images)\n        predictions = _softmax(predictions)\n\n        _, predictions = torch.max(predictions, 1)\n        labels = labels.type(torch.LongTensor)\n        num_data += labels.size(0)\n        corrects += (predictions == labels.to(m.device)).sum().item()\n\n    accuracy = 100 * corrects / num_data\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:19:37.070355Z","iopub.execute_input":"2022-02-19T19:19:37.070609Z","iopub.status.idle":"2022-02-19T19:19:37.080348Z","shell.execute_reply.started":"2022-02-19T19:19:37.070574Z","shell.execute_reply":"2022-02-19T19:19:37.079574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Seed","metadata":{}},{"cell_type":"code","source":"import random\n\ndef set_random_seed(random_seed):\n    torch.manual_seed(random_seed)\n    torch.cuda.manual_seed(random_seed)\n    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n    np.random.seed(random_seed)\n    random.seed(random_seed)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:19:37.081567Z","iopub.execute_input":"2022-02-19T19:19:37.082469Z","iopub.status.idle":"2022-02-19T19:19:37.089009Z","shell.execute_reply.started":"2022-02-19T19:19:37.082434Z","shell.execute_reply":"2022-02-19T19:19:37.088275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_random_seed(12321)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:19:37.090403Z","iopub.execute_input":"2022-02-19T19:19:37.09066Z","iopub.status.idle":"2022-02-19T19:19:37.101007Z","shell.execute_reply.started":"2022-02-19T19:19:37.090625Z","shell.execute_reply":"2022-02-19T19:19:37.100319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyper Parameter settings for training","metadata":{}},{"cell_type":"code","source":"config = {\n    \"model_name\": \"digit-recognizer\",\n    \"dataset\": \"digit-recognizer\",\n    \"classes\": 10,\n    \"channels\": 1,\n    \"batch_size\": 256,\n    \"epochs\": 50,\n    \"momentum\": 0.9,\n    \"lr\": 1e-2,\n    \"lr_step\": [50],\n    \"lr_decay\": 0.5,\n    \"weight_decay\": 1e-8,\n    \"dropout_rate\": 5e-1,\n    \"grad_clip\": None, \n    \"adjustable_grad_clip\": False,\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:19:37.102449Z","iopub.execute_input":"2022-02-19T19:19:37.102709Z","iopub.status.idle":"2022-02-19T19:19:37.108728Z","shell.execute_reply.started":"2022-02-19T19:19:37.102675Z","shell.execute_reply":"2022-02-19T19:19:37.10774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Loader\n\n#### Data Augmentation\n- Random Shift (Zero Padding + Random Crop)\n- Random Rotation","metadata":{}},{"cell_type":"code","source":"import torchvision\n\nprint('Load Training Data')\n_train_set = Dataset(\n    path=data_root, name='digit-recognizer', ratio=0.9, is_train=True, \n    transform=torchvision.transforms.Compose([\n        torchvision.transforms.Pad(padding=2), \n        torchvision.transforms.RandomRotation(degrees=2),\n        torchvision.transforms.RandomCrop(size=28),  \n        torchvision.transforms.ToTensor()\n    ])\n)\ntrain_set = torch.utils.data.DataLoader(\n    _train_set, batch_size=config['batch_size'], shuffle=True, num_workers=2\n)\n\nprint('Load Test Data')\n_test_set = Dataset(\n    path=data_root, name='digit-recognizer', ratio=0.9, is_train=False, \n    transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n)\ntest_set = torch.utils.data.DataLoader(\n    _test_set, batch_size=config['batch_size'], shuffle=False, num_workers=1\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:19:37.112792Z","iopub.execute_input":"2022-02-19T19:19:37.113082Z","iopub.status.idle":"2022-02-19T19:20:13.803936Z","shell.execute_reply.started":"2022-02-19T19:19:37.113052Z","shell.execute_reply":"2022-02-19T19:20:13.803156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"os.makedirs('/kaggle/model', exist_ok=True)\n\nm = Model(\n    classes=config['classes'],\n    channels=config['channels'],\n    lr=config['lr'],\n    lr_step=config['lr_step'],\n    lr_decay=config['lr_decay'],\n    momentum=config['momentum'],\n    weight_decay=config['weight_decay'],\n    dropout_rate=config['dropout_rate'],\n    grad_clip=config['grad_clip'],\n    adjustable_grad_clip=config['adjustable_grad_clip']\n)\n\nepochs = config['epochs']\nlr = config['lr']\n\nhistory = {\n    'loss': [],\n    'accuracy': []\n}\n\nfor epoch in range(epochs):\n    \n    _loss = []\n    \n    m.net.train()\n    for i, data in enumerate(train_set):\n        images, labels = data\n        labels = labels.type(torch.LongTensor)\n        _loss.append(m.optimize(images, labels))\n        \n    if m.lr_scheduler:\n        lr = m.lr_scheduler.get_last_lr()[0]\n        m.lr_scheduler.step()\n        \n    accuracy = validation(m, test_set)\n    \n    print(f'Epoch: {epoch + 1:03d}/{epochs:03d} | loss={np.mean(_loss):.8f} | lr={lr:.5f} | accuracy={accuracy:.2f}')\n    \n    history['loss'].append(np.mean(_loss))\n    history['accuracy'].append(accuracy)\n    \n    m.save(f'/kaggle/model/model-{epoch + 1:03d}.pth')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:20:13.805139Z","iopub.execute_input":"2022-02-19T19:20:13.805397Z","iopub.status.idle":"2022-02-19T19:26:13.978423Z","shell.execute_reply.started":"2022-02-19T19:20:13.805363Z","shell.execute_reply":"2022-02-19T19:26:13.977495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize the training history\n- Training Loss\n- Validation Accuracy","metadata":{}},{"cell_type":"code","source":"loss = history['loss'] # on training set\naccuracy = history['accuracy'] # on test set\n\nepochs = np.arange(len(loss))\n\nfig, ax1 = plt.subplots()\nax2 = ax1.twinx()\n\nplot1, = ax1.plot(epochs, loss, marker='.', c='blue', label='loss')\nplot2, = ax2.plot(epochs, accuracy, marker='.', c='red', label='accuracy')\nplt.legend([plot1, plot2], ['loss', 'accuracy'], loc='upper right')\n\nplt.grid()\n\nax1.set_xlabel('Epoch')\nax1.set_ylabel('loss', color='blue')\nax2.set_ylabel('accuracy', color='red')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:26:13.980174Z","iopub.execute_input":"2022-02-19T19:26:13.980836Z","iopub.status.idle":"2022-02-19T19:26:14.25533Z","shell.execute_reply.started":"2022-02-19T19:26:13.98079Z","shell.execute_reply":"2022-02-19T19:26:14.254626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Early Stopping","metadata":{}},{"cell_type":"code","source":"import glob\n\n\nmodel_history = glob.glob('/kaggle/model/*.pth')\nmodel_history = sorted(model_history, key=os.path.basename)\n\nbest = {\n    'epoch': 0,\n    'accuracy': 0,\n    'path': ''\n}\n\nfor i, model_path in enumerate(model_history):\n    m.load(model_path)\n    accuracy = validation(m, test_set)\n    if accuracy >= best['accuracy']:\n        best['epoch'] = i\n        best['accuracy'] = accuracy\n        best['path'] = model_path\n        print(f'Best accuracy at epoch={i} with {accuracy:.2f}%')\n\nbest_epoch = best['epoch']\nbest_accuracy = best['accuracy']\nbest_path = best['path']\n\nprint(f'Final model is epoch={best_epoch} with accurayc={best_accuracy:.2f}%')\nprint(f'Path={best_path}')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:26:14.256649Z","iopub.execute_input":"2022-02-19T19:26:14.257003Z","iopub.status.idle":"2022-02-19T19:26:34.424815Z","shell.execute_reply.started":"2022-02-19T19:26:14.256962Z","shell.execute_reply":"2022-02-19T19:26:34.423972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion Matrix with Best Model","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\n\n@torch.no_grad()\ndef confusion_matrix(_m, ds):\n    \n    _pred = []\n    _gt = []\n    \n    _m.net.eval()\n    _softmax = torch.nn.Softmax(dim=1)\n    for i, data in enumerate(ds):\n        images, labels = data\n        \n        predictions = _m.inference(images)\n        predictions = _softmax(predictions)\n\n        _, predictions = torch.max(predictions, 1)\n        labels = labels.type(torch.LongTensor)\n        _pred += predictions.cpu().tolist()\n        _gt += labels.cpu().tolist()\n        \n    return metrics.confusion_matrix(_gt, _pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:26:34.426552Z","iopub.execute_input":"2022-02-19T19:26:34.427048Z","iopub.status.idle":"2022-02-19T19:26:34.760407Z","shell.execute_reply.started":"2022-02-19T19:26:34.42701Z","shell.execute_reply":"2022-02-19T19:26:34.759685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\n\nm.load(best_path)\ncmat = confusion_matrix(m, test_set)\n\nsns.reset_defaults()\nax = sns.heatmap(cmat, annot=True, fmt='d', cbar=False)\n\nax.set_yticklabels(list(range(10)), rotation=0)\nax.set_xticklabels(list(range(10)), rotation=0)\n\nplt.xlabel('prediction', fontsize=12)\nplt.ylabel('label', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:26:34.761718Z","iopub.execute_input":"2022-02-19T19:26:34.761989Z","iopub.status.idle":"2022-02-19T19:26:35.689985Z","shell.execute_reply.started":"2022-02-19T19:26:34.761953Z","shell.execute_reply":"2022-02-19T19:26:35.689134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ErrorAnalysis","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef error_analysis(_m, ds):\n    \n    _pred = []\n    _gt = []\n    _images = []\n    \n    _m.net.eval()\n    _softmax = torch.nn.Softmax(dim=1)\n    for i, data in enumerate(ds):\n        images, labels = data\n        \n        predictions = _m.inference(images)\n        predictions = _softmax(predictions)\n\n        _, predictions = torch.max(predictions, 1)\n        labels = labels.type(torch.LongTensor)\n        failures = predictions != labels.to(m.device)\n        \n        _pred += predictions[failures].cpu().tolist()\n        _gt += labels[failures].cpu().tolist()\n        _images += images[failures].tolist()\n        \n    return _images, _pred, _gt","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:26:35.691594Z","iopub.execute_input":"2022-02-19T19:26:35.692026Z","iopub.status.idle":"2022-02-19T19:26:35.699858Z","shell.execute_reply.started":"2022-02-19T19:26:35.691987Z","shell.execute_reply":"2022-02-19T19:26:35.699196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, preds, gts  = error_analysis(m, test_set)\n\nnum_failures = len(gts)\nprint(num_failures)\n\nh, w = 3, 6\n\nfig, ax = plt.subplots(h, w, figsize=(20, 10))\nidx = 0\n\nfor i in range(h):\n        \n    for j in range(w):\n        \n        if idx < num_failures:        \n            img = np.array(images[idx]).reshape(28, 28)\n            ax[i, j].set_title(f'GT: {gts[idx]} | Pred: {preds[idx]}')\n            ax[i, j].imshow(img, cmap='gray')\n        ax[i, j].axis('off')\n        idx += 1\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:26:35.701012Z","iopub.execute_input":"2022-02-19T19:26:35.701379Z","iopub.status.idle":"2022-02-19T19:26:36.941312Z","shell.execute_reply.started":"2022-02-19T19:26:35.701342Z","shell.execute_reply":"2022-02-19T19:26:36.940639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make a submission with best model","metadata":{}},{"cell_type":"code","source":"data = np.loadtxt(os.path.join('/kaggle/input/digit-recognizer/test.csv'), delimiter=',', skiprows=1, dtype=np.float32)\n\nprint(data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:26:36.942662Z","iopub.execute_input":"2022-02-19T19:26:36.943298Z","iopub.status.idle":"2022-02-19T19:26:49.390612Z","shell.execute_reply.started":"2022-02-19T19:26:36.943259Z","shell.execute_reply":"2022-02-19T19:26:49.389831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 2048\nnum_test_set, _ = data.shape\n\nm.load(best_path)\nm.net.eval()\n\npredictions = []\n_softmax = torch.nn.Softmax(dim=1)\nfor i in range(0, num_test_set, batch_size):\n    images = data[i: i + batch_size].reshape(-1, 1, 28, 28)\n    images = torch.tensor(images)\n    \n    p = m.inference(images)\n    p = _softmax(p)\n    _, p = torch.max(p, 1)\n    \n    predictions += p.cpu().tolist()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:26:49.391954Z","iopub.execute_input":"2022-02-19T19:26:49.392383Z","iopub.status.idle":"2022-02-19T19:26:49.536962Z","shell.execute_reply.started":"2022-02-19T19:26:49.392344Z","shell.execute_reply":"2022-02-19T19:26:49.536185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idxs = list(range(1, num_test_set + 1))\nprint(len(idxs), len(predictions))\nsubmission = np.concatenate(([idxs], [predictions]), axis=0)\nsubmission = submission.T\n","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:26:49.538126Z","iopub.execute_input":"2022-02-19T19:26:49.538375Z","iopub.status.idle":"2022-02-19T19:26:49.555165Z","shell.execute_reply.started":"2022-02-19T19:26:49.538343Z","shell.execute_reply":"2022-02-19T19:26:49.554452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(submission, columns=['ImageId', 'Label'])\ndf.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:26:49.55643Z","iopub.execute_input":"2022-02-19T19:26:49.556694Z","iopub.status.idle":"2022-02-19T19:26:49.601785Z","shell.execute_reply.started":"2022-02-19T19:26:49.556661Z","shell.execute_reply":"2022-02-19T19:26:49.601118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-02-19T19:26:49.603075Z","iopub.execute_input":"2022-02-19T19:26:49.603331Z","iopub.status.idle":"2022-02-19T19:26:49.617115Z","shell.execute_reply.started":"2022-02-19T19:26:49.603297Z","shell.execute_reply":"2022-02-19T19:26:49.616155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}