{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n#import seaborn as sn\nfrom sklearn.model_selection import train_test_split\n\nfrom random import seed\nseed(1)\nseed = 43\n\nimport tensorflow as tf\nfrom tensorflow import keras\nprint(\"Tensorflow Version: \", tf.__version__)\nprint(\"Keras Version: \",keras.__version__)\n\n\nkaggle = 1 # Kaggle path active = 1\n\n# change your local path here\nif kaggle == 1 :\n    MNIST_PATH= '../input/digit-recognizer'\nelse:\n    MNIST_PATH= '../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer'\n\n\n\nimport os\nfor dirname, _, filenames in os.walk(MNIST_PATH): \n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:37.577287Z","iopub.execute_input":"2021-09-07T07:27:37.577652Z","iopub.status.idle":"2021-09-07T07:27:37.588824Z","shell.execute_reply.started":"2021-09-07T07:27:37.577614Z","shell.execute_reply":"2021-09-07T07:27:37.588026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduction - MNIST Training Competition\nLink to the topic: https://www.kaggle.com/c/digit-recognizer/data\n\nThis is another Notebook to take a look into annother algorithm. Here I want to give the Deep Neural Network with the Framework Keras a try. As already mentioned in other notebooks, I will skip some explanations about the data set here. Moreover I will use the already discovered knowledge about the data and transform/prepare the data rightaway.\n\nIf you are interested in some more clearly analysis of the dataset take a look into my other notebooks about the MNIS-dataset:\n- Another MNIST Try: https://www.kaggle.com/skiplik/another-mnist-try\n- First NN by Detecting Handwritten Characters: https://www.kaggle.com/skiplik/first-nn-by-detecting-handwritten-characters\n...\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Get Data","metadata":{}},{"cell_type":"code","source":"# Data path and file\nCSV_FILE_TRAIN='train.csv'\nCSV_FILE_TEST='test.csv'\n \ndef load_mnist_data(minist_path, csv_file):\n    csv_path = os.path.join(minist_path, csv_file)\n    return pd.read_csv(csv_path)\n\ndef load_mnist_data_manuel(minist_path, csv_file):\n    csv_path = os.path.join(minist_path, csv_file)\n    csv_file = open(csv_path, 'r')\n    csv_data = csv_file.readlines()\n    csv_file.close()\n    return csv_data\n\ndef split_train_val(data, val_ratio):\n    return \n    \n\ntrain = load_mnist_data(MNIST_PATH,CSV_FILE_TRAIN)\ntest = load_mnist_data(MNIST_PATH,CSV_FILE_TEST)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:37.590386Z","iopub.execute_input":"2021-09-07T07:27:37.590955Z","iopub.status.idle":"2021-09-07T07:27:43.510512Z","shell.execute_reply.started":"2021-09-07T07:27:37.590914Z","shell.execute_reply":"2021-09-07T07:27:43.509565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train['label'].copy()\nX = train.drop(['label'], axis=1)\n\nX_test = test.copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:43.512146Z","iopub.execute_input":"2021-09-07T07:27:43.512665Z","iopub.status.idle":"2021-09-07T07:27:43.712721Z","shell.execute_reply.started":"2021-09-07T07:27:43.512616Z","shell.execute_reply":"2021-09-07T07:27:43.711764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train / Val Split","metadata":{}},{"cell_type":"code","source":"print(\"Shape of the Features: \",X.shape)\nprint(\"Shape of the Labels: \", y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:43.714489Z","iopub.execute_input":"2021-09-07T07:27:43.714779Z","iopub.status.idle":"2021-09-07T07:27:43.720091Z","shell.execute_reply.started":"2021-09-07T07:27:43.714751Z","shell.execute_reply":"2021-09-07T07:27:43.719005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label Value Count\r\nVisualizing the label distribution of the full train dataset.","metadata":{}},{"cell_type":"code","source":"train.value_counts('label')","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:43.721462Z","iopub.execute_input":"2021-09-07T07:27:43.721845Z","iopub.status.idle":"2021-09-07T07:27:43.740912Z","shell.execute_reply.started":"2021-09-07T07:27:43.721814Z","shell.execute_reply":"2021-09-07T07:27:43.739838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=seed, test_size=0.15\n                                                  , stratify=y\n                                                 )","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:43.742529Z","iopub.execute_input":"2021-09-07T07:27:43.742814Z","iopub.status.idle":"2021-09-07T07:27:44.022793Z","shell.execute_reply.started":"2021-09-07T07:27:43.742788Z","shell.execute_reply":"2021-09-07T07:27:44.021655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comparing the equally splitted train- and val-sets based on the given label y.","metadata":{}},{"cell_type":"code","source":"print(\"Train - Set Distribution\")\nprint(y_train.value_counts() / y_train.value_counts().sum() )\nprint('--------------------------------------------------------------')\nprint('--------------------------------------------------------------')\nprint('--------------------------------------------------------------')\nprint(\"Val - Set Distribution\")\nprint(y_val.value_counts() / y_val.value_counts().sum() )\n","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:44.02407Z","iopub.execute_input":"2021-09-07T07:27:44.024419Z","iopub.status.idle":"2021-09-07T07:27:44.053543Z","shell.execute_reply.started":"2021-09-07T07:27:44.024385Z","shell.execute_reply":"2021-09-07T07:27:44.052471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X: \", X.shape)\nprint(\"X_train: \", X_train.shape)\nprint(\"X_val: \", X_val.shape)\n\nprint(\"y_train: \", y_train.shape)\nprint(\"y_val: \", y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:44.056029Z","iopub.execute_input":"2021-09-07T07:27:44.05635Z","iopub.status.idle":"2021-09-07T07:27:44.063701Z","shell.execute_reply.started":"2021-09-07T07:27:44.056319Z","shell.execute_reply":"2021-09-07T07:27:44.062724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building Transforming Piplines","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import StandardScaler\n\npipeline = Pipeline([\n    ('normalizer', Normalizer())\n    #('std_scalar',StandardScaler())\n])","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:44.065821Z","iopub.execute_input":"2021-09-07T07:27:44.066184Z","iopub.status.idle":"2021-09-07T07:27:44.075351Z","shell.execute_reply.started":"2021-09-07T07:27:44.066151Z","shell.execute_reply":"2021-09-07T07:27:44.074163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_prep = pipeline.fit_transform(X_train)      # fitting the pipeline to the train and transform it\nX_val_prep = pipeline.transform(X_val)              # transform val data with this information","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:44.076915Z","iopub.execute_input":"2021-09-07T07:27:44.077259Z","iopub.status.idle":"2021-09-07T07:27:44.313469Z","shell.execute_reply.started":"2021-09-07T07:27:44.077231Z","shell.execute_reply":"2021-09-07T07:27:44.312539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building a Deep Neural Network based on RandomizedSearch","metadata":{}},{"cell_type":"markdown","source":"## Preparing Model Visualization with Tensorboard (not for Kaggle)","metadata":{}},{"cell_type":"code","source":"root_logdir = \"../../tensorboard-logs\"\n\nprint(\"Relative root_logdir: \",root_logdir)\n\ndef get_run_logdir():\n    import time\n    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n    return os.path.join(root_logdir,run_id)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:44.314785Z","iopub.execute_input":"2021-09-07T07:27:44.315385Z","iopub.status.idle":"2021-09-07T07:27:44.321118Z","shell.execute_reply.started":"2021-09-07T07:27:44.31535Z","shell.execute_reply":"2021-09-07T07:27:44.320431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_logdir = get_run_logdir()\nprint(\"Current run logdir for Tensorboard: \", run_logdir)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:44.322338Z","iopub.execute_input":"2021-09-07T07:27:44.322619Z","iopub.status.idle":"2021-09-07T07:27:44.33316Z","shell.execute_reply.started":"2021-09-07T07:27:44.322591Z","shell.execute_reply":"2021-09-07T07:27:44.332123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_logdir","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:44.334628Z","iopub.execute_input":"2021-09-07T07:27:44.334941Z","iopub.status.idle":"2021-09-07T07:27:44.344642Z","shell.execute_reply.started":"2021-09-07T07:27:44.334913Z","shell.execute_reply":"2021-09-07T07:27:44.343898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Keras Callbacks for Tensorboard\nWith Keras there is a way of using Callbacks for the Tensorboard to write log files for the board and visualize the different graphs (loss and val curve)\n","metadata":{}},{"cell_type":"code","source":"tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:44.345729Z","iopub.execute_input":"2021-09-07T07:27:44.346153Z","iopub.status.idle":"2021-09-07T07:27:44.357674Z","shell.execute_reply.started":"2021-09-07T07:27:44.346115Z","shell.execute_reply":"2021-09-07T07:27:44.356762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building Model Architecture","metadata":{}},{"cell_type":"markdown","source":"### Architecture for Hyperparameter Optimization\r\n- Amount of Layers\r\n- Amount of Neurons\r\n- Learningrate\r\n- Checkpoints\r\n- Early Stopping ","metadata":{}},{"cell_type":"code","source":"def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[784]):\n    model = keras.models.Sequential()                               # base model structure (Sequential API by Keras)\n\n    model.add(keras.layers.InputLayer(input_shape=input_shape))     # input layer\n\n    for layer in range(n_hidden):                                   # add layers as often as defined in constructor \n        model.add(keras.layers.Dense(n_neurons,activation=\"relu\"))  # add layer with given neurons and relu activation function\n\n    model.add(keras.layers.Dense(10, activation=\"softmax\"))                               # add output layer \n\n    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)   # define optimizer (especially the larning rate for hyperparameter optimization)\n\n    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])                  # make it ready\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:44.358943Z","iopub.execute_input":"2021-09-07T07:27:44.359345Z","iopub.status.idle":"2021-09-07T07:27:44.370588Z","shell.execute_reply.started":"2021-09-07T07:27:44.359304Z","shell.execute_reply":"2021-09-07T07:27:44.369562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using keras wrapper as hull \nkeras_cl = keras.wrappers.scikit_learn.KerasClassifier(build_model)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:44.372145Z","iopub.execute_input":"2021-09-07T07:27:44.37267Z","iopub.status.idle":"2021-09-07T07:27:44.385396Z","shell.execute_reply.started":"2021-09-07T07:27:44.372625Z","shell.execute_reply":"2021-09-07T07:27:44.38448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameter Space","metadata":{}},{"cell_type":"code","source":"from scipy.stats import reciprocal\n\n# Hyperparameter set\nparam_dist= {\n            \"n_neurons\": range(20, 500, 20)\n            ,\"n_hidden\": range(10, 100, 10)\n            ,\"learning_rate\": [1e-3, 2e-3]\n    }\n\n\nparam_dist_lr= {\n        \"n_neurons\": [10, 50, 100, 150, 300]\n        ,\"n_hidden\": [10, 50, 100, 150]\n        ,\"learning_rate\": [1e-3, 3e-4, 3e-2]\n}\n\n\nparam_dist_bestrun_1 = {\n        \"n_neurons\": [150]\n        ,\"n_hidden\": [30]\n        ,\"learning_rate\": [2e-3]  \n}\n\n\nparam_dist_bestrun_2 = {\n        \"n_neurons\": [100]\n        ,\"n_hidden\": [10]\n        ,\"learning_rate\": [2e-3]  \n}","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:44.386718Z","iopub.execute_input":"2021-09-07T07:27:44.387018Z","iopub.status.idle":"2021-09-07T07:27:44.395564Z","shell.execute_reply.started":"2021-09-07T07:27:44.386991Z","shell.execute_reply":"2021-09-07T07:27:44.394635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Checkpoints","metadata":{}},{"cell_type":"code","source":"checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cl_model.h5\", save_best_only=True, save_weights_only=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T07:27:44.396513Z","iopub.execute_input":"2021-09-07T07:27:44.39688Z","iopub.status.idle":"2021-09-07T07:27:44.406345Z","shell.execute_reply.started":"2021-09-07T07:27:44.396854Z","shell.execute_reply":"2021-09-07T07:27:44.405371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"markdown","source":"### Randomized Search\r\nFinding best hyperparameters with Randomized search","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nran_ker_cl = RandomizedSearchCV(keras_cl, param_dist_lr, n_iter=10, n_jobs=5, cv=3, random_state=seed, return_train_score=True)\nhistory_ker_cl = ran_ker_cl.fit(X_train_prep, y_train, epochs=50, validation_data=(X_val_prep, y_val), callbacks=[checkpoint_cb, keras.callbacks.EarlyStopping(patience=5), tensorboard_cb])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-09-07T07:27:51.680837Z","iopub.execute_input":"2021-09-07T07:27:51.681325Z","iopub.status.idle":"2021-09-07T07:28:47.914555Z","shell.execute_reply.started":"2021-09-07T07:27:51.681294Z","shell.execute_reply":"2021-09-07T07:28:47.912506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_ker_cl.best_params_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_ker_cl","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Training with Full Dataset \r\nIn this part I will train the model with the full dataset. This time I will use the discovered hyperparameters from the randomized search from the previous part.\r\n\r\nBased on the hyperparameter search the following parameters were found:\r\n- n_neurons = 150\r\n- n_hidden = 10\r\n- learning_rate = 0.03","metadata":{}},{"cell_type":"code","source":"# Creating wrapped regression model with our function. \nkeras_cl_model = keras_cl.build_fn(n_neurons= 150, n_hidden= 10, learning_rate=0.03)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras_cl_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a new log dir for tensorboard\ntensorboard_cb_f = keras.callbacks.TensorBoard(get_run_logdir())\ncheckpoint_cb_f = keras.callbacks.ModelCheckpoint(\"my_keras_cl_model.h5\", save_best_only=False, save_weights_only=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preparing data based on our beautifull trained data pipeline\nX_prep_all = pipeline.transform(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model again pleeeeease with all you got .... especially the new transformed data matrix X \nkeras_cl_model.fit(X_prep_all, y, epochs=100, callbacks=[tensorboard_cb_f, checkpoint_cb_f])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Prediction of Unknown Data (Test Data)","metadata":{}},{"cell_type":"markdown","source":"## Peparing Test Data\r\nThe test data for the competition needs to be prepared as well as did with the training data set. Therefore the trained pipeline (trained only on the training dataset) will be used.","metadata":{}},{"cell_type":"code","source":"X_test_prep = pipeline.transform(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_prep","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Competition File","metadata":{}},{"cell_type":"code","source":"mnist_competition_file = pd.DataFrame(columns=['ImageId','Label'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction of Testdata","metadata":{}},{"cell_type":"code","source":"plt.imshow(X_test_prep[43].reshape(28,28), cmap='Greys')","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Propability of all lables for given pixels: \", keras_cl_model.predict(X_test_prep[43].reshape(1,-1)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Predicted Digit: \",np.argmax(keras_cl_model.predict(X_test_prep[43].reshape(1,-1))))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 1\r\nfor row in X_test_prep:\r\n    index = i\r\n    predicted_label = np.argmax(keras_cl_model.predict(row.reshape(1,-1)))\r\n\r\n    mnist_competition_file = mnist_competition_file.append({'ImageId': index, 'Label': predicted_label}, ignore_index = True )\r\n    i = i + 1\r\n    pass","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnist_competition_file","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnist_competition_file.ImageId = mnist_competition_file.ImageId.astype(int)\r\nmnist_competition_file.Label = mnist_competition_file.Label.astype(int)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnist_competition_file.to_csv('mnist_submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}