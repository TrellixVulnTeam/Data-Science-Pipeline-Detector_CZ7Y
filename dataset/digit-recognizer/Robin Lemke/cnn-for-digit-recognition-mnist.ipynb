{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom functools import partial\n#import seaborn as sn\nfrom sklearn.model_selection import train_test_split\n\nfrom random import seed\nseed(1)\nseed = 43\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow import image\nfrom tensorflow import core\nfrom tensorflow.keras import layers\nprint(\"Tensorflow Version: \", tf.__version__)\nprint(\"Keras Version: \",keras.__version__)\n\n\nKAGGLE = 1 # Kaggle path active = 1\nDATA_DIR = \"input/digit-recognizer\"\n\n\n# change your local path here\nif KAGGLE == 1 :\n    MNIST_PATH= os.path.join('..', DATA_DIR)\nelse:\n    MNIST_PATH= os.path.join(os.getcwd(), \"data\", DATA_DIR)\n\nprint(MNIST_PATH)\n\n\nfor dirname, _, filenames in os.walk(MNIST_PATH): \n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduction - MNIST Training Competition\nThis notebook is a fork or copy of my previous developed notebook for digit recognition. Therefore you will find some parts that look common to the notebook <a href=\"https://www.kaggle.com/skiplik/digit-recognition-with-a-deep-neural-network\">Digit Recognition with a Deep Neural Network</a> or <a href=\"https://www.kaggle.com/skiplik/finetuning-hyperparameters-in-deep-neural-network\">Finetuning Hyperparameters in Deep Neural Network</a>.\n\nLink to the data topic: https://www.kaggle.com/c/digit-recognizer/data\n\nAs in the previous notebooks I will use Tensorflow with Keras. I already mentioned in other notebooks, I will skip some explanations about the data set here. Moreover I will use the already discovered knowledge about the data and transform/prepare the data rightaway.\n\n## Convolutional Neural Networks\nMy focus on this notebook lies in using Convolutional Neural Networks. I worked with them before but since I read different articles and books about its architecture, I got a deeper understanding of the different layers and their result to the rest of the network. \n\nAs in the previous notebooks I will use different architecture / layer configurations and submit the results to the Kaggle competition to get a rated accuracy value. This will be an indicator for the used model architecture. The plan is to commit the notebook in Git as well as in Kaggle to versionize the architecture with its accuracy value. This will help me to understand the benefits of the different layers a little and look into the progress of the different architectures later.\n\nThe idea is to use different layers in different combinations. The following layers will be used in this notebook:\n\n- Convolutional layers (Conv2D, Conv3D,...)\n- Max Pooling layers\n- Avg Pooling  \n- Batch Normalization\n- Dropout\n\n\nNot part of this notebook will be the architecture of Transfer-Learning where a pretrained model is used and retrained with a new dataset. I already tried that approach in the following notebook: https://www.kaggle.com/skiplik/picturerecognition-tf-and-transferlearning-resnet\n\n## Best Runs\nThe best run was based on Kaggle version 6 with an accuracy of 99.12% on the kaggle competition \"Digit Recognizer\". For this version the special improvement was (next to the Conv2D layers, the reduction of the epochs for training): https://www.kaggle.com/skiplik/cnn-for-digit-recognition-mnist?scriptVersionId=79696075\n\nRight after that there where an equivalent run with an accuracy of 99.025%. Here happened some architecture changes, added more filters to the Conv-Layers and increased the kernel size. Due to the observation of the training process (via tensorboard) I recognized the validation accuracy starts to get a little bit noisy, therefore I decided to reduce the epochs number to a value where the accuracy still got its none noisy behaviour. In my opinion this is the most important configuration for this accuracy value. The reduction of the epochs just saves the model's capability of giving better answers to totally new, unseen data.\n\n## My other Projects\nIf you are interested in some more clearly analysis of the dataset take a look into my other notebooks about the MNIS-dataset:\n- Finetuning Hyperparameters in Deep Neural Network:\n    - https://www.kaggle.com/skiplik/finetuning-hyperparameters-in-deep-neural-network\n- Digit Recognition with a Deep Neural Network: \n    - https://www.kaggle.com/skiplik/digit-recognition-with-a-deep-neural-network\n- Another MNIST Try:\n    - https://www.kaggle.com/skiplik/another-mnist-try\n- First NN by Detecting Handwritten Characters:\n    - https://www.kaggle.com/skiplik/first-nn-by-detecting-handwritten-characters\n...\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Get Data","metadata":{}},{"cell_type":"code","source":"# Data path and file\nCSV_FILE_TRAIN='train.csv'\nCSV_FILE_TEST='test.csv'\n\ndef load_mnist_data(minist_path, csv_file):\n    csv_path = os.path.join(minist_path, csv_file)\n    return pd.read_csv(csv_path)\n\ndef load_mnist_data_manuel(minist_path, csv_file):\n    csv_path = os.path.join(minist_path, csv_file)\n    csv_file = open(csv_path, 'r')\n    csv_data = csv_file.readlines()\n    csv_file.close()\n    return csv_data\n\ndef split_train_val(data, val_ratio):\n    return \n    \n\ntrain = load_mnist_data(MNIST_PATH,CSV_FILE_TRAIN)\ntest = load_mnist_data(MNIST_PATH,CSV_FILE_TEST)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train['label'].copy()\nX = train.drop(['label'], axis=1)\n\n# competition dataset\nX_test = test.copy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train / Val Split","metadata":{}},{"cell_type":"code","source":"print(\"Shape of the Features: \",X.shape)\nprint(\"Shape of the Labels: \", y.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label Value Count\nVisualizing the label distribution of the full train dataset.","metadata":{}},{"cell_type":"code","source":"train.value_counts('label')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=seed, test_size=0.20\n                                                  , stratify=y\n                                                 )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comparing the equally splitted train- and val-sets based on the given label y.","metadata":{}},{"cell_type":"code","source":"print(\"Train - Set Distribution\")\nprint(y_train.value_counts() / y_train.value_counts().sum() )\nprint('--------------------------------------------------------------')\nprint('--------------------------------------------------------------')\nprint('--------------------------------------------------------------')\nprint(\"Val - Set Distribution\")\nprint(y_val.value_counts() / y_val.value_counts().sum() )\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X: \", X.shape)\nprint(\"X_train: \", X_train.shape)\nprint(\"X_val: \", X_val.shape)\n\nprint(\"y_train: \", y_train.shape)\nprint(\"y_val: \", y_val.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building Transforming Piplines","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import StandardScaler\n\npipeline = Pipeline([\n    #('normalizer', Normalizer())\n    ('std_scalar',StandardScaler())\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing Data","metadata":{}},{"cell_type":"markdown","source":"### Data Augmentation with Tensorflow Data Api","metadata":{}},{"cell_type":"code","source":"def random_crop(image):\n    shape = tf.shape(image)\n    min_dim = tf.reduce_min([shape[0], shape[1]]) * 85 // 100       # croping to 90% of the initial picture \n    return tf.image.random_crop(image, [min_dim, min_dim, 1])\n\n\ndef crop_flip_resize(image, label, flipping = True):\n    if flipping == True:\n        cropped_image = random_crop(image)\n        cropped_image = tf.image.flip_left_right(cropped_image)\n    else:\n        cropped_image = random_crop(image)\n\n    ## final solution\n    resized_image = tf.image.resize(cropped_image, [28,28])\n    final_image = resized_image\n    #final_image = keras.applications.xception.preprocess_input(resized_image)\n    return final_image, label  \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting dataframe format into tensorflow compatible format.\nX_train = X_train.values.reshape(X_train.shape[0], 28, 28, 1)\nX_val = X_val.values.reshape(X_val.shape[0], 28, 28, 1)\n\nX_train_crop = X_train.copy()\nX_val_crop = X_val.copy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating tensorbased dataset \n\ntraining_dataset = (\n    tf.data.Dataset.from_tensor_slices(\n        (\n            tf.cast(X_train, tf.float32),\n            tf.cast(y_train, tf.int32)\n        )\n    )\n)\n\n\nval_dataset = (\n    tf.data.Dataset.from_tensor_slices(\n        (\n             tf.cast(X_val, tf.float32),\n             tf.cast(y_val, tf.int32)\n        )\n    )\n)\n\n\ntraining_crop_dataset = (\n    tf.data.Dataset.from_tensor_slices(\n        (\n            tf.cast(X_train_crop, tf.float32),\n            tf.cast(y_train, tf.int32)\n        )\n    )\n)\n\n\nval_crop_dataset = (\n    tf.data.Dataset.from_tensor_slices(\n        (\n             tf.cast(X_val_crop, tf.float32),\n             tf.cast(y_val, tf.int32)\n        )\n    )\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resizing, croping images via self build function\ntraining_crop_dataset = training_crop_dataset.map(partial(crop_flip_resize, flipping=False))\nval_crop_dataset = val_crop_dataset.map(partial(crop_flip_resize, flipping=False))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing a croped, flipped, resized image from new dataset.\nfor X_values, y_values in training_crop_dataset.take(1):\n    for index in range(1):\n        plt.imshow(X_values)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# concate the two datasets\ntraining_dataset_all = training_dataset.concatenate(training_crop_dataset)\nval_dataset_all = val_dataset.concatenate(val_crop_dataset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"training_dataset_all length: \", len(list(training_dataset_all)))\nprint(\"val_dataset_all length: \", len(list(val_dataset_all)))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shuffeling and batching data\ntf.random.set_seed(seed)\n\ntrain_ds = training_dataset_all.shuffle(10000).batch(32).prefetch(1)\nval_ds = val_dataset_all.shuffle(8000).batch(32).prefetch(1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building a Deep Neural Network","metadata":{}},{"cell_type":"markdown","source":"## Preparing Model Visualization with Tensorboard (not for Kaggle)","metadata":{}},{"cell_type":"code","source":"root_logdir = \"../../tensorboard-logs\"\n\nprint(\"Relative root_logdir: \",root_logdir)\n\ndef get_run_logdir():\n    import time\n    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n    return os.path.join(root_logdir,run_id)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_logdir = get_run_logdir()\nprint(\"Current run logdir for Tensorboard: \", run_logdir)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_logdir","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Keras Callbacks for Tensorboard\nWith Keras there is a way of using Callbacks for the Tensorboard to write log files for the board and visualize the different graphs (loss and val curve)\n","metadata":{}},{"cell_type":"code","source":"tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building Model Architecture","metadata":{}},{"cell_type":"code","source":"from keras.layers import LeakyReLU\n\ninput_shape=[784]\ninput_shape_notFlattened=[28,28,1]\n\nbatch_shape = []\n\n\nlearning_rt = 1e-03 \nactivation_fn = \"relu\"\ninitializer = \"he_normal\"\nregularizer =  None\n\n# Model building\ndef create_model_struc():  \n    model = keras.models.Sequential()\n\n    model.add(keras.layers.Conv2D(filters=256, kernel_size=6, strides=2, padding='same', input_shape=input_shape_notFlattened))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Activation(activation_fn))\n    model.add(keras.layers.Dropout(rate=0.2))\n    #model.add(keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same'))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Activation(activation_fn))\n    #model.add(keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n    model.add(keras.layers.Dropout(rate=0.2))\n    ## \n    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation=activation_fn))\n    model.add(keras.layers.Dropout(rate=0.2))\n    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation=activation_fn))\n\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(64, activation=activation_fn))\n    model.add(keras.layers.Dense(64, activation=activation_fn))\n    \n    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n\n    optimizer = keras.optimizers.Adam(learning_rate=learning_rt)\n\n    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'] )\n    model.build()\n\n    return model   \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model_struc()\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Checkpoints","metadata":{}},{"cell_type":"code","source":"checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_train_model.h5\", save_best_only=True, save_weights_only=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_ds, epochs=15, validation_data=val_ds, callbacks=[checkpoint_cb, keras.callbacks.EarlyStopping(patience=8), tensorboard_cb])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing the Progress","metadata":{}},{"cell_type":"code","source":"plt.plot(pd.DataFrame(history.history))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Training with Full Dataset \nIn this part I will train the model with the full dataset. This time I will use the discovered hyperparameters from previous section.","metadata":{}},{"cell_type":"code","source":"model_full = create_model_struc()\nmodel_full.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a new log dir for tensorboard\ntensorboard_cb_f = keras.callbacks.TensorBoard(get_run_logdir())\ncheckpoint_cb_f = keras.callbacks.ModelCheckpoint(\"my_modell_full.h5\", save_best_only=False, save_weights_only=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preparing full features set (X) for the tensorflow data api\n\ntraining_dataset_all = training_dataset.concatenate(training_crop_dataset)\nval_dataset_all = val_dataset.concatenate(val_crop_dataset)\n\ntraining_ds_all = training_dataset_all.concatenate(val_dataset_all)\n\ntraining_ds_all = training_ds_all.shuffle(20000).batch(32).prefetch(1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model again pleeeeease with all you got .... especially the new transformed data matrix X \nhistory_full = model_full.fit(training_ds_all, epochs=12, callbacks=[tensorboard_cb_f, checkpoint_cb_f])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(pd.DataFrame(history_full.history))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Prediction of Unknown Data (Test Data)","metadata":{}},{"cell_type":"markdown","source":"## Peparing Test Data\nAs well as previously done, we need to create a TF dataset of the test set as well.","metadata":{}},{"cell_type":"code","source":"# converting dataframe format into tensorflow compatible format.\nX_test = X_test.values.reshape(X_test.shape[0], 28, 28, 1)\n\n\ntest_dataset = (\n    tf.data.Dataset.from_tensor_slices(\n        (\n            tf.cast(X_test, tf.float32)\n        )\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = test_dataset.batch(32).prefetch(1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Competition File","metadata":{}},{"cell_type":"code","source":"mnist_competition_file = pd.DataFrame(columns=['ImageId','Label'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction of Testdata","metadata":{}},{"cell_type":"code","source":"# Visualizing the image\nplt.figure(figsize=(12, 12))\nfor X_batch in test_ds.take(1):\n    for index in range(1):\n        plt.subplot(3, 3, index + 1)\n        plt.imshow(X_batch[index])\n\nplt.show()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for element in test_ds.take(1):\n    print(\"Propability of all lables for given pixels: \", model_full.predict(test_ds.take(1))[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Predicted Digit: \",np.argmax(model_full.predict(test_ds.take(1))[0]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model_full.predict(test_ds)                                                                           # predict the probability\npredictions = np.argmax(predictions, axis=1)                                                                        # getting the predicted digit numbers based ont the probability of every np element \nmnist_competition_file = pd.DataFrame(predictions)                                                                  # converting into df\nmnist_competition_file.index += 1                                                                                   # index should start at 1\nmnist_competition_file.reset_index(level=0, inplace=True)                                                           # make the index a column \nmnist_competition_file = mnist_competition_file.rename(columns={\"index\": \"ImageId\", 0: \"Label\"}, errors=\"raise\")    # renamen them according to the competition requirements","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnist_competition_file","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnist_competition_file.ImageId = mnist_competition_file.ImageId.astype(int)\nmnist_competition_file.Label = mnist_competition_file.Label.astype(int)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnist_competition_file.to_csv('mnist_submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}