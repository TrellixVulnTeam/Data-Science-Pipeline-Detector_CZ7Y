{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nThis notebook will handle the topic of an autoencoder on the MNIST-dataset. In particular there will be an denoising autoencoder that reduces noise in data by reconstructing the original image.\n\nThe specifics of autoencoding are in the fact that there is no label needed to predict as it is known in common deep-learning architecture. Under this particular architecture, the goal is to \"predict\" its given input values (the features). Therefore we better say \"reconstruct\" instead of \"predict\". The model is forced to reconstruct the the given features, this is implemented through three major changes to the traditional NN structure:\n1. Building the model out of two seperate models (encoder and decorder).\n2. Reducing the given information in the middle of the network (codings).\n3. Using the features as label values as well (prediction value is the input).\n\nYou will find these structures as well as two variations of denoising autoencoders in this notebook, one with a simple deep neural network (First Model - Deep Denoising Autoencoder) and a dropout layer and another one (Second Model - Convolutional Denoising Autoencoder) with convolution layers and a GaussianNoise creation.\n\nFinally to visualize the capabilities of autoencoding, one of the two trained models will be used to train a new model for a completely other task, a classification one. This represents the unsupervised pre-trained approach of model development when there is not enough data to train a model for. \n\n## My other Projects\nIf you are interested in some more clearly analysis of the dataset, take a look into my other notebooks about the MNIS-dataset:\n\n- cnn-for-digit-recognition-MNIST (accuracy score: 0.99135):\n    - https://www.kaggle.com/skiplik/cnn-for-digit-recognition-mnist \n- Finetuning Hyperparameters in Deep Neural Network:\n    - https://www.kaggle.com/skiplik/finetuning-hyperparameters-in-deep-neural-network\n- Digit Recognition with a Deep Neural Network:\n    - https://www.kaggle.com/skiplik/digit-recognition-with-a-deep-neural-network\n- Another MNIST Try:\n    - https://www.kaggle.com/skiplik/another-mnist-try\n- First NN by Detecting Handwritten Characters:\n    - https://www.kaggle.com/skiplik/first-nn-by-detecting-handwritten-characters \n- ...","metadata":{}},{"cell_type":"markdown","source":"# Imports and Helper Functions","metadata":{}},{"cell_type":"code","source":"import sys\nassert sys.version_info >= (3,5)\n\n# Is this notebook running on Colab or Kaggle?\nIS_COLAB = \"google.colab\" in sys.modules\nIS_KAGGLE = \"kaggle_secrets\" in sys.modules\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom functools import partial\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow import image\nfrom tensorflow import core\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import plot_model\n\n#import mlflow\n#from mlflow import log_metric, log_param, log_artifacts\n#import mlflow.tensorflow\n#from mlflow import pyfunc\n\nassert tf.__version__ >= \"2.0\"\n\nprint(f\"Tensorflow Version: {tf.__version__}\")\nprint(f\"Keras Version: {keras.__version__}\")\n\nif not tf.config.list_physical_devices('GPU'):\n    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n    if IS_COLAB:\n        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n    if IS_KAGGLE:\n        print(\"Go to Settings > Accelerator and select GPU.\")\n\n\ntf.random.set_seed(42)\nnp.random.seed(42)\nrandom_state=42\n\nkaggle = 1 # Kaggle path active = 1\n\n# change your local path here\nif kaggle == 1 :\n    MNIST_PATH= '../input/digit-recognizer'\nelse:\n    MNIST_PATH= '../autoencoding-mnist/data/input/digit-recognizer'\n\n\n\nimport os\nfor dirname, _, filenames in os.walk(MNIST_PATH): \n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get The Data","metadata":{}},{"cell_type":"code","source":"# Data path and file\nCSV_FILE_TRAIN='train.csv'\nCSV_FILE_TEST='test.csv'\n\ndef load_csv_data(path, csv_file):\n    csv_path = os.path.join(path, csv_file)\n    return pd.read_csv(csv_path)\n\ndef load_csv_data_manuel(path, csv_file):\n    csv_path = os.path.join(path, csv_file)\n    csv_file = open(csv_path, 'r')\n    csv_data = csv_file.readlines()\n    csv_file.close()\n    return csv_data\n    \n\ntrain = load_csv_data(MNIST_PATH,CSV_FILE_TRAIN)\ntest = load_csv_data(MNIST_PATH,CSV_FILE_TEST)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Val Split","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid =  train_test_split(train.loc[:, train.columns != 'label'], train['label'], test_size=0.33, random_state=random_state)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparing for Neural Network Structure","metadata":{}},{"cell_type":"code","source":"X_train = X_train.astype(np.float32) / 255\nX_valid = X_valid.astype(np.float32) / 255\nX_test = test.astype(np.float32) / 255","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"'X_train' shape: {X_train.shape}\")\nprint(f\"'X_valid' shape: {X_valid.shape}\")\nprint(f\"'X_test' shape: {X_test.shape}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Reshaping Data in Proper Structure","metadata":{}},{"cell_type":"code","source":"### DEBUG TODO: implement /wo chanel param\ndef reshape_images(df_images):\n    '''Reshaping image structure to a three dimensional tensor'''\n    df_images_resh = df_images.values.reshape(df_images.shape[0], 28, 28)\n    return df_images_resh\n\ndef reshape_conv_images(df_images):\n    '''\n    Reshaping image structure to a four dimensional tensor for conv networks,\n    where chanel is last\n    '''\n    df_images_conv_resh = df_images.values.reshape(df_images.shape[0], 28, 28, 1)\n    return df_images_conv_resh","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using this data for only dense layer models\nX_train_resh = reshape_images(X_train)\nX_valid_resh = reshape_images(X_valid)\nX_test_resh = reshape_images(X_test)\n\n# using this data for convolutional models\nX_train_resh_ch = reshape_conv_images(X_train)\nX_valid_resh_ch = reshape_conv_images(X_valid)\nX_test_resh_ch = reshape_conv_images(X_test)\n\ny_train_resh =  y_train.values.reshape(y_train.shape[0], 1)\ny_valid_resh = y_valid.values.reshape(y_valid.shape[0], 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"'X_train_resh' shape: {X_train_resh.shape}\")\nprint(f\"'X_valid_resh' shape: {X_valid_resh.shape}\")\nprint(f\"'X_test_resh' shape: {X_test_resh.shape}\")\nprint(f\"'y_train_resh' shape: {y_train_resh.shape}\")\nprint(f\"'y_valid_resh' shape: {y_valid_resh.shape}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting Functions","metadata":{}},{"cell_type":"code","source":"def plot_image(image):\n    plt.imshow(image, cmap=\"binary\")\n    plt.axis(\"off\")\n\ndef show_reconstructions(model, X_valid, n_images=5):\n    reconstructions = model.predict(X_valid[:n_images])\n    fig = plt.figure(figsize=(n_images * 1.5, 3))\n\n    for image_index in range(n_images):\n        plt.subplot(2, n_images, 1 + image_index)\n        plot_image(X_valid[image_index])\n        plt.subplot(2, n_images, 1 + n_images + image_index)\n        plot_image(reconstructions[image_index])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting One Example Value","metadata":{}},{"cell_type":"code","source":"print(f\"Example label: {y_valid.iloc[1]}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_image(X_valid.iloc[1].values.reshape(28,28))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Autoencoding Models for Denoising\nThis chapter will be about two denoising autoencoder structures and their different ways of building such an architecture to reduce noise in data. The results of these models will be shown in the next chapter \"Results - Denoising Autoencoders\".\n\nBasically an autoencoder architecture includes two seperate models, the encoder and the decorder. In the neuron point of view they both have a rejuvenation which represents a need of information compression - keep only the realy relevant information and drop the less relevant information. Both models combined therefore need to recreate information artificially - the main idea of an autoencoder structure.","metadata":{}},{"cell_type":"markdown","source":"## First Model - Deep Denoising Autoencoder \nThis model uses fully connected layers and a dropout layer to simulate the noising in the data, which it will be trained on in the later process. There is no convolutional layer or other structures used like in the model in the following chapter.","metadata":{}},{"cell_type":"markdown","source":"### Encoder Architecture","metadata":{}},{"cell_type":"code","source":"dropout_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(100, activation=\"selu\"),\n    keras.layers.Dense(30, activation=\"selu\")           # Codings\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dropout_encoder.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decoder Architecture","metadata":{}},{"cell_type":"code","source":"dropout_decoder = keras.models.Sequential([\n    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dropout_decoder.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building the Model","metadata":{}},{"cell_type":"code","source":"dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])\ndropout_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.5))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training and Logging -  Deep Denoising Autoencoder","metadata":{}},{"cell_type":"markdown","source":"#### Logging the Model (ML Flow)","metadata":{}},{"cell_type":"code","source":"#mlflow.tensorflow.autolog()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training the Model","metadata":{}},{"cell_type":"code","source":"history = dropout_ae.fit(X_train_resh, X_train_resh, epochs= 10, validation_data=(X_valid_resh, X_valid_resh))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Losses\nThe question is: \"How good does the model reconstruct the given features/information\". So there is no prediction of some label value! The model \"predicts\" (or better) reconstruct its input values as good as it can.","metadata":{}},{"cell_type":"code","source":"# Getting in touch with the model statistics \n# shows the available keys in models history:  print(history.history.keys())\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Second Model - Convolutional Denoising Autoencoder\nThe second model is built on a convolutional structure. It uses several Conv2D layers in combinations with MaxPool2D layers to build the base structure. Instead of a Dropout layer to create noise  in the data (like the model one version) this time a GaussianNoise layer is used.","metadata":{}},{"cell_type":"markdown","source":"### Convolutional Encoder Architecture  ","metadata":{}},{"cell_type":"code","source":"conv_encoder = keras.models.Sequential([\n    keras.layers.GaussianNoise(0.1, input_shape = [28, 28, 1]),\n    keras.layers.Conv2D(16, kernel_size=3, activation='selu'),\n    keras.layers.MaxPool2D(pool_size=2),\n    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"selu\"),\n    keras.layers.MaxPool2D(pool_size=4),\n    keras.layers.Dense(392, activation=\"relu\")           # Codings\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_encoder.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Convolutional Decoder Architecture","metadata":{}},{"cell_type":"code","source":"conv_decoder = keras.models.Sequential([\n    keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"valid\",activation=\"selu\", input_shape=[3, 3, 392]),\n    keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"same\",activation=\"selu\"),\n    keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"same\", activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28, 1])\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_decoder.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building the Model - Deep Convolutional Denoising Autoencoder","metadata":{}},{"cell_type":"code","source":"conv_denoising_ae = keras.models.Sequential([conv_encoder, conv_decoder])\nconv_denoising_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.5))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_denoising_ae.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training and Logging - Deep Convolutional Denoising Autoencoder","metadata":{}},{"cell_type":"markdown","source":"#### Training the Model","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = conv_denoising_ae.fit(X_train_resh_ch, X_train_resh_ch, epochs= 10, validation_data=(X_valid_resh_ch, X_valid_resh_ch))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saving model for weight using in later process\nconv_denoising_ae.save('conv_denoising_ae')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Probably not working on Kaggle\nplot_model(conv_denoising_ae, 'conv_autencoder.png', show_shapes=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results - Denoising Autoencoders\nThe structure of the \"Results\" chapter will in first place visualize the results of the different models (First Model - Deep Denoising Autoencoder and Second Model - Convolutional Denoising Autoencoder) by showing the origin digit and the reconstructed one without any noised data input. This is followed by a noised data test where a noised digit represents the input into the model and and a denoised, reconstructed one its result (\"prediction\").","metadata":{}},{"cell_type":"markdown","source":"## Results - Deep Denoising Autoencoder","metadata":{}},{"cell_type":"markdown","source":"### Origin Digit","metadata":{}},{"cell_type":"code","source":"plot_image(X_valid_resh[10])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (\"Predicted\") Reconstructed digit","metadata":{}},{"cell_type":"code","source":"testimage = X_valid_resh[10].reshape(1, 28, 28)     # single image prepared for the test (reshape)\nplot_image(dropout_ae.predict(testimage)[0, :, :])  # needed to extract the second and third array of the three dimensional tensor struc for printing the image","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Showing Multi Results","metadata":{}},{"cell_type":"code","source":"show_reconstructions(dropout_ae, X_valid_resh)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using Noised Images","metadata":{}},{"cell_type":"markdown","source":"#### Creating Noisy Data\n","metadata":{}},{"cell_type":"code","source":"new_images = X_test[5:10]\nnew_images = reshape_images(new_images)\nnoisy_images = new_images + np.random.randn(5,28,28) *0.1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Origin Number\n","metadata":{}},{"cell_type":"code","source":"idx_testnumber = 0      # Index of test digit for the next plottings \nplot_image(new_images[idx_testnumber])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Noisy Digit","metadata":{}},{"cell_type":"code","source":"plot_image(noisy_images[idx_testnumber])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Denoised Digit","metadata":{}},{"cell_type":"code","source":"# Very Important ! added a new axis according to the models batch based behavior\nplot_image(dropout_ae.predict(noisy_images[np.newaxis ,idx_testnumber]).reshape(28,28)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Multiple Digits in Comparision","metadata":{}},{"cell_type":"code","source":"show_reconstructions(dropout_ae, noisy_images)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Results - Convolutional Denoising Autoencoder","metadata":{}},{"cell_type":"markdown","source":"### Using Noised Images","metadata":{}},{"cell_type":"markdown","source":"#### Creating Noisy Data","metadata":{}},{"cell_type":"code","source":"new_images_conv = X_test[5:10]\nnew_images_conv = reshape_conv_images(new_images_conv)\nnoisy_images_conv = new_images_conv + np.random.randn(5, 28, 28, 1) *0.1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Origin Digit\n","metadata":{}},{"cell_type":"code","source":"idx_testnumber = 0      # Index of test number for the next plottings \nplot_image(new_images_conv[idx_testnumber])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Noisy Digit","metadata":{}},{"cell_type":"code","source":"plot_image(noisy_images_conv[idx_testnumber])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Denoised Digit","metadata":{}},{"cell_type":"code","source":"# Very Important ! added a new axis according to the models batch based behavior\nplot_image(conv_denoising_ae.predict(noisy_images_conv[np.newaxis ,idx_testnumber]).reshape(28,28))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Multiple Digits in Comparision","metadata":{}},{"cell_type":"code","source":"show_reconstructions(conv_denoising_ae, noisy_images_conv)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Third Model - Unsupervised Pre-Training for Supervised Training\nThis chapter is about a third model whose topic is to predict a digit shown on a MNIST image. Basically, the architecture represents the way of using unsupervised pre-training for projects that do not have enough training data to train the model properly. In this part layers from the already trained Convolutional Denoising Autoencoder (second model) will be used to build a classification prediction model.","metadata":{}},{"cell_type":"code","source":"# Loading untouched model weights \n# Doing this for the reason that model weights are modified not only for a specifically created model object (that's what I was recognizing), but for the stored object in the cache.\n# Therefore I load here the model new from storage to be capable of running multiple new model trainings without any influence on previous runs (make this training deterministic)\nconv_denoising_ae_clone = tf.keras.models.load_model(\"conv_denoising_ae\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ae_model_id = 0 # 0 for encorder / 1 for decorder\nlayerscount = 5 # how many layers of the model ...\n\n\nnew_model = keras.models.Sequential(conv_denoising_ae_clone.layers[ae_model_id].layers[:layerscount])\nnew_model.trainable =True  # Setting it on True to sepcificly set them on False afterwards  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Making the Layers Trainable / Not-Trainable\nThe already trained layers which have been trained in the unsupervised way above need to be frozen so that only the new layers for the new topic (classification) can be trained.","metadata":{}},{"cell_type":"code","source":"# Make the layers not trainable \nfor layer in new_model.layers[:layerscount -1 ]:              # last layer still be trainable\n    layer.trainable = False\n    print(f\"Layer '{layer.name}' is Trainable = {layer.trainable}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adding the layers for the new topic","metadata":{}},{"cell_type":"code","source":"new_model.add(keras.layers.Flatten())\nnew_model.add(keras.layers.Dense(10, activation=\"softmax\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Viewing final layers-construction and its trainabilaties","metadata":{}},{"cell_type":"code","source":"for layer in new_model.layers:\n    print(f\"Layer '{layer.name}' trainable state = {layer.trainable}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Nadam(), metrics=[\"accuracy\"]) ##keras.optimizers.SGD(learning_rate=0.0003)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(new_model, 'autencoder_base_w_classifier.png', show_shapes=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.save('class_net_01')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Training Data for Unsupervised Pre-Training Model\nIn this part 500 data points will be created for training a normal backpropagation model based on the unsupervised pre-trained model.\n\nAdditionally, the remaining data points will be used for testing the model's accuracy.","metadata":{}},{"cell_type":"code","source":"#DEBUG TODO: Using the reshape_conv_image function here or better the already converted dataframe set.\n\nX_train_pret_resh_500 = X_train_resh_ch[:500]\nX_valid_pret_resh_500 = X_valid_resh_ch[:500]\n\nX_valid_pret_resh_r = X_valid_resh_ch[500:]   # Choosing the last 500 digits for testing unknown, untrained data\n\n\ny_train_pretrained_500 = y_train_resh[:500]\ny_valid_pretrained_500 = y_valid_resh[:500]\n\ny_valid_pretrained_r = y_valid_resh[500:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and Logging","metadata":{}},{"cell_type":"markdown","source":"#### Tensorboard Logging","metadata":{}},{"cell_type":"code","source":"# Tensorboard logging structure function\nroot_logdir = \"../../tensorboard-logs\"\n\ndef get_run_logdir(root_logdir, project):\n    '''\n    Returns logdir to the Tensorboard log for a specific project.\n\n            Parameters:\n                    root_logdir (str) : basic logdir from Tensorboard\n                    project (str): projectname that will be logged in TB\n\n            Returns:\n                    os.path (str): Path to the final logdir\n    '''\n    import time\n    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n    project_logdir = os.path.join(root_logdir,project)\n    return os.path.join(project_logdir, run_id)\n\n\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_run_logdir(root_logdir,\"autoencoding_mnist\"), histogram_freq=1)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training the Pre-Trained Model","metadata":{}},{"cell_type":"code","source":"history_pretrainted = new_model.fit(X_train_pret_resh_500,y_train_pretrained_500 ,epochs=20, \\\n                                        validation_data=(X_valid_pret_resh_500,y_valid_pretrained_500), \\\n                                        callbacks=tensorboard_callback\n                                    )\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loss Plotting","metadata":{}},{"cell_type":"code","source":"plt.plot(history_pretrainted.history['loss'])\nplt.plot(history_pretrainted.history['val_loss'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predicting the Digit on a Pre-Trained Autoencoder Based Model\n\nThe prediction test on unseen data with the pre-trained autoencoder based model will be used with the validation dataset. The model is trained on the first 500 digits from the train set and validated by the first 500 digits on the validation set. There are still enough data in the validation set (and in the train dataset but it sounds better to use the validation set for) to test the model with unseen data (in total 13.360 digits).\n\nFirst there is a visualized test, where the test digit and its prediction will be printed.","metadata":{}},{"cell_type":"code","source":"idx_testnumber_cls_ae = 8      # Index of test number for the next plottings \nplot_image(X_valid_pret_resh_r[idx_testnumber_cls_ae])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Prediction based on the picture above: {np.argmax(new_model.predict(X_valid_pret_resh_r[np.newaxis, idx_testnumber_cls_ae]))}\")\nprint(f\"Probability of the Prediction: {new_model.predict(X_valid_pret_resh_r[np.newaxis, idx_testnumber_cls_ae])}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Following will be determine the accuracy on the remaining validation dataset of 13.360 digits and shows the overall accuracy of the model after pre-training and classification training.","metadata":{}},{"cell_type":"code","source":"y_val_pred_r = new_model.predict(X_valid_pret_resh_r)\ny_val_pred_r = y_val_pred_r.argmax(axis = 1)[:,None]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nacc_score_val = accuracy_score(y_valid_pretrained_r, y_val_pred_r)\n\nprint(f\"Unsupervised pre-trained model, trained on 500 digits, predicting {y_val_pred_r.shape[0]:} digits with only 20 epochs trained with an accuracy of: {acc_score_val}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}