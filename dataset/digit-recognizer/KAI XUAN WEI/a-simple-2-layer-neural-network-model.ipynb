{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d7a346d9-e60c-db06-778b-922354c2fe59"},"source":"## A simple 2-layer neural network model implemented only with `numpy`\nSince most engineers use high-level APIs such as `Caffe`, `Tensorflow`, without knowing the underlining principal of  training neural network, this notebook will guide you to implement a 2-layer full-connected neural network from scratch.\n\n**NOTE**: using our default hyper parameters set, we can achieve about 90% accuracy in our validation set."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b0b40d17-c724-d33f-25fe-54aff108a25f"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"69a5d64c-e27f-e860-dbfa-eb6b7313fb1c"},"outputs":[],"source":"df = pd.read_csv(\"../input/train.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a19db3c-1861-90e2-7b9c-33774daa85eb"},"outputs":[],"source":"# Extract data from dataframe\ndata = df.as_matrix()\n# Split data into training set and validation set\ny = data[:, 0]\nX = data[:, 1:].astype(np.float64)\ntrain_num = 41000\nval_num = 1000\nX_train, y_train = X[:train_num], y[:train_num]\nX_val, y_val = X[train_num:], y[train_num:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"73242148-6890-5e7a-8e4f-21413fa8bf95"},"outputs":[],"source":"print(X_train.shape, y_train.shape, X_train.dtype, y_train.dtype)\nprint(X_val.shape, y_val.shape, X_val.dtype, y_val.dtype)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"16b46766-ae23-79a4-ec91-4a31d9260009"},"outputs":[],"source":"# Data Preprocessing\nmean_pixel = X_train.mean(axis=0)\nX_train -= mean_pixel\nX_val -= mean_pixel"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a81bc625-d34c-9e06-d8fa-63b33d29254f"},"outputs":[],"source":"# An simple 2-layers full-connected neural network model\n# Note we only use numpy \n\n# Initialize our nn\ndef initialize_global_weights():\n    global W1, b1, W2, b2\n    N, D = train_num, 784\n    H, C = 500, 10\n    W1 = 0.001 * np.random.rand(D, H)\n    b1 = np.zeros(H)\n    W2 = 0.001 * np.random.rand(H, C)\n    b2 = np.zeros(C)\n\ninitialize_global_weights()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3cbb1bc2-3bb6-ea27-a04f-c7a5afa70c0b"},"outputs":[],"source":"# Implement our train function\ndef train_or_evaluate(X, y=None, loss_fn=None, lr=1e-3, reg=0.0):\n    global W1, W2, b1, b2\n    # forward pass\n    a = X.dot(W1) + b1\n    scores = a.dot(W2) + b2\n    if y is None:\n        return scores\n    loss, dscores = loss_fn(scores, y)\n    print('loss: %f' % loss)\n    # backward pass\n    dW2 = np.dot(a.T, dscores) + reg * W2\n    db2 = np.sum(dscores, axis=0)\n    da = np.dot(dscores, W2.T)\n    db1 = np.sum(da, axis=0)\n    dW1 = np.dot(X.T, da) + reg * W1\n    # update params\n    W1 += - lr * dW1\n    W2 += - lr * dW2\n    b1 += - lr * db1\n    b2 += - lr * db2\n    return loss"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88a75f56-d7a8-24d4-f8ff-854bd5ede30e"},"outputs":[],"source":"# Implement our softmax loss function\ndef softmax(scores, y):\n    N = scores.shape[0]\n    scores = scores.copy()\n    scores -= np.max(scores, axis=1)[:, None]\n    probs = np.exp(scores)\n    probs /= np.sum(probs, axis=1)[:, None]\n    loss = np.sum(-np.log(probs[np.arange(N), y])) / N\n    \n    dscores = probs.copy()\n    dscores[np.arange(N), y] -= 1\n    \n    return loss, dscores"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1633845d-054b-5a42-80e7-f774cdc6bf08"},"outputs":[],"source":"# Use initialized weight to checkout train accuracy\nscores = train_or_evaluate(X_train)\nprint((np.argmax(scores, axis=1) == y_train).mean())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a31d854d-4240-c13b-bc6d-3f3a2543171f"},"outputs":[],"source":"# Training our 2-layer model\nnum_iters = 50\ninitialize_global_weights()\nfor i in range(num_iters):\n    loss = train_or_evaluate(X_train, y_train, softmax, lr=1e-7, reg=1e-5)\n    if np.isinf(loss):\n        break"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"153b7860-523b-1809-29f0-82ef1f9d5693"},"outputs":[],"source":"# Use trained weight to checkout train accuracy and val accuracy\ntrain_scores = train_or_evaluate(X_train)\ntrain_acc = (np.argmax(train_scores, axis=1) == y_train).mean()\nval_scores = train_or_evaluate(X_val)\nval_acc = (np.argmax(val_scores, axis=1) == y_val).mean() \nprint(train_acc, val_acc)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f3a051f-a8d9-3c11-a1f4-4f5bcc572a8f"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}