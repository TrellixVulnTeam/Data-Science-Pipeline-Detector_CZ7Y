{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n'''\nPandas is a kind like excel format, that read Comma Separated Values (CSV) files,\nand convert it to the pandas dataframe\n'''\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n'''\ntrain.iloc[:, 1:] will get the data without the label\ntrain.iloc[:,0] will only get the label\ntest_size will split the size of the data proportonially to 10% or 0.1\nrandom_state is a constant value while train_test_split, shuffle the dataset\n'''\n#train.iloc[:, 1:] will get the data without the label\nX_train, X_valid, y_train, y_valid = train_test_split(train.iloc[:,1:], train.iloc[:,0], test_size=0.1, random_state=42)\nX_test = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ndivided all of the data by 255.0, is meant for normalize the dataset value\nif its not divied by 255.0, then the neural network will be constant,\n\nreshaping it to 28,28,1 from x, 784. is meant for inputing it to Conv2D\n'''\n\nX_train = X_train.values.reshape(-1,28,28,1) / 255.0\nX_valid = X_valid.values.reshape(-1,28,28,1) / 255.0\nX_test = X_test.values.reshape(-1,28,28,1) / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\n'''\nConv2D will read the shape of 4D dimension (num, height, weight, channels)\nMaxPooling2D will 'projectile' it to lower dimension, to accerelate the process\nFlatten will reduce the size to 1D array\nDense is a normal neuron point\nDropout will throw away all the unneccesary neuron\n\n'''\nmodel = keras.models.Sequential([\n    keras.layers.Conv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n    keras.layers.MaxPooling2D(pool_size=2),\n    keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding=\"SAME\"),\n    keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding=\"SAME\"),\n    keras.layers.MaxPooling2D(pool_size=2),\n    keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding=\"SAME\"),\n    keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding=\"SAME\"),\n    keras.layers.MaxPooling2D(pool_size=2),\n    keras.layers.Flatten(),\n    keras.layers.Dense(units=128, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(units=64, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(units=10, activation='softmax'),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nSparse Categorical Crossentropy is meant for multiclass classification\nNadam is a optimizer, with faster convergen\nAccuracy is a metrics for calculating the predictions / true value\n'''\nmodel.compile(\n    loss=\"sparse_categorical_crossentropy\",\n    optimizer = 'nadam',\n    metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train,y_train,\n                   validation_data=(X_valid,y_valid),\n                   epochs=10,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(history.history).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n# predict results\npred = model.predict(X_test)\n\n# select the index with the maximum probability\npred = np.argmax(pred,axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")\n# Here we will change the Sample Submission value, to predictions that we have calculate\nsubmissions.Label = pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions.to_csv(\"submissions.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}