{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,BatchNormalization,LeakyReLU\nfrom sklearn.metrics import confusion_matrix\n\n# ignore warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-09T05:53:22.734764Z","iopub.execute_input":"2021-08-09T05:53:22.73513Z","iopub.status.idle":"2021-08-09T05:53:27.496208Z","shell.execute_reply.started":"2021-08-09T05:53:22.735053Z","shell.execute_reply":"2021-08-09T05:53:27.495338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !head -n 2 /kaggle/input/digit-recognizer/train.csv\ntrain_data = pd.read_csv(\"{}/train.csv\".format(dirname))\ntest_data = pd.read_csv(\"{}/test.csv\".format(dirname))","metadata":{"execution":{"iopub.status.busy":"2021-08-09T05:53:27.499533Z","iopub.execute_input":"2021-08-09T05:53:27.499807Z","iopub.status.idle":"2021-08-09T05:53:33.033679Z","shell.execute_reply.started":"2021-08-09T05:53:27.499781Z","shell.execute_reply":"2021-08-09T05:53:33.032697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T05:53:33.037578Z","iopub.execute_input":"2021-08-09T05:53:33.037885Z","iopub.status.idle":"2021-08-09T05:53:33.068448Z","shell.execute_reply.started":"2021-08-09T05:53:33.037854Z","shell.execute_reply":"2021-08-09T05:53:33.067524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.to_numpy().shape","metadata":{"execution":{"iopub.status.busy":"2021-08-09T05:53:33.070249Z","iopub.execute_input":"2021-08-09T05:53:33.07062Z","iopub.status.idle":"2021-08-09T05:53:33.076365Z","shell.execute_reply.started":"2021-08-09T05:53:33.070585Z","shell.execute_reply":"2021-08-09T05:53:33.075416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.to_numpy().shape","metadata":{"execution":{"iopub.status.busy":"2021-08-09T05:53:33.077918Z","iopub.execute_input":"2021-08-09T05:53:33.07835Z","iopub.status.idle":"2021-08-09T05:53:33.087794Z","shell.execute_reply.started":"2021-08-09T05:53:33.078289Z","shell.execute_reply":"2021-08-09T05:53:33.086532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.max(train_data.to_numpy()[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-09T05:53:33.089309Z","iopub.execute_input":"2021-08-09T05:53:33.089714Z","iopub.status.idle":"2021-08-09T05:53:33.0985Z","shell.execute_reply.started":"2021-08-09T05:53:33.089678Z","shell.execute_reply":"2021-08-09T05:53:33.097513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage import feature\nfrom skimage import filters\nfrom skimage.transform import resize\n# resize(heatmap.numpy(),(28,28),)\n\ntrain_label = train_data.label.to_numpy()\n\ndef ArrayFilter(imgarray):\n    img2 = np.array([imgarray,#edge_img,edge_img\n                    ]).transpose(1,2,0)\n    return img2\n\ntrain_image=np.array([ \n        ArrayFilter(img.reshape(28,28))\n    for img in train_data.to_numpy()[0:,1:]\n])\n\ntest_image =np.array([\n        ArrayFilter(img.reshape(28,28))\n    for img in test_data.to_numpy() \n])\n","metadata":{"execution":{"iopub.status.busy":"2021-08-09T05:53:33.10008Z","iopub.execute_input":"2021-08-09T05:53:33.100517Z","iopub.status.idle":"2021-08-09T05:53:34.60105Z","shell.execute_reply.started":"2021-08-09T05:53:33.100477Z","shell.execute_reply":"2021-08-09T05:53:34.599964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# この関数は、1行5列のグリッド形式で画像をプロットし、画像は各列に配置されます。\ndef plotImages(images_arr,title_arr):\n    fig, axes = plt.subplots(1, 10, figsize=(20,10))\n    axes = axes.flatten()\n    for img, ax , title in zip( images_arr, axes,title_arr):\n        ax.set_title(title)\n        ax.imshow(img,\n                  cmap=\"gray\"\n                 )\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-09T05:53:34.603287Z","iopub.execute_input":"2021-08-09T05:53:34.603698Z","iopub.status.idle":"2021-08-09T05:53:34.611935Z","shell.execute_reply.started":"2021-08-09T05:53:34.603658Z","shell.execute_reply":"2021-08-09T05:53:34.610894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rescale=1./255, \n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    #horizontal_flip=True,\n    validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T05:53:34.613607Z","iopub.execute_input":"2021-08-09T05:53:34.61405Z","iopub.status.idle":"2021-08-09T05:53:34.622595Z","shell.execute_reply.started":"2021-08-09T05:53:34.613991Z","shell.execute_reply":"2021-08-09T05:53:34.621595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_gen=datagen.flow(train_image,train_label, batch_size=294, shuffle=True,subset=\"training\")\nvalid_data_gen=datagen.flow(train_image,train_label, \n                                       batch_size=126, subset=\"validation\")\n\nfor indx in range(0,3):\n    augmented_images = [train_data_gen[indx][0][i] for i in range(10)]\n    plotImages(augmented_images,train_data_gen[indx][1][0:10])","metadata":{"execution":{"iopub.status.busy":"2021-08-09T05:53:34.623944Z","iopub.execute_input":"2021-08-09T05:53:34.624255Z","iopub.status.idle":"2021-08-09T05:53:38.700114Z","shell.execute_reply.started":"2021-08-09T05:53:34.624227Z","shell.execute_reply":"2021-08-09T05:53:38.699354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyper parameterのfine tuneを行う\nimport keras_tuner as kt\nimport IPython","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:32:04.777892Z","iopub.execute_input":"2021-08-08T07:32:04.778211Z","iopub.status.idle":"2021-08-08T07:32:04.830445Z","shell.execute_reply.started":"2021-08-08T07:32:04.778182Z","shell.execute_reply":"2021-08-08T07:32:04.829644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"shape:\",train_data_gen[0][0][0].shape)\nprint(\"max:\",np.max(train_data_gen[0][0][0]))","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:32:05.857875Z","iopub.execute_input":"2021-08-08T07:32:05.858219Z","iopub.status.idle":"2021-08-08T07:32:05.990117Z","shell.execute_reply.started":"2021-08-08T07:32:05.858193Z","shell.execute_reply":"2021-08-08T07:32:05.989267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:32:06.118499Z","iopub.execute_input":"2021-08-08T07:32:06.118813Z","iopub.status.idle":"2021-08-08T07:32:06.125678Z","shell.execute_reply.started":"2021-08-08T07:32:06.118785Z","shell.execute_reply":"2021-08-08T07:32:06.124712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# have completed tune at Version11\ndef model_builder(hp):\n    # input layer\n    hp_input_layer = hp.Int(\"InputParam\",min_value=28, max_value=28,step=4)\n    # layer1\n    hp_drop_rate1 = hp.Choice('drop_rate1', values = [0.2]) \n    hp_layer_units1 = hp.Int('units1', min_value = 28, max_value = 28, step = 4)\n    # hp_layer_units1 = hp.Int('units1', min_value = 28, max_value = 36, step = 4)\n    hp_reg_rate1 = hp.Choice('reg_rate1', values = [ #1e-2,1e-3,\n                                                    1e-4]) \n    # layer2\n    hp_layer_units2 = hp.Int('units2', min_value = 28, max_value = 28, step = 4)\n    # hp_layer_units2 = hp.Int('units2', min_value = 28, max_value = 36, step = 4)\n    hp_reg_rate2 = hp.Choice('reg_rate2', values = [# 1e-2,1e-3,\n                                                    1e-4]) \n\n    model = keras.Sequential([\n        keras.Input(shape=(28,28,1)),\n        Conv2D(hp_input_layer, (4,4), activation='relu',\n               name = \"InputLayer\"),\n        # layer1\n        Conv2D(hp_layer_units1, (4,4),activation='relu',\n          kernel_regularizer=keras.regularizers.l2(hp_reg_rate1)),\n        BatchNormalization(),\n        LeakyReLU(0.2),\n        keras.layers.Dropout(hp_drop_rate1),\n\n        # layer2\n        Conv2D(hp_layer_units2,(4,4) ,activation='relu', padding=\"same\",\n               kernel_regularizer=keras.regularizers.l2(hp_reg_rate2),name=\"layer2\"),\n        BatchNormalization(),\n        LeakyReLU(0.2),\n        keras.layers.Dropout(hp_drop_rate1),\n        keras.layers.AveragePooling2D(pool_size=(2, 2)),\n    ])\n    \n    \"\"\"\n    hp_layer3_flag = hp.Choice('layer3_flag', values = [True,\n                                                        False\n                                                    ]) \n    if hp_layer3_flag:\n        model.add(\n            Conv2D(28,(3,3) , padding=\"same\",name= \"layer3\",\n                   activation='relu',kernel_regularizer=keras.regularizers.l2(1e-4))\n        )\n        model.add(BatchNormalization())\n        model.add(LeakyReLU(0.2))\n    \"\"\"\n    \n    model.add(\n        Conv2D(28,(3,3) , padding=\"same\",name= \"layer3\",\n               activation='relu',kernel_regularizer=keras.regularizers.l2(1e-4))\n    )\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(0.2))\n\n    model.add(\n        Conv2D(28,(3,3) , padding=\"same\",name= \"lastConvLayer\",\n               activation='relu',kernel_regularizer=keras.regularizers.l2(1e-4))\n    )\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(0.2))\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    \n    # compile \n    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2]) \n    model.compile(loss=\"sparse_categorical_crossentropy\",\n                  optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n                  metrics=[\"accuracy\"])\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:32:07.675918Z","iopub.execute_input":"2021-08-08T07:32:07.676247Z","iopub.status.idle":"2021-08-08T07:32:07.689619Z","shell.execute_reply.started":"2021-08-08T07:32:07.676217Z","shell.execute_reply":"2021-08-08T07:32:07.68867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf ./my_dir\ntuner = kt.Hyperband(model_builder,\n                     objective = 'val_accuracy', \n                     max_epochs = 50,\n                     directory = 'my_dir',\n                     project_name = 'intro_to_kt')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:32:09.302992Z","iopub.execute_input":"2021-08-08T07:32:09.303308Z","iopub.status.idle":"2021-08-08T07:32:11.988047Z","shell.execute_reply.started":"2021-08-08T07:32:09.303279Z","shell.execute_reply":"2021-08-08T07:32:11.987168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ClearTrainingOutput(tf.keras.callbacks.Callback):\n    def on_train_end(*args, **kwargs):\n        IPython.display.clear_output(wait = True)\n\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", \n                                              factor=0.5, patience=5, \n                                              min_lr=1e-8, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:32:12.768209Z","iopub.execute_input":"2021-08-08T07:32:12.768533Z","iopub.status.idle":"2021-08-08T07:32:12.774757Z","shell.execute_reply.started":"2021-08-08T07:32:12.768503Z","shell.execute_reply":"2021-08-08T07:32:12.773908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search(train_data_gen,\n             steps_per_epoch=100, \n             epochs=50, \n             validation_data=valid_data_gen, \n             validation_steps=50, \n             callbacks = [ClearTrainingOutput(),\n                          reduce_lr,\n                          early_stop]\n            )","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:32:18.817887Z","iopub.execute_input":"2021-08-08T07:32:18.818205Z","iopub.status.idle":"2021-08-08T07:32:47.436104Z","shell.execute_reply.started":"2021-08-08T07:32:18.818176Z","shell.execute_reply":"2021-08-08T07:32:47.435309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the optimal hyperparameters\nbest_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n\nfrom pprint import pprint\nprint(\"tuned model parameter----------\")\npprint(best_hps.values)\nprint(\"----------\")\n\nmodel = tuner.hypermodel.build(best_hps)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:32:50.598697Z","iopub.execute_input":"2021-08-08T07:32:50.599024Z","iopub.status.idle":"2021-08-08T07:32:50.933319Z","shell.execute_reply.started":"2021-08-08T07:32:50.598993Z","shell.execute_reply":"2021-08-08T07:32:50.932549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist=model.fit(train_data_gen,\n               steps_per_epoch=100, \n               epochs=200, \n               validation_data=valid_data_gen, \n               validation_steps=50, \n               callbacks = [reduce_lr,early_stop],\n               verbose=2\n            )","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:32:53.39758Z","iopub.execute_input":"2021-08-08T07:32:53.397929Z","iopub.status.idle":"2021-08-08T07:38:49.722893Z","shell.execute_reply.started":"2021-08-08T07:32:53.397899Z","shell.execute_reply":"2021-08-08T07:38:49.722044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = model.evaluate(valid_data_gen, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:38:49.724501Z","iopub.execute_input":"2021-08-08T07:38:49.724859Z","iopub.status.idle":"2021-08-08T07:38:51.619317Z","shell.execute_reply.started":"2021-08-08T07:38:49.724822Z","shell.execute_reply":"2021-08-08T07:38:51.618494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_dict = hist.history\n\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(acc) + 1)\nhist_result = (acc,val_acc),(loss,val_loss) ","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:38:51.621258Z","iopub.execute_input":"2021-08-08T07:38:51.621626Z","iopub.status.idle":"2021-08-08T07:38:51.626764Z","shell.execute_reply.started":"2021-08-08T07:38:51.621587Z","shell.execute_reply":"2021-08-08T07:38:51.625827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(20,8))\naxes = axes.flatten()\n\nfor res, ax,title in zip( hist_result, axes,[\"Accuracy\",\"loss\"]):\n    ax.plot(epochs,res[0], 'b', label='{} {}'.format(\"Training\",title)) \n    ax.plot(epochs,res[1], 'r', label='{} {}'.format(\"Validation\",title)) \n    ax.set_xlabel('Epochs')\n    ax.set_ylabel(title)\n    ax.set_xlim(0,epochs[-1])\n    ax.grid()\n    ax.legend()\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:38:51.628449Z","iopub.execute_input":"2021-08-08T07:38:51.629111Z","iopub.status.idle":"2021-08-08T07:38:52.081417Z","shell.execute_reply.started":"2021-08-08T07:38:51.629077Z","shell.execute_reply":"2021-08-08T07:38:52.08041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = train_data_gen # train_data_gen\nresults =[ tf.argmax(i) for i in model.predict(data.x, verbose=2)]\nconfusion_mtx = confusion_matrix(data.y, results) \n\nimport seaborn as sns\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"cubehelix\",linecolor=\"gray\", fmt= '.1f')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:38:52.082515Z","iopub.execute_input":"2021-08-08T07:38:52.082836Z","iopub.status.idle":"2021-08-08T07:39:01.44303Z","shell.execute_reply.started":"2021-08-08T07:38:52.082805Z","shell.execute_reply":"2021-08-08T07:39:01.442255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:39:01.444158Z","iopub.execute_input":"2021-08-08T07:39:01.444474Z","iopub.status.idle":"2021-08-08T07:39:01.451856Z","shell.execute_reply.started":"2021-08-08T07:39:01.444446Z","shell.execute_reply":"2021-08-08T07:39:01.450888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = model.predict(test_image[:]/255)\noutput = pd.DataFrame({'ImageId':[ i+1 for i in range(len(test_image))], \n                       'Label': [ xi.argmax() for xi in res]})\noutput.to_csv('submission_grid.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:39:01.453364Z","iopub.execute_input":"2021-08-08T07:39:01.454065Z","iopub.status.idle":"2021-08-08T07:39:02.987035Z","shell.execute_reply.started":"2021-08-08T07:39:01.454029Z","shell.execute_reply":"2021-08-08T07:39:02.986172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"offset = 5\nfor i in range(3):\n    print(\"predicted: \",res[i+ offset].argmax())\n    plt.imshow(test_image[i + offset],cmap=\"gray\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:39:02.989071Z","iopub.execute_input":"2021-08-08T07:39:02.989427Z","iopub.status.idle":"2021-08-08T07:39:03.316714Z","shell.execute_reply.started":"2021-08-08T07:39:02.989393Z","shell.execute_reply":"2021-08-08T07:39:03.315759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Try using Grad-cam\n\n- Credit\n    - https://keras.io/examples/vision/integrated_gradients/\n    - https://keras.io/examples/vision/grad_cam/","metadata":{}},{"cell_type":"code","source":"def show_figure(img_arr,alpha=0.5,pred=None):\n    # print(pred)\n    col = 3\n    if pred is not None:\n        col = 4\n    fig, axes = plt.subplots(1, col, figsize=(20,5))\n    axes = axes.flatten()\n    axes[0].imshow(img_arr[0],cmap=\"gray\")\n    axes[0].imshow(img_arr[1],alpha=alpha)\n    axes[1].imshow(img_arr[0],cmap=\"gray\")\n    axes[2].imshow(img_arr[1])\n    if col == 4:\n        x = [i for i in range(len(pred[0]))]\n        axes[3].bar(x, pred[0])\n        axes[3].set_xticks(x)\n        axes[3].set_yscale('log')\n        axes[3].set_xlabel(\"Class\")\n        axes[3].set_ylabel(\"Score\")\n\n    axes[0].axis('off')\n    axes[1].axis('off')\n    axes[2].axis('off')\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:39:09.247692Z","iopub.execute_input":"2021-08-08T07:39:09.248018Z","iopub.status.idle":"2021-08-08T07:39:09.25867Z","shell.execute_reply.started":"2021-08-08T07:39:09.247988Z","shell.execute_reply":"2021-08-08T07:39:09.257763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_gradients(img_input,index):\n    images = tf.cast(img_input/255, tf.float32)\n\n    with tf.GradientTape() as tape:\n        tape.watch(images)\n        preds = model(images)\n        class_channel = preds[:, index]\n        index =tf.argmax(preds[0])\n        print(\"index: \",index, \" rate:\",preds[0][index])\n        # preds[0][index] = 0\n    grads = tape.gradient(class_channel, images)\n    # print(grads.shape)\n    glad_img = np.array(grads[0]).reshape(28,28,1)\n    glad_img = (glad_img-np.min(glad_img))*255 /(np.max(glad_img)-np.min(glad_img))\n    return img_input[0],glad_img","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:39:13.532627Z","iopub.execute_input":"2021-08-08T07:39:13.532958Z","iopub.status.idle":"2021-08-08T07:39:13.539885Z","shell.execute_reply.started":"2021-08-08T07:39:13.532929Z","shell.execute_reply":"2021-08-08T07:39:13.538866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"offset = 20\nfor i in range(0,10):\n    num = i\n    pred = model.predict(test_image[i+offset:i+offset+1]/255)\n    print(\"pledicted result\",pred[0].argmax())\n    img_arr  = get_gradients(test_image[i+offset:i+offset+1],pred[0].argmax())\n    show_figure(img_arr,pred=pred)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:39:15.838763Z","iopub.execute_input":"2021-08-08T07:39:15.839093Z","iopub.status.idle":"2021-08-08T07:39:22.369793Z","shell.execute_reply.started":"2021-08-08T07:39:15.839064Z","shell.execute_reply":"2021-08-08T07:39:22.36886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Grad-cam \n\nAm I using grad-cam correctly?  \nIf it can be used, is this model training correctly?  \nI would like advice from someone who is familiar with it.","metadata":{}},{"cell_type":"code","source":"from skimage.transform import resize\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-08T07:39:29.149162Z","iopub.execute_input":"2021-08-08T07:39:29.149525Z","iopub.status.idle":"2021-08-08T07:39:29.155418Z","shell.execute_reply.started":"2021-08-08T07:39:29.149492Z","shell.execute_reply":"2021-08-08T07:39:29.154622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lastCoveLater = \"lastConvLayer\"\ndef make_gradcam_heatmap(img_array, model, pred_index=None):\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(lastCoveLater).output, model.output]\n    )\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array/255)\n        # print(\"predicted index:\",tf.argmax(preds[0]),\"\\n result: \",preds)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    #print(last_conv_layer_output.shape)\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    # print(heatmap.shape)\n    heatmap = tf.squeeze(heatmap)\n    # print(heatmap.shape)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return resize(heatmap.numpy(),(28,28),)\n\n#bottle_resized = resize(bottle, (140, 54), anti_aliasing=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:39:30.232973Z","iopub.execute_input":"2021-08-08T07:39:30.233325Z","iopub.status.idle":"2021-08-08T07:39:30.241425Z","shell.execute_reply.started":"2021-08-08T07:39:30.233294Z","shell.execute_reply":"2021-08-08T07:39:30.240231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"offset = 25000\nnum = 10\nfor i in range(offset,offset +num):\n    num = i\n    pred = model.predict(test_image[num:num+1]/255)\n    print(\"index:\",pred[0].argmax(), \"labels: \",pred[0])\n    heatmap = make_gradcam_heatmap(test_image[num:num+1],model,pred[0].argmax())\n    arr = [test_image[num],heatmap]\n    show_figure(arr,alpha=0.7,pred=pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:39:32.4027Z","iopub.execute_input":"2021-08-08T07:39:32.403032Z","iopub.status.idle":"2021-08-08T07:39:39.260267Z","shell.execute_reply.started":"2021-08-08T07:39:32.403001Z","shell.execute_reply":"2021-08-08T07:39:39.259369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# try image segmentation\n\n## first  make segmentation data set\n","metadata":{}},{"cell_type":"code","source":"def segImg(imgarray):\n    # use edge filter\n    edge =filters.sobel(imgarray)\n    edge_img = np.array( [edge/np.max(edge)])\n    \n    edge_img_bn = np.where( edge_img >= 0.5,1,0)\n    return edge_img_bn.transpose(1,2,0)\n\n\ntrain_edge = np.array([ \n        segImg(img.reshape(28,28))\n    for img in train_data.to_numpy()[0:,1:]\n])\n\nprint(train_edge.shape)\nfor i in range(0,3):\n    plt.imshow(train_edge[i]);\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T06:55:20.549896Z","iopub.execute_input":"2021-08-09T06:55:20.550218Z","iopub.status.idle":"2021-08-09T06:55:29.133983Z","shell.execute_reply.started":"2021-08-09T06:55:20.550186Z","shell.execute_reply":"2021-08-09T06:55:29.133208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_model():\n    inputs = keras.Input(shape=(28,28,1))\n\n    ### [First half of the network: downsampling inputs] ###\n\n    # Entry block\n    x = Conv2D(32, (5,5), padding=\"same\",\n               kernel_regularizer=keras.regularizers.l2(1e-4))(inputs)\n    x = LeakyReLU(0.2)(x)\n    x = BatchNormalization()(x)\n\n    # Conv block\n    x = Conv2D(36, (5,5), padding=\"same\",\n               kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n\n    x = LeakyReLU(0.2)(x)\n    x = BatchNormalization()(x)\n    x = keras.layers.AveragePooling2D(pool_size=(2, 2))(x)\n    x = keras.layers.Dropout(0.3)(x)\n    \n    # classification layer\n    class_ = Flatten()(x)\n    y = Dense(10, activation='softmax',name=\"class\")(class_)\n\n    # segmentaion layer\n    segmentaion = keras.layers.UpSampling2D(2)(x)\n    segmentaion = Conv2D(2, (4,4), padding=\"same\",activation='softmax',name=\"segment\")(segmentaion)\n\n    model = keras.Model(inputs, [y,segmentaion])\n    return model\n                         \nseg_model = make_model()\nseg_model.summary()\n\nres=seg_model(train_data_gen[0][0][0:1])","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:18:19.634945Z","iopub.execute_input":"2021-08-09T07:18:19.635268Z","iopub.status.idle":"2021-08-09T07:18:19.804417Z","shell.execute_reply.started":"2021-08-09T07:18:19.635236Z","shell.execute_reply":"2021-08-09T07:18:19.803179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(seg_model, \"my_model.png\", show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:18:27.245313Z","iopub.execute_input":"2021-08-09T07:18:27.24568Z","iopub.status.idle":"2021-08-09T07:18:27.496762Z","shell.execute_reply.started":"2021-08-09T07:18:27.245646Z","shell.execute_reply":"2021-08-09T07:18:27.495821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop = keras.callbacks.EarlyStopping(monitor='class_loss', patience=20)\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_class_accuracy', \n                                              factor=0.5, patience=10, \n                                              min_lr=1e-8, verbose=1)\n\nseg_model.compile(loss=[ \"sparse_categorical_crossentropy\" ,\"sparse_categorical_crossentropy\"],\n              loss_weights = [1.0,0.3],\n              optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n              metrics=[\"accuracy\"])\n\n\nhist=seg_model.fit(train_image/255,\n                   {\"class\":train_label,\"segment\":train_edge},\n                   steps_per_epoch=200, \n                   batch_size=400,\n                   validation_batch_size=200,\n                   validation_split=0.2,\n                   epochs=200,\n                   shuffle=True,\n                   callbacks = [reduce_lr,early_stop],\n                   verbose=2\n            )","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:20:51.956045Z","iopub.execute_input":"2021-08-09T07:20:51.956365Z","iopub.status.idle":"2021-08-09T07:25:52.312986Z","shell.execute_reply.started":"2021-08-09T07:20:51.956336Z","shell.execute_reply":"2021-08-09T07:25:52.312156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_dict = hist.history\n\nacc = history_dict['class_accuracy']\nval_acc = history_dict['val_class_accuracy']\nloss = history_dict['class_loss']\nval_loss = history_dict['val_class_loss']\n\nepochs = range(1, len(acc) + 1)\nhist_result = (acc,val_acc),(loss,val_loss) ","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:26:08.109611Z","iopub.execute_input":"2021-08-09T07:26:08.109948Z","iopub.status.idle":"2021-08-09T07:26:08.115464Z","shell.execute_reply.started":"2021-08-09T07:26:08.109915Z","shell.execute_reply":"2021-08-09T07:26:08.114242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(20,8))\naxes = axes.flatten()\n\nfor res, ax,title in zip( hist_result, axes,[\"Accuracy\",\"loss\"]):\n    ax.plot(epochs,res[0], 'b', label='{} {}'.format(\"Training\",title)) \n    ax.plot(epochs,res[1], 'r', label='{} {}'.format(\"Validation\",title)) \n    ax.set_xlabel('Epochs')\n    ax.set_ylabel(title)\n    ax.set_xlim(2,epochs[-1])\n    #ax.set_ylim(0.97,1.01)\n    ax.grid()\n    ax.legend()\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:30:24.844611Z","iopub.execute_input":"2021-08-09T07:30:24.844987Z","iopub.status.idle":"2021-08-09T07:30:25.327534Z","shell.execute_reply.started":"2021-08-09T07:30:24.84495Z","shell.execute_reply":"2021-08-09T07:30:25.326667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = train_image/255 # train_data_gen\nresults =[ tf.argmax(i) for i in seg_model.predict(data)[0]]\nconfusion_mtx = confusion_matrix(train_label, results) \n\nimport seaborn as sns\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"cubehelix\",linecolor=\"gray\", fmt= '.1f')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:26:33.924823Z","iopub.execute_input":"2021-08-09T07:26:33.925203Z","iopub.status.idle":"2021-08-09T07:26:47.215196Z","shell.execute_reply.started":"2021-08-09T07:26:33.92517Z","shell.execute_reply":"2021-08-09T07:26:47.214179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = seg_model.predict(test_image[:]/255)[0]\noutput = pd.DataFrame({'ImageId':[ i+1 for i in range(len(test_image))], \n                       'Label': [ xi.argmax() for xi in res]})\noutput.to_csv('submission_grid2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:26:47.219075Z","iopub.execute_input":"2021-08-09T07:26:47.219441Z","iopub.status.idle":"2021-08-09T07:26:49.082326Z","shell.execute_reply.started":"2021-08-09T07:26:47.219393Z","shell.execute_reply":"2021-08-09T07:26:49.081502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head ./submission_grid2.csv","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:26:52.559937Z","iopub.execute_input":"2021-08-09T07:26:52.560302Z","iopub.status.idle":"2021-08-09T07:26:53.329258Z","shell.execute_reply.started":"2021-08-09T07:26:52.560269Z","shell.execute_reply":"2021-08-09T07:26:53.328172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num =0\nfor num in range(num,num+80):\n    fig, axes = plt.subplots(1, 3, figsize=(18,6))\n    axes = axes.flatten()\n\n    img = test_image[num:num+1]/255\n    res=seg_model.predict(img)\n\n    print(tf.argmax(res[0][0]))\n\n    axes[0].imshow(img[0])\n\n    im=axes[1].imshow(res[1][0][:,:,1])\n    fig.colorbar(im)\n\n    x = [i for i in range(10)]\n    axes[2].bar(x, res[0][0])\n    axes[2].set_xticks(x)\n    axes[2].set_yscale('log')\n    axes[2].set_xlabel(\"Class\")\n    axes[2].set_ylabel(\"Score\")\n    axes[2].set_ylim(1e-2,1)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:27:44.719848Z","iopub.execute_input":"2021-08-09T07:27:44.720206Z","iopub.status.idle":"2021-08-09T07:28:38.004505Z","shell.execute_reply.started":"2021-08-09T07:27:44.72017Z","shell.execute_reply":"2021-08-09T07:28:38.003599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}