{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import division\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os \n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torchvision\nimport torch.nn.functional as fun\nimport torch.nn as nn \nimport torch.utils.data\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"!pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/digit-recognizer/train.csv')\n#display(train_df.head())\n\ntest_df = pd.read_csv('../input/digit-recognizer/test.csv')\n\n\ny = torch.tensor(train_df.label.values)\nx = torch.tensor(train_df.iloc[:,1:].values)\n\n\nx_tr, x_ts, y_tr, y_ts = train_test_split(x,y, test_size = 0.1, random_state=42)\n\n\nprint(f'Train size: {len(y_tr)} \\nTest size: {len(y_ts)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, labels, transform = None):\n        'Initialization'\n        self.labels = labels\n        self.inp_feats = inputs\n        self.transform = transform\n    \n    def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.labels)\n    \n    def __getitem__(self, index):\n        'Generates one sample of data'\n        # Select/Load sample data and get label\n        X = self.inp_feats[index].type('torch.FloatTensor')\n        X *= 1/255.0\n        y = self.labels[index]\n        \n        if self.transform is not None:\n            X = self.transform(X)\n\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameters\nparams = {'batch_size': 128,\n          'shuffle': True,\n          'num_workers': 0}\n\ntraining_set = Dataset(x_tr, y_tr)\ntrain_gen = torch.utils.data.DataLoader(training_set, **params, drop_last=True)\n\ntesting_set = Dataset(x_ts, y_ts)\ntest_gen = torch.utils.data.DataLoader(testing_set, **params, drop_last=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(1)\ntorch.cuda.manual_seed(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define cuda device: \n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vanilla Variational Autoencoder (VAE):"},{"metadata":{"trusted":true},"cell_type":"code","source":"' construct VAE architecture '\n\nclass VAE(nn.Module):\n    def __init__(self):\n        super(VAE, self).__init__()\n        \n        \n        \n        self.encoder = nn.Sequential(\n            nn.Linear(784, width**2),\n            nn.BatchNorm1d(width**2),\n            nn.ReLU(),\n            nn.Linear(width**2, width**2),\n            nn.BatchNorm1d(width**2),\n            nn.ReLU(),\n            nn.Linear(width**2, width**2),\n            nn.BatchNorm1d(width**2),\n            nn.ReLU(),\n            nn.Linear(width**2, 3*2),\n            nn.BatchNorm1d(3*2)\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(3, width**2),\n            nn.BatchNorm1d(width**2),\n            nn.ReLU(),\n            nn.Linear(width**2, width**2),\n            nn.BatchNorm1d(width**2),\n            nn.ReLU(),\n            nn.Linear(width**2, 784),\n            nn.Sigmoid(),\n    \n        )\n        \n        \n    def reparam_trick(self, mu, logvar):\n        if self.training:\n            std = logvar.mul(0.5).exp_()\n            eps = std.data.new(std.size()).normal_()\n            return eps.mul(std).add_(mu)\n        else:\n            return mu\n        \n    def forward(self, x):\n        mu_logvar = self.encoder(x.view(-1, 784)).view(-1, 2, 3)\n        mu = mu_logvar[:, 0, :]\n        logvar = mu_logvar[:, 1, :]\n        z = self.reparam_trick(mu, logvar)\n        return self.decoder(z), z, mu, logvar\n        \nwidth = 25\n# initialize the NN     \nmodel = VAE().to(device)\n#print(model)\n        \nfrom torchsummary import summary\nsummary(model, (1, 28*28))\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrate = 0.00100031312\noptimizer = torch.optim.Adam(\n            model.parameters(),\n            lr = lrate)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def VAE_loss(x_tilde, x, mu, logvar, beta):\n    BCE = fun.binary_cross_entropy(x_tilde, x.view(-1, 784), reduction = 'sum')\n    KL = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2))\n    return BCE + beta * KL \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Train model"},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"def train_model(beta, epochs, model):\n    dic = dict(latent_space = list(), mu_list=list(), logsig2_list=list(), y=list())\n    for epoch in range(0, epochs + 1):\n        # ========= TRAINING =========\n        if epoch > 0: \n            model.train()\n            train_loss = 0\n            for X, _ in train_gen:\n                X = X.to(device)\n                # forward pass ...\n                x_tilde, z, mu, logvar = model(X)\n                loss = VAE_loss(x_tilde, X, mu, logvar, beta)\n                train_loss += loss.item()\n                # backward pass ...\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            # log ...\n            print(f'----> Epoch: {epoch} Average loss: {train_loss / len(train_gen.dataset):.4f}')\n\n        # ========= TESTING ========= \n\n        z_list, means, logvars , labels = list(), list(), list(), list()\n        with torch.no_grad():\n            model.eval()\n            test_loss = 0\n            for X, Y in test_gen:\n                X = X.to(device)\n                # forward ...\n                x_tilde, z, mu, logvar = model(X)\n                test_loss += VAE_loss(x_tilde, X, mu, logvar, beta).item()\n                # log ...\n                z_list.append(z.detach())\n                means.append(mu.detach())\n                logvars.append(logvar.detach())\n                labels.append(Y.detach())\n        # log ...\n        dic['latent_space'].append(torch.cat(z_list))\n        dic['mu_list'].append(torch.cat(means))\n        dic['logsig2_list'].append(torch.cat(logvars))\n        dic['y'].append(torch.cat(labels))\n        test_loss /= len(test_gen.dataset)\n        print(f'----> Test set loss: {test_loss:.4f}')\n    return dic\n    \nbeta = 1\nepochs = 50\ndic = train_model(beta, epochs, model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Plot latent space "},{"metadata":{"trusted":true},"cell_type":"code","source":"z_arr = dic['latent_space'][0].cpu().numpy()\ny_arr = dic['y'][0].cpu().numpy()\nplt.figure(figsize = (10,5))\nplt.subplot(1,2,1)\nplt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr)\nplt.subplot(1,2,2)\nplt.scatter(z_arr[:,1], z_arr[:,2], c = y_arr)\nplt.colorbar()\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above latent space did not do a great job in disentangling the mnist digits; however, this should ideally be fixed by increasing the latent space dimension. For example, we expand the dimension size from 3 to width parameter, albeit we lose the ability to visualize it. If you do plan to expand the latent space dimension from 3 to width parameter, you can then implement t-SNE to map the latent space to a lower dimension so that you potentially visualize distinct MNIST digit clusters."},{"metadata":{},"cell_type":"markdown","source":"## Beta Variational Autoencoder\n\nHere we introduce the $\\beta$-VAE, where $\\beta$>1 restricts the reconstruction accuracy and increases the degree of disentanglement of learn features. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# all we need to do now is call the VAE model and define beta > 1 \nwidth = 25\n# initialize the NN     \nmodel = VAE().to(device)\nprint(model)\n        \nfrom torchsummary import summary\nsummary(model, (1,28*28), 1)\n\nbeta = 3 # beta becomes an additional hyperparameter\nepochs = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### train $\\beta$-VAE"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"dic = train_model(beta, epochs, model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### plot latent space"},{"metadata":{"trusted":true},"cell_type":"code","source":"z_arr = dic['latent_space'][0].cpu().numpy()\ny_arr = dic['y'][0].cpu().numpy()\nplt.figure(figsize = (10,5))\nplt.subplot(1,2,1)\nplt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr)\nplt.subplot(1,2,2)\nplt.scatter(z_arr[:,1], z_arr[:,2], c = y_arr)\nplt.colorbar()\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ref:\n\nOverall, the workflow was adapted from Alfredo Canziani work at https://atcold.github.io/pytorch-Deep-Learning/ with changes to the preprocessing step, specific architectures details, and model extention by including $\\beta$-VAE. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}