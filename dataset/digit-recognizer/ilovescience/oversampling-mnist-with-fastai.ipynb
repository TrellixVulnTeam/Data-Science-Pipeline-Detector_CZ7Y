{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Oversampling MNIST with Fastai\n\nThis kernel highlights the usefulness of oversampling for imbalanced datasets. I use fastai callbacks to oversample data during training. I will train on the full dataset, then an imbalanced dataset, and then an oversampled version of the imbalanced dataset.\n\nWe will see that the oversampled version will get improved performance (both on training set and on public leaderboard)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom fastai.vision import *\nfrom fastai.metrics import *\n\nimport os\npath = '../input'\nprint(os.listdir(path))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data\n\nSince the data are represented as rows in a csv file, a custom `ImageList` is necessary to be able to properly open the data (adapted from [this](https://www.kaggle.com/steventesta/digit-recognizer-fast-ai-custom-databunch) kernel):"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomImageList(ImageList):\n    def open(self, fn):\n        img = fn.reshape(28,28)\n        img = np.stack((img,)*3, axis=-1)\n        return Image(pil2tensor(img, dtype=np.float32))\n    \n    @classmethod\n    def from_csv_custom(cls, path:PathOrStr, csv_name:str, imgIdx:int=1, header:str='infer', **kwargs)->'ItemList': \n        df = pd.read_csv(Path(path)/csv_name, header=header)\n        res = super().from_df(df, path=path, cols=0, **kwargs)\n        \n        res.items = df.iloc[:,imgIdx:].apply(lambda x: x.values / 255.0, axis=1).values\n        \n        return res\n    \n    @classmethod\n    def from_df_custom(cls, path:PathOrStr, df:DataFrame, imgIdx:int=1, header:str='infer', **kwargs)->'ItemList': \n        res = super().from_df(df, path=path, cols=0, **kwargs)\n        \n        res.items = df.iloc[:,imgIdx:].apply(lambda x: x.values / 255.0, axis=1).values\n        \n        return res","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create our DataBunch."},{"metadata":{"trusted":true},"cell_type":"code","source":"test = CustomImageList.from_csv_custom(path=path, csv_name='test.csv', imgIdx=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (CustomImageList.from_csv_custom(path=path, csv_name='train.csv', imgIdx=1)\n                .split_by_rand_pct(.2)\n                .label_from_df(cols='label')\n                .add_test(test, label=0)\n                .transform(get_transforms(do_flip=False))\n                .databunch(bs=128, num_workers=0)\n                .normalize(imagenet_stats))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(5,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Original Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, models.resnet18, metrics=[accuracy], model_dir='/kaggle/working/models')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(4,max_lr=1e-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10,max_lr = slice(1e-6,1e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, we are able to get effectively perfect accuracy on the validation set. Let's create a submission of our model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the predictions\npredictions, *_ = learn.get_preds(DatasetType.Test)\nlabels = np.argmax(predictions, 1)\n# output to a file\nsubmission_df = pd.DataFrame({'ImageId': list(range(1,len(labels)+1)), 'Label': labels})\nsubmission_df.to_csv(f'submission_orig.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating imbalanced dataset\n\nNow let's create an imbalanced version of the MNIST dataset. The training dataset will be imbalanced and the validation dataset will be the same."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(path+'/train.csv')\nfrom sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(train_df,test_size=0.2) # Here we will perform an 80%/20% split of the dataset, with stratification to keep similar distribution in validation set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Current distribution:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['label'].hist(figsize = (10, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"proportions = pd.DataFrame({0: [0.5],\n                            1: [0.05],\n                            2: [0.1],\n                            3: [0.03],\n                            4: [0.03],\n                            5: [0.03],\n                            6: [0.03],\n                            7: [0.5],\n                            8: [0.5],\n                            9: [0.5],\n                           })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imbalanced_train_df = train_df.groupby('label').apply(lambda x: x.sample(frac=proportions[x.name]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"New distribution:"},{"metadata":{"trusted":true},"cell_type":"code","source":"imbalanced_train_df['label'].hist(figsize = (10, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([imbalanced_train_df,val_df])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create our DataBunch:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (CustomImageList.from_df_custom(df=df,path=path, imgIdx=1)\n                .split_by_idx(range(len(imbalanced_train_df)-1,len(df)))\n                .label_from_df(cols='label')\n                .add_test(test, label=0)\n                .transform(get_transforms(do_flip=False))\n                .databunch(bs=128, num_workers=0)\n                .normalize(imagenet_stats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(5,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, the images are predominately zeroes, sevens, eights and nines."},{"metadata":{},"cell_type":"markdown","source":"## Train model on imbalanced data"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, models.resnet18, metrics=[accuracy], model_dir='/kaggle/working/models')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(4,max_lr=1e-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10,max_lr = slice(1e-6,5e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is significantly less accuracy for the same set-up. Let's create a submission."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the predictions\npredictions, *_ = learn.get_preds(DatasetType.Test)\nlabels = np.argmax(predictions, 1)\n# output to a file\nsubmission_df = pd.DataFrame({'ImageId': list(range(1,len(labels)+1)), 'Label': labels})\nsubmission_df.to_csv(f'submission_imbalanced.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train on imbalanced dataset with oversampling\n\nI will first show how we can use the Weighted Random Sampler in PyTorch to implement oversampling. We will then implement a callback for fastai that will perform oversampling of the dataset."},{"metadata":{},"cell_type":"markdown","source":"Currently the sampler is a random sampler:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.train_dl.dl.sampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = []\nfor img,target in data.train_dl.dl:\n    labels.append(target)\nlabels = torch.cat(labels)\nplt.hist(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we instead use a weighted random sampler with weights that are inverse of the counts of the labels, we can get a relatively balanced distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"np.bincount([data.train_dl.dataset.y[i].data for i in range(len(data.train_dl.dataset))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(np.max(np.bincount([data.train_dl.dataset.y[i].data for i in range(len(data.train_dl.dataset))])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data.sampler import WeightedRandomSampler\n\ntrain_labels = data.train_dl.dataset.y.items\n_, counts = np.unique(train_labels,return_counts=True)\nclass_weights = 1./counts\nweights = class_weights[train_labels]\nlabel_counts = np.bincount([learn.data.train_dl.dataset.y[i].data for i in range(len(learn.data.train_dl.dataset))])\ntotal_len_oversample = int(learn.data.c*np.max(label_counts))\ndata.train_dl.dl.batch_sampler = BatchSampler(WeightedRandomSampler(weights,total_len_oversample), data.train_dl.batch_size,False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = []\nfor img,target in data.train_dl:\n    labels.append(target)\nlabels = torch.cat(labels)\nplt.hist(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now create a callback which can be passed to the `Learner`."},{"metadata":{"trusted":true},"cell_type":"code","source":"class OverSamplingCallback(LearnerCallback):\n    def __init__(self,learn:Learner):\n        super().__init__(learn)\n        self.labels = self.learn.data.train_dl.dataset.y.items\n        _, counts = np.unique(self.labels,return_counts=True)\n        self.weights = torch.DoubleTensor((1/counts)[self.labels])\n        self.label_counts = np.bincount([self.learn.data.train_dl.dataset.y[i].data for i in range(len(self.learn.data.train_dl.dataset))])\n        self.total_len_oversample = int(self.learn.data.c*np.max(self.label_counts))\n        \n    def on_train_begin(self, **kwargs):\n        self.learn.data.train_dl.dl.batch_sampler = BatchSampler(WeightedRandomSampler(weights,self.total_len_oversample), self.learn.data.train_dl.batch_size,False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, models.resnet18, metrics=[accuracy], callback_fns = [partial(OverSamplingCallback)], model_dir='/kaggle/working/models')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(4,1e-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10,5e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is much better than the severely imbalanced case but still not as good as training on the original dataset. Let's create a submission."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the predictions\npredictions, *_ = learn.get_preds(DatasetType.Test)\nlabels = np.argmax(predictions, 1)\n# output to a file\nsubmission_df = pd.DataFrame({'ImageId': list(range(1,len(labels)+1)), 'Label': labels})\nsubmission_df.to_csv(f'submission_oversampled.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we look at the submissions to the leaderboard, a previous run obtained these results:\n* Original - 0.99142\n* Imbalanced - 0.94700\n* Oversampled - 0.98557\n\nThis again demonstrates the usefulness of oversampling for imbalanced datasets."},{"metadata":{},"cell_type":"markdown","source":"I hope this kernel demonstrated how to perform oversampling in the fastai library. This feature may be added to the `fastai` library if this is helpful to others."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}