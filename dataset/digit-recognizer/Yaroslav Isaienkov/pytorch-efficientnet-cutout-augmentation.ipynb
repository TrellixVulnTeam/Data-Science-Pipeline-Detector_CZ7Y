{"cells":[{"metadata":{},"cell_type":"markdown","source":"1. [Configuration](#1)\n2. [Split data](#2)\n3. [Create DataLoader](#3)\n    - [Initialize Dataset](#3.1)\n    - [Initialize Augmentations](#3.2)\n    - [Create train and valid datasets](#3.3)\n    - [Create train and valid dataloaders](#3.4)\n4. [Build Model](#4)\n    - [Initialize loss and accuracy classes](#4.1)\n    - [Train function](#4.2)\n    - [Load MobileNetV2](#4.3)\n    - [Train model](#4.4)\n5. [Inference Model](#5)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q efficientnet_pytorch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Configuration <a class=\"anchor\" id=\"1\"></a>","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import time\nimport random\nimport datetime\nimport os\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import model_selection\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport efficientnet_pytorch\n\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataLoaderConfig:\n    batch_size = 64\n    num_workers = 8\n\n\nclass TrainConfig:\n    criterion = nn.CrossEntropyLoss \n    n_epochs = 10\n    lr = 0.001\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n    scheduler_params = dict(\n        mode='min',\n        factor=0.5,\n        patience=1,\n        verbose=False, \n        threshold=0.0001,\n        threshold_mode='abs',\n        cooldown=0, \n        min_lr=1e-8,\n        eps=1e-08\n    )\n    \n\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Split data <a class=\"anchor\" id=\"2\"></a>","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/digit-recognizer/train.csv')\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['label'].values\nX = df.drop(['label'], axis=1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Create DataLoader <a class=\"anchor\" id=\"3\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Initialize Dataset <a class=\"anchor\" id=\"3.1\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class DatasetRetriever(Dataset):\n    def __init__(self, X, y, transforms=None):\n        super().__init__()\n        self.X = X.reshape(-1, 28, 28).astype(np.float32)\n        self.y = y\n        self.transforms = transforms\n\n    def __getitem__(self, index):\n        image, target = self.X[index], self.y[index]\n        image = np.stack([image] * 3, axis=-1)\n        image /= 255.\n        if self.transforms:\n            image = self.transforms(image=image)['image']\n            \n        return image, torch.tensor(target, dtype=torch.long)\n\n    def __len__(self):\n        return self.y.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Initialize Augmentations <a class=\"anchor\" id=\"3.2\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_transforms():\n    return A.Compose(\n        [\n            A.Rotate(limit=10, border_mode=cv2.BORDER_REPLICATE, p=0.5),\n            A.Cutout(num_holes=8, max_h_size=2, max_w_size=2, fill_value=0, p=0.5),\n            A.Cutout(num_holes=8, max_h_size=1, max_w_size=1, fill_value=1, p=0.5),\n            A.Resize(32, 32, p=1.),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0)\n\ndef get_valid_transforms():\n    return A.Compose(\n        [\n            A.Resize(32, 32, p=1.),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3 Create train and valid datasets <a class=\"anchor\" id=\"3.3\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = DatasetRetriever(\n    X = X_train,\n    y = y_train,\n    transforms=get_train_transforms(),\n)\n\nvalid_dataset = DatasetRetriever(\n    X = X_valid,\n    y = y_valid,\n    transforms=get_valid_transforms(),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6))\n\nfor i in range(10):    \n    image, target = train_dataset[random.randint(0, len(train_dataset))]\n    numpy_image = image.permute(1, 2, 0).cpu().numpy()\n\n    plt.subplot(2, 5, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(target.cpu().numpy(), fontsize=15)\n    plt.imshow(numpy_image);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.4 Create train and valid dataloaders <a class=\"anchor\" id=\"3.4\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(\n    train_dataset,\n    batch_size=DataLoaderConfig.batch_size,\n    shuffle=True,\n    num_workers=DataLoaderConfig.num_workers,\n)\n\nvalid_loader = DataLoader(\n    valid_dataset, \n    batch_size=DataLoaderConfig.batch_size,\n    shuffle=False,\n    num_workers=DataLoaderConfig.num_workers,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Build Model <a class=\"anchor\" id=\"4\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Initialize loss and accuracy classes <a class=\"anchor\" id=\"4.1\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n        \nclass AccMeter:\n    def __init__(self):\n        self.true_count = 0\n        self.all_count = 0\n        self.avg = 0\n        \n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().astype(int)\n        y_pred = y_pred.cpu().numpy().argmax(axis=1).astype(int)\n        self.true_count += (y_true == y_pred).sum()\n        self.all_count += y_true.shape[0]\n        self.avg = self.true_count / self.all_count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2 Train function <a class=\"anchor\" id=\"4.2\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Fitter:\n    def __init__(\n        self, model, device, criterion, n_epochs, \n        lr, sheduler=None, scheduler_params=None\n    ):\n        self.epoch = 0\n        self.n_epochs = n_epochs\n        self.base_dir = './'\n        self.log_path = f'{self.base_dir}/log.txt'\n        self.best_summary_loss = np.inf\n\n        self.model = model\n        self.device = device\n\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n        \n        if sheduler:\n            self.scheduler = sheduler(self.optimizer, **scheduler_params)\n            \n        self.criterion = criterion().to(self.device)\n        \n        self.log(f'Fitter prepared. Device is {self.device}')\n\n    def fit(self, train_loader, valid_loader):\n        for e in range(self.n_epochs):\n            current_lr = self.optimizer.param_groups[0]['lr']\n            self.log(f'\\n{datetime.datetime.utcnow().isoformat()}\\nLR: {current_lr}')\n\n            t = int(time.time())\n            summary_loss, final_scores = self.train_one_epoch(train_loader)\n            self.log(\n                f'[RESULT]: Train. Epoch: {self.epoch}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.avg:.5f}, ' + \\\n                f'time: {int(time.time()) - t} s'\n            )\n\n            t = int(time.time())\n            summary_loss, final_scores = self.validation(valid_loader)\n            self.log(\n                f'[RESULT]: Valid. Epoch: {self.epoch}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.avg:.5f}, ' + \\\n                f'time: {int(time.time()) - t} s'\n            )\n            \n            f_best = 0\n            if summary_loss.avg < self.best_summary_loss:\n                self.best_summary_loss = summary_loss.avg\n                f_best = 1\n\n            \n            self.scheduler.step(metrics=summary_loss.avg)\n                \n            self.save(f'{self.base_dir}/last-checkpoint.bin')\n            \n            if f_best:\n                self.save(f'{self.base_dir}/best-checkpoint.bin')\n                print('New best checkpoint')\n\n            self.epoch += 1\n\n    def validation(self, val_loader):\n        self.model.eval()\n        summary_loss = LossMeter()\n        final_scores = AccMeter()\n        \n        t = int(time.time())\n        for step, (images, targets) in enumerate(val_loader):\n            print(\n                f'Valid Step {step}/{len(val_loader)}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.avg:.5f}, ' + \\\n                f'time: {int(time.time()) - t} s', end='\\r'\n            )\n            \n            with torch.no_grad():\n                targets = targets.to(self.device)\n                images = images.to(self.device)\n                batch_size = images.shape[0]\n                \n                outputs = self.model(images)\n                loss = self.criterion(outputs, targets)\n                \n                final_scores.update(targets, outputs)\n                summary_loss.update(loss.detach().item(), batch_size)\n\n        return summary_loss, final_scores\n\n    def train_one_epoch(self, train_loader):\n        self.model.train()\n        summary_loss = LossMeter()\n        final_scores = AccMeter()\n        \n        t = int(time.time())\n        for step, (images, targets) in enumerate(train_loader):\n            print(\n                f'Train Step {step}/{len(train_loader)}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.avg:.5f}, ' + \\\n                f'time: {int(time.time()) - t} s', end='\\r'\n            )\n            \n            targets = targets.to(self.device)\n            images = images.to(self.device)\n            batch_size = images.shape[0]\n\n            self.optimizer.zero_grad()\n            outputs = self.model(images)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            final_scores.update(targets, outputs.detach())\n            summary_loss.update(loss.detach().item(), batch_size)\n            \n            self.optimizer.step()\n\n        return summary_loss, final_scores\n    \n    def save(self, path):\n        self.model.eval()\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'best_summary_loss': self.best_summary_loss,\n            'epoch': self.epoch,\n        }, path)\n\n    def load(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        self.best_summary_loss = checkpoint['best_summary_loss']\n        self.epoch = checkpoint['epoch'] + 1\n        \n    def log(self, message):\n        print(message)\n        with open(self.log_path, 'a+') as logger:\n            logger.write(f'{message}\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3 Load Model <a class=\"anchor\" id=\"4.3\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_net():\n    net = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b7')\n    net._fc = nn.Linear(in_features=2560, out_features=10, bias=True)\n    return net\n\nnet = get_net().to(DEVICE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.4 Train model <a class=\"anchor\" id=\"4.4\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fitter = Fitter(\n    model=net, \n    device=DEVICE, \n    criterion=TrainConfig.criterion, \n    n_epochs=TrainConfig.n_epochs, \n    lr=TrainConfig.lr, \n    sheduler=TrainConfig.scheduler, \n    scheduler_params=TrainConfig.scheduler_params\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fitter.fit(train_loader, valid_loader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Inference Model <a class=\"anchor\" id=\"5\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = torch.load('../working/best-checkpoint.bin')\nnet.load_state_dict(checkpoint['model_state_dict']);\nnet.eval();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/digit-recognizer/test.csv')\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DatasetRetriever(Dataset):\n    def __init__(self, X, transforms=None):\n        super().__init__()\n        self.X = X.reshape(-1, 28, 28).astype(np.float32)\n        self.transforms = transforms\n\n    def __getitem__(self, index):\n        image = self.X[index]\n        image = np.stack([image] * 3, axis=-1)\n        image /= 255.\n        if self.transforms:\n            image = self.transforms(image=image)['image']\n            \n        return image\n\n    def __len__(self):\n        return self.X.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = DatasetRetriever(\n    X = X,\n    transforms=get_valid_transforms(),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader = DataLoader(\n    test_dataset, \n    batch_size=DataLoaderConfig.batch_size,\n    shuffle=False,\n    num_workers=DataLoaderConfig.num_workers\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = []\nfor step, images in enumerate(test_loader):\n    print(step, end='\\r')\n    \n    y_pred = net(images.to(DEVICE)).detach().cpu().numpy().argmax(axis=1).astype(int)\n    \n    result.extend(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6))\n\nfor i in range(10):    \n    image = test_dataset[i]\n    numpy_image = image.permute(1, 2, 0).cpu().numpy()\n\n    plt.subplot(2, 5, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(f'Predict: {result[i]}', fontsize=15)\n    plt.imshow(numpy_image);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/digit-recognizer/sample_submission.csv', index_col=0)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['Label'] = result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}