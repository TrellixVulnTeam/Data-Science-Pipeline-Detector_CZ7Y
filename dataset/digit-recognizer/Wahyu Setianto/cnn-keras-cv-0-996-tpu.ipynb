{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\nThis kernel is on purpose to build model for MNIST digits dataset. In this kernel we're gonna do some preprocessing then make augmentation datagen so our model didn't train on the same image data, then at each of our model(here we use 15 folds so there will be 15 models) to make prediction for test dataset and by the end we're gonna do ensembleing for the prediction.\n# Web App\nYou can visit my web app for the live prediction by the best model trained on this kernel run on Tensorflow JS [Digit Recognizer](https://hyuto.github.io/showcase/digit-recognizer).","metadata":{}},{"cell_type":"markdown","source":"# Train on TPU!!\nwhy? Because it's **faster**. While people usualy train on GPU for image related things, in this notebook we try to do things on TPU and see how it affect the Accuracy.","metadata":{}},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nfrom timeit import default_timer\nfrom sklearn.model_selection import KFold\n\n# Plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Tensorflow and Keras\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D \nfrom tensorflow.keras.layers import MaxPool2D, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nprint(f'Using Tensorflow Version : {tf.__version__}')\nprint(f'Using Keras Version      : {keras.__version__}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the Data\nLoad the MNIST data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/test.csv')\ntrain.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess\n## 1. Specifying X and y\nfor y we need to encode to one hot vector. In keras we have function `to_categorical` for this.\n\nExample : \n```\ny = [1, 0, 4]\nto_categorical(y)\n\n# Output:\n[\n [0,1,0,0,0], # 1\n [1,0,0,0,0], # 0\n [0,0,0,0,1], # 4\n]\n```","metadata":{}},{"cell_type":"code","source":"# Specifying X and y\nX = train.drop(['label'], axis = 1)\ny = to_categorical(train['label'].values) # To Categorical y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Normalizing Images\nData normalization is an important step to ensures that each input parameter (pixel, in this case) has a similar data distribution. This makes convergence faster while training the network.","metadata":{}},{"cell_type":"code","source":"# Normalize \nX = X / 255.0\nX_test = test / 255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Reshape\nTrain and test images (28px x 28px) has been stock into pandas. Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.","metadata":{}},{"cell_type":"code","source":"# Reshape Array\nX = X.values.reshape(-1, 28, 28, 1)\nX_test = X_test.values.reshape(-1, 28, 28, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's take a look at our data","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=10, nrows=5, figsize = (13, 7))\ninit = 0\nfor i in range(5):\n    j = 0\n    for k in range(2):\n        ind = random.choices(train.label[train.label == init].index, k = 5)\n        init += 1\n        while j < len(ind):\n            axes[i, k*5 + j].imshow(X[ind[j]][:,:,0], cmap=plt.cm.binary)\n            axes[i, k*5 + j].axis('off')\n            j += 1\n        j = 0\nfig.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"as you can see there some nice & bad hand writen digits number at our dataset. ","metadata":{}},{"cell_type":"markdown","source":"# Data Augmentation\nwe currently have about 42000 image data, let's mutiply that value by doing some soft augmentation.","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(rotation_range=10,  \n                             zoom_range = 0.10,\n                             width_shift_range=0.1,\n                             height_shift_range=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's take a look on our Augmentation datagen","metadata":{}},{"cell_type":"code","source":"def AUG_test(X, y):\n    fig, axes = plt.subplots(1, 5, figsize = (10,5))\n    axes[0].imshow(X[:,:,0], cmap=plt.cm.binary)\n    axes[0].set_title('Actual')\n    axes[0].axis('off')\n    for i in range(1, 5):\n        aug, _ = datagen.flow(X.reshape(1,28,28,1), y.reshape(1,10)).next()\n        axes[i].imshow(aug.reshape(28,28),cmap=plt.cm.binary)\n        axes[i].set_title('Augmented')\n        axes[i].axis('off')\n    fig.tight_layout()\n    return plt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUG_test(X[0], y[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build CNN Model\nThe CNNs in this kernel follow LeNet5's design on [Chris Deotte](https://www.kaggle.com/cdeotte) kernel [here](https://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist)","metadata":{}},{"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size = 3, activation='relu', \n                     input_shape = (28, 28, 1)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', \n                     activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', \n                     activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", \n                  metrics=[\"accuracy\"])\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Detect and Instantiate TPU Distribution Strategy","metadata":{}},{"cell_type":"code","source":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Config\nEPOCHS = 45\nBATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training\nHere we use Kfold CV to split our data by 15 and build model at each fold. At the callbacks we use `f(x) = 1e-3 * 0.95 ** x` for our LR Scheduler and do Checkpoint at best `val_acc` score.\n\nNote that Tensorflow distribution strategy haven't supported ImageDataGenerator by this [issue](https://github.com/tensorflow/tensorflow/issues/34346) so instead use that at `fit_generator` we just have to extract Augmentation data by looping through and done training by `fit`.","metadata":{}},{"cell_type":"code","source":"# Init\nscores, History = [], []\npred = np.zeros(shape = (len(test), 10))\n\n# CV\ncv = KFold(n_splits=15, shuffle = True, random_state = 42)\nfor fold, (train_index, val_index) in enumerate(cv.split(X)):\n    start = default_timer()\n    # Clear Session\n    K.clear_session()\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    \n    # Splitting\n    X_train , y_train = X[train_index], y[train_index]\n    X_val, y_val = X[val_index], y[val_index]\n    \n    # Augmentation\n    Train_x, Train_y = None, None\n    batch = 0\n    for x_batch, y_batch in datagen.flow(X_train, y_train, \n                                         batch_size=BATCH_SIZE):\n        if batch == 0:\n            Train_x, Train_y = x_batch, y_batch\n        elif batch >= X.shape[0] // BATCH_SIZE:\n            break\n        else:\n            Train_x = np.concatenate((Train_x, x_batch))\n            Train_y = np.concatenate((Train_y, y_batch))\n        batch += 1\n    \n    # Model\n    with tpu_strategy.scope():\n        model = build_model()\n        \n    # Callbacks\n    annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x) # LR\n    sv = ModelCheckpoint(f'Model Fold {fold}.h5', monitor='val_accuracy',\n                         save_best_only=True, mode='max')\n    \n    # Training\n    history = model.fit(Train_x, Train_y, batch_size = BATCH_SIZE, \n                        epochs = EPOCHS, verbose = 0, callbacks=[annealer, sv],\n                        steps_per_epoch = X_train.shape[0]//BATCH_SIZE,\n                        validation_data = (X_val, y_val))\n    History.append(history.history)\n    \n    # Load best model\n    model = load_model(f'Model Fold {fold}.h5')\n    \n    # Evaluate\n    score = model.evaluate(X_val, y_val, verbose = 0)[1]\n    scores.append(score)\n    \n    # Making Prediction\n    pred += model.predict(X_test)\n    \n    time = round(default_timer() - start, 4)\n    print(f'[INFO] Fold {fold + 1} val_accuracy : {round(score, 4)} - Time : {time} s')\n\nprint()\nprint(f'[INFO] Mean CV scores : {round(sum(scores)/len(scores), 4)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And so we've got really great CV score there. Let's check the Training History.","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output\n\ncontents = [('loss', 1), ('accuracy', 4), ('val_loss', 1), ('val_accuracy', 4)]\nfor content in contents:\n    plt.figure(figsize = (15, 10))\n    for i in range(len(History)):\n        plt.plot(list(range(EPOCHS))[10:], History[i][content[0]][10:], \n                 label = f'Fold {i + 1}')\n    plt.title(f'History of {content[0].title()}', fontsize = 25)\n    plt.legend(loc=content[1])\n    plt.savefig(f'{content[0]}')\n    plt.show()\n    \nclear_output()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%HTML\n\n<head>\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n    <style>\n        body {font-family: Arial;}\n        img {max-width:100%; height:auto}\n        .tab {\n          overflow: hidden;\n          border: 1px solid #ccc;\n          background-color: #f1f1f1;\n        }\n        .tab button {\n          background-color: #5ECF57;\n          float: left;\n          border: none;\n          outline: none;\n          cursor: pointer;\n          padding: 14px 16px;\n          transition: 0.3s;\n          font-size: 17px;\n        }\n        .tab button:hover {\n          background-color: #48C768;\n        }\n        .tab button.active {\n          background-color: #48C768;\n        }\n        .tabcontent {\n          display: none;\n          padding: 6px 12px;\n          border: 1px solid #ccc;\n          border-top: none;\n        }\n    </style>\n</head>\n<body>\n    <h1>History</h1>\n    <p>Click on the buttons inside the tabbed menu</p>\n\n    <div class=\"tab\">\n        <button class=\"tablinks\" onclick=\"openCity(event, 'loss')\">Loss</button>\n        <button class=\"tablinks\" onclick=\"openCity(event, 'val_loss')\">Val Loss</button>\n        <button class=\"tablinks\" onclick=\"openCity(event, 'accuracy')\">Accuracy</button>\n        <button class=\"tablinks\" onclick=\"openCity(event, 'val_accuracy')\">Val Accuracy</button>\n    </div>\n\n    <div id=\"loss\" class=\"tabcontent\">\n        <h3>Loss</h3>\n        <p>Loss History</p>\n        <img src=\"./loss.png\" alt=\"loss.png\">\n    </div>\n\n    <div id=\"val_loss\" class=\"tabcontent\">\n        <h3>Val Loss</h3>\n        <p>Val Loss History</p>\n        <img src=\"./val_loss.png\" alt=\"val_loss.png\">\n    </div>\n    \n    <div id=\"accuracy\" class=\"tabcontent\">\n        <h3>Accuracy</h3>\n        <p>Accuracy History</p>\n        <img src=\"./accuracy.png\" alt=\"accuracy.png\">\n    </div>\n    \n    <div id=\"val_accuracy\" class=\"tabcontent\">\n        <h3>Val Accuracy</h3>\n        <p>Val Accuracy History</p>\n        <img src=\"./val_accuracy.png\" alt=\"val_accuracy.png\">\n    </div>\n\n    <script>\n        function openCity(evt, cityName) {\n            var i, tabcontent, tablinks;\n            tabcontent = document.getElementsByClassName(\"tabcontent\");\n            for (i = 0; i < tabcontent.length; i++) {\n                tabcontent[i].style.display = \"none\";\n            }\n            tablinks = document.getElementsByClassName(\"tablinks\");\n            for (i = 0; i < tablinks.length; i++) {\n                tablinks[i].className = tablinks[i].className.replace(\" active\", \"\");\n            }\n            document.getElementById(cityName).style.display = \"block\";\n            evt.currentTarget.className += \" active\";\n        }\n    </script>\n   \n</body>","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensembleing Predictions\n`argmax` through the prediction to get the number of class","metadata":{}},{"cell_type":"code","source":"pred = np.array([np.argmax(x) for x in pred])\n\n# Countplot Prediction\nplt.figure(figsize = (7,7))\nsns.countplot(pred)\nplt.title('Countplot of Predictions')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's check some of our prediction","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=10, nrows=5, figsize = (13, 7))\ninit = 0\nfor i in range(5):\n    j = 0\n    for k in range(2):\n        ind = random.choices(test.index, k = 5)\n        init += 1\n        while j < len(ind):\n            axes[i, k*5 + j].imshow(X_test[ind[j]][:,:,0], cmap=plt.cm.binary)\n            axes[i, k*5 + j].set_title(f'Prediction : {pred[ind][j]}', fontsize = 11)\n            axes[i, k*5 + j].axis('off')\n            j += 1\n        j = 0\nfig.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"looks like our models really doing good for predicting test data","metadata":{}},{"cell_type":"markdown","source":"# Make Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('../input/digit-recognizer/sample_submission.csv')\nsub['Label'] = pred\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('Submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusions\nBased on our CV scores it's lower than [Chris Deotte](https://www.kaggle.com/cdeotte) kernel [here](https://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist) with 0.99757 on val_accuracy on the same model architecture. So here's the point:\n> GPU do better job in this task [Expected] while TPU give you lower accuracy but faster since we'd train 15 CNNs model on 45 epochs in less than one hour.","metadata":{}},{"cell_type":"markdown","source":"## Thank you very much for reading my post\nPlease tell me when I make mistakes in program and English. I hope this kernel will help.","metadata":{}},{"cell_type":"markdown","source":"# Refferences\n1. 25 Million Images! [0.99757] MNIST [Link](https://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist)\n1. Introduction to CNN Keras - 0.997 (top 6%) [Link](https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6)","metadata":{}}]}