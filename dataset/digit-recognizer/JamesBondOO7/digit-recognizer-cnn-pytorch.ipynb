{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step 1 : Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn # Neural Network modules, loss functions, Activation functions\nimport torch.optim as optim # Optimizers like SGD, ADAM, etc\nimport torch.nn.functional as F # Activation functions like tanh, relu, etc\nfrom torch.utils.data import DataLoader # for mini batches\nimport torchvision.transforms as transforms # for transformations on dataset\n\nimport pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2 : Create a CNN","metadata":{}},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, in_channels=1, num_classes=10):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) # same conv\n        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) # same conv\n        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.fc1 = nn.Linear(32*3*3, 64)\n        self.dropout = nn.Dropout(p=0.3)\n        self.fc2 = nn.Linear(64, 32)\n        self.fc3 = nn.Linear(32, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = F.relu(self.conv3(x))\n        x = self.pool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3 : Set device","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.get_device_name(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4 : Hyperparameters","metadata":{}},{"cell_type":"code","source":"in_channels = 1\nnum_classes = 10\nlearning_rate = 0.001\nbatch_size = 64\nnum_epoch = 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 5 : Load Data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntrain_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train_data.iloc[:, 1:]\ny_train = train_data.iloc[:, 0]\n\nX_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.values.reshape(42000, 1, 28, 28)\nX_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ClassificationDataset:\n    def __init__(self, X, y):\n        \n        self.X = X\n        self.y = y\n        print(X.shape)\n        print(y.shape)\n        \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, item):\n        \n        return {\n            \"image\" : torch.tensor(self.X[item], dtype=torch.float),\n            \"targets\": torch.tensor(self.y[item], dtype=torch.long)\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = ClassificationDataset(X_train, y_train)\n\ntrain_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=64, shuffle=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 6 : Init Network","metadata":{}},{"cell_type":"code","source":"model = CNN().to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 7 : Loss and Optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 8 : Train Network","metadata":{}},{"cell_type":"code","source":"for data in train_loader:\n    \n    print(data[\"image\"].shape)\n    print(data[\"targets\"].shape)\n    break\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epoch):\n    for batch in train_loader:\n        # Get data to cuda if possible\n        data = batch[\"image\"].to(device=device)\n        targets = batch[\"targets\"].to(device=device)\n\n        # forward\n        scores = model(data)\n        loss = criterion(scores, targets)\n\n        # backward\n        optimizer.zero_grad() # making grad to 0\n        # so that it doesn't use the gradient from the previous batch\n        loss.backward()\n\n        # gradient descent or adam step\n        optimizer.step()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 9 : Check Accuarcy","metadata":{}},{"cell_type":"code","source":"def check_accuracy(loader, model):\n\n    num_correct = 0\n    num_samples = 0\n    model.eval()\n\n    with torch.no_grad():\n        for batch in train_loader:\n            # Get data to cuda if possible\n            x = batch[\"image\"].to(device=device)\n            y = batch[\"targets\"].to(device=device)\n            \n            scores = model(x) # 64 X 10\n            _, predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n\n        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples) * 100:.2f}\")\n\n    model.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_accuracy(train_loader, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 10 : Testing and Submission","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"../input/digit-recognizer/test.csv\")\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test.values\nX_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = X_test.reshape(28000, 1, 28, 28)\nprint(X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ClassificationTestDataset:\n    def __init__(self, X):\n        \n        self.X = X\n        print(X.shape)\n        \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, item):\n        \n        return {\n            \"image\" : torch.tensor(self.X[item], dtype=torch.float)\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = ClassificationTestDataset(X_test)\n\ntest_loader = torch.utils.data.DataLoader(\n        test_dataset, batch_size=64, shuffle=False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\n\nmodel.eval()\n\nfor data in test_loader:\n    x = data[\"image\"].to(device=device)\n    scores = model(x)\n    _, predictions = scores.max(1)\n    for p in predictions:\n        preds.append(p.item())\n    \nmodel.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(preds[:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(sub)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub[\"Label\"] = preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}