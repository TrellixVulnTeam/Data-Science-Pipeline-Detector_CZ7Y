{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-04-11T15:47:05.011303Z","iopub.status.busy":"2021-04-11T15:47:05.010481Z","iopub.status.idle":"2021-04-11T15:47:05.01571Z","shell.execute_reply":"2021-04-11T15:47:05.015197Z"},"papermill":{"duration":0.030834,"end_time":"2021-04-11T15:47:05.01586","exception":false,"start_time":"2021-04-11T15:47:04.985026","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduction","metadata":{"papermill":{"duration":0.01939,"end_time":"2021-04-11T15:47:05.05537","exception":false,"start_time":"2021-04-11T15:47:05.03598","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"The MNIST database (Modified National Institute of Standards and Technology database) of handwritten digits consists of a training set of 42,000 examples, and a test set of 28,000 examples. It is a subset of a larger set available from NIST. Additionally, the black and white images from NIST were size-normalized and centered to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels.\n\nThis database is well liked for training and testing in the field of machine learning and image processing. It is a remixed subset of the original NIST datasets. ","metadata":{"papermill":{"duration":0.019393,"end_time":"2021-04-11T15:47:05.094418","exception":false,"start_time":"2021-04-11T15:47:05.075025","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Reading the MNIST data set","metadata":{"papermill":{"duration":0.019322,"end_time":"2021-04-11T15:47:05.134472","exception":false,"start_time":"2021-04-11T15:47:05.11515","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:05.178621Z","iopub.status.busy":"2021-04-11T15:47:05.178004Z","iopub.status.idle":"2021-04-11T15:47:09.762112Z","shell.execute_reply":"2021-04-11T15:47:09.761147Z"},"papermill":{"duration":4.607176,"end_time":"2021-04-11T15:47:09.76226","exception":false,"start_time":"2021-04-11T15:47:05.155084","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:09.807669Z","iopub.status.busy":"2021-04-11T15:47:09.807163Z","iopub.status.idle":"2021-04-11T15:47:15.47104Z","shell.execute_reply":"2021-04-11T15:47:15.470055Z"},"papermill":{"duration":5.688758,"end_time":"2021-04-11T15:47:15.471183","exception":false,"start_time":"2021-04-11T15:47:09.782425","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:15.520164Z","iopub.status.busy":"2021-04-11T15:47:15.519506Z","iopub.status.idle":"2021-04-11T15:47:15.523041Z","shell.execute_reply":"2021-04-11T15:47:15.523423Z"},"papermill":{"duration":0.030761,"end_time":"2021-04-11T15:47:15.523545","exception":false,"start_time":"2021-04-11T15:47:15.492784","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:15.568886Z","iopub.status.busy":"2021-04-11T15:47:15.568292Z","iopub.status.idle":"2021-04-11T15:47:15.571473Z","shell.execute_reply":"2021-04-11T15:47:15.571869Z"},"papermill":{"duration":0.028325,"end_time":"2021-04-11T15:47:15.572004","exception":false,"start_time":"2021-04-11T15:47:15.543679","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(2)","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:15.62133Z","iopub.status.busy":"2021-04-11T15:47:15.620774Z","iopub.status.idle":"2021-04-11T15:47:15.6364Z","shell.execute_reply":"2021-04-11T15:47:15.636783Z"},"papermill":{"duration":0.044307,"end_time":"2021-04-11T15:47:15.636919","exception":false,"start_time":"2021-04-11T15:47:15.592612","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(2)","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:15.691308Z","iopub.status.busy":"2021-04-11T15:47:15.690641Z","iopub.status.idle":"2021-04-11T15:47:15.695608Z","shell.execute_reply":"2021-04-11T15:47:15.695182Z"},"papermill":{"duration":0.037545,"end_time":"2021-04-11T15:47:15.695709","exception":false,"start_time":"2021-04-11T15:47:15.658164","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data processing","metadata":{"papermill":{"duration":0.021492,"end_time":"2021-04-11T15:47:15.738968","exception":false,"start_time":"2021-04-11T15:47:15.717476","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"The images from the data set have the size 28 x 28. Every line of these files consists of an image, i.e. 785 numbers between 0 and 255. The first number of each line is the label, i.e. the digit which is depicted in the image. The following 784 numbers are the pixels of the 28 x 28 image.","metadata":{"papermill":{"duration":0.022319,"end_time":"2021-04-11T15:47:15.782948","exception":false,"start_time":"2021-04-11T15:47:15.760629","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X = train.drop('label',axis=1)\nY = train['label']","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:15.90704Z","iopub.status.busy":"2021-04-11T15:47:15.830749Z","iopub.status.idle":"2021-04-11T15:47:15.909545Z","shell.execute_reply":"2021-04-11T15:47:15.909111Z"},"papermill":{"duration":0.104834,"end_time":"2021-04-11T15:47:15.909676","exception":false,"start_time":"2021-04-11T15:47:15.804842","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.isnull().any().describe()","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:15.95964Z","iopub.status.busy":"2021-04-11T15:47:15.958228Z","iopub.status.idle":"2021-04-11T15:47:15.98684Z","shell.execute_reply":"2021-04-11T15:47:15.986324Z"},"papermill":{"duration":0.05511,"end_time":"2021-04-11T15:47:15.986984","exception":false,"start_time":"2021-04-11T15:47:15.931874","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:16.035948Z","iopub.status.busy":"2021-04-11T15:47:16.035434Z","iopub.status.idle":"2021-04-11T15:47:16.04104Z","shell.execute_reply":"2021-04-11T15:47:16.040628Z"},"papermill":{"duration":0.030976,"end_time":"2021-04-11T15:47:16.041145","exception":false,"start_time":"2021-04-11T15:47:16.010169","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image representation","metadata":{"papermill":{"duration":0.022359,"end_time":"2021-04-11T15:47:16.086123","exception":false,"start_time":"2021-04-11T15:47:16.063764","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Now, we reshape the data in 3 dimensions to represent an image:\n+ -1 keeps the number of data as it, values convert the dataframe to arrays\n+ 28, 28 is height and width\n+ 1 is grayscale, if we have coloured we should use 3.","metadata":{"papermill":{"duration":0.022387,"end_time":"2021-04-11T15:47:16.131263","exception":false,"start_time":"2021-04-11T15:47:16.108876","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X = X.values.reshape(-1, 28,28,1)","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:16.18152Z","iopub.status.busy":"2021-04-11T15:47:16.180035Z","iopub.status.idle":"2021-04-11T15:47:16.182208Z","shell.execute_reply":"2021-04-11T15:47:16.182607Z"},"papermill":{"duration":0.028771,"end_time":"2021-04-11T15:47:16.18272","exception":false,"start_time":"2021-04-11T15:47:16.153949","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax_arr = plt.subplots(10, 10, figsize=(7, 7))\nfig.subplots_adjust(wspace=.025, hspace=.025)\n\nax_arr = ax_arr.ravel()\nfor i, ax in enumerate(ax_arr):\n    ax.imshow(X[i], cmap=\"gray\")\n    ax.axis(\"off\")\n    \nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:16.244689Z","iopub.status.busy":"2021-04-11T15:47:16.244148Z","iopub.status.idle":"2021-04-11T15:47:19.242822Z","shell.execute_reply":"2021-04-11T15:47:19.242397Z"},"papermill":{"duration":3.037746,"end_time":"2021-04-11T15:47:19.242961","exception":false,"start_time":"2021-04-11T15:47:16.205215","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape #Shape of X_train","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:19.299994Z","iopub.status.busy":"2021-04-11T15:47:19.299271Z","iopub.status.idle":"2021-04-11T15:47:19.302876Z","shell.execute_reply":"2021-04-11T15:47:19.302418Z"},"papermill":{"duration":0.033633,"end_time":"2021-04-11T15:47:19.303013","exception":false,"start_time":"2021-04-11T15:47:19.26938","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check if the dataset is unbalanced?","metadata":{"papermill":{"duration":0.026146,"end_time":"2021-04-11T15:47:19.355309","exception":false,"start_time":"2021-04-11T15:47:19.329163","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import seaborn as sns\nsns.countplot(Y)","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:19.411722Z","iopub.status.busy":"2021-04-11T15:47:19.411206Z","iopub.status.idle":"2021-04-11T15:47:19.968807Z","shell.execute_reply":"2021-04-11T15:47:19.968307Z"},"papermill":{"duration":0.587246,"end_time":"2021-04-11T15:47:19.968953","exception":false,"start_time":"2021-04-11T15:47:19.381707","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check for null and missing values","metadata":{"papermill":{"duration":0.027259,"end_time":"2021-04-11T15:47:20.025466","exception":false,"start_time":"2021-04-11T15:47:19.998207","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test.isnull().any().describe()","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:20.08472Z","iopub.status.busy":"2021-04-11T15:47:20.083969Z","iopub.status.idle":"2021-04-11T15:47:20.096484Z","shell.execute_reply":"2021-04-11T15:47:20.096884Z"},"papermill":{"duration":0.044534,"end_time":"2021-04-11T15:47:20.097032","exception":false,"start_time":"2021-04-11T15:47:20.052498","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now, we convert Y from series type to array type","metadata":{"papermill":{"duration":0.027113,"end_time":"2021-04-11T15:47:20.151959","exception":false,"start_time":"2021-04-11T15:47:20.124846","status":"completed"},"tags":[]}},{"cell_type":"code","source":"Y = Y.values\ntype(Y)","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:20.210801Z","iopub.status.busy":"2021-04-11T15:47:20.21003Z","iopub.status.idle":"2021-04-11T15:47:20.213702Z","shell.execute_reply":"2021-04-11T15:47:20.213308Z"},"papermill":{"duration":0.03457,"end_time":"2021-04-11T15:47:20.213804","exception":false,"start_time":"2021-04-11T15:47:20.179234","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data normalization","metadata":{"papermill":{"duration":0.027711,"end_time":"2021-04-11T15:47:20.269187","exception":false,"start_time":"2021-04-11T15:47:20.241476","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Note that, the algorithm converges faster on [0 to 1] data than on [0 to 255]. The images of the MNIST dataset are greyscale and the pixels range between 0 and 255 including both bounding values. We will map these values into an interval from [0.01 to 1] by multiplying each pixel by 0.99 / 255 and adding 0.01 to the result. This way, we avoid 0 values as inputs, which are capable of preventing weight updates.","metadata":{"papermill":{"duration":0.02909,"end_time":"2021-04-11T15:47:20.326032","exception":false,"start_time":"2021-04-11T15:47:20.296942","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X = np.array(X, dtype=\"float\") / 255.0 * 0.99 + 0.01","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:20.386168Z","iopub.status.busy":"2021-04-11T15:47:20.385161Z","iopub.status.idle":"2021-04-11T15:47:20.546296Z","shell.execute_reply":"2021-04-11T15:47:20.54577Z"},"papermill":{"duration":0.192784,"end_time":"2021-04-11T15:47:20.546424","exception":false,"start_time":"2021-04-11T15:47:20.35364","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We have all setup, we now create a convolution model using tensorflow.keras ","metadata":{"papermill":{"duration":0.031002,"end_time":"2021-04-11T15:47:20.606692","exception":false,"start_time":"2021-04-11T15:47:20.57569","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Let’s create the architecture for our CNN model. The architecture is simple, it has three Convolutional layers and two fully connected layers.","metadata":{"papermill":{"duration":0.028689,"end_time":"2021-04-11T15:47:20.665069","exception":false,"start_time":"2021-04-11T15:47:20.63638","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')])\n\nmodel.summary() #model summary\n\n# compile the model\nmodel.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics = ['acc']) ","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:20.728293Z","iopub.status.busy":"2021-04-11T15:47:20.72765Z","iopub.status.idle":"2021-04-11T15:47:23.361391Z","shell.execute_reply":"2021-04-11T15:47:23.362399Z"},"papermill":{"duration":2.668977,"end_time":"2021-04-11T15:47:23.362617","exception":false,"start_time":"2021-04-11T15:47:20.69364","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model\n\nFinally, let’s train our model and see if the augmentations had any positive impact on the result!","metadata":{"papermill":{"duration":0.028208,"end_time":"2021-04-11T15:47:23.419852","exception":false,"start_time":"2021-04-11T15:47:23.391644","status":"completed"},"tags":[]}},{"cell_type":"code","source":"history = model.fit(X, Y, validation_split=0.1, epochs=40, batch_size=128, verbose=0)\n\n# list all data in history\nprint(history.history.keys())\n\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:47:23.483196Z","iopub.status.busy":"2021-04-11T15:47:23.482636Z","iopub.status.idle":"2021-04-11T15:48:11.35582Z","shell.execute_reply":"2021-04-11T15:48:11.356271Z"},"papermill":{"duration":47.908418,"end_time":"2021-04-11T15:48:11.356417","exception":false,"start_time":"2021-04-11T15:47:23.447999","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion matrix¶","metadata":{"papermill":{"duration":0.030187,"end_time":"2021-04-11T15:48:11.416937","exception":false,"start_time":"2021-04-11T15:48:11.38675","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Confusion matrix can be very helpfull to see your model drawbacks. We plot the confusion matrix of the validation results.","metadata":{"papermill":{"duration":0.029828,"end_time":"2021-04-11T15:48:11.476668","exception":false,"start_time":"2021-04-11T15:48:11.44684","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\nmodel.fit(X_train,y_train, epochs=6, validation_data=(X_test,y_test), batch_size=128, verbose=1)\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\ny_pred = model.predict(X_train)\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_train, y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:48:11.546571Z","iopub.status.busy":"2021-04-11T15:48:11.546079Z","iopub.status.idle":"2021-04-11T15:48:23.545784Z","shell.execute_reply":"2021-04-11T15:48:23.544882Z"},"papermill":{"duration":12.039289,"end_time":"2021-04-11T15:48:23.545929","exception":false,"start_time":"2021-04-11T15:48:11.50664","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the values from the validation dataset\ny_pred = model.predict(X_test)\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_test, y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:48:23.697466Z","iopub.status.busy":"2021-04-11T15:48:23.696504Z","iopub.status.idle":"2021-04-11T15:48:24.754728Z","shell.execute_reply":"2021-04-11T15:48:24.7543Z"},"papermill":{"duration":1.135499,"end_time":"2021-04-11T15:48:24.75485","exception":false,"start_time":"2021-04-11T15:48:23.619351","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To better understand what happen\nDisplay some error results","metadata":{"papermill":{"duration":0.073836,"end_time":"2021-04-11T15:48:24.902157","exception":false,"start_time":"2021-04-11T15:48:24.828321","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Errors are difference between predicted labels and true labels\nerrors = (y_pred_classes - y_test != 0)\n\nY_pred_classes_errors = y_pred_classes[errors]\nY_pred_errors = y_pred[errors]\nY_true_errors = y_test[errors]\nX_val_errors = X_test[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-10:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:48:25.073228Z","iopub.status.busy":"2021-04-11T15:48:25.059758Z","iopub.status.idle":"2021-04-11T15:48:25.482751Z","shell.execute_reply":"2021-04-11T15:48:25.481836Z"},"papermill":{"duration":0.506244,"end_time":"2021-04-11T15:48:25.482875","exception":false,"start_time":"2021-04-11T15:48:24.976631","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Process the prediction data set by reshaping & normalizing the data","metadata":{"papermill":{"duration":0.074613,"end_time":"2021-04-11T15:48:25.632549","exception":false,"start_time":"2021-04-11T15:48:25.557936","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Reshape image in 3 dimensions (height = 28px, width = 28px, canal = 1)\n","metadata":{"papermill":{"duration":0.074626,"end_time":"2021-04-11T15:48:25.782163","exception":false,"start_time":"2021-04-11T15:48:25.707537","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test = test.values.reshape(-1,28,28,1)\ntest = np.array(test, dtype=\"float\") / 255.0 * 0.99 + 0.01\ntest.shape","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:48:25.937013Z","iopub.status.busy":"2021-04-11T15:48:25.936017Z","iopub.status.idle":"2021-04-11T15:48:26.043469Z","shell.execute_reply":"2021-04-11T15:48:26.043875Z"},"papermill":{"duration":0.187181,"end_time":"2021-04-11T15:48:26.044039","exception":false,"start_time":"2021-04-11T15:48:25.856858","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, apply the model to predict the test dataset and check the result","metadata":{"papermill":{"duration":0.075203,"end_time":"2021-04-11T15:48:26.195824","exception":false,"start_time":"2021-04-11T15:48:26.120621","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.001, random_state=42)\nmodel.fit(X_train,y_train, epochs=6, validation_data=(X_test,y_test), batch_size=128, verbose=0)\n\npredictions = model.predict(test)\nresults = predictions.argmax(axis=-1)\n#check if your model predicted correctly or not\nprint(\"Prediction result for a score {}\".format(results[22250]))\nplt.imshow(test[22250]) #model predicted correclty ","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:48:26.356623Z","iopub.status.busy":"2021-04-11T15:48:26.355585Z","iopub.status.idle":"2021-04-11T15:48:35.103547Z","shell.execute_reply":"2021-04-11T15:48:35.103109Z"},"papermill":{"duration":8.833125,"end_time":"2021-04-11T15:48:35.103663","exception":false,"start_time":"2021-04-11T15:48:26.270538","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now, submit the prediction result","metadata":{"papermill":{"duration":0.076012,"end_time":"2021-04-11T15:48:35.25684","exception":false,"start_time":"2021-04-11T15:48:35.180828","status":"completed"},"tags":[]}},{"cell_type":"code","source":"result = pd.DataFrame()\nresult['ImageId'] = list(range(1,28001))\nresult['Label'] = results\nresult.to_csv(\"output.csv\", index = False)","metadata":{"execution":{"iopub.execute_input":"2021-04-11T15:48:35.44046Z","iopub.status.busy":"2021-04-11T15:48:35.439401Z","iopub.status.idle":"2021-04-11T15:48:35.580075Z","shell.execute_reply":"2021-04-11T15:48:35.579613Z"},"papermill":{"duration":0.247624,"end_time":"2021-04-11T15:48:35.580202","exception":false,"start_time":"2021-04-11T15:48:35.332578","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}