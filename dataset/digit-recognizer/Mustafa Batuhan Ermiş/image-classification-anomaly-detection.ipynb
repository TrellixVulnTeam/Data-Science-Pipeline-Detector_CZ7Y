{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Classification & Anomaly Detection","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:15.975489Z","iopub.execute_input":"2022-01-05T00:35:15.977712Z","iopub.status.idle":"2022-01-05T00:35:15.993529Z","shell.execute_reply.started":"2022-01-05T00:35:15.977614Z","shell.execute_reply":"2022-01-05T00:35:15.992459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Description","metadata":{}},{"cell_type":"markdown","source":"**Data**: The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. Some examples from the MNIST are below: ","metadata":{}},{"cell_type":"code","source":"## Loading data\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:15.995816Z","iopub.execute_input":"2022-01-05T00:35:15.996555Z","iopub.status.idle":"2022-01-05T00:35:16.384932Z","shell.execute_reply.started":"2022-01-05T00:35:15.996506Z","shell.execute_reply":"2022-01-05T00:35:16.384216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Shapes\n\nprint('X_train shape :', x_train.shape)\nprint('y_train shape :', y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:16.386555Z","iopub.execute_input":"2022-01-05T00:35:16.387079Z","iopub.status.idle":"2022-01-05T00:35:16.393937Z","shell.execute_reply.started":"2022-01-05T00:35:16.387034Z","shell.execute_reply":"2022-01-05T00:35:16.392943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Let's visualize first 3 data points.\n\nfig, ax = plt.subplots(1,3, figsize=(16,4))\nfor i in range(3):\n    image = np.reshape(x_train[i], (28, 28))\n    ax[i].imshow(image, cmap='Greys');","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:16.397083Z","iopub.execute_input":"2022-01-05T00:35:16.397452Z","iopub.status.idle":"2022-01-05T00:35:16.819324Z","shell.execute_reply.started":"2022-01-05T00:35:16.397405Z","shell.execute_reply":"2022-01-05T00:35:16.818356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing Before Model","metadata":{}},{"cell_type":"code","source":"# Create validation data on train data\n\nx_valid = x_train[48000:]\ny_valid = y_train[48000:]\n\nx_train = x_train[:48000]\ny_train = y_train[:48000]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:16.821174Z","iopub.execute_input":"2022-01-05T00:35:16.821505Z","iopub.status.idle":"2022-01-05T00:35:16.827727Z","shell.execute_reply.started":"2022-01-05T00:35:16.821461Z","shell.execute_reply":"2022-01-05T00:35:16.826579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape[0], 'train samples')\nprint(x_valid.shape[0], 'validation samples')\nprint(x_test.shape[0], 'test samples')","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:16.8289Z","iopub.execute_input":"2022-01-05T00:35:16.829128Z","iopub.status.idle":"2022-01-05T00:35:16.842004Z","shell.execute_reply.started":"2022-01-05T00:35:16.829101Z","shell.execute_reply":"2022-01-05T00:35:16.841102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Flattening the images from the 28x28 pixels to 1D\n\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_valid = x_valid.reshape(x_valid.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:16.843105Z","iopub.execute_input":"2022-01-05T00:35:16.843367Z","iopub.status.idle":"2022-01-05T00:35:16.856031Z","shell.execute_reply.started":"2022-01-05T00:35:16.843338Z","shell.execute_reply":"2022-01-05T00:35:16.855378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = x_train.astype('float32')\nx_valid = x_valid.astype('float32')\nx_test = x_test.astype('float32')","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:16.857017Z","iopub.execute_input":"2022-01-05T00:35:16.857231Z","iopub.status.idle":"2022-01-05T00:35:16.970408Z","shell.execute_reply.started":"2022-01-05T00:35:16.857204Z","shell.execute_reply":"2022-01-05T00:35:16.969552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizing pixel values (0-255) > (0-1)\n\nx_train /= 255\nx_test /= 255","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:16.971992Z","iopub.execute_input":"2022-01-05T00:35:16.972508Z","iopub.status.idle":"2022-01-05T00:35:16.995876Z","shell.execute_reply.started":"2022-01-05T00:35:16.972472Z","shell.execute_reply":"2022-01-05T00:35:16.99482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One-hot encoding using keras\n\nfrom tensorflow.keras.utils import to_categorical\n\ny_train = to_categorical(y_train, 10)\ny_valid = to_categorical(y_valid, 10)\ny_test = to_categorical(y_test, 10)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:16.998869Z","iopub.execute_input":"2022-01-05T00:35:16.999349Z","iopub.status.idle":"2022-01-05T00:35:17.005837Z","shell.execute_reply.started":"2022-01-05T00:35:16.999313Z","shell.execute_reply":"2022-01-05T00:35:17.004787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building Classification Model","metadata":{}},{"cell_type":"code","source":"# Building a linear stack of layers with the sequential model\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import categorical_crossentropy\n\nmodel = Sequential()\n\n# convolutional layer\nmodel.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n# flatten output of conv\nmodel.add(Flatten())\n\n# hidden layer\nmodel.add(Dense(32, activation='relu'))\n\n# output layer\nmodel.add(Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:17.007752Z","iopub.execute_input":"2022-01-05T00:35:17.008272Z","iopub.status.idle":"2022-01-05T00:35:17.076971Z","shell.execute_reply.started":"2022-01-05T00:35:17.008209Z","shell.execute_reply":"2022-01-05T00:35:17.076014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:17.078126Z","iopub.execute_input":"2022-01-05T00:35:17.078679Z","iopub.status.idle":"2022-01-05T00:35:17.089091Z","shell.execute_reply.started":"2022-01-05T00:35:17.078636Z","shell.execute_reply":"2022-01-05T00:35:17.088166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nplot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:17.090872Z","iopub.execute_input":"2022-01-05T00:35:17.091912Z","iopub.status.idle":"2022-01-05T00:35:17.250928Z","shell.execute_reply.started":"2022-01-05T00:35:17.09187Z","shell.execute_reply":"2022-01-05T00:35:17.249977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compiling the sequential model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:17.252708Z","iopub.execute_input":"2022-01-05T00:35:17.252976Z","iopub.status.idle":"2022-01-05T00:35:17.265888Z","shell.execute_reply.started":"2022-01-05T00:35:17.252948Z","shell.execute_reply":"2022-01-05T00:35:17.265012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training the model for 2 epochs\nhistory = model.fit(x_train, y_train, batch_size=128, epochs=3, validation_data=(x_valid, y_valid))\nhistory","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:17.266967Z","iopub.execute_input":"2022-01-05T00:35:17.267794Z","iopub.status.idle":"2022-01-05T00:35:56.727294Z","shell.execute_reply.started":"2022-01-05T00:35:17.267717Z","shell.execute_reply":"2022-01-05T00:35:56.726331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<pre>\n\nCNN method has the best accuracy result and also the worst source performance compared to other methods according by literature. Especially, the feature extraction layer in CNN can capture the sharp and important points of the image that comes from the numbers.The structure of a CNN is actually very similar to Regular Neural Networks. Just like in RegularNets, we use a loss function and an optimizer in CNNs. Additionally, in CNNs, there are also Convolutional Layers, Pooling Layers, and Flatten Layers. So I thought CNN was the most appropriate method.\n\n</pre>","metadata":{}},{"cell_type":"markdown","source":"## Measurement Model Performance","metadata":{}},{"cell_type":"code","source":"test_scores = model.evaluate(x_test, y_test,verbose = 0)\n\nprint(\"Train Accuracy =\", history.history['accuracy'][-1])\nprint(\"Validation Accuracy =\", history.history['val_accuracy'][-1])\nprint('Test accuracy:', test_scores[1])\nprint(\"--------------------------------------\")\nprint(\"Train Loss =\", history.history['loss'][-1])\nprint(\"Validation Loss =\", history.history['val_loss'][-1])\nprint('Test loss:', test_scores[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:56.729062Z","iopub.execute_input":"2022-01-05T00:35:56.729379Z","iopub.status.idle":"2022-01-05T00:35:57.829107Z","shell.execute_reply.started":"2022-01-05T00:35:56.729338Z","shell.execute_reply":"2022-01-05T00:35:57.828184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<pre>\n\nWhen we look at the performance metrics, it is possible to say that the model learns very well and makes predictions with very high accuracy in the test data.\n\n</pre>","metadata":{"execution":{"iopub.status.busy":"2022-01-04T23:32:15.877493Z","iopub.execute_input":"2022-01-04T23:32:15.878219Z","iopub.status.idle":"2022-01-04T23:32:15.883722Z","shell.execute_reply.started":"2022-01-04T23:32:15.878171Z","shell.execute_reply":"2022-01-04T23:32:15.882861Z"}}},{"cell_type":"code","source":"fig = plt.figure()\nplt.figure(figsize=(12,6))\nplt.subplot(2,1,1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.subplot(2,1,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.tight_layout()\nfig;","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:57.830273Z","iopub.execute_input":"2022-01-05T00:35:57.830565Z","iopub.status.idle":"2022-01-05T00:35:58.319363Z","shell.execute_reply.started":"2022-01-05T00:35:57.830533Z","shell.execute_reply":"2022-01-05T00:35:58.318437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2D Visualizing Data in 2D Latent Dimensions with t-SNE","metadata":{}},{"cell_type":"code","source":"(x_train,y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:58.320638Z","iopub.execute_input":"2022-01-05T00:35:58.321036Z","iopub.status.idle":"2022-01-05T00:35:58.655402Z","shell.execute_reply.started":"2022-01-05T00:35:58.320997Z","shell.execute_reply":"2022-01-05T00:35:58.654508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = x_train.reshape(60000,784)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:58.656559Z","iopub.execute_input":"2022-01-05T00:35:58.656767Z","iopub.status.idle":"2022-01-05T00:35:58.662589Z","shell.execute_reply.started":"2022-01-05T00:35:58.656741Z","shell.execute_reply":"2022-01-05T00:35:58.661955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### TruncatedSVD","metadata":{"tags":[]}},{"cell_type":"markdown","source":"<font color='orange'>**We will use t-SNE as the model for 2 dimension, but before we will use TruncatedSVD to reduce the dimension to 50. Because, in essence, tSNE requires pairwise comparison of datapoints, so it can be incredibly computationally taxing on scRNA-seq datasets unless the dimensionality undergoes an initial reduction.**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nx = StandardScaler().fit_transform(x)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:58.663538Z","iopub.execute_input":"2022-01-05T00:35:58.664384Z","iopub.status.idle":"2022-01-05T00:35:59.786595Z","shell.execute_reply.started":"2022-01-05T00:35:58.664346Z","shell.execute_reply":"2022-01-05T00:35:59.785787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\ntsvd = TruncatedSVD(n_components=50).fit_transform(x)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:35:59.787875Z","iopub.execute_input":"2022-01-05T00:35:59.788119Z","iopub.status.idle":"2022-01-05T00:36:03.161896Z","shell.execute_reply.started":"2022-01-05T00:35:59.788092Z","shell.execute_reply":"2022-01-05T00:36:03.161044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### t-SNE","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import TSNE\ntsne_res = TSNE(n_components=2, n_jobs = -1, random_state = 42).fit_transform(tsvd)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:36:03.163442Z","iopub.execute_input":"2022-01-05T00:36:03.163733Z","iopub.status.idle":"2022-01-05T00:47:42.056596Z","shell.execute_reply.started":"2022-01-05T00:36:03.163689Z","shell.execute_reply":"2022-01-05T00:47:42.05582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### t-SNE Visualization","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\nplt.figure(figsize=(14, 14))\nplt.title(\"Visualization of t-SNE results on MNIST train data\", fontsize=24, weight='bold')\nsns.scatterplot(tsne_res[:, 0], tsne_res[:, 1], data = tsne_res, hue=y_train, palette=\"bright\", legend=\"full\")\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.xlabel(\"Component 1\", fontsize=16)\nplt.ylabel(\"Component 2\", fontsize=16)\nplt.legend(fontsize=16);","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:47:42.062865Z","iopub.execute_input":"2022-01-05T00:47:42.063358Z","iopub.status.idle":"2022-01-05T00:47:46.097977Z","shell.execute_reply.started":"2022-01-05T00:47:42.063308Z","shell.execute_reply":"2022-01-05T00:47:46.097014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some interesting findings:\n\n<pre>\nWe can see that images of 7 are more close to images of 9 than images of 1. Also when we look at the middle region, it is remarkable that 3, 5 and 8 are more confused with each other because they are similar numbers compared to other groups. Since the algorithm separates the corners well, it is seen that 9 and 6 are very far from each other. The fact that 4 is very close to 9 may indicate that there are anomalies in these pictures.\n</pre>","metadata":{}},{"cell_type":"markdown","source":"## Anomally Detection with PCA","metadata":{}},{"cell_type":"code","source":"(x_train,y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()\nx_train = pd.DataFrame(x_train.reshape(60000,x_train.shape[1]**2))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:47:46.099372Z","iopub.execute_input":"2022-01-05T00:47:46.100006Z","iopub.status.idle":"2022-01-05T00:47:46.426847Z","shell.execute_reply.started":"2022-01-05T00:47:46.099968Z","shell.execute_reply":"2022-01-05T00:47:46.425871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:47:46.428119Z","iopub.execute_input":"2022-01-05T00:47:46.428378Z","iopub.status.idle":"2022-01-05T00:47:46.448391Z","shell.execute_reply.started":"2022-01-05T00:47:46.428347Z","shell.execute_reply":"2022-01-05T00:47:46.447313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = 5)\npca_data = pca.fit_transform(x_train)\ninverse_pca_data = pca.inverse_transform(pca_data)\n\nprint(\"x_train shape\",x_train.shape)\nprint(\"pca_data shape\",pca_data.shape)\nprint(\"inverse_pca_data shape\",inverse_pca_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:47:46.449893Z","iopub.execute_input":"2022-01-05T00:47:46.450199Z","iopub.status.idle":"2022-01-05T00:47:49.469113Z","shell.execute_reply.started":"2022-01-05T00:47:46.450157Z","shell.execute_reply":"2022-01-05T00:47:49.468298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reconstruction Error\nMSE = ((x_train-inverse_pca_data)**2).sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:47:49.47038Z","iopub.execute_input":"2022-01-05T00:47:49.470591Z","iopub.status.idle":"2022-01-05T00:47:50.277439Z","shell.execute_reply.started":"2022-01-05T00:47:49.470564Z","shell.execute_reply":"2022-01-05T00:47:50.276564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualization 20 digits with the highest MSE ( decreasing from left to right )\n\nMSE_max_scores = MSE.nlargest(20).index\n\nplt.figure(figsize = (18,10))\n\nfor i in range(20):  \n    plt.subplot(4, 5, i+1)\n    plt.imshow(x_train.iloc[MSE_max_scores[i]].values.reshape(28,28),interpolation='nearest', cmap='Greys')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:47:50.28201Z","iopub.execute_input":"2022-01-05T00:47:50.282326Z","iopub.status.idle":"2022-01-05T00:47:51.917893Z","shell.execute_reply.started":"2022-01-05T00:47:50.282281Z","shell.execute_reply":"2022-01-05T00:47:51.91696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3 photos of each digit with the highest MSE\n\nplt.figure(figsize = (20,15))\nrow, colums = 3, 10\n    \nfor number in range(10):\n    dataset = pd.DataFrame(x_train[(y_train == number)].reset_index().drop(\"index\",axis = 1))\n    pca = PCA(n_components = 5)\n    pca_dataset = pca.fit_transform(dataset)\n\n    inverse_transform_dataset = pca.inverse_transform(pca_dataset)\n    MSE_score = ((dataset-inverse_transform_dataset)**2).sum(axis=1)\n    MSE_worst = MSE_score.nlargest(3).index\n    for number2 in range(0,3):\n        plt.subplot(colums, row, (number2+(number*3))+ 1)\n        plt.imshow(dataset.iloc[MSE_worst[number2]].values.reshape(28,28),interpolation='nearest', cmap='Greys')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T00:47:51.919441Z","iopub.execute_input":"2022-01-05T00:47:51.91966Z","iopub.status.idle":"2022-01-05T00:47:59.2761Z","shell.execute_reply.started":"2022-01-05T00:47:51.919633Z","shell.execute_reply":"2022-01-05T00:47:59.275461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<pre>\nThe technique roughly calculates the distance between the projection of the subspace created by PCA for each data point and the original data point. ( MSE as Reconstruction Error ) \n\nThe larger this distance is, the more abnormal the initial image is. Because, even when a decent photograph is reduced to subspace, its structure is not deformed beyond recognition.\n</pre>","metadata":{}},{"cell_type":"markdown","source":"<font color='blue'>*Created with* ❤ *by Mustafa Batuhan Ermiş.*<font>","metadata":{}}]}