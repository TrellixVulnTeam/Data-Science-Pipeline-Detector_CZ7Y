{"cells":[{"metadata":{},"cell_type":"markdown","source":"## I am currently working through the FastAI MOOC and this NoteBook is meant to do a few things\n\n1. For me to practce and develop my ability using the FAST AI library. \n\n2. I have used TensorFlow to build CNNs for this Competition and tested different architectures to get upto as high as the top 23% of the competitors in this competition. I intend to compare the results and accuracy of these two libraries as well as the ease of use of both. \nMy Tensorflow Notebook can be found [here](https://www.kaggle.com/sanwal092/tensorflow-and-cnn-99-accuracy). I was able to achieve 99.428% accuracy with the code in this mentioned Notebook\n\n\nI really appreciate [Chris Wallenwein's instructive Notebook](https://www.kaggle.com/christianwallenwein/beginners-guide-to-mnist-with-fast-ai). He does an excellent job of creating an easy to follow the fastai library\n\n### In this Notebook, I will be adding a lot of comments and thoughts as a way for me to virtually \"think out loud\" and figure out as I use the FASTAI library. Let's get to work. \n\n![](https://media.giphy.com/media/l0HlxJMw7rkPTN8sg/giphy.gif)"},{"metadata":{},"cell_type":"markdown","source":"## Table of Conetents\n\n** Model Log for my iterations is [here](#model_log) **\n\n1. [Setting up data for the FastAI library](#fastaipath)\n2. [Preparing Data for FastAI](#data_prep)    \n    * [Converting raw pixels to images](#pix2img)\n    * [Plot Images](#plot_images)\n3. [Feed Data to FastAI](#feed_fastai)\n4. [Iterating different models](#model_log)\n5. [Checking some predictions made by the model.](#make_preds)"},{"metadata":{},"cell_type":"markdown","source":"** The Following cell of code is used everytime FASTAI library is used. They tell the notebook to reload any changes made to any libraries used. They also ensure that any graphs are plotted are shown in this notebook**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# FOR NON-FASTAI LIBRARIES\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport random\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# FOR ALL THE FASTAI LIBRARIES\n\nfrom fastai.vision import *\nfrom fastai.metrics import *\n\n\n# make sure CUDA is available and enabled\nprint(torch.cuda.is_available(), torch.backends.cudnn.enabled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = 'fastaipath'></a>\n\n## BUILDING THE PATH TO THE FILES TO BE FED TO THE FASTAI LIBRARY\n\nUsing the **Path** instead of the Python OS library lets us do a lot more things organically that the traditional OS library doesn't. One of things which we can do is constructing concatenated path easily. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# mainDIR = \"/kaggle/input/digit-recognizer/\"\n# os.listdir(mainDIR)\nINPUT = Path(\"../input/digit-recognizer\")\nos.listdir(INPUT)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df = pd.read_csv(mainDIR+ \"train.csv\")\ntrain_df = pd.read_csv(INPUT/\"train.csv\")\ntrain_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(INPUT/\"test.csv\")\ntest_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<a id = 'data_prep'></a>\n### To use FASTAI library, we need to feed our data into their **ImageDataBunch** function. However,\n\n1. It only accepts images, not csv pixel data as we do have right now. \n2. It also needs the data to be in proper labeled ImageNet format. So something like such:\n\n    > path\\\n        train\\\n        0\\\n            ___.jpg\n            ___.jpg\n            ___.jpg\n        1\\\n            ___.jpg\n            ___.jpg\n        2\\\n            ...\n        3\\\n           ...\n           ...\n       test\\\n           ___.jpg\n           ___.jpg\n            ...\n    \n### So,\n\nWe will create the folder structure which matches this kind of folder structure. \n\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"# TRAIN = Path(\"/kaggle/train/\")\n# TEST = Path(\"/kaggle/test/\")\n\nTRAIN = Path(\"../train\")\nTEST = Path(\"../test\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MAKE DIRECTORIES  FOR TRAINING FOLDER\n\nfor i in range(10):    \n    try:         \n        os.makedirs(TRAIN/str(i))       \n    except:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CHECK IF MAKING THE DIRECTORIES WORKED!!\nsorted(os.listdir(TRAIN))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LET'S MAKE THE TEST FOLDER \n\ntry:\n    os.makedirs(TEST)\nexcept:\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(TEST)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# os.listdir(TEST)\nif os.path.isdir(TRAIN):\n    print('Train directory has been created')\nelse:\n    print('Train directory creation failed.')\n\nif os.path.isdir(TEST):\n    print('Test directory has been created')\nelse:\n    print('Test directory creation failed.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = 'pix2img'></a>\n### So, the train and test directories have been created. Now, here are a few things to consider. \n1. The directories exist. \n2. The picture data exist in the csv files as pixel values for each pixels. \n\n### Since FastAI only takes data in as images, not pixel values, we will have to convert this data into images for which we will use the PIL library. \n\n\nWe will have to reshape this into 28x28 matrices. To do this, I will use the PIL library in Python "},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pix2img(pix_data, filepath):\n    img_mat = pix_data.reshape(28,28)\n    img_mat = img_mat.astype(np.uint8())\n    \n    img_dat = Image.fromarray(img_mat)\n    img_dat.save(filepath)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SAVE TRAINING IMAGES \n\nfor idx, data in train_df.iterrows():\n    \n    label, data = data[0], data[1:]\n    folder = TRAIN/str(label)\n    \n    fname = f\"{idx}.jpg\"\n    filepath = folder/fname\n    \n    img_data = data.values\n    \n    pix2img(img_data,filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# THE SAME PROCESS FOR TESTING DATA \nfor idx, data in test_df.iterrows():\n    \n#     label, data = data[0], data[1:]\n    folder = TEST\n    \n    fname = f\"{idx}.jpg\"\n    filepath = folder/fname\n    \n    img_data = data.values\n    \n    pix2img(img_data,filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<a id = 'plot_images'></a>\n### Let's plot some of the training images to see what they are looking like\n"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def plotTrainImage():\n    \n    fig = plt.figure(figsize= (5,10))\n    \n    for rowIdx in range(1,10):\n        \n        foldNum = str(rowIdx)\n        path = TRAIN/foldNum\n        \n        images = os.listdir(path)\n        \n        for sampleIdx in range(1,6):\n            \n            randNum = random.randint(0, len(images)-1)\n            image = Image.open(path/images[randNum])\n            ax = fig.add_subplot(10, 5, 5*rowIdx + sampleIdx)\n            ax.axis(\"off\")\n            \n            plt.imshow(image, cmap='gray')\n            \n    plt.show()      \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('plotting training images')\nplotTrainImage()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FUNCTION FOR PLOTTING TEST IMAGES \n\ndef plotTestImage():\n    \n    fig = plt.figure(figsize=(5, 10))    \n    paths = os.listdir(TEST)    \n        \n    for i in range(1, 51):\n        randomNumber = random.randint(0, len(paths)-1)\n        image = Image.open(TEST/paths[randomNumber])\n        \n        ax = fig.add_subplot(10, 5, i)\n        ax.axis(\"off\")\n        \n        plt.imshow(image, cmap='gray')\n    plt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('plotting testing images')\nplotTestImage()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = 'feed_fastai'></a>\n### Now that the data is in the correct file and folder structure, we will feed it it to [DataBunch](https://docs.fast.ai/basic_data.html#DataBunch) object which is used inside the FastAI library to train the CNN Leaner class"},{"metadata":{"trusted":true},"cell_type":"code","source":"# transforms which are a part of data augmentation\ntfms = get_transforms(do_flip = False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('test : ',TEST)\nprint('train: ', TRAIN)\nprint(type(TEST))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = ImageDataBunch.from_folder(\n\n    path = (\"../train\"),\n    test = (\"../test\"),\n    valid_pct = 0.1,\n#     bs = 16,\n    bs = 256,    \n    size = 28,\n    num_workers = 0,\n    ds_tfms = tfms\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data.normalize(mnist_stats)\ndata.normalize(imagenet_stats)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.classes)\nprint('There are', data.c, 'classes here')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## The data is ready. Time to feed it to a Convolutional Neural Network. \n\n* There are many architures to choose it from. I have tried different architectures, implemented them in Tensorflow that you can find in \n    [this Notebook](https://www.kaggle.com/sanwal092/tensorflow-and-cnn-99-accuracy)\n* For implementation here, I will use Resnet18 which as shown in FASTAI lecture 1. It performed well on many different metrics. There are more sophiscated version of Resnet such as Resnet34 and Resnet50, but I will be sticking to Resnet18 here\n\n* I will be using FastAI's cnn_learner fucntion to implement a ResNet architecture. This is a really handy function to skip implementing the Resnet architecture from scratch which would be a nightmare. \n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#VERSION 1\n# learn = cnn_learner(data, base_arch = models.resnet18, metrics = accuracy,model_dir=\"/tmp/models\", callback_fns=ShowGraph )\n\n#version 2\nlearn = cnn_learner(data, base_arch = models.resnet34, metrics = accuracy,model_dir=\"/tmp/models\", callback_fns=ShowGraph )\n\n# version 3\n# learn = cnn_learner(data, base_arch = models.resnet50, metrics = accuracy,model_dir=\"/tmp/models\", callback_fns=ShowGraph )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### In FastAI, the function to fit the CNN to the data is called fit_one_cycle which is based on the application of this [paper by Leslie Smith](https://arxiv.org/abs/1803.09820)\n\n"},{"metadata":{},"cell_type":"markdown","source":"<a id = 'model_log'></a>\n## So far, this is what I tried:\n\n## VERSION 1: \n    * This is a bit of cheating because I tried it in 2 phases. For both the phases I used Resnet18. \n    * However, in the first phase I only trained for maybe 10 epochs. In the second, I trained for 30. The score jumped up from 10% to 99.03% \n    at test-time. \n    * The learning rate I used was 1e-6.\n    \n## VERSION 2:\n    * I will be using Resnet34 here. \n    * I used 15 epochs with learning rate of 4e-6. \n    * The training time was about 30 minutes on Kaggle GPUs. \n    * Score = 99.10%    \n   \n## VERSION 3:\n    * Still Resnet34.\n    * 20 epochs, learning rate of 4e-6\n    * Took about 40 minutes of training with result 99.10%. My highest score was 99.428% using TensorFlow to build up model\n      which took close to 2 hours to train.I want to see how close I can get to that if not beat it.\n    * Score = 99.142%\n    \n## VERSION 4: \n    * Resnet50\n    * 15 epochs to start and see what happens\n    * It took almost 1.5 hours to train and didn't offer any significant imporvement on anything. ResNet might be a\n      bit of an overkill.\n    * Score = 97.75%. \n\n## VERSION 5: \n    * Back to Resnet34. \n    * Will try 30 epochs this. \n    * Instead of using mnist_stats, i am normalizing based on image_net stats and using a batch size of 256 instead of 16.\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"doc(fit_one_cycle)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### train fit_one_cycle for 5 cycles to get an idea of how accurate the model is."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Our model was able to get to very high accuracy in just a few epoch(s). \n\n* This is nothing to be sneezed at. Now, we will fine tune the mode \n\n* We will now use FastAI's lr_find function to find a range of learning rate which we could choose from. \n\n* We use recorder.plot to visualize this rannge."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('model1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('model1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(30 , slice(1e-3, 1e-2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = 'make_preds'></a>\n### In just a few epochs, the model was able to achieve a very high accuracy.Time to evaluate results \n\n### Let's see some of the predictions made by our model\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.show_results(3, figsize= (7,7))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's check the the top 6 images with highest losses. "},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_top_losses(6, figsize=(7, 7))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Okay, some of these are really hard to pin down as one specific integers. So, I don't feel too bad about my model getting it wrong. Let's take a look at the Confusion matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time to make some predictions\n\n![](https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_score , y = learn.get_preds(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probabilities = class_score[0].tolist()\n[f\"{index}: {probabilities[index]}\" for index in range(len(probabilities))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Right now, our predictions include 10 separate predictions for each image. We will only take the top class and then save it as our result"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_score = np.argmax(class_score, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_score[1].item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission =  pd.read_csv(INPUT/\"sample_submission.csv\")\ndisplay(sample_submission.head(2))\ndisplay(sample_submission.tail(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove file extension from filename\nImageId = [os.path.splitext(path)[0] for path in os.listdir(TEST)]\n# typecast to int so that file can be sorted by ImageId\nImageId = [int(path) for path in ImageId]\n# +1 because index starts at 1 in the submission file\nImageId = [ID+1 for ID in ImageId]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission  = pd.DataFrame({\n    \"ImageId\": ImageId,\n    \"Label\": class_score\n})\n# submission.sort_values(by=[\"ImageId\"], inplace = True)\nsubmission.to_csv(\"submission.csv\", index=False)\ndisplay(submission.head(3))\ndisplay(submission.tail(3))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}