{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook\n\n- flexible transfer learning using timm models and pytorch\n- data augmentation with Albumentations\n- links for documentations\n- learning curves plots\n- predictions with resnet50 (99%+)\n\nThis notebook is an extension of my [previous notebook](https://www.kaggle.com/hinepo/pytorch-tutorial-cv-99-23-lb-98-93). Here I am not training a custom CNN model from scratch, but levaraging the power of transfer learning by using models in timm library that contain already pre-trained weights.\n\nSo the only difference here, in terms of code, is the model section and a few changes in the Dataset class, so we can have the inputs to be in the appropriate shape to feed timm models.\n\ntimm is an awesome repository and is widely used the Kaggle competitions with computer vision tasks because of its flexibility and unified api for hundreds of pre-trained image models.\n\nHere I am using resnet50 backbone, but many other image models in [timm github](https://github.com/rwightman/pytorch-image-models) also work on this setup and dataset as well. \n\nHowever, the chosen model architecture/backbone must be compatible with the image size on the dataset we are using. For exemple, 'densenets' and 'vit' (vision transformer models) require the input images to be of much larger dimensions than our images from MNIST have. So our small dimensions (28, 28) limit our choices a bit.\n\nAlso check the [timm docs](https://rwightman.github.io/pytorch-image-models/), and the list of available models (timm.list_models).","metadata":{}},{"cell_type":"markdown","source":"# Installs","metadata":{}},{"cell_type":"code","source":"!pip install timm -q","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:47:55.902195Z","iopub.execute_input":"2022-04-14T20:47:55.902904Z","iopub.status.idle":"2022-04-14T20:48:05.998461Z","shell.execute_reply.started":"2022-04-14T20:47:55.902818Z","shell.execute_reply":"2022-04-14T20:48:05.997592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport time\nimport random # for torch seed\nimport os # for torch seed\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam, AdamW, RMSprop # optmizers\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau # Learning rate schedulers\n\nimport albumentations as A\n# from albumentations.pytorch import ToTensorV2\n\nimport timm","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:06.000378Z","iopub.execute_input":"2022-04-14T20:48:06.000651Z","iopub.status.idle":"2022-04-14T20:48:13.942842Z","shell.execute_reply.started":"2022-04-14T20:48:06.000613Z","shell.execute_reply":"2022-04-14T20:48:13.941853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data\nINPUT_PATH = '../input/digit-recognizer/'\nOUTPUT_PATH = './'\n\ntrain = pd.read_csv(INPUT_PATH + \"train.csv\")\ntest = pd.read_csv(INPUT_PATH + \"test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:13.946604Z","iopub.execute_input":"2022-04-14T20:48:13.946834Z","iopub.status.idle":"2022-04-14T20:48:18.723555Z","shell.execute_reply.started":"2022-04-14T20:48:13.946804Z","shell.execute_reply":"2022-04-14T20:48:18.722826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train shape: \", train.shape)\nprint(\"Test shape: \", test.shape)\n\nprint(\"\\nTrain dataset:\")\ndisplay(train)\nprint(\"\\nTest dataset:\")\ndisplay(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:18.725531Z","iopub.execute_input":"2022-04-14T20:48:18.725769Z","iopub.status.idle":"2022-04-14T20:48:18.775192Z","shell.execute_reply.started":"2022-04-14T20:48:18.725737Z","shell.execute_reply":"2022-04-14T20:48:18.774531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG\n\nThis class enables easy configuration to simulate and understand results.\n\nYou can tweak some parameters and see how they impact on the metrics, plots, and predictions.","metadata":{}},{"cell_type":"code","source":"class CFG:\n  DEBUG = False\n\n  ### input: not configurable\n  IMG_HEIGHT = 28\n  IMG_WIDTH = 28\n  N_CLASS = len(np.unique(train['label']))\n\n  ### split train and validation sets\n  split_fraction = 0.95\n\n  ### model\n  model_name = 'resnet50' # 'resnet34', 'resnet200d', 'efficientnet_b1_pruned', 'efficientnetv2_m', efficientnet_b7 ...  \n\n  ### training\n  print_freq = 100\n  BATCH_SIZE = 1024\n  N_EPOCHS = 40\n\n  ### set only one to True\n  save_best_loss = False\n  save_best_accuracy = True\n\n  ### optimizer\n  # optimizer = 'adam'\n  # optimizer = 'adamw'\n  optimizer = 'rmsprop'\n  LEARNING_RATE = 1e-3\n  weight_decay = 0.1 # for adamw\n  l2_penalty = 0.01 # for RMSprop\n  rms_momentum = 0 # for RMSprop\n\n  ### learning rate scheduler (LRS)\n  scheduler = 'ReduceLROnPlateau'\n  # scheduler = 'CosineAnnealingLR'\n  plateau_factor = 0.5\n  plateau_patience = 3\n  cosine_T_max = 4\n  cosine_eta_min = 1e-8\n  verbose = True\n\n  ### train and validation DataLoaders\n  shuffle = False\n\n  ### albumentations\n  probability = 0.6\n\n  random_seed = 42","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:18.776524Z","iopub.execute_input":"2022-04-14T20:48:18.776971Z","iopub.status.idle":"2022-04-14T20:48:18.787747Z","shell.execute_reply.started":"2022-04-14T20:48:18.776935Z","shell.execute_reply":"2022-04-14T20:48:18.786964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.DEBUG:\n  CFG.N_EPOCHS = 3\n  train = train.sample(frac = 0.1).reset_index(drop=True) # n = 10_000\n  CFG.N_CLASS = len(np.unique(train['label']))\n\nprint(f'Using {CFG.N_CLASS} classes to train')","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:18.789175Z","iopub.execute_input":"2022-04-14T20:48:18.789517Z","iopub.status.idle":"2022-04-14T20:48:18.796613Z","shell.execute_reply.started":"2022-04-14T20:48:18.789471Z","shell.execute_reply":"2022-04-14T20:48:18.795732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"DEBUG?: \", CFG.DEBUG)\nprint(\"Train shape: \", train.shape)\nprint(\"Test shape: \", test.shape)\n\nprint(f\"\\nImage shape (H, W): ({CFG.IMG_HEIGHT},{CFG.IMG_WIDTH})\")\nprint(\"Number of classes in train dataset: \", CFG.N_CLASS)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:18.79826Z","iopub.execute_input":"2022-04-14T20:48:18.79895Z","iopub.status.idle":"2022-04-14T20:48:18.810073Z","shell.execute_reply.started":"2022-04-14T20:48:18.79891Z","shell.execute_reply":"2022-04-14T20:48:18.809242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detect and define device \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:18.812646Z","iopub.execute_input":"2022-04-14T20:48:18.812843Z","iopub.status.idle":"2022-04-14T20:48:18.870006Z","shell.execute_reply.started":"2022-04-14T20:48:18.812821Z","shell.execute_reply":"2022-04-14T20:48:18.869206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for reproducibility\ndef seed_torch(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed = CFG.random_seed)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:18.871218Z","iopub.execute_input":"2022-04-14T20:48:18.872049Z","iopub.status.idle":"2022-04-14T20:48:18.881523Z","shell.execute_reply.started":"2022-04-14T20:48:18.872013Z","shell.execute_reply":"2022-04-14T20:48:18.880742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split","metadata":{}},{"cell_type":"code","source":"print('Before split:')\nprint('train shape: ', train.shape)\n\n### simple split\n# split = int(CFG.split_fraction * len(train))\n# valid_df = train[split:].reset_index(drop = True)\n# train_df = train[:split].reset_index(drop = True)\n\n### random split\ntrain_df, valid_df = train_test_split(train, test_size=(1-CFG.split_fraction), random_state=CFG.random_seed)\n\nprint('\\nAfter split:')\nprint('train_df shape: ', train_df.shape)\nprint('valid_df shape: ', valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:18.885853Z","iopub.execute_input":"2022-04-14T20:48:18.886114Z","iopub.status.idle":"2022-04-14T20:48:19.075421Z","shell.execute_reply.started":"2022-04-14T20:48:18.886061Z","shell.execute_reply":"2022-04-14T20:48:19.073748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset class\n\n[torch Dataset and DataLoader documentation](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files)\n\nA custom Dataset class must implement three functions: __init__, __len__, and __getitem__. \n\n- The __init__ function is run once when instantiating the Dataset object. We initialize the variable X_col (features columns), and the variable y_col ('label' column).\n\n- The __len__ function returns the number of samples in our dataset.\n\n- The __getitem__ function returns a sample from the dataset at the given index idx. Based on the index, it retrieves the image’s features and label on the csv file and then converts that to a tensor.\n\nWhen performing inference, we obviously don't have the label values.\n\nThe Dataset class retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, and DataLoader is an iterable that abstracts this complexity for us in an easy API.","metadata":{}},{"cell_type":"code","source":"### for training and validation\nclass DigitDataset(Dataset):\n    def __init__(self, df, X_col, y_col, augmentations = None):\n        self.df = df\n        self.features = df[X_col].values/255 # scale (greyscale) only features. do not scale target\n        self.targets = df[y_col].values.reshape((-1, 1))\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n      image = self.features[idx].reshape((28, 28))\n      label = self.targets[idx]\n\n      if self.augmentations is not None:\n        augmented = self.augmentations(image=image)  \n        image = augmented['image']\n        image = torch.from_numpy(image).float()\n        image = torch.stack([image, image, image], dim = 0) # images must have 3 channels to enter timm models, check the model's fisrt layer parameters to confirm        \n        return image, label\n      else:\n        image = torch.from_numpy(image).float()\n        image = torch.stack([image, image, image], dim = 0) # images must have 3 channels to enter timm models, check the model's fisrt layer parameters to confirm\n        return image, label\n\n\n### for inference\nclass DigitInferenceDataset(Dataset):\n    def __init__(self, df, augmentations = None): # for inference we only have the features dataframe\n        self.df = df\n        self.features = df[:].values/255 # scale (greyscale) only features. do not scale target\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image = self.features[idx].reshape((28, 28))\n        image = torch.from_numpy(image).float()\n        image = torch.stack([image, image, image], dim = 0) # images must have 3 channels to enter timm models, check the model's fisrt layer parameters to confirm\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:19.07688Z","iopub.execute_input":"2022-04-14T20:48:19.077155Z","iopub.status.idle":"2022-04-14T20:48:19.08885Z","shell.execute_reply.started":"2022-04-14T20:48:19.07712Z","shell.execute_reply":"2022-04-14T20:48:19.08807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation\n\nSet parameter p (probability of applying the transformation) to 1 to make sure you will visualize the augmentations.\n\n[Albumentations Demo](https://albumentations-demo.herokuapp.com/)\n\n[Albumentations docs](https://albumentations.ai/docs/getting_started/transforms_and_targets/)\n\n[Albumentations transforms](https://albumentations.ai/docs/getting_started/transforms_and_targets/)","metadata":{}},{"cell_type":"code","source":"transform_train = A.Compose([\n                  # A.Resize(CFG.IMG_HEIGHT - 20, CFG.IMG_WIDTH - 20, p=CFG.probability),\n                  # A.HorizontalFlip(p=CFG.probability), # 0.2\n                  # A.VerticalFlip(p=CFG.probability), # 0.5\n                  # A.CenterCrop(23, 23, p=CFG.probability),\n                  # A.RandomCrop(width=23, height=23, p=CFG.probability),                  \n                  # A.MotionBlur(p=CFG.probability), # 0.2\n                  # A.Normalize(p=CFG.probability)                  \n                  # A.Affine(p=CFG.probability),                  \n                  # A.Equalize(p=CFG.probability),                  \n                  # A.CLAHE(p=CFG.probability),                  \n                  # ToTensorV2(),\n\n\n                  A.Rotate(limit=40, p=CFG.probability), \n                  A.ShiftScaleRotate(rotate_limit=40, p=CFG.probability),\n                  # A.IAASharpen(p=CFG.probability),\n                  A.Downscale(scale_min=0.7, scale_max=0.7, p=CFG.probability)\n])\n\n\ntransform_valid = A.Compose([\n                  # A.Resize(CFG.IMG_HEIGHT, CFG.IMG_WIDTH, p=CFG.probability),\n                  # ToTensorV2(),\n\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:19.090404Z","iopub.execute_input":"2022-04-14T20:48:19.090669Z","iopub.status.idle":"2022-04-14T20:48:19.101702Z","shell.execute_reply.started":"2022-04-14T20:48:19.090634Z","shell.execute_reply":"2022-04-14T20:48:19.100977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check if Dataset class is working\n# check some augmentations\ny_col = \"label\"\nX_col = [c for c in train.columns if c != 'label']\n\n# instantiate Dataset class\ntd = DigitDataset(train, X_col, y_col, augmentations = None) # no augmentation\ntd_aug = DigitDataset(train, X_col, y_col, augmentations = transform_train) # with data augmentation\n\n# DataLoaders\ntl = DataLoader(td, batch_size = CFG.BATCH_SIZE, shuffle = True) # no augmentation\ntl_aug = DataLoader(td_aug, batch_size = CFG.BATCH_SIZE, shuffle = True) # with data augmentation\n\nprint('Length train_dataset (td): ', len(td))\nprint('Length train_dataloader (tl): ', len(tl))\nprint('Batch size: ', CFG.BATCH_SIZE)\n\nimg_aug, lab_aug = td_aug.__getitem__(8) # with data augmentation\nprint('Label: ', lab_aug)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:19.103208Z","iopub.execute_input":"2022-04-14T20:48:19.103506Z","iopub.status.idle":"2022-04-14T20:48:19.515528Z","shell.execute_reply.started":"2022-04-14T20:48:19.10347Z","shell.execute_reply":"2022-04-14T20:48:19.514771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning: timm\n\n[timm docs](https://rwightman.github.io/pytorch-image-models/)","metadata":{}},{"cell_type":"code","source":"class DigitModel(nn.Module):\n    def __init__(self, model_name = CFG.model_name, pretrained = True):\n        super().__init__()\n\n        self.model_name = model_name\n        self.cnn = timm.create_model(self.model_name, pretrained = pretrained, num_classes = CFG.N_CLASS)\n\n    def forward(self, x):\n        x = self.cnn(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:19.516731Z","iopub.execute_input":"2022-04-14T20:48:19.517455Z","iopub.status.idle":"2022-04-14T20:48:19.523738Z","shell.execute_reply.started":"2022-04-14T20:48:19.517414Z","shell.execute_reply":"2022-04-14T20:48:19.522763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### check model structure\n\nm = DigitModel()\nm","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:19.525138Z","iopub.execute_input":"2022-04-14T20:48:19.525571Z","iopub.status.idle":"2022-04-14T20:48:24.072601Z","shell.execute_reply.started":"2022-04-14T20:48:19.525537Z","shell.execute_reply":"2022-04-14T20:48:24.071876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## List of timm models","metadata":{}},{"cell_type":"code","source":"print('Number of models available: ', len(timm.list_models(pretrained=True)))\nprint('\\nDensenet models: ', timm.list_models('*densenet*'))\nprint('\\nEfficientNet models: ', timm.list_models('efficientnet*')[0:5])","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:24.073885Z","iopub.execute_input":"2022-04-14T20:48:24.074311Z","iopub.status.idle":"2022-04-14T20:48:24.085439Z","shell.execute_reply.started":"2022-04-14T20:48:24.074274Z","shell.execute_reply":"2022-04-14T20:48:24.084695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### all models\n# timm.list_models()","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:24.087003Z","iopub.execute_input":"2022-04-14T20:48:24.087679Z","iopub.status.idle":"2022-04-14T20:48:24.092958Z","shell.execute_reply.started":"2022-04-14T20:48:24.087599Z","shell.execute_reply":"2022-04-14T20:48:24.092253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### checking model architecture and number of input neurons in the last layer\nm = timm.create_model('vgg16') # just testing, vgg will not be used\n\nm.head.fc # print last layer","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:24.095232Z","iopub.execute_input":"2022-04-14T20:48:24.095945Z","iopub.status.idle":"2022-04-14T20:48:26.36453Z","shell.execute_reply.started":"2022-04-14T20:48:24.095894Z","shell.execute_reply":"2022-04-14T20:48:26.363882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimizer\n\n[torch optimizer documentation](https://pytorch.org/docs/stable/optim.html#)\n\nFunction to get the optimizer to be used (can be tuned in CFG class).","metadata":{}},{"cell_type":"code","source":"def get_optimizer(lr = CFG.LEARNING_RATE):\n\n  if CFG.optimizer == 'adam':\n      optimizer = Adam(model.parameters(), lr=lr, weight_decay = CFG.weight_decay, amsgrad = False)\n\n  elif CFG.optimizer == 'adamw':\n      optimizer = AdamW(model.parameters(), lr = lr, weight_decay = CFG.weight_decay)\n\n  elif CFG.optimizer == 'rmsprop':\n      optimizer = RMSprop(model.parameters(), lr = lr, weight_decay = CFG.l2_penalty, momentum = CFG.rms_momentum)\n\n  else:\n      print('Optimizer is not defined')      \n\n  return optimizer","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:26.365879Z","iopub.execute_input":"2022-04-14T20:48:26.366296Z","iopub.status.idle":"2022-04-14T20:48:26.373412Z","shell.execute_reply.started":"2022-04-14T20:48:26.366259Z","shell.execute_reply":"2022-04-14T20:48:26.372639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LR Scheduler\n\n[torch LRS documentation](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)\n\nFunction to get the Learning Rate Scheduler to be used (can be tuned in CFG class).\n\ntorch.optim.lr_scheduler provides several methods to adjust the learning rate based on the number of epochs. \n\ntorch.optim.lr_scheduler.ReduceLROnPlateau allows dynamic learning rate reducing based on some validation measurements.\n\nLearning rate scheduling should be applied after optimizer’s update.","metadata":{}},{"cell_type":"code","source":"def get_scheduler(optimizer):\n\n  if CFG.scheduler=='ReduceLROnPlateau':\n      scheduler = ReduceLROnPlateau(optimizer, mode='max', factor = CFG.plateau_factor, patience = CFG.plateau_patience, verbose = CFG.verbose)\n\n  elif CFG.scheduler=='CosineAnnealingLR':\n      scheduler = CosineAnnealingLR(optimizer, T_max = CFG.cosine_T_max, eta_min = CFG.cosine_eta_min)\n\n  else:\n      print('LR Scheduler is not defined')\n\n  return scheduler ","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:26.374639Z","iopub.execute_input":"2022-04-14T20:48:26.374974Z","iopub.status.idle":"2022-04-14T20:48:26.383833Z","shell.execute_reply.started":"2022-04-14T20:48:26.374935Z","shell.execute_reply":"2022-04-14T20:48:26.383054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train function","metadata":{}},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optmizer, device):\n  # switch to train mode\n  model.train()\n    \n    \n  size = len(train_loader.dataset)\n  num_batches = len(train_loader)\n\n  loss, correct = 0, 0\n\n  ################################# train #################################\n\n  for batch, (X, y) in enumerate(train_loader):\n\n    start = time.time()\n\n    device = torch.device(device)\n    X, y = X.to(device), y.to(device)  \n\n    # compute predictions and loss\n    optimizer.zero_grad()\n    pred = model(X)\n    loss = criterion(pred, y.long().squeeze()) \n    current = batch * len(X)\n\n    # Backpropagation: only in train function, not done in validation function\n    loss.backward()\n    optimizer.step()\n\n    # sum correct predictions\n    y_pred, y_true = torch.argmax(pred, axis=1), y.long().squeeze()\n    correct += (y_pred == y_true).type(torch.float).sum().item()\n\n    end = time.time()\n    time_delta = np.round(end - start, 3)\n\n    # log\n    loss, current = np.round(loss.item(), 5), batch * len(X)\n    # if batch % (CFG.print_freq) == 0:\n    #   print(f\"Train Batch: {current:>5d}/{size:>5d}: loss: {loss:>5f} Elapsed Time: {time_delta} s\")\n  \n  # metrics: calculate accuracy and loss for epoch (all batches)\n  correct /= size # epoch accuracy\n  loss /= num_batches # epoch loss\n\n  print(f\"Train: Accuracy: {(100*correct):>0.2f}%, Avg loss: {loss:>5f} \\n\")\n\n  return loss, correct","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:26.387146Z","iopub.execute_input":"2022-04-14T20:48:26.387385Z","iopub.status.idle":"2022-04-14T20:48:26.396431Z","shell.execute_reply.started":"2022-04-14T20:48:26.38736Z","shell.execute_reply":"2022-04-14T20:48:26.395785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation function\n\n[torch.no_grad documentation](https://pytorch.org/docs/stable/generated/torch.no_grad.html)\n\nUse it when you are sure you will not call Tensor.backward(). It reduces memory and time consumption.","metadata":{}},{"cell_type":"code","source":"def valid_fn(valid_loader, model, criterion, device):\n  model.eval()\n\n  size = len(valid_loader.dataset)\n  num_batches = len(valid_loader)\n\n  loss, correct = 0, 0\n\n  ################################# validation #################################\n\n  with torch.no_grad(): # disable gradients\n    for batch, (X, y) in enumerate(valid_loader):\n\n      start = time.time()\n\n      device = torch.device(device)\n      X, y = X.to(device), y.to(device)\n\n      # compute predictions and loss\n      pred = model(X)\n      loss = criterion(pred, y.long().squeeze()) \n      current = batch * len(X)\n      \n      # sum correct predictions\n      y_pred, y_true = torch.argmax(pred, axis=1), y.long().squeeze()\n      correct += (y_pred == y_true).type(torch.float).sum().item()\n\n      end = time.time()\n      time_delta = np.round(end - start, 3)\n      \n      # log\n      loss, current = np.round(loss.item(), 5), batch * len(X)\n      # if batch % (CFG.print_freq) == 0:\n      #   print(f\"Valid Batch: {current:>5d}/{size:>5d}: loss: {loss:>5f} Elapsed Time: {time_delta} s\")\n\n  # metrics: calculate accuracy and loss for epoch (all batches)\n  correct /= size # epoch accuracy\n  loss /= num_batches # epoch loss\n\n  print(f\"Valid: Accuracy: {(100*correct):>0.2f}%, Avg loss: {loss:>5f} \\n\")\n\n  return loss, correct","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:26.397905Z","iopub.execute_input":"2022-04-14T20:48:26.398817Z","iopub.status.idle":"2022-04-14T20:48:26.409841Z","shell.execute_reply.started":"2022-04-14T20:48:26.398779Z","shell.execute_reply":"2022-04-14T20:48:26.409139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run training","metadata":{}},{"cell_type":"code","source":"start = time.time()\n\n# define loss function\nloss_fn = nn.CrossEntropyLoss()\n\n# instantiate model\ndevice = torch.device(device)\nmodel = DigitModel().to(device) # move the model to GPU before constructing optimizers for it\n\nprint('\\n ******************************* Using backbone: ', CFG.model_name, \" ******************************* \\n\")\n\n# define optimizer\noptimizer = get_optimizer(lr = CFG.LEARNING_RATE)\n\n# define scheduler\nscheduler = get_scheduler(optimizer)\n\n# prepare dataset\ny_col = \"label\"\nX_col = [c for c in train.columns if c != 'label']\n\ntrain_dataset = DigitDataset(train_df, X_col, y_col, augmentations=transform_train) # data augmentation. set augmentations = None to disable augmentations\nvalid_dataset = DigitDataset(valid_df, X_col, y_col, augmentations=transform_valid) # data augmentation. set augmentations = None to disable augmentations\n\ntrain_dataloader = DataLoader(train_dataset,\n                              batch_size = CFG.BATCH_SIZE,\n                              shuffle = CFG.shuffle)\n\nvalid_dataloader = DataLoader(valid_dataset,\n                              batch_size = CFG.BATCH_SIZE,\n                              shuffle = CFG.shuffle)\n\n\ntrain_loss_history = []\ntrain_acc_history = []\nvalid_loss_history = []\nvalid_acc_history = []\nLR_history = []\n\nbest_loss = np.inf\nbest_epoch_loss = 0\nbest_acc = 0\nbest_epoch_acc = 0\n\nprint('Starting Training...\\n')\n\nstart_train_time = time.time()\n\nfor epoch in range(0, CFG.N_EPOCHS):\n  print(f\"\\n-------------------------------   Epoch {epoch + 1}   -------------------------------\\n\")\n  start_epoch_time = time.time()\n\n  # train\n  train_loss, train_acc = train_fn(train_dataloader, model, loss_fn, optimizer, device)\n  train_loss_history.append(train_loss)\n  train_acc_history.append(train_acc)\n\n  # validation\n  valid_loss, valid_acc = valid_fn(valid_dataloader, model, loss_fn, device)\n  valid_loss_history.append(valid_loss)\n  valid_acc_history.append(valid_acc)\n\n  # apply LR scheduler after each epoch\n  if isinstance(scheduler, ReduceLROnPlateau):\n      scheduler.step(valid_loss)\n\n  elif isinstance(scheduler, CosineAnnealingLR):\n      scheduler.step()\n\n  # save LR value to plot later\n  for param_group in optimizer.param_groups:\n    LR_history.append(param_group['lr'])\n\n  # save validation loss if it was improved (reduced)\n  if valid_loss < best_loss:\n    best_epoch_loss = epoch + 1\n    best_loss = valid_loss\n    if CFG.save_best_loss:\n      # save the model's weights and biases only if CFG.save_best_loss == True\n      torch.save(model.state_dict(), OUTPUT_PATH + f\"DigitModel_ep{best_epoch_loss}.pth\")\n\n  # save validation accuracy if it was improved (increased)\n  if valid_acc > best_acc:\n    best_epoch_acc = epoch + 1\n    best_acc = valid_acc\n    if CFG.save_best_accuracy:\n      # save the model's weights and biases only if CFG.save_best_accuracy == True\n      torch.save(model.state_dict(), OUTPUT_PATH + f\"DigitModel_ep{best_epoch_acc}.pth\")    \n\n  end_epoch_time = time.time()\n  time_delta = np.round(end_epoch_time - start_epoch_time, 3)\n  print(\"\\n\\nEpoch Elapsed Time: {} s\".format(time_delta))\n\nend_train_time = time.time()\nprint(\"\\n\\nTotal Elapsed Time: {} min\".format(np.round((end_train_time - start_train_time)/60, 3)))\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:48:26.41125Z","iopub.execute_input":"2022-04-14T20:48:26.411603Z","iopub.status.idle":"2022-04-14T20:58:06.91537Z","shell.execute_reply.started":"2022-04-14T20:48:26.411568Z","shell.execute_reply":"2022-04-14T20:58:06.914653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Epochs\n\nPlot Train and Validation Loss and Accuracy for each Epoch.","metadata":{}},{"cell_type":"code","source":"print('Best loss: ', best_loss)\nprint('Best epoch (loss criteria): ', best_epoch_loss)\nprint('\\n')\nprint('Best accuracy: ', best_acc)\nprint('Best epoch (accuracy criteria): ', best_epoch_acc)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:58:06.916837Z","iopub.execute_input":"2022-04-14T20:58:06.917272Z","iopub.status.idle":"2022-04-14T20:58:06.924187Z","shell.execute_reply.started":"2022-04-14T20:58:06.917234Z","shell.execute_reply":"2022-04-14T20:58:06.923408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (18, 8))\nfig.suptitle('Epoch Results', fontsize = 18)\n\nabscissa = np.arange(1, CFG.N_EPOCHS + 1, 1)\n\n# x_ticks according to CFG.N_EPOCHS for better visuailzation\nif CFG.N_EPOCHS <= 20:\n  x_ticks = np.arange(1, CFG.N_EPOCHS + 1, 1)\nelse:\n  x_ticks = np.arange(1, CFG.N_EPOCHS + 1, int(CFG.N_EPOCHS/20) + 1)\n\n# Loss plot\nax1 = plt.subplot(1, 2, 1)\nax1.plot(abscissa, train_loss_history, label='Training', color = 'black')\nax1.plot(abscissa, valid_loss_history, label='Validation', color = 'red')\nplt.xticks(x_ticks)\nplt.axhline(0, linestyle = 'dashed', color = 'grey')\nplt.axvline(best_epoch_loss, linestyle = 'dashed', color = 'blue', label = 'Best val loss: ep ' + str(best_epoch_loss))\nplt.axvline(best_epoch_acc, linestyle = 'dashed', color = 'green', label = 'Best val acc: ep ' + str(best_epoch_acc))\nplt.title(\"Loss\")\nax1.legend(frameon=False);\n\n# Accuracy plot\nax2 = plt.subplot(1, 2, 2)\nax2.plot(abscissa, train_acc_history, label='Training', color = 'black')\nax2.plot(abscissa, valid_acc_history, label='Validation', color = 'red')\nplt.xticks(x_ticks)\nplt.axhline(0.99, linestyle = 'dashed', color = 'grey')\nplt.axvline(best_epoch_loss, linestyle = 'dashed', color = 'blue', label = 'Best val loss: ep ' + str(best_epoch_loss))\nplt.axvline(best_epoch_acc, linestyle = 'dashed', color = 'green', label = 'Best val acc: ep ' + str(best_epoch_acc))\nplt.title(\"Accuracy\")\nax2.legend(frameon=False);","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:58:06.925634Z","iopub.execute_input":"2022-04-14T20:58:06.926082Z","iopub.status.idle":"2022-04-14T20:58:07.727617Z","shell.execute_reply.started":"2022-04-14T20:58:06.926023Z","shell.execute_reply":"2022-04-14T20:58:07.726942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (14, 8))\n\nabscissa = np.arange(1, CFG.N_EPOCHS + 1, 1)\n\n# x_ticks according to CFG.N_EPOCHS for better visuailzation\nif CFG.N_EPOCHS <= 20:\n  x_ticks = np.arange(1, CFG.N_EPOCHS + 1, 1)\nelse:\n  x_ticks = np.arange(1, CFG.N_EPOCHS + 1, int(CFG.N_EPOCHS/20) + 1)\n\n# LR plot\nplt.plot(abscissa, LR_history, label='LR', color = 'orange')\nplt.xticks(x_ticks)\nplt.axhline(CFG.LEARNING_RATE, linestyle = 'dashed', color = 'grey')\nplt.axhline(0, linestyle = 'dashed', color = 'grey')\nplt.axvline(best_epoch_loss, linestyle = 'dashed', color = 'blue', label = 'Best val loss: ep ' + str(best_epoch_loss))\nplt.axvline(best_epoch_acc, linestyle = 'dashed', color = 'green', label = 'Best val acc: ep ' + str(best_epoch_acc))\nplt.title(f\"Learning Rate vs Epochs: {CFG.scheduler}\", fontsize = 16, color = 'orange')\nplt.legend(frameon=False);","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:58:07.729066Z","iopub.execute_input":"2022-04-14T20:58:07.729562Z","iopub.status.idle":"2022-04-14T20:58:08.041919Z","shell.execute_reply.started":"2022-04-14T20:58:07.729525Z","shell.execute_reply":"2022-04-14T20:58:08.041261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def softmax(x):\n    return np.exp(x)/np.sum(np.exp(x), axis=1)[:, None]\n\ndef inference(test_loader, model):\n    model.eval()\n\n    predictions = []\n\n    size = len(test_loader.dataset)\n    num_batches = len(test_loader)    \n\n    model = DigitModel().to(device)\n\n    if CFG.save_best_loss: # load model with best validation loss\n      model.load_state_dict(torch.load(OUTPUT_PATH + f\"DigitModel_ep{best_epoch_loss}.pth\"))\n    else: # load model with best validation accuracy\n      model.load_state_dict(torch.load(OUTPUT_PATH + f\"DigitModel_ep{best_epoch_acc}.pth\"))\n\n    # disable gradients for inference\n    with torch.no_grad():\n      for batch, X in enumerate(test_loader):\n        \n        ################################# inference #################################\n        start = time.time()\n        current = batch * len(X)\n\n        X = X.to(device)\n\n        # compute predictions\n        pred = model(X)       \n        # softmax\n        y_pred = softmax(pred.detach().cpu().numpy()) # convert tensor to numpy and apply softmax \n        y_pred = np.argmax(y_pred, axis = 1) # take the indice of the max value (higher probability: predicted class)\n\n        # store results\n        predictions.append(y_pred)\n\n        # log\n        end = time.time()\n        time_delta = np.round(end - start, 5)\n\n        # if batch % (CFG.print_freq) == 0:\n        #   print(f\"Inference Batch: {current:>5d}/{size:>5d}: Elapsed Time: {time_delta} s\")          \n\n    test_predictions = np.concatenate(predictions, axis = 0) # join sequence of arrays along axis 0\n    return test_predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:58:08.04314Z","iopub.execute_input":"2022-04-14T20:58:08.04379Z","iopub.status.idle":"2022-04-14T20:58:08.054236Z","shell.execute_reply.started":"2022-04-14T20:58:08.043748Z","shell.execute_reply":"2022-04-14T20:58:08.053387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instantiate Inference Dataset class (create inference Dataset)\ninference_dataset = DigitInferenceDataset(test, augmentations=None)\n\n# create Inference DataLoader object from Dataset class object\ninference_dataloader = DataLoader(inference_dataset,\n                                  batch_size = CFG.BATCH_SIZE,\n                                  shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:58:08.058634Z","iopub.execute_input":"2022-04-14T20:58:08.058919Z","iopub.status.idle":"2022-04-14T20:58:08.133532Z","shell.execute_reply.started":"2022-04-14T20:58:08.058881Z","shell.execute_reply":"2022-04-14T20:58:08.132784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# run inference\npredictions = inference(inference_dataloader, model)\npredictions","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:58:08.134927Z","iopub.execute_input":"2022-04-14T20:58:08.135234Z","iopub.status.idle":"2022-04-14T20:58:10.663678Z","shell.execute_reply.started":"2022-04-14T20:58:08.135198Z","shell.execute_reply":"2022-04-14T20:58:10.662996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(INPUT_PATH + \"sample_submission.csv\")\nsubmission[\"Label\"] = predictions\n\nsubmission.to_csv(OUTPUT_PATH + 'submission.csv', index = False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:58:10.664962Z","iopub.execute_input":"2022-04-14T20:58:10.665455Z","iopub.status.idle":"2022-04-14T20:58:10.737359Z","shell.execute_reply.started":"2022-04-14T20:58:10.665413Z","shell.execute_reply":"2022-04-14T20:58:10.736715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check predictions","metadata":{}},{"cell_type":"code","source":"# check some predictions\n\nfig = plt.figure(figsize = (12, 12))\nfig.suptitle('Visualizing Predictions', fontsize = 24)\n\n# define a range of predictions to plot\nbegin = 130\nend = begin + 20\n\nfor i in range(begin, end):\n\n  img = np.array(test.iloc[i, :]).reshape(1, 1, 28, 28) # reshape to image dimensions\n  plt.subplot(4, 5, i + 1 - begin) # 4 rows and 5 columns plot \n  label = str(submission.loc[i, 'Label'])\n  plt.title(\"Predicted label: \" + label, color=\"red\") # write label in each image title\n  plt.imshow(np.squeeze(img), cmap='gray') # plot image\n  plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-04-14T20:58:10.738631Z","iopub.execute_input":"2022-04-14T20:58:10.738856Z","iopub.status.idle":"2022-04-14T20:58:11.669887Z","shell.execute_reply.started":"2022-04-14T20:58:10.738824Z","shell.execute_reply":"2022-04-14T20:58:11.669159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Upvote if you found value in this notebook! 😀","metadata":{}}]}