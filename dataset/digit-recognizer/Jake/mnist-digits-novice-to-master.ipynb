{"cells":[{"metadata":{},"cell_type":"markdown","source":" To-do\n \n > dimensionality reduction\n > model with features from cnn and with features from images\n \n \n - [Data exploration](#section-one)\n - [The model](#section-two)\n - [What went wrong/right](#section-three)\n\n\n#### please comment if you have any improvements"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### This is a copy of my kernel for the Kannada mnist competition, to see how the model works with a different data set\n\nhttps://www.kaggle.com/jakelj/kannada-mnist-beginner-to"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Import Packages\n\nimport random\nimport keras\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.patches as mpatches\n\nfrom skimage.filters import threshold_otsu\nfrom skimage.segmentation import clear_border\nfrom skimage.measure import label, regionprops\nfrom skimage.morphology import closing, square\nfrom skimage.color import label2rgb\nfrom math import sqrt\n\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, BatchNormalization\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\nsubmission = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<a name=\"section-one\"></a>\n## Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train['label']\nX = train.drop(['label'],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost half the number of samples in the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nplt.imshow(X.values[3].reshape(28,28))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"# code for this plot taken from https://www.kaggle.com/josephvm/kannada-with-pytorch\n\nfig, ax = plt.subplots(nrows=10, ncols=10, figsize=(15,15))\n\n# I know these for loops look weird, but this way num_i is only computed once for each class\nfor i in range(10): # Column by column\n    num_i = X[y_train == i]\n    ax[0][i].set_title(i)\n    for j in range(10): # Row by row\n        ax[j][i].axis('off')\n        ax[j][i].imshow(num_i.iloc[j, :].to_numpy().astype(np.uint8).reshape(28, 28))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"by eye, it looks as if there may be some issues distinguishing between 5 and 6 on occasion"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nlab, val = np.unique(y_train,return_counts=True)\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,7))\nsns.barplot(lab,val)\nplt.title('distribution of samples in the training data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's see if the number of pixels that are non '0' are informative to the label? I suspect some numbers require more 'ink' than others"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels =[]\nfrequencies = []\n\n\nfor i in range(len(y_train)):\n    lab, freq = str(y_train[i]), len([n for n in X.values[i] if n > 0])\n    labels.append(lab)\n    frequencies.append(freq)\n    \n    \ndata = {'Labels':labels, 'Frequencies':frequencies}\n\ndf = pd.DataFrame(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean number of pixels per label\ndf.groupby('Labels').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,10))\nsns.boxplot(x = 'Labels', y = 'Frequencies', data = df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The digits in this dataset are more unifrom in those of the kannada dataset. Although the number of non zero pixles are lower in that dataset, I wonder if it is due to the nature of the symbols or the images.\n\nI wonder if the digits of the image give us any usefull information?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply threshold\nimage = X.values[3].reshape(28,28)\nthresh = threshold_otsu(image)\nbw = closing(image > thresh, square(3))\n\n# label image regions\nlabel_image = label(bw)\nimage_label_overlay = label2rgb(label_image, image=image)\n\nfig, ax = plt.subplots(figsize=(10, 6))\nax.imshow(image_label_overlay)\n\nfor region in regionprops(label_image):\n    # take regions with large enough areas\n    if region.area >= 30:\n        # draw rectangle around segmented coins\n        minr, minc, maxr, maxc = region.bbox\n        rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n                                  fill=False, edgecolor='green', linewidth=2)\n        ax.add_patch(rect)\nplt.text(1,1, f'Width: {maxc-minc} Height: {maxr -minr} Diagonal: {round(sqrt((((maxc-minc)**2) + (maxr-minr)**2)),2)}', color = 'w')\nax.set_axis_off()\nplt.tight_layout()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def measurements(images):\n    \n    widths = []\n    heights = []\n    diags = []\n    \n    for i in range(len(images)):\n        # apply threshold\n        image = images[i].reshape(28,28)\n        thresh = threshold_otsu(image)\n        bw = closing(image > thresh, square(3))\n\n        # label image regions\n        label_image = label(bw)\n        image_label_overlay = label2rgb(label_image, image=image)\n\n        for region in regionprops(label_image):\n            # take regions with large enough areas\n            if region.area >= 30:\n                # draw rectangle around segmented coins\n                minr, minc, maxr, maxc = region.bbox\n                \n        widths.append(maxc-minc)\n        heights.append(maxr -minr)\n        diags.append(sqrt((((maxc-minc)**2) + (maxr-minr)**2)))\n                     \n    return widths, heights, diags\n                     \n\n\nwidths, heights, diags = measurements(X.values)\n                     \ndata = {'Labels':labels, 'diagonals':diags, 'widths':widths, 'heights':heights, 'Area':frequencies}\n\ndf = pd.DataFrame(data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,10))\nsns.boxplot(x = 'Labels', y = 'diagonals', data = df)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,10))\nsns.boxplot(x = 'Labels', y = 'heights', data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,10))\nsns.boxplot(x = 'Labels', y = 'widths', data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, what have I learnt? Well, the height is very similar for each digit. This is strange to me as I would have though handwriting would vary alot more than that. Perhaps there is a logic error in my code?\n\nthe width of the digit is much more variable but still, its not a huge difference.\n\nLet's see if a decision tree can tell the difference given these data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\ntest_y = df['Labels']\n\ntest_x = df\ntest_x.drop('Labels', axis =1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1, X_val1, y_train1, y_val1 = train_test_split(test_x, test_y, test_size=0.1, random_state=1337)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rfc = RandomForestClassifier(n_estimators = 100)\nclf_rfc.fit(X_train1,y_train1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy_score(clf_rfc.predict(X_val1), y_val1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow I guess that is why CNN's are popular for this kind of problem.\n\nlet's try a KNN for fun before we move on"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n\nclf_knn = KNeighborsClassifier()\nclf_knn.fit(X_train1,y_train1)\n\naccuracy_score(clf_knn.predict(X_val1), y_val1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nope still not great.\n\nThis kind of model and these features are not going to cut it.\n\nSeeing as everyone else is doing so I assume it is well worth learning..."},{"metadata":{},"cell_type":"markdown","source":"#### Dimensionality reduction\n\nIn my laymens terms, what a PCA does is find the variables that are responsible for the most amount of variation in the dataset. If we had a straight line all the data would be in one component (I think)"},{"metadata":{"trusted":true},"cell_type":"code","source":"imaginery_data = [[1,2,3,4,5], [3,3,3,3,3]]\n\nplt.scatter(imaginery_data[0],imaginery_data[1])\n\n\npca_test = PCA()\npca_test.fit(imaginery_data).explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, the first principla component is responsible for all the variation. 'explained_variance_ratio_' should sum to one providing you're returning all the principle components. Any 2d data wiill have all the variance explained in the first component even if it is random \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"imaginary_data = np.random.rand(28,2)\n\n\n\nplt.scatter(imaginary_data[:,0], imaginary_data[:,1])\n\nprint(imaginary_data[0:10])\npca = PCA(n_components = 1)\npca.fit(imaginary_data).explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imaginary_data_pca = pca.transform(imaginary_data)\n\nprint(\"original shape:   \", imaginary_data.shape)\nprint(\"transformed shape:\", imaginary_data_pca.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imaginary_data_pca_new = pca.inverse_transform(imaginary_data_pca)\nplt.scatter(imaginary_data[:, 0], imaginary_data[:, 1], alpha=0.2)\nplt.scatter(imaginary_data_pca_new[:, 0], imaginary_data_pca_new[:, 1], alpha=0.8)\nplt.axis('equal')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the direction of max variance has been plotted by the principal components, if this were non random data it might be interesting"},{"metadata":{},"cell_type":"markdown","source":"But what of 3d data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nimaginary_data = np.random.rand(728,3)\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\ni = imaginary_data[:,0]\nj = imaginary_data[:,1]\nk = imaginary_data[:,2]\n\n\n\nax.scatter(i, j, k, c='r', marker='o')\n\nax.set_xlabel('X Label')\nax.set_ylabel('Y Label')\nax.set_zlabel('Z Label')\n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=2) # project from 784 to 2 dimensions so we can view them \npca.fit(imaginary_data)\nimaginary_data_pca = pca.transform(imaginary_data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imaginary_data_pca_new = pca.inverse_transform(imaginary_data_pca)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\ni = imaginary_data[:,0]\nj = imaginary_data[:,1]\nk = imaginary_data[:,2]\n\n\n\nax.scatter(i, j, k, c='r', marker='o')\n\nax.set_xlabel('X Label')\nax.set_ylabel('Y Label')\nax.set_zlabel('Z Label')\n\n\nl = imaginary_data_pca_new[:,0]\nm = imaginary_data_pca_new[:,1]\n\n\nax.scatter(l, m, c='b', marker='o')\n\n\nplt.axis('equal')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here you can see that random 3d data has been cast down to 2d data. Although, in this case it is rather pointless as the underlying data is random, we don't really learn anything.\n\nlet's do it with the image dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\npca = PCA(n_components=2) # project from 784 to 2 dimensions so we can view them \nprincipalComponents = pca.fit(X)\n\nprint('Explained variance for the 1st two components',principalComponents.explained_variance_ratio_)\n\nprincipalComponents = pca.transform(X)\nprincipal_df = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2'])\nplt.scatter(principalComponents[:, 0], principalComponents[:, 1], s= 1, c=y_train, cmap='Spectral')\nplt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10));\nplt.xlabel('PC1')\nplt.ylabel('PC2')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the results from our PCA it would seem that reducing dimensions in this dataset will not be easy. As there is some seperation but not a lot.\n\nTo read more about PCA look here: https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html"},{"metadata":{},"cell_type":"markdown","source":"What if we add are pca components to our knn model?"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {'Labels':labels, 'diagonals':diags, 'widths':widths, 'heights':heights, 'Area':frequencies, 'PC1':principalComponents[:, 0],'PC2':principalComponents[:, 1]}\n\ndf = pd.DataFrame(data)\ndf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_y = df['Labels']\n\ntest_x = df\ntest_x.drop('Labels', axis =1, inplace = True)\n\nX_train1, X_val1, y_train1, y_val1 = train_test_split(test_x, test_y, test_size=0.1, random_state=1337)\n\nclf_knn = KNeighborsClassifier()\nclf_knn.fit(X_train1,y_train1)\n\naccuracy_score(clf_knn.predict(X_val1), y_val1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An improvement!"},{"metadata":{},"cell_type":"markdown","source":"Next on my learning journey, we should surely look at some other dimensionality reduction tecniques.\n\n1st up\n#### Dictionary learning\n\nFrom the skelarn website - https://scikit-learn.org/stable/modules/decomposition.html#decompositions\n\n    Dictionary learning (DictionaryLearning) is a matrix factorization problem that amounts to finding a (usually overcomplete) dictionary that will perform well atsparsely encoding the fitted data.\n\n    Representing data as sparse combinations of atoms from an overcomplete dictionary is suggested to be the way the mammalian primary visual cortex works. Consequently, dictionary learning applied on image patches has been shown to give good results in image processing tasks such as image completion, inpainting and denoising, as well as for supervised recognition tasks."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import MiniBatchDictionaryLearning\n\nmbdl = MiniBatchDictionaryLearning(n_components = 2)\n\nmbdl.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comps = mbdl.transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"principal_df = pd.DataFrame(data = principalComponents, columns = ['C1', 'C2'])\nplt.scatter(comps[:, 0], comps[:, 1], s= 1, c=y_train, cmap='Spectral')\nplt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10));\nplt.xlabel('C1')\nplt.ylabel('C2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interesting, it seems worse than PCA in terms of seperation. Does it anything to our model though?"},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(d1,d1_lab, d2, d2_lab,data):\n    \n\n    data = {'Labels':labels, 'diagonals':diags, 'widths':widths, 'heights':heights, 'Area':frequencies, 'PC1':principalComponents[:, 0],'PC2':principalComponents[:, 1]}\n    data[d1_lab] = d1\n    data[d2_lab] = d2\n    \n    df = pd.DataFrame(data)\n    \n    print(df.columns)\n    test_y = df['Labels']\n\n    test_x = df\n    test_x.drop('Labels', axis =1, inplace = True)\n\n    X_train1, X_val1, y_train1, y_val1 = train_test_split(test_x, test_y, test_size=0.1, random_state=1337)\n\n    clf_knn = KNeighborsClassifier()\n    clf_knn.fit(X_train1,y_train1)\n\n    return accuracy_score(clf_knn.predict(X_val1), y_val1)\n\n\ntest_model(comps[:, 0],'d1', comps[:, 1],'d2', data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Woo, we are over 50%\n\nfor our next trick lets do LDA, in my research career, the one dimensionality reduction tecnique that comes after PCA is LDA\n\n#### Linear Discriminant analysis\n\nLinear Discriminant Analysis - https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\n\n    A classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule.\n\n    The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix.\n\n    The fitted model can also be used to reduce the dimensionality of the input by projecting it to the most discriminative directions.\n\nSO it is a supervised method, that can be used to reduce dimensionality.I would guess, based on my expereince on kaggle that this will sperate the data better - and overfit"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nlda = LinearDiscriminantAnalysis(n_components = 2, )\ncomps = lda.fit_transform(X,y_train.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"principal_df = pd.DataFrame(data = principalComponents, columns = ['C1', 'C2'])\nplt.scatter(comps[:, 0], comps[:, 1], s= 1, c=y_train, cmap='Spectral')\nplt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10));\nplt.xlabel('C1')\nplt.ylabel('C2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It does look better, slightly anyway. let's test it with out model"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_model(comps[:, 0],'lda1', comps[:, 1],'lda2', data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Oh, no we have regressed by using LDA - in this case. \n\nThe next algorithm is completely new to me T-SNE, I have only seen this since being on kaggle so I no nothing about it other than alot of kernels with t-sne in the title rate quite highly.\n\n#### distributed Stochastic Neighbor Embedding.\nhttps://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n\nt-SNE is a tool to visualize high-dimensional data. It converts similarities between data points to joint probabilities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. t-SNE has a cost function that is not convex, i.e. with different initializations we can get different results.\n\nIt is highly recommended to use another dimensionality reduction method (e.g. PCA for dense data or TruncatedSVD for sparse data) to reduce the number of dimensions to a reasonable amount (e.g. 50) if the number of features is very high. This will suppress some noise and speed up the computation of pairwise distances between samples.\n\nIf you understood that, please explain in the comments! I'm off to watch a youtube video"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''from sklearn.manifold import TSNE\n\ntsne = TSNE(n_components =2)\ncomps = tsne.fit_transform(X) \n\nprincipal_df = pd.DataFrame(data = principalComponents, columns = ['C1', 'C2'])\nplt.scatter(comps[:, 0], comps[:, 1], s= 1, c=y_train, cmap='Spectral')\nplt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10));\nplt.xlabel('C1')\nplt.ylabel('C2')\n\n'''\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you want to see an impressive 3d t-sne visualisation look here https://projector.tensorflow.org/"},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_model(comps[:, 0],'tsne1', comps[:, 1],'tsne2', data)#","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A massive improvement almost 80% accurate now. Although it did take about 30 minutes to run."},{"metadata":{},"cell_type":"markdown","source":"<a name=\"section-three\"></a>\n## Building the CNN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# Normalize the data\nX = X / 255.0\ntest = test / 255.0\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# re-shaping the data so that keras can use it, this is something that trips me up every time\n\nX = X.values.reshape(X.shape[0], 28, 28,1)\ntest = test.values.reshape(test.shape[0], 28, 28,1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This modifies some images slightly, I have seen this in a few tutorials and it usually makes the model more accurate. As a beginner, it goes without saying I don't fully understand all the parameters\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\nvalid_datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = to_categorical(y_train,num_classes=10) # the labels need to be one-hot encoded, this is something else I usually forget\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to modify the learning rate, if the loss does not change. Also saving the best weights of the model for prediction.\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', \n                                            patience=3, \n                                            verbose=10, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using this notebook as a guide https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist if you haven't read it, and you want to learn about cnn's do yourself a favour and read it\n\ndef build_model(input_shape=(28, 28, 1), classes = 10):\n    \n    activation = 'relu'\n    padding = 'same'\n    gamma_initializer = 'uniform'\n    \n    input_layer = Input(shape=input_shape)\n    \n    hidden=Conv2D(32, (3,3), padding=padding,activation = activation, name=\"conv1\")(input_layer)\n    hidden=BatchNormalization(name=\"batch1\")(hidden)\n    hidden=Conv2D(32, (3,3), padding=padding,activation = activation, name=\"conv2\")(hidden)\n    hidden=BatchNormalization(name=\"batch2\")(hidden)\n    hidden=Conv2D(32, (5,5), padding=padding,activation = activation, name=\"conv3\")(hidden)\n    hidden=BatchNormalization(name=\"batch3\")(hidden)\n    hidden=MaxPool2D(pool_size=2, padding=padding, name=\"max1\")(hidden)\n    hidden=Dropout(0.4)(hidden)\n\n    \n    \n    hidden=Conv2D(64, (3,3), padding =padding, activation = activation,  name=\"conv4\")(hidden)\n    hidden=BatchNormalization(name = 'batch4')(hidden)\n    hidden=Conv2D(64, (3,3), padding =padding, activation = activation,  name=\"conv45\")(hidden)\n    hidden=BatchNormalization(name = 'batch5')(hidden)\n    hidden=Conv2D(64, (5,5), padding =padding, activation = activation,  name=\"conv6\")(hidden)\n    hidden=BatchNormalization(name = 'batch6')(hidden)\n    hidden=MaxPool2D(pool_size=2, padding=\"same\", name=\"max2\")(hidden)\n    hidden=Dropout(0.4)(hidden)\n    \n\n    hidden=Flatten()(hidden)\n    hidden=Dense(264,activation = activation, name=\"Dense1\")(hidden)\n    hidden=Dropout(0.3)(hidden)\n    output = Dense(classes, activation = \"softmax\")(hidden)\n    \n    model = Model(inputs=input_layer, outputs=output)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#keras.backend.clear_session()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50\ninitial_learningrate=2e-3\nbatch_size = 264","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the optimizer\n#optimizer = Adam(learning_rate=initial_learningrate, beta_1=0.9, beta_2=0.999, amsgrad=False)\noptimizer = Adam(learning_rate=initial_learningrate)\n\n# Compile the model\n\n\nmodel = build_model(input_shape=(28, 28, 1), classes = 10)\n\n\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y_train, test_size=0.1, random_state=1337)\ndatagen.fit(X_train)\nvalid_datagen.fit(X_val)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [learning_rate_reduction]\nhistory = model.fit_generator(datagen.flow(X_train,y_train),\n                              epochs = epochs,\n                              validation_data=valid_datagen.flow(X_val,y_val),\n                              verbose = 1,\n                            callbacks = callbacks)\n\n# On the first attempt I forgot to add the 'learning_rate_reduction'\n\n#history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size ),\n#                              epochs = epochs,\n #                             validation_data=valid_datagen.flow(X_val,y_val),\n  #                            validation_steps = 50,\n   #                           verbose = 1,\n    #                          steps_per_epoch = X_train.shape[0] // batch_size,\n     #                       callbacks = callbacks)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a name=\"section-four\"></a>\n## How did we do?\n\nInterestingly for the first time, my notebook accuracy has been very similar to the leaderboard accuracy (version 9). That is encouraging! Now, that I am going to meddle with it I am sure it will change.\n- v10: Doubled the dense layer and increased the epochs by 10"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best')\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\n# used the code from https://www.kaggle.com/shahules/indian-way-to-learn-cnn to create this\n\ny_pre_test=model.predict(X_val)\ny_pre_test=np.argmax(y_pre_test,axis=1)\ny_test=np.argmax(y_val,axis=1)\n\nconf=confusion_matrix(y_test,y_pre_test)\nconf=pd.DataFrame(conf,index=range(0,10),columns=range(0,10))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.heatmap(conf, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('out of {} samples, we got {} incorrect'.format(len(X_train), round(len(X_train) - history.history['accuracy'][-1] * len(X_train))))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I think the model was struggling with classifying the 1s and 7s du to rotation, so i removed rotation. maybe?\n\nI am unsure why, but the results are very different to the leaderboard. "},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_val,axis = 1) \n\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 3\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True,figsize = (10,10))\n    fig.tight_layout()\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 9 errors \nmost_important_errors = sorted_dela_errors[-9:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(test[0].reshape(28,28))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = predictions.argmax(axis = -1)\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsubmission['Label'] = predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}