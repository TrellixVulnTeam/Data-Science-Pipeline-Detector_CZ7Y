{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\n\nimport nltk\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport nltk\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom wordcloud import WordCloud, STOPWORDS\nfrom string import punctuation\nfrom bs4 import BeautifulSoup\nimport re,string,unicodedata\nfrom nltk import pos_tag\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import wordnet, stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,plot_confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport collections","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/asap-aes/training_set_rel3.tsv', sep='\\t', encoding='ISO-8859-1')\ndf_test = pd.read_csv('/kaggle/input/asap-aes/test_set.tsv', sep='\\t', encoding='ISO-8859-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting more info about the test info\n\ndf_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting more info about the train dataset\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check how many values are none in each row of the train dataset\ndf_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since a large part of the dataset has columns with more than 70-80 percent missing values so Deleting those columns\ndf_train.dropna(axis = 1, inplace = True)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Describing the train set\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking how many unique essay id were given\nprint(df_train['essay_set'].nunique())\ndf_train['essay_set'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Counting the number of eacy essay_set\n\nprint(df_train.groupby('essay_set').size())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So there is 8 unique set of essay in the given training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets see the unique ratings which are being given by the rater1\n\nprint(df_train['rater1_domain1'].nunique())\ndf_train['rater1_domain1'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Counting the number of rates of each rates given by rater1\n\nprint(df_train.groupby('rater1_domain1').size())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is 30 rating points ranging from 0 to 30 excluding the 29 which have been given by rater1 to differen essay sests"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets see the unique ratings which are being given by the rater2\n\nprint(df_train['rater2_domain1'].nunique())\ndf_train['rater2_domain1'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Counting the number of rates of each rates given by rater1\n\nprint(df_train.groupby('rater1_domain1').size())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is 29 rating points ranging from 0 to 30 excluding the 28 and 29 which have been given by rater2 to differen essay sests"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Maximum domain score obtained by any essay\n\ndf_train['domain1_score'].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The maximum score that an essay scored is 60"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Minimum domain score obtained by any essay\n\ndf_train['domain1_score'].min()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The minimum score that was scored by any essay is 0"},{"metadata":{},"cell_type":"markdown","source":"## Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing the percentage wise share of the various sets of essay \n\nlabels = df_train['essay_set'].value_counts().index\nvalues = df_train['essay_set'].value_counts().values\n\ncolors = df_train['essay_set']\n\nfig = go.Figure(data = [go.Pie(labels = labels, values = values, textinfo = \"label+percent\",\n                              marker = dict(colors = colors, line=dict(color='#000000', width=2)), \n                              title = \"Distribution of sets of essay\")])\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"From the above Pie-Chart we can see that set 8 was the least distributed set "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing the percentage wise share of top 10 grades given by rater 1 and their percentage\n\nlabels = df_train['rater1_domain1'].value_counts()[:10].index\nvalues = df_train['rater1_domain1'].value_counts()[:10].values\n\ncolors = df_train['rater1_domain1']\n\nfig = go.Figure(data = [go.Pie(labels = labels, values = values, textinfo = \"label+percent\",\n                              marker = dict(colors = colors), \n                              title = \"Top 10 grades given by rater 1 and their percentage\")])\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above plot we can see that a large section of the essay rated by rater1 received just rating as 3,2,4 and 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing the percentage wise share of top 10 grades given by rater 1 and their percentage\n\nlabels = df_train['rater2_domain1'].value_counts()[:10].index\nvalues = df_train['rater2_domain1'].value_counts()[:10].values\n\ncolors = df_train['rater2_domain1']\n\nfig = go.Figure(data = [go.Pie(labels = labels, values = values, textinfo = \"label+percent\",\n                              marker = dict(colors = colors), \n                              title = \"Top 10 grades given by rater2 and their percentage\")])\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above plot we can see that a large section of the essay rated by rater2 received just rating as 3,2,4 and 1"},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"Data preprocessing is one of the critical steps in any machine learning project. It includes cleaning and formatting the data before feeding into a machine learning algorithm. For NLP, the preprocessing steps are comprised of the following tasks:\n\n* Tokenizing the string\n* Lowercasing\n* Removing stop words and punctuation\n* Stemming\n* Lemmatization"},{"metadata":{},"cell_type":"markdown","source":"### Cleaning the Text"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining function to clean the text\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying clean text function on short_description to clean the text of train set\n\ndf_train['essay'] = df_train['essay'].apply(lambda x: clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now checking whether the text of the essay columns have been changed or not\n\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the WordCloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"word_cloud = WordCloud(\n                       width=1600,\n                       height=800, \n                       margin=0,\n                       max_words=500, # Maximum numbers of words we want to see \n                       max_font_size=150, min_font_size=30,  # Font size range\n                       background_color=\"white\"\n            ).generate(\" \".join(df_train['essay']))\n\nplt.figure(figsize=(10, 16))\nplt.imshow(word_cloud, interpolation=\"gaussian\")\nplt.title('WordCloud of essay', fontsize = 40)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying clean text function on short_description to clean the text of test set\n\ndf_test['essay'] = df_test['essay'].apply(lambda x: clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_cloud = WordCloud(\n                       width=1600,\n                       height=800, \n                       margin=0,\n                       max_words=500, # Maximum numbers of words we want to see \n                       max_font_size=150, min_font_size=30,  # Font size range\n                       background_color=\"white\"\n            ).generate(\" \".join(df_test['essay']))\n\nplt.figure(figsize=(10, 16))\nplt.imshow(word_cloud, interpolation=\"gaussian\")\nplt.title('WordCloud of essay in test set', fontsize = 40)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tokenizing"},{"metadata":{"trusted":true},"cell_type":"code","source":"print()\ntext = \"I love you, don't you\"\n\n# instantiate tokenizer class\ntokenizer1 = nltk.tokenize.WhitespaceTokenizer()\ntokenizer2 = nltk.tokenize.TreebankWordTokenizer()\ntokenizer3 = nltk.tokenize.WordPunctTokenizer()\ntokenizer4 = nltk.tokenize.RegexpTokenizer(r'\\w+')\n\nprint(\"Example Text: \", text)\nprint(\"Tokenization by whitespace: \", tokenizer1.tokenize(text))\nprint(\"Tokenization by words using Treebank Word Tokenizer: \", tokenizer2.tokenize(text))\nprint(\"Tokenization by punctuation: \", tokenizer3.tokenize(text))\nprint(\"Tokenization by regular expression: \", tokenizer4.tokenize(text))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tokenizing the training and test set\n\n# instantiate the tokenizer class\ntokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n\n# Tokenizing the training set\ndf_train['essay'] = df_train['essay'].apply(lambda x: tokenizer.tokenize(x))\n\n# Tokenizing the test set\ndf_test['essay'] = df_test['essay'].apply(lambda x: tokenizer.tokenize(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing the tokenized string of the training set\nprint()\nprint('Tokenized String:')\ndf_train['essay'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing the tokenized string of the testing set\n\nprint()\nprint('Tokenized String:')\ndf_test['essay'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stopwords\n\nThe next step is to remove stop words. Stop words are words that don't add significant meaning to the text."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining function to remove the stopwords\n\ndef remove_stopwords(text):\n    \n    words = [word for word in text if word not in stopwords.words('english')]\n    return words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing the stopwords from the training set\n\ndf_train['essay'] = df_train['essay'].apply(lambda x: remove_stopwords(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing the stopwords from the test set\n\ndf_test['essay'] = df_test['essay'].apply(lambda x: remove_stopwords(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets now look at the training set\n\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets now look at the test set\n\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normalizing the Tokens and Stemming"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stemming and Lemmatization examples\n\ntext = \"How is the Josh\"\n\ntokenizer = nltk.tokenize.TreebankWordTokenizer()\ntokens = tokenizer.tokenize(text)\n\n# Stemmer \nstemmer = nltk.stem.PorterStemmer()\nprint(\"Stemming the sentence: \", \" \".join(stemmer.stem(token) for token in tokens))\n\n# Lemmatizer \nlemmatizer = nltk.stem.WordNetLemmatizer()\nprint(\"Lemmatizing the sentence: \", \" \".join(lemmatizer.lemmatize(token) for token in tokens))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# After preprocessing the text format\n\ndef combine_text(list_of_text):\n    \n    combined_text = ' '.join(list_of_text)\n    return combined_text\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing the train set\n\ndf_train['essay'] = df_train['essay'].apply(lambda x: combine_text(x))\n\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing the test set\n\ndf_test['essay'] = df_test['essay'].apply(lambda x: combine_text(x))\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# text preprocessing functions \ndef text_preprocessing(text):\n    \n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    \n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    remove_stopwords = [word for word in tokenized_text if word not in stopwords.words('english')]\n    combined_text = ' '.join(remove_stopwords)\n    return combined_text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transforming tokens to Vector"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CountVectorizer can do all the above task of preprocessing, tokenization, and stop words removal\n\ncount_vectorizer = CountVectorizer()\ntrain_vectors = count_vectorizer.fit_transform(df_train['essay'])\ntest_vectors = count_vectorizer.transform(df_test['essay'])\n\n# Keeping only non-zero elements to preserve spaces\nprint(train_vectors[0].todense())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TfidfVectorizer\n\ntfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\ntrain_tfidf = tfidf.fit_transform(df_train['essay'])\ntest_tfidf = tfidf.transform(df_test['essay'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building the Final Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's implement simple classifiers\n\nclassifiers = {\n    \"LogisiticRegression\": LogisticRegression(),\n    \"KNearest\": KNeighborsClassifier(n_neighbors=1),\n    \"Support Vector Classifier\": SVC(),\n    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n    \"MultinimialNB\": MultinomialNB()\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using the KNeighbors Classifiers\n\nfrom sklearn.model_selection import cross_val_score\n\nclassifier = KNeighborsClassifier()\n\nclassifier.fit(train_vectors, df_train[\"domain1_score\"])\ntraining_score = cross_val_score(classifier, train_vectors, df_train[\"domain1_score\"], cv=5)\nprint(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using the Logistic Regression\n\nfrom sklearn.model_selection import cross_val_score\n\nclassifier2 = LogisticRegression()\n\nclassifier2.fit(train_vectors, df_train[\"domain1_score\"])\ntraining_score = cross_val_score(classifier2, train_vectors, df_train[\"domain1_score\"], cv=5)\nprint(\"Classifiers: \", classifier2.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using the XGBoost\n\nimport xgboost as xgb\nfrom sklearn import model_selection\nclf_xgb = xgb.XGBClassifier(\n    learning_rate=0.1,\n    n_estimators=3000,\n    max_depth=15,\n    min_child_weight=1,\n    gamma=0,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective='multi:softmax',\n    nthread=42,\n    scale_pos_weight=1,\n    seed=27)\n\nscores = model_selection.cross_val_score(clf_xgb, train_vectors, df_train[\"domain1_score\"], cv=5, scoring=\"f1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}