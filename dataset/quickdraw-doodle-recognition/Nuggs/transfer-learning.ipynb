{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.datasets import load_files       \nfrom keras.utils import np_utils\n\nfrom glob import glob\n\nimport matplotlib.pyplot as plt\n\nfrom keras.callbacks import ModelCheckpoint  \n\nimport cv2                \nimport matplotlib.pyplot as plt                        \n%matplotlib inline \n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e689467b2c1e9dccd5465a92a898a7e029b3e932"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore') # to suppress some matplotlib deprecation warnings\n\nimport ast\nimport math\n\n# Have you installed your own package in Kernels yet? \n# If you need to, you can use the \"Settings\" bar on the right to install `simplification`\nfrom simplification.cutil import simplify_coords\n\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport glob\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d37d06cbd8fc0e9b3e49d6ea5e98e1c69bf6050"},"cell_type":"markdown","source":"## Loading data, changing space to undercore in labels "},{"metadata":{"trusted":true,"_uuid":"ec3130f023550bea9222c63604ef734a51e63d81"},"cell_type":"code","source":"# define function to load train, test, and validation datasets\n#def load_dataset(path):\n#    data = load_files(path)\n#    dog_files = np.array(data['filenames'])\n#    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n#    return dog_files, dog_targets\n\nfile_list = glob.glob('../input/train_simplified' + '/*.csv')\n\ntrain_files = []\ntrain_targets = []\nfor x in file_list[:10]:\n    train_data = pd.read_csv(x)\n    train_data[\"word\"] = train_data[\"word\"].replace(' ', '_', regex=True)\n    train_files.append(train_data[\"drawing\"])\n    train_targets.append(train_data[\"word\"])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7a7ff229ed503bd4688ebda8846ed954034a727"},"cell_type":"markdown","source":" ## Splitting data and labels and one hot encoding"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"c65f2cae29a518946a5e0655563b55f61564caba"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.utils import to_categorical\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\ny_train = np.asarray(train_targets)\nX_train = np.asarray(train_files)\n\nprint(train_data[\"drawing\"][0].shape)\nprint(X_train.shape)\nprint(y_train.shape)\n#one_hot = MultiLabelBinarizer()\n\n# One-hot encode data\n#one_hot.fit_transform(y_train)\n\n#one_hot.transform(y_train)\n\n\n# integer encoding\n#label_encoder = LabelEncoder()\n#integer_encoded = label_encoder.fit_transform(y_train)\n#print(integer_encoded)\n\n# binary encoding\n#onehot_encoder = OneHotEncoder(sparse=False)\n#integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n#onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n\n#encoded = to_categorical(integer_encoded, num_classes=10)\n#print(y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2625c35ea78605ef40b8a55199b0ee0c50dfaa40"},"cell_type":"code","source":"class_targets.head\n#print(type(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3043c10f8eac5bb4e495f6eead6b8d0d3c6e98b0"},"cell_type":"code","source":"#file_list = glob.glob('../input/train_simplified' + '/*.csv')\n#dfs=np.array([pd.read_csv(fp).values for fp in file_list])\n\n#data = pd.read_csv('../input/train_simplified/roller coaster.csv',\n#                   index_col='key_id',\n#nrows=100)#\n#train_data = []\n#i=0\n#for i in file_list:\n#    train_data = [pd.read_csv(i).values for fp in file_list]\n    \n#train_data = pd.read_csv(file_list[0])\n    \n    #classes[i] = file_list[i]\n    #classes[i] = classes[i].replace('../input/train_simplified/', '', regex=True)\n#print(train_data.head())\n#print(file_list[0])\n#print(train_data[\"drawing\"][0])\n#print(file_list)\n#data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa71190c7f2698d51546ac2e4c0c16cb83bfa481"},"cell_type":"code","source":"data['word'] = data['word'].replace(' ', '_', regex=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcdffd856ecd6e0a7d6a3d55448c0ab09ccaed6d"},"cell_type":"code","source":"test_raw = pd.read_csv('../input/test_raw.csv', index_col='key_id')\nfirst_ten_ids = test_raw.iloc[:10].index\nraw_images = [ast.literal_eval(lst) for lst in test_raw.loc[first_ten_ids, 'drawing'].values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdb50f43a43b55df436e8d5675cf3ebb3d7dd2c2"},"cell_type":"code","source":"def resample(x, y, spacing=1.0):\n    output = []\n    n = len(x)\n    px = x[0]\n    py = y[0]\n    cumlen = 0\n    pcumlen = 0\n    offset = 0\n    for i in range(1, n):\n        cx = x[i]\n        cy = y[i]\n        dx = cx - px\n        dy = cy - py\n        curlen = math.sqrt(dx*dx + dy*dy)\n        cumlen += curlen\n        while offset < cumlen:\n            t = (offset - pcumlen) / curlen\n            invt = 1 - t\n            tx = px * invt + cx * t\n            ty = py * invt + cy * t\n            output.append((tx, ty))\n            offset += spacing\n        pcumlen = cumlen\n        px = cx\n        py = cy\n    output.append((x[-1], y[-1]))\n    return output\n  \ndef normalize_resample_simplify(strokes, epsilon=1.0, resample_spacing=1.0):\n    if len(strokes) == 0:\n        raise ValueError('empty image')\n\n    # find min and max\n    amin = None\n    amax = None\n    for x, y, _ in strokes:\n        cur_min = [np.min(x), np.min(y)]\n        cur_max = [np.max(x), np.max(y)]\n        amin = cur_min if amin is None else np.min([amin, cur_min], axis=0)\n        amax = cur_max if amax is None else np.max([amax, cur_max], axis=0)\n\n    # drop any drawings that are linear along one axis\n    arange = np.array(amax) - np.array(amin)\n    if np.min(arange) == 0:\n        raise ValueError('bad range of values')\n\n    arange = np.max(arange)\n    output = []\n    for x, y, _ in strokes:\n        xy = np.array([x, y], dtype=float).T\n        xy -= amin\n        xy *= 255.\n        xy /= arange\n        resampled = resample(xy[:, 0], xy[:, 1], resample_spacing)\n        simplified = simplify_coords(resampled, epsilon)\n        xy = np.around(simplified).astype(np.uint8)\n        output.append(xy.T.tolist())\n\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d521e63efbd6b8ca324a6ea4860bbcc03b12dbf9"},"cell_type":"code","source":"simplified_drawings = []\nfor drawing in raw_images:\n    simplified_drawing = normalize_resample_simplify(drawing)\n    simplified_drawings.append(simplified_drawing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9cab0d6be48d78fdfad4e365f2833983adc6119"},"cell_type":"code","source":"for index, raw_drawing in enumerate(raw_images, 0):\n    \n    plt.figure(figsize=(6,3))\n    \n    for x,y,t in raw_drawing:\n        plt.subplot(1,2,1)\n        plt.plot(x, y, marker='.')\n        plt.axis('off')\n\n    plt.gca().invert_yaxis()\n    plt.axis('equal')\n\n    for x,y in simplified_drawings[index]:\n        plt.subplot(1,2,2)\n        plt.plot(x, y, marker='.')\n        plt.axis('off')\n\n    plt.gca().invert_yaxis()\n    plt.axis('equal')\n    plt.show()  \n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# define function to load train, test, and validation datasets\n#def load_dataset(path):\n#    data = load_files(path)\n#    dog_files = np.array(data['filenames'])\n#    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n#    return dog_files, dog_targets\n\ntrain_data = pd.read_csv('../input/train_simplified')\n\n# load train, test, and validation datasets\ntrain_files = data[\"drawing\"]\ntrain_targets = data[\"word\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d766b435ebb9c3b76f0d0870c754056b1c80bbb"},"cell_type":"code","source":"from keras.preprocessing import image                  \nfrom tqdm import tqdm\n\ndef path_to_tensor(img_path):\n    # loads RGB image as PIL.Image.Image type\n    img = image.load_img(img_path, target_size=(224, 224))\n    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n    x = image.img_to_array(img)\n    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n    return np.expand_dims(x, axis=0)\n\ndef paths_to_tensor(img_paths):\n    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n    return np.vstack(list_of_tensors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b1c3de84de31e3d7cd688eca57e83b5647bd05f"},"cell_type":"code","source":"# pre-process the data for Keras\ntrain_tensors = paths_to_tensor(train_files).astype('float32')/255\nvalid_tensors = paths_to_tensor(valid_files).astype('float32')/255\ntest_tensors = paths_to_tensor(test_files).astype('float32')/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e360685365cb4424b659c1c3e136df32a5a1f149"},"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Conv2D(filters =16,kernel_size = 2, padding = 'same',activation = 'relu', input_shape=(224,224,3)))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters =32,kernel_size = 2, padding = 'same',activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters =64,kernel_size = 2, padding = 'same',activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(filters =16,kernel_size = 2, padding = 'same',activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(filters =16,kernel_size = 2, padding = 'same',activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.3))\n\nmodel.add(GlobalAveragePooling2D())\n\n\nmodel.add(Dense(133, activation='softmax'))\n\n### TODO: Define your architecture.\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f52b16df9a6abd50a6b8a47a24128e707d10fc2"},"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e336b41a13298b2df2e0dcdfbe34796d53b412b"},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint  \n\n### TODO: specify the number of epochs that you would like to use to train the model.\n\nepochs = 50\n\n### Do NOT modify the code below this line.\n\ncheckpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n                               verbose=1, save_best_only=True)\n\nmodel.fit(train_tensors, train_targets, \n          validation_data=(valid_tensors, valid_targets),\n          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"255a1f0270d0fd62642972bc03edd1567004c5bd"},"cell_type":"code","source":"model.load_weights('saved_models/weights.best.from_scratch.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e2509442cbb341716430516f6342259a9aa1a4f"},"cell_type":"code","source":"# get index of predicted dog breed for each image in test set\ndog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n\n# report test accuracy\ntest_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\nprint('Test accuracy: %.4f%%' % test_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"839d05bb7f5102f42353a72bfbced828458302ae"},"cell_type":"code","source":"### TODO: Obtain bottleneck features from another pre-trained CNN.\nbottleneck_features = np.load('/data/bottleneck_features/DogInceptionV3Data.npz')\ntrain_inception = bottleneck_features['train']\nvalid_inception = bottleneck_features['valid']\ntest_inception = bottleneck_features['test']\n\nprint(test_inception.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f363af8feaa466726493beca2fb2e00242397df9"},"cell_type":"code","source":"### TODO: Define your architecture.\ninception_model = Sequential()\ninception_model.add(GlobalAveragePooling2D(input_shape=train_inception.shape[1:]))\ninception_model.add(Dense(133, activation='softmax'))\n\ninception_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64352f4727aadd2ddfbe0259885a1c12fd9220c3"},"cell_type":"code","source":"### TODO: Compile the model.\ninception_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8311ca48fa3195713bafb6e6103edba0436654c"},"cell_type":"code","source":"### TODO: Train the model.\ncheckpointer = ModelCheckpoint(filepath='saved_models/weights.best.InceptionV3.hdf5', \n                               verbose=1, save_best_only=True)\n\ninception_model.fit(train_inception, train_targets, \n          validation_data=(valid_inception, valid_targets),\n          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"884bbafcb885fee933e7bbeb10ed2e7eddf1d6c9"},"cell_type":"code","source":"### TODO: Load the model weights with the best validation loss.\ninception_model.load_weights('saved_models/weights.best.InceptionV3.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0366e4598f53d4d24ba3a4a3946fcd73e0318396"},"cell_type":"code","source":"### TODO: Calculate classification accuracy on the test dataset.\n# get index of predicted dog breed for each image in test set\ninception_predictions = [np.argmax(inception_model.predict(np.expand_dims(feature, axis=0))) for feature in test_inception]\n\n# report test accuracy\ntest_accuracy = 100*np.sum(np.array(inception_predictions)==np.argmax(test_targets, axis=1))/len(inception_predictions)\nprint('Test accuracy: %.4f%%' % test_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63d96ba03f94c4a35755ffd19a2816c27dc029d1"},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv', index_col='key_id')\n# Don't forget, your multi-word labels need underscores instead of spaces!\nmy_favorite_words = ['donut', 'roller_coaster', 'smiley_face']  \nsubmission['word'] = \" \".join(my_favorite_words)\nsubmission.to_csv('my_favorite_words.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27b7a2c6482599a388514bdedf0bae04d86a1444"},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da20424e4dc8bc5c17b139ea6ed02fd5acbe4b68"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}