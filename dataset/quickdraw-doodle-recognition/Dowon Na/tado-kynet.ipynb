{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from PIL import Image , ImageDraw\nfrom sklearn.preprocessing import *\nimport time\nimport ast\nimport os\nimport json\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport glob\nimport re\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nfrom tqdm import tqdm\nfrom keras import layers\nfrom keras import models \nfrom keras import regularizers\nfrom keras.layers import Activation\nfrom keras.layers import BatchNormalization \nfrom keras.layers import DepthwiseConv2D\nfrom keras.layers import MaxPooling2D\nimport keras\n\n\nfrom keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n\n\nimport os\nfol = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        fol.append(filename)\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def make_img(img_arr) :\n    image = Image.new(\"P\", (256,256), color=255)\n    image_draw = ImageDraw.Draw(image)\n    for stroke in img_arr:\n        for i in range(len(stroke[0])-1):\n            image_draw.line([stroke[0][i], \n                             stroke[1][i],\n                             stroke[0][i+1], \n                             stroke[1][i+1]],\n                            fill=0, width=5)\n    return image\n# img = make_img(img_arr[3])\n# plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing(filenames) :\n    img_batch = 2000\n    X= []\n    Y= []\n    class_label = []\n    st_time = time.time()\n    class_num = 340\n    Y_num = 0\n    for fname in tqdm(filenames[0:class_num]) :\n        #percent_bar(filenames[0:class_num],Y_num+1,st_time)\n        df = pd.read_csv(os.path.join(dirname,fname))\n        df['word'] = df['word'].replace(' ','_',regex = True)\n        class_label.append(df['word'][0])\n        keys = df.iloc[:img_batch].index\n        #print(len(keys))\n        \n        for i in range(len(df.loc[keys,'drawing'].values)) :\n            if df.loc[keys,'recognized'].values[i] == True :\n                drawing = ast.literal_eval(df.loc[keys,'drawing'].values[i])\n                img = make_img(drawing)\n                img = np.array(img.resize((64,64)))\n                img = img.reshape(64,64,1)\n                X.append(img)\n                Y.append(Y_num)\n        Y_num += 1\n        \n    tmpx = np.array(X)\n\n    Y = np.array([[i] for i in Y])\n    enc = OneHotEncoder(categories='auto')\n    enc.fit(Y)\n    tmpy = enc.transform(Y).toarray()\n    \n#     del X\n#     del Y     #RAM메모리 절약을 위해 사용하지 않는 변수 삭제\n    \n    return tmpx , tmpy , class_label , class_num\n\ntmpx , tmpy , class_label , class_num = preprocessing(filenames)\nprint('\\n',tmpx.shape, tmpy.shape, '\\n5th class : ',class_label[0:5])\n#df.head()\n#print(drawing[0])\n#img = make_img(drawing[1])\n#plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(tmpx,tmpy, test_size = 0.1,random_state = 3)\n    #RAM메모리 절약을 위해 사용하지 않는 변수 삭제\n\nprint(x_train.shape,x_test.shape,y_train.shape,y_test.shape)\ndel tmpx\ndel tmpy ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fil = 5\n# model = models.Sequential()\n# #model.add(layers.Conv2D(32,(fil,fil), activation='relu', input_shape=(50,50,1),padding='same',kernel_regularizer=regularizers.l2(0.1)))\n# model.add(layers.Conv2D(32,(fil,fil), activation='relu', input_shape=(64,64,1),padding='same'))\n# model.add(BatchNormalization(center=True, scale=True))\n# model.add(Activation('relu'))  \n# model.add(DepthwiseConv2D((64,64),strides=(1,1),padding='same'))\n# model.add(BatchNormalization(center=True, scale=True))\n# model.add(Activation('relu'))  \n# #model.add(layers.Dropout(0.2))\n\n# model.add(layers.Conv2D(64,(fil,fil), activation='relu',padding='same'))\n# model.add(BatchNormalization(center=True, scale=True))\n# model.add(Activation('relu'))  \n# model.add(DepthwiseConv2D((32,32),strides=(2,2),padding='same'))\n# model.add(BatchNormalization(center=True, scale=True))\n# model.add(Activation('relu')) \n\n# model.add(layers.Conv2D(128,(fil,fil), activation='relu',padding='same'))\n# model.add(BatchNormalization(center=True, scale=True))\n# model.add(Activation('relu'))  \n# model.add(DepthwiseConv2D((16,16),strides=(2,2),padding='same'))\n# model.add(BatchNormalization(center=True, scale=True))\n# model.add(Activation('relu')) \n\n# model.add(layers.Conv2D(256,(fil,fil), activation='relu',padding='same'))\n# model.add(BatchNormalization(center=True, scale=True))\n# model.add(Activation('relu'))  \n# model.add(DepthwiseConv2D((8,8),strides=(2,2),padding='same'))\n# model.add(BatchNormalization(center=True, scale=True))\n# model.add(Activation('relu')) \n\n\n# model.add(layers.Conv2D(128,(fil,fil), activation='relu',padding='same'))\n# model.add(BatchNormalization(center=True, scale=True))\n# model.add(Activation('relu'))  \n# model.add(DepthwiseConv2D((4,4),strides=(2,2),padding='same'))\n# model.add(BatchNormalization(center=True, scale=True))\n# model.add(Activation('relu')) \n\n# model.add(layers.Flatten())\n# model.add(layers.Dense(4*4*128))\n# model.add(BatchNormalization(center=True, scale=True))\n# model.add(layers.Dense(340,activation='softmax'))\n\n\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fil = 5\nmodel = models.Sequential()\n#model.add(layers.Conv2D(32,(fil,fil), activation='relu', input_shape=(50,50,1),padding='same',kernel_regularizer=regularizers.l2(0.1)))\nmodel.add(layers.Conv2D(32,(fil,fil), activation='relu', input_shape=(64,64,1),padding='same'))\nmodel.add(BatchNormalization(center=True, scale=True))\nmodel.add(Activation('relu'))  \nmodel.add(MaxPooling2D((2,2),padding='same'))\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(layers.Conv2D(64,(fil,fil), activation='relu',padding='same'))\nmodel.add(BatchNormalization(center=True, scale=True))\nmodel.add(Activation('relu'))  \nmodel.add(MaxPooling2D((2,2),padding='same'))\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(layers.Conv2D(128,(fil,fil), activation='relu',padding='same'))\nmodel.add(BatchNormalization(center=True, scale=True))\nmodel.add(Activation('relu'))  \nmodel.add(MaxPooling2D((2,2),padding='same'))\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(layers.Conv2D(256,(fil,fil), activation='relu',padding='same'))\nmodel.add(BatchNormalization(center=True, scale=True))\nmodel.add(Activation('relu'))  \nmodel.add(MaxPooling2D((1,1),padding='same'))\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(layers.Conv2D(512,(fil,fil), activation='relu',padding='same'))\nmodel.add(BatchNormalization(center=True, scale=True))\nmodel.add(Activation('relu'))  \nmodel.add(MaxPooling2D((1,1),padding='same'))\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(layers.Conv2D(256,(fil,fil), activation='relu',padding='same'))\nmodel.add(BatchNormalization(center=True, scale=True))\nmodel.add(Activation('relu'))  \nmodel.add(MaxPooling2D((1,1),padding='same'))\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(keras.layers.GlobalAveragePooling2D(data_format=None))\nmodel.add(layers.Dense(340,activation='softmax'))\n# model.add(layers.Flatten())\n# model.add(layers.Dense(4*4*256))\n# model.add(BatchNormalization(center=True, scale=True))\n# model.add(layers.Dense(340,activation='softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.metrics import top_k_categorical_accuracy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\ndef top_3_accuracy(x,y): \n    t3 = top_k_categorical_accuracy(x,y, 3)\n    return t3\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n                                   verbose=1, mode='auto', cooldown=5, min_lr=0.00025)\n\n\n\nearlystop = EarlyStopping(monitor='val_top_3_accuracy', mode='max', patience=5) \ncallbacks = [reduceLROnPlat,earlystop]\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy', top_3_accuracy])\nhists = []\nhist  = model.fit(x=x_train, y=y_train,\n          batch_size = 100,\n          epochs = 50,\n          validation_data = (x_test, y_test),\n          callbacks = callbacks,\n          verbose = 1)\n\nhists.append(hist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_df = pd.concat([pd.DataFrame(hist.history) for hist in hists], sort=True)\nhist_df.index = np.arange(1, len(hist_df)+1)\nfig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))\naxs[0].plot(hist_df.val_accuracy, lw=5, label='Validation Accuracy')\naxs[0].plot(hist_df.accuracy, lw=5, label='Training Accuracy')\naxs[0].set_title('--acc--')\naxs[0].set_ylabel('Accuracy')\naxs[0].set_xlabel('Epoch')\naxs[0].grid()\naxs[0].legend(loc=0)\naxs[1].plot(hist_df.val_loss, lw=5, label='Validation MLogLoss')\naxs[1].plot(hist_df.loss, lw=5, label='Training MLogLoss')\naxs[1].set_title('--Loss--')\naxs[1].set_ylabel('MLogLoss')\naxs[1].set_xlabel('Epoch')\naxs[1].grid()\naxs[1].legend(loc=0)\nfig.savefig('hist.png', dpi=300)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(hist_df.val_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(hist_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(hist_df.loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del x_train\n# del y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(x_test, y_test)\nprint(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing_test(df) :\n    X= []\n    keys = df.iloc[:].index\n    for i in tqdm(range(len(df.loc[keys,'drawing'].values))) :\n        drawing = ast.literal_eval(df.loc[keys,'drawing'].values[i])\n        img = make_img(drawing)\n        img = np.array(img.resize((64,64)))\n        img = img.reshape(64,64,1)\n        X.append(img)\n    \n    tmpx = np.array(X)\n    return tmpx\n\ntest = pd.read_csv(os.path.join('/kaggle/input/quickdraw-doodle-recognition', 'test_simplified.csv'))\nx_test = preprocessing_test(test)\nprint(test.shape, x_test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs = x_test\npred = model.predict(imgs, verbose=1)\ntop_3 = np.argsort(-pred)[:, 0:3]\nprint(\"Finished !!\")\n\n#print(pred)\nprint(top_3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_3_pred = ['%s %s %s' % (class_label[k[0]], class_label[k[1]], class_label[k[2]]) for k in top_3]\nprint(top_3_pred[0:5])\npreds_df = pd.read_csv('/kaggle/input/quickdraw-doodle-recognition/sample_submission.csv', index_col=['key_id'])\npreds_df['word'] = top_3_pred\npreds_df.to_csv('subcnn_small.csv')\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}