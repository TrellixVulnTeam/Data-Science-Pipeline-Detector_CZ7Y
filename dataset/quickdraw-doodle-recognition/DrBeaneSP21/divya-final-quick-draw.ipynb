{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Quick, Draw!\n\n#### Divya Sanathkumar\n\n\n\n\nThe Quick Draw dataset is a collection of images hand drawn by users which consists of about 340 classes. The goal is to build a Neural network that tries to classify these hand drawn images. In order to do that, a Convolutional Neural Networks, used to analyze visual imagery, is built. The data is split into training and validation sets and is fed to this CNN model to predict the accuracy of the image recognition.","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport math\nfrom tqdm import tqdm\nfrom PIL import Image\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import *\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load and Prep Data","metadata":{}},{"cell_type":"code","source":"candle_data = pd.read_csv('../input/quickdraw-doodle-recognition/train_simplified/candle.csv')\ncandle_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strokes_str = candle_data.drawing[50]\nprint(type(strokes_str))\nprint(strokes_str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strokes_list = eval(strokes_str)\nprint(type(strokes_list))\nprint(len(strokes_list))\n\nfor s in strokes_list:\n    print(s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label Encoder","metadata":{}},{"cell_type":"code","source":"path = os.listdir('../input/quickdraw-doodle-recognition/train_simplified')\nuniq_labels = np.array(sorted([x[:-4] for x in path]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(uniq_labels))\nprint(uniq_labels[:20])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc = LabelEncoder()\nenc.fit(uniq_labels)\n\ntemp = uniq_labels[[0, 37, 42]] \nprint(temp)\nprint(enc.transform(temp))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_lookup = pd.DataFrame({\n    'label' : list(map(lambda x : x.replace(' ', '_'), uniq_labels)),\n})\n\nlabel_lookup.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_lookup.to_csv('path' + 'label_lookup.csv', header=True, index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Batch Size and Steps Per Epoch","metadata":{}},{"cell_type":"code","source":"n_train = 24854214\nn_valid = 24854043\n\nprint(n_train)\nprint(n_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bs = 64\n\ntrain_steps = 100\nvalid_steps = 100\n\nprint(train_steps)\nprint(valid_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training and Validation Sets","metadata":{}},{"cell_type":"code","source":"train_temp = pd.read_csv('../input/quickdrawcombined/train.csv', chunksize=bs)\nnext(train_temp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/quickdrawcombined/train.csv', chunksize=bs)\nvalid = pd.read_csv('../input/quickdrawcombined/valid.csv', chunksize=bs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generators","metadata":{}},{"cell_type":"markdown","source":"## img_to_np Function","metadata":{}},{"cell_type":"code","source":"def img_to_np(img_str, ht, wt, lw, pad):\n    if img_str == 'drawing':\n        print(np.zeros((ht, wt), np.uint8))\n    \n    strokes = eval(img_str)\n    \n    ht_ = ht - 2*pad\n    wt_ = wt - 2*pad\n    \n    img = np.zeros((ht, wt), np.uint8)\n\n    for s in strokes:\n        sx = (np.array(s[0]) * wt_ / 256).round().astype('int') + pad\n        sy = (np.array(s[1]) * ht_ / 256).round().astype('int') + pad\n        for i in range(len(sx) - 1):\n            p1 = (sx[i],   sy[i])\n            p2 = (sx[i+1], sy[i+1])\n            img = cv2.line(img, p1, p2, (255, 0, 0), lw, lineType=cv2.LINE_AA)\n            \n    return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_array = img_to_np(strokes_str, 64,64,1,5)\n\nplt.imshow(img_array, cmap='binary')\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Generator","metadata":{}},{"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    \n    #####################################################################\n    # Constructor\n    # - df is a TextFileReader for reading in DataFrame\n    #####################################################################\n    def __init__(self, df, n_classes, batch_size, n_steps, img_params):\n        #self.path = path\n        self.df = df\n        self.n_classes = n_classes\n        self.batch_size = batch_size\n        self.n_steps = n_steps\n        self.img_params = img_params\n        \n    #####################################################################\n    # __getitem__ \n    # This is directly called by Keras methods. It returns a single \n    # batch of data. \n    #####################################################################\n    def __getitem__(self, index):\n        \n        # Typically, this would determine the rows to select for the\n        # current batch. In our case, we will simply grab the next \n        # batch from the TextFileReader\n\n        X, y = self.__data_generation(index)\n\n        return X, y\n\n    #####################################################################\n    # __data_generation \n    # This is called by __getitem__ to generate the batch.\n    #####################################################################\n    def __data_generation(self, index):\n\n        # Get next batch\n        batch = next(self.df)\n\n        # Create blank canvas\n        ht, wt, lw, pad = self.img_params\n        X = np.zeros(shape=(len(batch), ht, wt, 1))\n        \n        ###########################################################\n        #print(index, len(batch), batch.columns)\n\n\n        # Process each image in the batch\n        for i, img_str in enumerate(batch.drawing.values):\n\n            if img_str == 'drawing':\n                img_str == batch.drawing.values[i+1]\n                batch.word.values[i] = batch.word.values[i+1]\n\n            X[i, :, :, 0] = img_to_np(img_str, ht, wt, lw, pad) / 255\n\n        # Get batch labels\n        labels = batch.word.values\n        y = enc.transform(labels)\n\n        return X, y\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return self.n_steps\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Display Batch Images","metadata":{}},{"cell_type":"code","source":"temp_dg = DataGenerator(train_temp, n_classes=20, batch_size=bs, n_steps=10,\n                        img_params=(64, 64, 1, 2))\n\nX, y = temp_dg.__getitem__(2)\n\nlabels = uniq_labels[y]\n\nplt.figure(figsize=[12,12])\nfor i in range(64):\n    plt.subplot(8,8,i+1)\n    plt.imshow(X[i,:,:,0], cmap='binary')\n    plt.title(labels[i])\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Train and Valid Generators","metadata":{}},{"cell_type":"code","source":"train_dg = DataGenerator(train, batch_size=bs, n_classes=20, n_steps=train_steps,\n                         img_params=(64, 64, 1, 2))\n\nvalid_dg = DataGenerator(valid, batch_size=bs, n_classes=20, n_steps=valid_steps,\n                         img_params=(64, 64, 1, 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN","metadata":{}},{"cell_type":"markdown","source":"## Build Network","metadata":{}},{"cell_type":"code","source":"np.random.seed(1)\n\ncnn = Sequential()\n\ncnn.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same', input_shape=(64,64,1)))\ncnn.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(MaxPooling2D(2,2))\ncnn.add(BatchNormalization())\n\ncnn.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(MaxPooling2D(2,2))\ncnn.add(BatchNormalization())\n\ncnn.add(Conv2D(512, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(Conv2D(512, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(MaxPooling2D(2,2))\ncnn.add(BatchNormalization())\n\ncnn.add(Conv2D(1024, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(Conv2D(1024, (3,3), activation = 'relu', padding = 'same'))\ncnn.add(MaxPooling2D(2,2))\ncnn.add(BatchNormalization())\ncnn.add(Flatten())\n\ncnn.add(Dense(2048, activation='relu'))\ncnn.add(BatchNormalization())\n\ncnn.add(Dense(1024, activation='relu'))\ncnn.add(BatchNormalization())\n\ncnn.add(Dense(512, activation='relu'))\ncnn.add(BatchNormalization())\n\ncnn.add(Dense(340, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Network","metadata":{}},{"cell_type":"markdown","source":"### Run 1","metadata":{}},{"cell_type":"code","source":"%%time \n\nopt = keras.optimizers.Adam(0.001)\ncnn.compile(loss='SparseCategoricalCrossentropy', optimizer=opt, metrics=['accuracy'])\n\nh1 = cnn.fit(train_dg, validation_data=valid_dg,\n             verbose=1, epochs=100, batch_size = 1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Function to display plot","metadata":{}},{"cell_type":"code","source":"def vis_training(hlist, start=1, size=[12,6], show_val=True):\n    tr_loss = []\n    va_loss = []\n    tr_acc = []\n    va_acc = []\n    for h in hlist:\n        tr_loss += h.history['loss'] \n        va_loss += h.history['val_loss']\n        tr_acc += h.history['accuracy'] \n        va_acc += h.history['val_accuracy']\n    \n    plt.figure(figsize = size)\n    a = start\n    b = len(tr_loss) + 1\n    plt.subplot(1,2,1)\n    plt.plot(range(a,b), tr_loss[a-1:], label='Training')\n    if(show_val): \n        plt.plot(range(a,b), va_loss[a-1:], label='Validation')\n    plt.title('Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.grid()\n    plt.legend()\n    plt.subplot(1,2,2)\n    plt.plot(range(a,b), tr_acc[a-1:], label='Training')\n    if(show_val):  \n        plt.plot(range(a,b), va_acc[a-1:], label='Validation')\n    plt.title('Accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.grid()\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vis_training([h1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run 2","metadata":{}},{"cell_type":"code","source":"h2 = cnn.fit(train_dg, validation_data=valid_dg,\n             verbose=1, epochs=100,batch_size=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vis_training([h1,h2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run 3","metadata":{}},{"cell_type":"code","source":"keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)\nh3 = cnn.fit(train_dg, validation_data=valid_dg,\n             verbose=1, epochs=100,batch_size=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vis_training([h1, h2, h3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the Model","metadata":{}},{"cell_type":"markdown","source":"## Distribution of Top 3 Probabilities","metadata":{}},{"cell_type":"code","source":"def get_top_3(probs):\n    top_classes = np.argpartition(probs, -3)[-3:]                  # Gives top 3 classes in increasing order\n    top_classes = top_classes[np.argsort(probs[top_classes])]      # Sorts in increasing order\n    top_classes = np.flip(top_classes)                             # Flips the order.\n    top_probs = probs[top_classes]              \n\n    return top_probs, top_classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NB = len(train_dg)\n#NB = 10\n\ntop_3_probs = np.zeros(shape=(64*NB, 3))\n\nfor i in range(NB):\n    batch_imgs, batch_labels = train_dg.__getitem__(i)\n    batch_pred = cnn.predict(batch_imgs)\n\n    ## Loop over each image in the batch\n    for j in range(64):\n        top_probs, top_classes = get_top_3(batch_pred[j, :])\n        top_3_probs[i,:] = top_probs\n\nprint(top_3_probs.shape)\n\nplt.figure(figsize=[10,6])\nfor i in range(3):\n    plt.subplot(3,1,i+1)\n    plt.hist(top_3_probs[:,i], color='orchid', edgecolor='k', bins = np.arange(0, 1.01, 0.025))\n    plt.yscale('log')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MAP at 3","metadata":{}},{"cell_type":"code","source":"def MAP3(t):\n    NB = len(valid_dg)\n    #NB = 20\n\n    sum_ap3 = 0\n    N_obs = 0\n\n    for i in range(NB):\n        batch_imgs, batch_labels = train_dg.__getitem__(i)\n        batch_pred = cnn.predict(batch_imgs)\n\n        ## Loop over each image in the batch\n        for j in range(64):\n            probs = batch_pred[j, :]\n            top_classes = np.argpartition(probs, -3)[-3:]                  # Gives top 3 classes in increasing order\n            top_classes = top_classes[np.argsort(probs[top_classes])]      # Sorts in increasing order\n            top_classes = np.flip(top_classes)                             # Flips the order.\n\n            top_probs = probs[top_classes]              # Don't need this when not using a threshold\n\n            # Keep Probs Over Threshold\n            sel = top_probs > t\n            sel[0] = True                               # Always keep first pred\n            top_classes = top_classes[sel]\n\n            K = len(top_classes)   # Number of classes to submit\n            if K == 3:\n                scores = np.array([11/18, 5/18, 2/18])\n            elif K == 2:\n                scores = np.array([3/4, 1/4])\n            else:\n                scores = np.array([1])\n            \n            sel = (top_classes == batch_labels[j])\n            ap3 = np.sum(scores * sel)\n\n            sum_ap3 += ap3\n            N_obs += 1\n            \n            #print(ap3)\n\n    map3 = sum_ap3 / N_obs\n\n    return map3\n\nfor t in np.arange(0, 1.01, 0.05):\n    print(round(t, 2), '\\t', MAP3(t))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nMAP3_scores = []\nt_array = np.arange(0.05, 1.01, 0.05) \n\nfor t in t_array:\n    MAP3_scores.append(MAP3(t))\n\nplt.plot(t_array, MAP3_scores)\nplt.scatter(t_array, MAP3_scores)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CAM","metadata":{}},{"cell_type":"markdown","source":"## Create CAM Function","metadata":{}},{"cell_type":"code","source":"class GradCAM:\n    def __init__(self, model, classIdx, layerName=None):\n        self.model = model\n        self.classIdx = classIdx\n        self.layerName = layerName\n        if self.layerName is None:\n            self.layerName = self.find_target_layer()\n            \n    def find_target_layer(self):\n        for layer in reversed(self.model.layers):\n            if len(layer.output_shape) == 4:\n                return layer.name\n        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n        \n    def compute_heatmap(self, image, eps=1e-8):\n        gradModel = Model(\n            inputs=[self.model.inputs],\n            outputs=[self.model.get_layer(self.layerName).output,self.model.output]\n       )\n           \n        with tf.GradientTape() as tape:\n            inputs = tf.cast(image, tf.float32)\n            (convOutputs, predictions) = gradModel(inputs)\n            loss = predictions[:, self.classIdx]\n            grads = tape.gradient(loss, convOutputs)\n\n            castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n            castGrads = tf.cast(grads > 0, \"float32\")\n            guidedGrads = castConvOutputs * castGrads * grads\n            convOutputs = convOutputs[0]\n            guidedGrads = guidedGrads[0]\n\n            weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n            cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n\n            (w, h) = (image.shape[2], image.shape[1])\n            heatmap = cv2.resize(cam.numpy(), (w, h))\n            numer = heatmap - np.min(heatmap)\n            denom = (heatmap.max() - heatmap.min()) + eps\n            heatmap = numer / denom\n            heatmap = (heatmap * 255).astype(\"uint8\")\n        return heatmap\n\n    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n        colormap = cv2.COLORMAP_VIRIDIS):\n        heatmap = cv2.applyColorMap(heatmap, colormap)\n        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n        return (heatmap, output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_new = pd.read_csv('../input/quickdrawcombined/train.csv', chunksize=bs)\n\ntrain_dg = DataGenerator(train_new, batch_size=bs, n_classes=20, n_steps=train_steps,\n                         img_params=(64, 64, 1, 2))\n\nX, y = train_dg.__getitem__(2)\n\nlabels = uniq_labels[y]\n\nplt.figure(figsize=[12,12])\nfor i in range(64):\n    plt.subplot(8,8,i+1)\n    plt.imshow(X[i,:,:,0], cmap='binary')\n    plt.title(labels[i])\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_pred = cnn.predict(X)\nbatch_pred.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=[16,48])\nfor n in range(64):\n\n    top_probs, top_classes = get_top_3(batch_pred[n, :])\n    \n    cam = GradCAM(cnn, top_classes[0])             \n    heatmap = cam.compute_heatmap(X[[n], :, :, :]) \n\n    plt.subplot(16,4,n+1)\n    plt.imshow(X[n,:,:,0], cmap='binary')\n    plt.imshow(heatmap, alpha=0.6, cmap='coolwarm')\n    plt.title(f'{labels[n]} - {uniq_labels[top_classes]} \\n{top_classes} - {top_probs.round(2)}')\n    plt.axis('off')\n    \nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the Model","metadata":{}},{"cell_type":"code","source":"cnn.save('demo_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Test Data","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/quickdraw-doodle-recognition/test_simplified.csv')\nprint(test.shape)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert Test Strings to Arrays","metadata":{}},{"cell_type":"code","source":"def img_to_np(img_str, ht, wt, lw, pad):\n\n    strokes = eval(img_str)\n\n    ht_ = ht - 2*pad\n    wt_ = wt - 2*pad\n\n    img = np.zeros((ht, wt), np.uint8)\n\n    for s in strokes:\n        sx = (np.array(s[0]) * wt_ / 256).round().astype('int') + pad\n        sy = (np.array(s[1]) * ht_ / 256).round().astype('int') + pad\n\n        for i in range(len(sx) - 1):\n            p1 = (sx[i],   sy[i])\n            p2 = (sx[i+1], sy[i+1])\n            img = cv2.line(img, p1, p2, (255, 0, 0), lw, lineType=cv2.LINE_AA)\n            #img = cv2.resize(img, (ht, wt))\n    return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs = np.zeros(shape = (test.shape[0], 64, 64, 1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfor i, row in test.iterrows():\n    test_imgs[i,:,:,0] = img_to_np(row.drawing, 64, 64, 1, 2) / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=[12,12])\nfor i in range(64):\n    plt.subplot(8,8,i+1)\n    plt.imshow(test_imgs[i,:,:,0], cmap='binary')\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = test.sample(64)\nsample.shape\n\nplt.figure(figsize=[12,12])\nfor i in range(64):\n    plt.subplot(8,8,i+1)\n    plt.imshow(img_to_np(sample.drawing.values[i], 64, 64, 1, 2), cmap='binary')\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Model","metadata":{}},{"cell_type":"code","source":"cnn = keras.models.load_model('./demo_model.h5')\ncnn.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate Predictions","metadata":{}},{"cell_type":"code","source":"test_imgs.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nprobs = cnn.predict(test_imgs)\n\nprint(probs.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Top 3 Probabilities","metadata":{}},{"cell_type":"code","source":"N_train = probs.shape[0]\ntop_3_probs = np.zeros(shape=(N_train, 3))\n\nfor i in range(N_train):\n    p = probs[i, :]\n    top_classes = np.argpartition(p, -3)[-3:]                      # Gives top 3 classes in increasing order\n    top_classes = top_classes[np.argsort(p[top_classes])]      # Sorts in increasing order\n    top_classes = np.flip(top_classes)                             # Flips the order.\n\n    top_probs = p[top_classes]              \n\n    top_3_probs[i,:] = top_probs\n    \nprint(top_3_probs[:10, :].round(2))\n\nprint(top_3_probs.shape)\n\nplt.figure(figsize=[10,6])\nfor i in range(3):\n    plt.subplot(3,1,i+1)\n    plt.hist(top_3_probs[:,i], color='orchid', edgecolor='k', bins = np.arange(0, 1.01, 0.025))\n    plt.yscale('log')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Determine Predictions","metadata":{}},{"cell_type":"code","source":"N_train = probs.shape[0]\npredictions = []\n\nt = 0.35\n\nfor i in range(N_train):\n    p = probs[i, :]\n    top_classes = np.argpartition(p, -3)[-3:]                   # Gives top 3 classes in increasing order\n    top_classes = top_classes[np.argsort(p[top_classes])]       # Sorts in increasing order\n    top_classes = np.flip(top_classes)                          # Flips the order.\n\n    top_probs = p[top_classes]              \n\n    # Keep Probs Over Threshold\n    sel = top_probs > t\n    sel[0] = True                               # Always keep first pred\n    predictions.append(top_classes[sel])\n    \nprint(len(predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Submission","metadata":{}},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/quickdraw-doodle-recognition/sample_submission.csv')\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(submission)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_lookup_df = pd.read_csv('path' + 'label_lookup.csv')\nlabel_lookup = {k:v for k,v in zip(label_lookup_df.index.values, label_lookup_df.label.values)}\nlabel_lookup[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfor i in range(N_train):\n    classes = predictions[i]\n    words_list = [label_lookup[c] for c in classes]\n    words_string = ' '.join(words_list)\n    submission.loc[i, 'word'] = words_string\n    #print(words_string)\n    \nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Images with Predictions","metadata":{}},{"cell_type":"code","source":"idx = np.random.choice(range(N_train), 64, replace=False)\ntest_sample = test.iloc[idx,:]\nsub_sample = submission.iloc[idx, :]\n\nplt.figure(figsize=[16,16])\n\nfor i in range(64):\n    plt.subplot(8,8,i+1)\n    plt.imshow(img_to_np(test_sample.drawing.values[i], 64, 64, 1, 2), cmap='binary')\n    plt.title(sub_sample.word.values[i].replace(' ', '\\n'))\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}