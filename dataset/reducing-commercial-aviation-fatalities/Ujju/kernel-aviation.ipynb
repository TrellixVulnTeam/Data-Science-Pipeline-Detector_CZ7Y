{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Load both test and train data, here not loading test since it's only for competision"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load both test and train data, here not loading test since it's only for competision\n# df_full_test = pd.read_csv('/kaggle/input/test.csv')\ndf_full = pd.read_csv('/kaggle/input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Visualize both the data types\n# df_full.shape  \n# df_full.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for null or miussing values\n# df_full.isnull().sum().sum() # There are no null values\n# df_full_test.isnull().sum().sum() # THere are no null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Counts: \\n\"+str(df_full.event.value_counts())+\"\\n\")\nprint(\"Unique values: \\n\"+str(df_full.event.nunique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ds_o_y = ds_o_train['event']\n# ds_o_y.head()\n# del ds_o_train['event']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \n# Split data into train and validation set\ndf_train , df_val = train_test_split(df_full,test_size=0.25,shuffle='true')\n# Split train again for Train and Test data\ndf_train, df_test = train_test_split(df_train,test_size=0.10)\n\nprint(\"Shape:\")\nprint(\"======================\")\nprint(\"Train: \"+str(df_train.shape))\nprint(\"Validation: \"+str(df_val.shape))\nprint(\"Test: \"+str(df_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy Y values from the training data set seperately \ndf_tra_y = df_train['event']\ndf_val_y = df_val['event']\ndf_tes_y = df_test['event']\n\n# Delete Y values from the data set, so that its not part of X values\ndel df_train['event']\ndel df_val['event']\ndel df_test['event']\n\n# Printing all the values to keep track of shape\nprint(\"TRAIN     : \"+str(df_train.shape)+\" Y: \"+str(df_tra_y.shape)+\"\\n\")\nprint(\"VALIDATION: \"+str(df_val.shape)+\" Y: \"+str(df_val_y.shape)+\"\\n\")\nprint(\"TEST      : \"+str(df_test.shape)+\" Y: \"+str(df_tes_y.shape)+\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy the Categorical data seperately, because that will be fed into Embedding layers seperately \ndf_tra_experiment = df_train['experiment']\ndf_val_experiment = df_val['experiment']\ndf_tes_experiment = df_test['experiment']\n\n# delete the value\ndel df_train['experiment']\ndel df_val['experiment']\ndel df_test['experiment']\n\nprint(df_tra_experiment.shape)\nprint(df_train.shape)\nprint(df_val_experiment.shape)\nprint(df_val.shape)\nprint(df_tes_experiment.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Empty array\ncategorical_array = [] \n# Array of all columns\nall_columns = df_train.columns\n# Define just the categorical column name\ncategorical_array.append('experiment')\n# Substract categorical coumn from other columns\nother_columns = [i for i in all_columns if i not in categorical_array]\n\nprint(categorical_array)\nprint(other_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## This is for sequential model\n# t_model = Sequential()\n# t_model.add(Dense(100,activation='relu',input_shape(27,)))\n# t_model.add(Dense(50,activation='relu'))\n# t_model.add(Dense(4))\n# t_model.compile(loss=\"mean_squared_error\",\n#                 optimizer=Adam(lr=0.001),\n#                 metrics=[metrics.mae])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will convert categorical data to integer data, only then It can be converted into One-hot encoding\nfrom sklearn.preprocessing import LabelEncoder\ndf_tra_experiment = LabelEncoder().fit_transform(df_tra_experiment)\ndf_val_experiment = LabelEncoder().fit_transform(df_val_experiment)\ndf_tes_experiment = LabelEncoder().fit_transform(df_tes_experiment)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will convert Label (Y values) to integer data, only then It can be converted into One-hot encoding\ndf_tra_y = LabelEncoder().fit_transform(df_tra_y)\ndf_val_y = LabelEncoder().fit_transform(df_val_y)\ndf_tes_y = LabelEncoder().fit_transform(df_tes_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert labels to categorical one-hot encoding, This is optional , depending on the LOSS_FUNCTION\nfrom keras.utils import to_categorical\none_hot_tra_y = to_categorical(df_tra_y, num_classes=4)\none_hot_val_y = to_categorical(df_val_y, num_classes=4)\none_hot_tes_y = to_categorical(df_tes_y, num_classes=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MEAN Normalize here\ndf_train = (df_train-df_train.mean())/df_train.std()\ndf_val = (df_val-df_val.mean())/df_val.std()\ndf_test = (df_test-df_test.mean())/df_test.std()\n# df_tra_experiment_n = (df_tra_experiment-df_tra_experiment.mean())/df_tra_experiment.std()\n# df_val_experiment_n = (df_val_experiment-df_val_experiment.mean())/df_val_experiment.std()\n# df_tes_experiment_n = (df_tes_experiment-df_tes_experiment.mean())/df_tes_experiment.std()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(5):\n    print(df_tes_experiment[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# # sns.scatterplot(x=\"crew\",y=\"crew\",data=df_train)\n\n# ax1 = df_train.plot(kind='scatter', x='eeg_fp1', y='eeg_f7', color='r')    \n# ax2 = df_train.plot(kind='scatter', x='eeg_f8', y='eeg_t4', color='g', ax=ax1)    \nax3 = df_train.plot(kind='scatter', x='eeg_t6', y='eeg_t5', color='b')\n# # ax3 = df_train.plot(kind='scatter', x='eeg_t3', y='eeg_fp2', color='b', ax=ax1)\nax3 = df_train.plot(kind='scatter', x='eeg_o1', y='eeg_p3', color='g', ax=ax3)\n# # ax3 = df_train.plot(kind='scatter', x='eeg_pz', y='eeg_f3', color='b', ax=ax1)\n# # ax3 = df_train.plot(kind='scatter', x='eeg_fz', y='eeg_f4', color='b', ax=ax1)\n# # ax3 = df_train.plot(kind='scatter', x='eeg_c4', y='eeg_p4', color='b', ax=ax1)\n# # ax3 = df_train.plot(kind='scatter', x='eeg_poz', y='eeg_c3', color='b', ax=ax1)\n# # ax3 = df_train.plot(kind='scatter', x='eeg_cz', y='eeg_o2', color='b', ax=ax1)\n# ax3 = df_train_n.plot(kind='scatter', x='ecg', y='eeg_p4', color='b', ax=ax1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get MAX and MIN value of a column , this is the perfect place to check for values range\n# After this we can verify and apply standardization\ndf_train.max()\ndf_train.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MIN MAX normalization\n\ndf_train = (df_train-df_train.min())/(df_train.max()-df_train.min())\ndf_val = (df_val-df_val.min())/(df_val.max()-df_val.min())\ndf_test = (df_test-df_test.min())/(df_test.max()-df_test.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# # sns.scatterplot(x=\"crew\",y=\"crew\",data=df_train)\n\n# ax1 = df_train.plot(kind='scatter', x='eeg_fp1', y='eeg_f7', color='r')    \n# ax2 = df_train.plot(kind='scatter', x='eeg_f8', y='eeg_t4', color='g', ax=ax1)    \nax3 = df_train.plot(kind='scatter', x='eeg_t6', y='eeg_t5', color='b')\n# # ax3 = df_train.plot(kind='scatter', x='eeg_t3', y='eeg_fp2', color='b', ax=ax1)\nax3 = df_train.plot(kind='scatter', x='eeg_o1', y='eeg_p3', color='g', ax=ax3)\n# # ax3 = df_train.plot(kind='scatter', x='eeg_pz', y='eeg_f3', color='b', ax=ax1)\n# # ax3 = df_train.plot(kind='scatter', x='eeg_fz', y='eeg_f4', color='b', ax=ax1)\n# # ax3 = df_train.plot(kind='scatter', x='eeg_c4', y='eeg_p4', color='b', ax=ax1)\n# # ax3 = df_train.plot(kind='scatter', x='eeg_poz', y='eeg_c3', color='b', ax=ax1)\n# # ax3 = df_train.plot(kind='scatter', x='eeg_cz', y='eeg_o2', color='b', ax=ax1)\n# ax3 = df_train_n.plot(kind='scatter', x='ecg', y='eeg_p4', color='b', ax=ax1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In Keras 2.0, embedding can be achieved only by Functional Model (agast Sequential Model where concatinating is deprecated and not possible)\nIn Functional Model, its important to track INPUT and OUTPUT of each layer, so it can be combined later\n* Create EMBEDDING Layer (for CATEGORICAL column), with INPUT and OUTPUT \n* Create INPUT layer (for Other column), with INPUT\n* Concatenate EMBEDDING and INPUT layers\n* Add Few Dense layers \n* Create OUTPUT from Dense(for Other column)\n* Create MODEL (Functional Model) using INPUTS & OUTPUTS from both layer\n* Compile "},{"metadata":{"trusted":true},"cell_type":"code","source":"# # This FUNCTIONAL MODEL produces wrong output file \n\n# from keras.models import Sequential,Model\n# from keras.layers import Dense,Activation,Dropout,Embedding,Reshape,concatenate,Input,Flatten\n# from keras.optimizers import Adam,RMSprop\n# from keras import metrics\n# from keras.utils import plot_model\n\n# input_of_experiment = Input(shape=(1,),dtype='int32',name='input_of_experiment')\n# x = Embedding(output_dim=4,input_dim=100,input_length=1)(input_of_experiment)\n# out_of_experiment = Flatten()(x)\n# output_of_experiment = Dense(4,activation='relu',name='output_of_experiment')(out_of_experiment)\n\n# input_of_other = Input(shape=(df_train.shape[1],), name='input_of_other')\n# lyr = concatenate([input_of_other,output_of_experiment])\n# lyr = Dense(50, activation='relu')(lyr)\n# lyr = Dense(50, activation='relu')(lyr)\n# lyr = Dense(50, activation='relu')(lyr)\n\n# ## For one hot encoding this is 4\n# output_of_other = Dense(4,activation='softmax',name='output_of_other')(lyr)\n\n\n# t_model = Model(inputs = [input_of_experiment,input_of_other], \n#                 outputs = [output_of_other,output_of_experiment])\n\n\n# ## THese to compile functions work when the Y value is in INTEGER form\n# # t_model.compile(loss = \"mean_squared_error\",\n# #                optimizer = Adam(lr=0.01),\n# #                metrics = [metrics.mae],\n# #                loss_weights = [1.0,0.5])\n\n# # t_model.compile(loss = \"mean_absolute_percentage_error\",\n# #                optimizer = Adam(lr=0.01),\n# #                metrics = [metrics.mae],\n# #                loss_weights = [1.0,0.5])\n\n# # t_model.compile(optimizer = Adam(lr=0.01),\n# #              loss='categorical_crossentropy',\n# #              metrics=['accuracy'])\n\n# t_model.compile(optimizer = RMSprop(lr=0.01),\n#              loss='categorical_crossentropy',\n#              metrics=['accuracy'])\n# # val_output_of_other_acc: 0.7926 - val_output_of_experiment_acc: 0.8770 One Hot encoding of the values\n# # val_output_of_other_acc: 0.9727 - val_output_of_experiment_acc: 0.8039 Normalization \n# # val_output_of_other_acc: 0.9761 - val_output_of_experiment_acc: 0.8770 (lr=0.01 , 200 input, 6 epoch )\n# # val_output_of_other_acc: 0.9745 - val_output_of_experiment_acc: 0.8770 (lr=0.001 , 200 input, 10 epoch )\n# # val_output_of_other_acc: 0.9804 - val_output_of_experiment_acc: 0.8772 (lr=0.001 , 200 input, 10 epoch , added layer)\n# # val_output_of_other_acc: 0.9887 - val_output_of_experiment_acc: 0.8772 (lr=0.001 , 200 input, 10 epoch , added another layer)\n# # val_output_of_other_acc: 0.9685 - val_output_of_experiment_acc: 0.8775 (added Dropout , but not helping)\n# # val_output_of_other_acc: 0.9567 - val_output_of_experiment_acc: 0.9236 (optimizer = 'rmsProp' , loss='categorical_crossentropy' ,batch=500 , epoch=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# THIS IS SECOND MODEL USING FUNCTIONAL LAYER IN KERAS WITH PROPER OUTPUT FORMAT\n\nfrom keras.models import Sequential,Model\nfrom keras.layers import Dense,Activation,Dropout,Embedding,Reshape,concatenate,Input,Flatten\nfrom keras.optimizers import Adam,RMSprop\nfrom keras import metrics\nfrom keras.utils import plot_model\n\ninputExperiment = Input(shape=(1,),dtype='int32', name='inputExperiment')\nx1 = Embedding(output_dim=4,input_dim=50,input_length=1)(inputExperiment)\nx1 = Flatten()(x1)\nx1 = Dense(50,activation='relu',name='outputExperiment')(x1)\nx1 = Dense(50,activation='relu')(x1)\nx1 = Dense(50,activation='relu')(x1)\nx1 = Model(inputs=inputExperiment,outputs=x1)\n\ninputOther = Input(shape=(df_train.shape[1],), name='inputOther')\nx2 = Dense(50, activation='relu')(inputOther)\nx2 = Dense(50, activation='relu')(x2)\nx2 = Dense(50, activation='relu')(x2)\nx2 = Dense(50, activation='relu')(x2)\nx2 = Model(inputs=inputOther, outputs=x2)\n\ncombined = concatenate([x1.output,x2.output])\n\ny = Dense(25,activation='relu', name='outputCombined')(combined)\ny = Dense(4, activation='softmax')(y)\n\n## For one hot encoding this is 4\n\n\nt_model = Model(inputs = [inputExperiment,inputOther], \n                outputs = y)\n\n\n\nt_model.compile(optimizer = RMSprop(lr=0.001),\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])\n\n# loss: 0.1503 - acc: 0.9653 - val_loss: 0.1560 - val_acc: 0.9668\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n# MEAN SQUARED ERROR = 0 for perfect value, always positive, more value = more error\n"},{"metadata":{},"cell_type":"markdown","source":"FIT & EVALUATE\n===\n--------------------------"},{"metadata":{},"cell_type":"markdown","source":"\n\n# One Hot encoded Y values with MEAN_SQUARED_ERROR\n* loss: 0.1520\n* output_of_other_loss: 0.1349\n* output_of_experiment_loss: 0.0342\n* output_of_other_mean_absolute_error: 0.2696\n* output_of_experiment_mean_absolute_error: 0.0618\n* val_loss: 0.1520\n* val_output_of_other_loss: 0.1348\n* val_output_of_experiment_loss: 0.0344\n* val_output_of_other_mean_absolute_error: 0.2665\n* val_output_of_experiment_mean_absolute_error: 0.0621\n\n\n# This is INTEGER type Y value , with categorical_crossentropy error\n* loss: nan\n* output_of_other_loss: nan\n* output_of_experiment_loss: nan\n* output_of_other_acc: 0.5851\n* output_of_experiment_acc: 0.5851\n* val_loss: nan\n* val_output_of_other_loss: nan\n* val_output_of_experiment_loss: nan\n* val_output_of_other_acc: 0.5856\n* val_output_of_experiment_acc: 0.5856\n\n# MEAN_SQUARED_ERROR with INTEGER type Y values\n* loss: 730602.4012\n* output_of_other_loss: 730581.6555\n* output_of_experiment_loss: 41.4912\n* output_of_other_mean_absolute_error: 0.8520\n* output_of_experiment_mean_absolute_error: 0.8512\n* val_loss: 834527.5918\n* val_output_of_other_loss: 834506.8710\n* val_output_of_experiment_loss: 41.4395\n* val_output_of_other_mean_absolute_error: 0.8509\n* val_output_of_experiment_mean_absolute_error: 0.8506\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## This is using one hot encoded labels and NORMALIZED values\nhistory = t_model.fit([df_tra_experiment,df_train],[one_hot_tra_y],batch_size = 1000,epochs = 100,shuffle=True,verbose=1, \n                      validation_data = ([df_val_experiment,df_val],[one_hot_val_y]))\n\nscore = t_model.evaluate([df_tes_experiment,df_test],[one_hot_tes_y],verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Releases most of the memory taken by dataframe\nimport gc\ndel df_full\ndel df_train\ndel df_val\ndel df_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_full_test = pd.read_csv('/kaggle/input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will convert categorical data to integer data, only then It can be converted into One-hot encoding\nfrom sklearn.preprocessing import LabelEncoder\ndf_full_test[categorical_array] = LabelEncoder().fit_transform(df_full_test[categorical_array])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction for SINGLE VALUE, contains 2 arrays since our model has 2 inputs(categorical and numerical) we need to pass is seperately\n# Here we are passing 2 value for each input, but OUTPUT is 1\nsingle_input_array = [ \n                        [df_full_test[categorical_array].iloc[1111111]] , \n                        [df_full_test[other_columns].iloc[1111111]]\n                    ]\n\npredicted_value = t_model.predict(single_input_array, verbose=1)\nprint(predicted_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.shape(single_input_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # This DOES'NT WORK for 2 inputs values\n\n# # Prediction for TWO VALUE, contains 2 arrays since our model has 2 inputs(categorical and numerical) we need to pass is seperately\n# # Here we are passing 2 value for each input, but OUTPUT is 1\n# two_input_array = [ \n#                         [[df_full_test[categorical_array].iloc[1111111]] , \n#                         [df_full_test[other_columns].iloc[1111111]],],\n#                         [[df_full_test[categorical_array].iloc[1111111]] , \n#                         [df_full_test[other_columns].iloc[1111111]],]\n#                 ]\n# np.shape(two_input_array)\n# predicted_value = t_model.predict(two_input_array, verbose=1)\n# # print(predicted_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction for MULTIPLE VALUE, contains 2 arrays since our model has 2 inputs(categorical and numerical) we need to pass is seperately\n\n# multiple_input_array_categorical = pd.concat([df_full_test[categorical_array]], axis = 1)\n# multiple_input_array_integer = pd.concat([df_full_test[other_columns]], axis = 1)\n\n# multiple_input_array = [ \n#                         multiple_input_array_categorical , \n#                         multiple_input_array_integer \n#                     ]\n\npredicted_value = t_model.predict([df_full_test[categorical_array],df_full_test[other_columns]], verbose=1)\nprint(predicted_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.shape(predicted_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy ID so the df_full_test can be released from momory\nID = df_full_test.id\nID.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"event = predicted_value\nevent.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_full_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(ID)\nsub.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub1 = pd.DataFrame(event)\nsub1.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create DATAFRAME for SUBMISSION \nsub2 = pd.concat([sub, sub1],axis=1, ignore_index=True, sort =False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename column names to \nsub2.columns = ['id', 'A','B','C','D']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert FLOAT to INT (Pretty easy and Usefull actually)\nsub2 = sub2.astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub2.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# you could use any filename. We choose submission here\nsub2.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## This is using one hot encoded labels\n# history = t_model.fit([df_tra_experiment,df_train],[one_hot_tra_y,one_hot_tra_y],batch_size = 50,epochs = 5,shuffle=True,verbose=1, \n#                       validation_data = ([df_val_experiment,df_val],[one_hot_val_y,one_hot_val_y]))\n\n# score = t_model.evaluate([df_tes_experiment,df_test],[one_hot_tes_y,one_hot_tes_y],verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"# t_model.summary()\n# plot_model(t_model,to_file='/plot.png',show_shapes=True,show_layer_names=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# t_model.get_session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## Not using this, since there is not test data\n# history = t_model.fit([df_tra_experiment,df_train],[df_tra_y,df_tra_y],batch_size = 128,epochs = 5,shuffle=True,verbose=1, \n#                       validation_data = ([df_val_experiment,df_val],[df_val_y,df_val_y]))\n\n# score = t_model.evaluate([df_tes_experiment,df_test],[df_tes_y,df_tes_y],verbose=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def preproc(X_train):\n#     input_list_train = []\n#     for c in categorical_array:\n#         vals = np.asarray(X_train[c].tolist())\n#         vals = pd.factorize(vals)[0]\n#         input_list_train.append(np.asarray(vals))\n        \n#     input_list_train.append(X_train[other_columns].values)\n#     return input_list_train\n\n# df_tr_modified = preproc(ds_o_X)\n# df_val_modified = preproc(ds_o_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.models import Sequential\n# from keras.layers import Dense,Activation,Dropout,Embedding,Reshape,Concatenate\n\n# for categorical_val in categorical_array:\n#     print (\"for categorical column \",categorical_val)\n#     model = Sequential()\n#     no_of_unique_cat = ds_o_train[categorical_val].nunique()\n# #     no_of_unique_cat = 3\n#     print (\"number of unique cat\", no_of_unique_cat)\n    \n#     embedding_size = min(np.ceil(no_of_unique_cat/2),50)\n#     embedding_size = int(embedding_size)\n    \n#     print (\"embedding_size set as \", embedding_size)\n    \n#     model.add(Embedding(no_of_unique_cat+1,embedding_size, input_length = 1))\n#     model.add(Reshape(target_shape=([embedding_size])))\n#     print (model.summary())\n#     model_array.append(model)\n     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# So the model contains N_CAT + 1 models (N_CAT models for each of the categorical\n# columns and one for all other columns)\n# model_array[0].summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.layers import Concatenate,BatchNormalization,PReLU\n# from keras.models import Model\n# full_model = Concatenate()([model_array])\n\n# full_model.compile(optimizer=ada_grad,\n#                    loss='binary_crossentropy',\n#                    metrics=['accuracy'])\n\n# x = BatchNormalization()(full_model)\n# x = Dense(80, activation='relu')(full_model)\n# x = Dropout(.35)(x)\n# x = Dense(20, activation='relu')(x)\n# x = Dropout(.15)(x)\n# x = Dense(10, activation='relu')(x)\n# x = Dropout(.15)(x)\n# output = Dense(1, activation='sigmoid')(x)\n# # x = PReLU()(x)\n# # x = Dropout(0.2)(x)\n# # x = Dense(4)(x)\n# # x = BatchNormalization()(x)\n# out = Activation('sigmoid')(x)\n\n# merged_model = Model(model_array,out)\n# merged_model.compile(optimizer = 'rmsprop',\n#                  loss='categorical_crossentropy',\n#                  metrics=['accuracy'])\n\n# # merged_model.compile(loss = 'binary_crossentropy',\n# #                      optimizer = 'adam', \n# #                      metrics = ['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Delete categorical data(temporary)\n# ds_o_val = ds_o_val.drop(ds_o_val.index[[1]])\n# del ds_o_X['experiment']\n# del ds_o_val['experiment']\n\n# input_list_train =[]\n# vals = np.asarray(ds_o_train)\n\n# # Aattempt to embed categorical data\n# def embedding_cat():\n#     mode = Sequential()\n#     no_of_uniqe_cat = ds_o_X['experiment'].nunique()\n#     emb_size = min(np.ceil(no_of_uniqe_cat/2),50)\n#     emb_size = int(emb_size)\n#     vocab = no_of_uniqe_cat+1\n#     model.add(Embedding(vocab,emb_size,input_length=4))\n# #     model.add(Reshape(target_shape=(emb_size,)))\n#     models_array.append(model)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}