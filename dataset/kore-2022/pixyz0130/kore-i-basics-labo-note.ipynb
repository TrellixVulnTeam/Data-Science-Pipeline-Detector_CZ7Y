{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install --upgrade kaggle_environments","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:02.437683Z","iopub.execute_input":"2022-06-05T13:04:02.438112Z","iopub.status.idle":"2022-06-05T13:04:15.426339Z","shell.execute_reply.started":"2022-06-05T13:04:02.438005Z","shell.execute_reply":"2022-06-05T13:04:15.425175Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_environments import make\nfrom kaggle_environments.envs.kore_fleets.kore_fleets import random_agent,miner_agent,attacker_agent,balanced_agent\nenv = make(\"kore_fleets\", debug=True)\nenv.run([balanced_agent,miner_agent])\nenv.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:15.429097Z","iopub.execute_input":"2022-06-05T13:04:15.42945Z","iopub.status.idle":"2022-06-05T13:04:19.863329Z","shell.execute_reply.started":"2022-06-05T13:04:15.429404Z","shell.execute_reply":"2022-06-05T13:04:19.859676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2022 06 15  \npixyz  \nゆっくりしていってね！","metadata":{}},{"cell_type":"markdown","source":"**霊夢:Kore2022の基本的な事で気になった点について、検証、実験をするNotebookだよ。**\n\n**Reimu: It's a notebook that verifies and experiments on the basics of Kore2022.**","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://4.bp.blogspot.com/-uoVuBWIbdiA/WvQHqpx_YCI/AAAAAAABL8g/NiFZ6K71VBc_0_dcKb3_4nhnvFJ_JMNuACLcBGAs/s450/network_dennou_sekai_figure.png\" width = 300>","metadata":{}},{"cell_type":"markdown","source":"# Contents\n\n<span style=\"font-size: 200%; color: black;\">\n    \nv0 [**beta_champion_agent**](#v0-bata-champion-agent)    \n\nv1 [**public agent**](#v1-public-agent)\n\nv2 [**flight plan**](#v2-Flight-Plan)\n\nv3 [**steps**](#v3-steps)\n\nv4 [**Reinforcement Learning**](#v4-Reinforcement-Learning)\n\n\n</span>","metadata":{}},{"cell_type":"markdown","source":"# v0 beta_champion_agent","metadata":{}},{"cell_type":"markdown","source":"**魔理沙:最初にbeta版でのチャンピオンのagentをみてみよう！**\n\nhttps://www.kaggle.com/code/realneuralnetwork/kore-beta-1st-place-solution","metadata":{}},{"cell_type":"markdown","source":"sysを使うと、他のコードから、agentを引っ張り出すことができます。","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/kore-beta-1st-place-solution\")","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:19.866091Z","iopub.execute_input":"2022-06-05T13:04:19.866735Z","iopub.status.idle":"2022-06-05T13:04:19.870863Z","shell.execute_reply.started":"2022-06-05T13:04:19.866689Z","shell.execute_reply":"2022-06-05T13:04:19.869973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from main import agent as beta_champion","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:19.873188Z","iopub.execute_input":"2022-06-05T13:04:19.873727Z","iopub.status.idle":"2022-06-05T13:04:19.907181Z","shell.execute_reply.started":"2022-06-05T13:04:19.873685Z","shell.execute_reply":"2022-06-05T13:04:19.906351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env.run([beta_champion])\nenv.render(mode=\"ipython\",width=800,height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:06:14.373723Z","iopub.execute_input":"2022-06-05T13:06:14.374772Z","iopub.status.idle":"2022-06-05T13:06:21.846689Z","shell.execute_reply.started":"2022-06-05T13:06:14.374726Z","shell.execute_reply":"2022-06-05T13:06:21.845619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# v1 public agent","metadata":{}},{"cell_type":"markdown","source":"**魔理沙:実際にBovard氏が書いてくれたいくつかのAgentを読み込んで戦わせてみるぜ**\n\n**Marisa:I'm actually going to load some Agents that Bovard wrote and let them fight**","metadata":{}},{"cell_type":"markdown","source":"**attacker_agentにはmathモジュールがインポートされていないバグがあったので、修正したprivate notebookを使用します。**\n\n**Attacker_agent had a bug that the math module was not imported, so use the fixed private notebook.**","metadata":{}},{"cell_type":"markdown","source":"## switch","metadata":{}},{"cell_type":"markdown","source":"もしも、お急ぎでしたら、スキップスイッチをONにしてください","metadata":{}},{"cell_type":"code","source":"IS_SKIP = True","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:27.242052Z","iopub.execute_input":"2022-06-05T13:04:27.242431Z","iopub.status.idle":"2022-06-05T13:04:27.249139Z","shell.execute_reply.started":"2022-06-05T13:04:27.242397Z","shell.execute_reply":"2022-06-05T13:04:27.248423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"kaggle_environments.envs.kore_fleets.kore_fleetsから、基本的なagentを読み込むことができます。","metadata":{}},{"cell_type":"code","source":"from kaggle_environments.envs.kore_fleets.kore_fleets import random_agent,miner_agent,attacker_agent,balanced_agent\n\n# random_agent = \"../input/kore-python-random-agent/agent.py\"\n# miner_agent = \"../input/kore-miner-agent/miner.py\"\n# attacker_agent = \"../input/kore-attacker-agent-repair/attacker.py\"\n# balanced_agent = \"../input/kore-balanced-agent/balanced.py\"","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:27.250275Z","iopub.execute_input":"2022-06-05T13:04:27.250849Z","iopub.status.idle":"2022-06-05T13:04:27.32198Z","shell.execute_reply.started":"2022-06-05T13:04:27.250814Z","shell.execute_reply":"2022-06-05T13:04:27.321102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## battle1 random_agent vs random_agent","metadata":{}},{"cell_type":"code","source":"env.run([random_agent,random_agent])\nenv.render(mode=\"ipython\", width=800, height=640)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-05T13:04:27.32312Z","iopub.execute_input":"2022-06-05T13:04:27.323984Z","iopub.status.idle":"2022-06-05T13:04:36.288776Z","shell.execute_reply.started":"2022-06-05T13:04:27.323922Z","shell.execute_reply":"2022-06-05T13:04:36.288036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## battle2 miner_agent vs miner_agent","metadata":{}},{"cell_type":"code","source":"if not IS_SKIP:\n    env.run([miner_agent,miner_agent])\n    env.render(mode=\"ipython\", width=800, height=640)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-05T13:04:36.290045Z","iopub.execute_input":"2022-06-05T13:04:36.290284Z","iopub.status.idle":"2022-06-05T13:04:36.297025Z","shell.execute_reply.started":"2022-06-05T13:04:36.290255Z","shell.execute_reply":"2022-06-05T13:04:36.296142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## battle3 attacker_agent vs attacker_agent","metadata":{}},{"cell_type":"code","source":"if not IS_SKIP:\n    env.run([attacker_agent,attacker_agent])\n    env.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:36.300197Z","iopub.execute_input":"2022-06-05T13:04:36.300751Z","iopub.status.idle":"2022-06-05T13:04:36.308551Z","shell.execute_reply.started":"2022-06-05T13:04:36.300706Z","shell.execute_reply":"2022-06-05T13:04:36.307685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## battle4 balanced_agent vs balanced_agent","metadata":{}},{"cell_type":"code","source":"if not IS_SKIP:\n    env.run([balanced_agent,balanced_agent])\n    env.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:36.309997Z","iopub.execute_input":"2022-06-05T13:04:36.310252Z","iopub.status.idle":"2022-06-05T13:04:36.321817Z","shell.execute_reply.started":"2022-06-05T13:04:36.310219Z","shell.execute_reply":"2022-06-05T13:04:36.320779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## battle5 random_agent vs miner_agent","metadata":{}},{"cell_type":"code","source":"if not IS_SKIP:\n    env.run([random_agent,miner_agent])\n    env.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:36.323112Z","iopub.execute_input":"2022-06-05T13:04:36.323439Z","iopub.status.idle":"2022-06-05T13:04:36.335617Z","shell.execute_reply.started":"2022-06-05T13:04:36.323394Z","shell.execute_reply":"2022-06-05T13:04:36.334954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## battle6 attacker_agent vs balanced_agent","metadata":{}},{"cell_type":"code","source":"if not IS_SKIP:\n    env.run([attacker_agent,balanced_agent])\n    env.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:36.337009Z","iopub.execute_input":"2022-06-05T13:04:36.337269Z","iopub.status.idle":"2022-06-05T13:04:36.349394Z","shell.execute_reply.started":"2022-06-05T13:04:36.33724Z","shell.execute_reply":"2022-06-05T13:04:36.34861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## battle7 random_agent vs attacker_agent","metadata":{}},{"cell_type":"code","source":"if not IS_SKIP:\n    env.run([random_agent,attacker_agent])\n    env.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:36.350605Z","iopub.execute_input":"2022-06-05T13:04:36.350837Z","iopub.status.idle":"2022-06-05T13:04:36.363844Z","shell.execute_reply.started":"2022-06-05T13:04:36.350798Z","shell.execute_reply":"2022-06-05T13:04:36.363116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## battle8 miner_agent vs balanced_agent","metadata":{}},{"cell_type":"code","source":"if not IS_SKIP:\n    env.run([miner_agent,balanced_agent])\n    env.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:36.365204Z","iopub.execute_input":"2022-06-05T13:04:36.365474Z","iopub.status.idle":"2022-06-05T13:04:36.377587Z","shell.execute_reply.started":"2022-06-05T13:04:36.365433Z","shell.execute_reply":"2022-06-05T13:04:36.37691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## battle9 miner_agent vs attacker_agent","metadata":{}},{"cell_type":"code","source":"if not IS_SKIP:\n    env.run([miner_agent,attacker_agent])\n    env.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:36.379056Z","iopub.execute_input":"2022-06-05T13:04:36.379429Z","iopub.status.idle":"2022-06-05T13:04:36.39197Z","shell.execute_reply.started":"2022-06-05T13:04:36.379399Z","shell.execute_reply":"2022-06-05T13:04:36.391249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## battle10 random_agent vs balanced_agent","metadata":{}},{"cell_type":"code","source":"if not IS_SKIP:\n    env.run([random_agent,balanced_agent])\n    env.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:36.393276Z","iopub.execute_input":"2022-06-05T13:04:36.393619Z","iopub.status.idle":"2022-06-05T13:04:36.40538Z","shell.execute_reply.started":"2022-06-05T13:04:36.393591Z","shell.execute_reply":"2022-06-05T13:04:36.40466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## battle11 4 agents","metadata":{}},{"cell_type":"code","source":"if not IS_SKIP:\n    env.run([random_agent,miner_agent,attacker_agent,balanced_agent])\n    env.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:36.406893Z","iopub.execute_input":"2022-06-05T13:04:36.407408Z","iopub.status.idle":"2022-06-05T13:04:36.426021Z","shell.execute_reply.started":"2022-06-05T13:04:36.407354Z","shell.execute_reply":"2022-06-05T13:04:36.425012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**霊夢:Nameerrorが起きたけど原因はわからなかったよ**\n\n**Reimu: Nameerror happened but I couldn't figure out why**","metadata":{}},{"cell_type":"markdown","source":"# v2 Flight Plan ","metadata":{}},{"cell_type":"markdown","source":"**霊夢:フライトプランを指定する方法がなんだかピンとこないなあ**\n\n**魔理沙:じゃあ実際にいくつかのルートを指定して動きをみてみよう**\n\n**Reimu: Somehow it doesn't come out**\n\n**Marisa: Let's actually specify some routes and see how they move**","metadata":{}},{"cell_type":"code","source":"%%writefile pilot2.py\n   \nfrom kaggle_environments.envs.kore_fleets.helpers import *\nfrom random import randint\n\nflight_plan = \"N2S\"\n\ndef agent(obs, config):\n    board = Board(obs, config)\n    me=board.current_player\n\n    me = board.current_player\n    turn = board.step\n    spawn_cost = board.configuration.spawn_cost\n    kore_left = me.kore\n    for shipyard in me.shipyards:\n        if shipyard.ship_count >= 50:\n            action = ShipyardAction.launch_fleet_with_flight_plan(50, flight_plan)\n            shipyard.next_action = action\n        elif kore_left >= spawn_cost:\n            action = ShipyardAction.spawn_ships(1)\n            shipyard.next_action = action\n\n    return me.next_actions","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:36.427612Z","iopub.execute_input":"2022-06-05T13:04:36.428363Z","iopub.status.idle":"2022-06-05T13:04:36.441598Z","shell.execute_reply.started":"2022-06-05T13:04:36.428313Z","shell.execute_reply":"2022-06-05T13:04:36.440891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env.run([\"/kaggle/working/pilot2.py\"])\nenv.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:36.442763Z","iopub.execute_input":"2022-06-05T13:04:36.443175Z","iopub.status.idle":"2022-06-05T13:04:42.544855Z","shell.execute_reply.started":"2022-06-05T13:04:36.443143Z","shell.execute_reply":"2022-06-05T13:04:42.544129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**魔理沙:フライトプランをN2Sにして動かしてみたぜ。**\n\n**霊夢:北に3マス動いてから、南に移動しているね。**\n\n**魔理沙:もうひとつ試してみよう。**\n\n**Marisa: I changed the flight plan to N2S and tried it.**\n\n**Reimu: You've moved 3 squares north and then south.**\n\n**Marisa: Let's try another one.**","metadata":{}},{"cell_type":"code","source":"%%writefile pilot3.py\n   \nfrom kaggle_environments.envs.kore_fleets.helpers import *\nfrom random import randint\n\nflight_plan = \"N10E10S\"\n\ndef agent(obs, config):\n    board = Board(obs, config)\n    me=board.current_player\n\n    me = board.current_player\n    turn = board.step\n    spawn_cost = board.configuration.spawn_cost\n    kore_left = me.kore\n    for shipyard in me.shipyards:\n        if shipyard.ship_count >= 50:\n            action = ShipyardAction.launch_fleet_with_flight_plan(50, flight_plan)\n            shipyard.next_action = action\n        elif kore_left >= spawn_cost:\n            action = ShipyardAction.spawn_ships(1)\n            shipyard.next_action = action\n\n    return me.next_actions","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:42.54574Z","iopub.execute_input":"2022-06-05T13:04:42.545964Z","iopub.status.idle":"2022-06-05T13:04:42.554186Z","shell.execute_reply.started":"2022-06-05T13:04:42.545922Z","shell.execute_reply":"2022-06-05T13:04:42.553345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env.run([\"/kaggle/working/pilot3.py\"])\nenv.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:42.555423Z","iopub.execute_input":"2022-06-05T13:04:42.555642Z","iopub.status.idle":"2022-06-05T13:04:48.728774Z","shell.execute_reply.started":"2022-06-05T13:04:42.555614Z","shell.execute_reply":"2022-06-05T13:04:48.727777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**魔理沙:今度はフライトプランをN10E10Sにして実行してみたぜ。**\n\n**霊夢:なるほど、今度は北に11マス、東に11マス、そして南に移動し続けたな。つまり、数字は前の文字が表す方角にその数だけ進むことを表しているってことか！**\n\n**Marisa: This time I set the flight plan to N10E10S and executed it.**\n\n**Reimu: I see, this time I kept moving 11 squares to the north, 11 squares to the east, and south. In other words, the number means that the number goes in the direction indicated by the previous letter!**","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://1.bp.blogspot.com/-Qec8tKinr_o/VCkbguVH6-I/AAAAAAAAnII/ifsr6_x3WXw/s400/hirameki_man.png\" width = 200> ","metadata":{}},{"cell_type":"markdown","source":"# v3 steps","metadata":{}},{"cell_type":"code","source":"steps = env.run([balanced_agent,balanced_agent])\nenv.render(mode=\"ipython\", width=800, height=640)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:48.730367Z","iopub.execute_input":"2022-06-05T13:04:48.730612Z","iopub.status.idle":"2022-06-05T13:04:55.493732Z","shell.execute_reply.started":"2022-06-05T13:04:48.730581Z","shell.execute_reply":"2022-06-05T13:04:55.492916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"stepsを出力先にすると、データの中身を見ることができます。","metadata":{}},{"cell_type":"code","source":"print(type(steps))\nprint(len(steps))","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:55.494693Z","iopub.execute_input":"2022-06-05T13:04:55.494918Z","iopub.status.idle":"2022-06-05T13:04:55.499807Z","shell.execute_reply.started":"2022-06-05T13:04:55.494891Z","shell.execute_reply":"2022-06-05T13:04:55.498846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"stepsはlist形式で、勝負が243ターンで決まったので、stepsの数は243です。\n\nまず、100ターン目のデータを見てみます。","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"print(steps[100])","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:55.500967Z","iopub.execute_input":"2022-06-05T13:04:55.501214Z","iopub.status.idle":"2022-06-05T13:04:55.517237Z","shell.execute_reply.started":"2022-06-05T13:04:55.501175Z","shell.execute_reply":"2022-06-05T13:04:55.516555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1つのstepはagentの数だけあるlist形式で、辞書型になっている。重複するobservationは2つ目以降は省略されている。","metadata":{}},{"cell_type":"markdown","source":"## step list\n* action 辞書型\n* reward　float\n* info 辞書型\n* observation 辞書型\n * kore リスト\n * players リスト(shipとshipyard,船の数,koreの数,x座標,y座標,航路)\n * player int\n * step int\n * remainingOverageTime int\n * status ACTIVE","metadata":{}},{"cell_type":"markdown","source":"observationの中身だけ見てみます。","metadata":{}},{"cell_type":"code","source":"for key, item in steps[100][0]['observation'].items():\n    print(key,item)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:55.518127Z","iopub.execute_input":"2022-06-05T13:04:55.518369Z","iopub.status.idle":"2022-06-05T13:04:55.531805Z","shell.execute_reply.started":"2022-06-05T13:04:55.518328Z","shell.execute_reply":"2022-06-05T13:04:55.530757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## kore","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:55.533349Z","iopub.execute_input":"2022-06-05T13:04:55.533594Z","iopub.status.idle":"2022-06-05T13:04:55.541864Z","shell.execute_reply.started":"2022-06-05T13:04:55.533562Z","shell.execute_reply":"2022-06-05T13:04:55.540977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kore = steps[0][0]['observation']['kore']\nlen(kore)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:55.54531Z","iopub.execute_input":"2022-06-05T13:04:55.545547Z","iopub.status.idle":"2022-06-05T13:04:55.556353Z","shell.execute_reply.started":"2022-06-05T13:04:55.54552Z","shell.execute_reply":"2022-06-05T13:04:55.555553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kore = np.array(kore).reshape((21,21))\nprint(kore)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:55.557494Z","iopub.execute_input":"2022-06-05T13:04:55.558112Z","iopub.status.idle":"2022-06-05T13:04:55.570478Z","shell.execute_reply.started":"2022-06-05T13:04:55.558075Z","shell.execute_reply":"2022-06-05T13:04:55.569867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**.reshapeを使って、koreを21*21のリストに変換します。**\n\n**Use .reshape to convert kore to a list of 21 * 21.**","metadata":{}},{"cell_type":"code","source":"print(kore[9:12,9:12])\nprint(kore[9:12,9:12].sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:55.571688Z","iopub.execute_input":"2022-06-05T13:04:55.572106Z","iopub.status.idle":"2022-06-05T13:04:55.584728Z","shell.execute_reply.started":"2022-06-05T13:04:55.572062Z","shell.execute_reply":"2022-06-05T13:04:55.584019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**範囲を指定してその範囲のkoreを取得し、.sum()でその範囲の値の合計を求めることができます。**\n\n**You can specify a range to get the kore of that range and use .sum () to sum the values in that range.**","metadata":{}},{"cell_type":"code","source":"print(np.roll(kore,(3,4),axis = (0,1)))","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:55.585903Z","iopub.execute_input":"2022-06-05T13:04:55.586519Z","iopub.status.idle":"2022-06-05T13:04:55.597756Z","shell.execute_reply.started":"2022-06-05T13:04:55.586477Z","shell.execute_reply":"2022-06-05T13:04:55.59691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**.rollを使用して、koreのリストを指定した数だけ回転させます。**\n\n**Use .roll to rotate the list of kore by the specified number.**","metadata":{}},{"cell_type":"code","source":"print(kore)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:55.598776Z","iopub.execute_input":"2022-06-05T13:04:55.599578Z","iopub.status.idle":"2022-06-05T13:04:55.611593Z","shell.execute_reply.started":"2022-06-05T13:04:55.599532Z","shell.execute_reply":"2022-06-05T13:04:55.610895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**元のデータは変更されません**\n\n**Original data will not change**","metadata":{}},{"cell_type":"code","source":"%%writefile steps_analyze.py\nimport matplotlib.pylab as plt\ndef steps_analyze(steps,name = None):\n    step_size = len(steps)\n    num_players=len(steps[0])\n    Kore = [[steps[i][j][\"reward\"] for j in range(num_players)] for i in range(step_size)] \n    Cargo = [[0]*num_players for j in range(step_size)]\n    Ships = [[0]*num_players for j in range(step_size)]\n    All = [[0]*num_players for j in range(step_size)]\n    \n    for j in range(num_players): \n        for i in range(step_size):\n            for x in steps[i][0]['observation'][\"players\"][j][2].values():\n                Cargo[i][j] += x[1]\n        for i in range(step_size):\n            for x in steps[i][0]['observation'][\"players\"][j][1].values():\n                Ships[i][j] += x[1]\n            for x in steps[i][0]['observation'][\"players\"][j][2].values():\n                Ships[i][j] += x[2]\n        for i in range(step_size):\n            All[i][j] = Kore[i][j]+Cargo[i][j]+(Ships[i][j]-50)*10 \n            \n    fig, ax = plt.subplots(figsize = (20, 10))\n    plt.rcParams[\"font.size\"] = 12\n    plt.subplot(2,2,1)\n    plt.plot(Kore)\n    plt.title(\"Kore\")\n    plt.grid()\n    plt.subplot(2,2,2)    \n    plt.plot(Cargo)\n    plt.title(\"Cargo\")\n    plt.grid()\n    plt.subplot(2,2,3)\n    plt.plot(Ships)\n    plt.title('Ships')\n    plt.grid()\n    plt.subplot(2,2,4)\n    plt.plot(All)\n    plt.title('All')\n    plt.grid()\n    # plt.title(df_main.loc[0,columns[0]])\n    if name: fig.savefig(name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## players","metadata":{}},{"cell_type":"markdown","source":"**playersの中には、それぞれのプレイヤーの情報が入ったリストが入っています。それぞれのリストには、プレイヤーのKore(float)、shipyardの情報（辞書型）、shipの情報（辞書型）、が入っています。shipyardの情報は、ID、position、船の数、経過ターンが入ってます。**","metadata":{}},{"cell_type":"code","source":"steps[100][0]['observation']['players']","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:55.612869Z","iopub.execute_input":"2022-06-05T13:04:55.613299Z","iopub.status.idle":"2022-06-05T13:04:55.6255Z","shell.execute_reply.started":"2022-06-05T13:04:55.613256Z","shell.execute_reply":"2022-06-05T13:04:55.624845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0.026999999999986812 reward\n\n'0-1': [110, 14, 100]  \n'0-1' shipyard ID  \n110   position(21×y + x)  \n14    ship count  \n100   elapsed turn  \n\n'83-1': [172, 108.26799999999997, 21, 0, '3E']  \n'83-1' fleet ID\n172    position(xy)  \n108.   Cargo  \n21     ship count  \n0      direction  \n'3E'   flight plan","metadata":{}},{"cell_type":"code","source":"%%writefile steps_analyze.py\nimport matplotlib.pylab as plt\n\ndef steps_analyze(steps,name = None):\n    step_size = len(steps)\n    Kore = [steps[i][0][\"reward\"] for i in range(step_size)]\n    Cargo = [0]*step_size\n    Ships = [0]*step_size\n    All = [0]*step_size\n\n    for i in range(step_size):\n        for x in steps[i][0]['observation'][\"players\"][0][2].values():\n            Cargo[i] += x[1]\n    for i in range(step_size):\n        for x in steps[i][0]['observation'][\"players\"][0][1].values():\n            Ships[i] += x[1]\n        for x in steps[i][0]['observation'][\"players\"][0][2].values():\n            Ships[i] += x[2]\n    for i in range(step_size):\n        All[i] = Kore[i]+Cargo[i]+(Ships[i]-50)*10 \n            \n    fig, ax = plt.subplots(figsize = (20, 10))\n    plt.rcParams[\"font.size\"] = 12\n    plt.subplot(2,2,1)\n    plt.plot(Kore)\n    plt.title(\"Kore\")\n    plt.grid()\n    plt.subplot(2,2,2)    \n    plt.plot(Cargo)\n    plt.title(\"Cargo\")\n    plt.grid()\n    plt.subplot(2,2,3)\n    plt.plot(Ships)\n    plt.title('Ships')\n    plt.grid()\n    plt.subplot(2,2,4)\n    plt.plot(All)\n    plt.title('All')\n    plt.grid()\n    # plt.title(df_main.loc[0,columns[0]])\n    if name: fig.savefig(name)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:55.626756Z","iopub.execute_input":"2022-06-05T13:04:55.627203Z","iopub.status.idle":"2022-06-05T13:04:55.639821Z","shell.execute_reply.started":"2022-06-05T13:04:55.627157Z","shell.execute_reply":"2022-06-05T13:04:55.638755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from steps_analyze import steps_analyze\nsteps_analyze(steps)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:04:55.641489Z","iopub.execute_input":"2022-06-05T13:04:55.642347Z","iopub.status.idle":"2022-06-05T13:04:56.220997Z","shell.execute_reply.started":"2022-06-05T13:04:55.642304Z","shell.execute_reply":"2022-06-05T13:04:56.220119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# v4 Reinforcement Learning","metadata":{}},{"cell_type":"markdown","source":"SAMUEL氏のコピペのコメント抜きです。  \nhttps://www.kaggle.com/code/lesamu/reinforcement-learning-baseline-in-python","metadata":{}},{"cell_type":"code","source":"%%writefile rl_config.py\nimport numpy as np\nfrom kaggle_environments import make\n\nENV_SPECIFICATION = make('kore_fleets').specification\nSHIP_COST = ENV_SPECIFICATION.configuration.spawnCost.default\nSHIPYARD_COST = ENV_SPECIFICATION.configuration.convertCost.default\nGAME_CONFIG = {\n    'episodeSteps':  ENV_SPECIFICATION.configuration.episodeSteps.default,\n    'size': ENV_SPECIFICATION.configuration.size.default,\n    'maxLogLength': None\n}\n\nOPPONENT = 'opponent.py'\nGAME_AGENTS = [None, OPPONENT]\n\nN_FEATURES = 4\nACTION_SIZE = (2,)\nDTYPE = np.float64\nMAX_OBSERVABLE_KORE = 500\nMAX_OBSERVABLE_SHIPS = 200\nMAX_ACTION_FLEET_SIZE = 150\nMAX_KORE_IN_RESERVE = 40000\nWIN_REWARD = 1000","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile rl_opponent.py\nfrom kaggle_environments.envs.kore_fleets.helpers import *\n\ndef agent(obs, config):\n    board = Board(obs, config)\n\n    me = board.current_player\n    turn = board.step\n    spawn_cost = board.configuration.spawn_cost\n    kore_left = me.kore\n\n    for shipyard in me.shipyards:\n        if shipyard.ship_count > 10:\n            direction = Direction.from_index(turn % 4)\n            action = ShipyardAction.launch_fleet_with_flight_plan(2, direction.to_char())\n            shipyard.next_action = action\n        elif kore_left > spawn_cost * shipyard.max_spawn:\n            action = ShipyardAction.spawn_ships(shipyard.max_spawn)\n            shipyard.next_action = action\n            kore_left -= spawn_cost * shipyard.max_spawn\n        elif kore_left > spawn_cost:\n            action = ShipyardAction.spawn_ships(1)\n            shipyard.next_action = action\n            kore_left -= spawn_cost\n\n    return me.next_actions","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile rl_reward_utils.py\nfrom rl_config import GAME_CONFIG, SHIP_COST, SHIPYARD_COST\nfrom kaggle_environments.envs.kore_fleets.helpers import Board\nimport numpy as np\nfrom math import floor\n\n# Compute weight constants -- See get_board_value's docstring\n_max_steps = GAME_CONFIG['episodeSteps']\n_end_of_asset_value = floor(.5 * _max_steps)\n_weights_assets = np.linspace(start=1, stop=0, num=_end_of_asset_value)\n_weights_kore = np.linspace(start=0, stop=1, num=_end_of_asset_value)\nWEIGHTS_ASSETS = np.append(_weights_assets, np.zeros(_max_steps - _end_of_asset_value))\nWEIGHTS_KORE = np.append(_weights_kore, np.ones(_max_steps - _end_of_asset_value))\nWEIGHTS_MAX_SPAWN = {x: (x+3)/4 for x in range(1, 11)}  # Value multiplier of a shipyard as a function of its max spawn\nWEIGHTS_KORE_IN_FLEETS = WEIGHTS_KORE * WEIGHTS_ASSETS/2  # Always equal or smaller than either, almost always smaller\n\n\ndef get_board_value(board: Board) -> float:\n    board_value = 0\n    if not board:\n        return board_value\n\n    step = board.step\n    weight_kore, weight_assets, weight_cargo = WEIGHTS_KORE[step], WEIGHTS_ASSETS[step], WEIGHTS_KORE_IN_FLEETS[step]\n\n    for player in board.players.values():\n        player_fleets, player_shipyards = list(player.fleets), list(player.shipyards)\n\n        value_kore = weight_kore * player.kore\n\n        value_fleets = weight_assets * SHIP_COST * (\n                sum(fleet.ship_count for fleet in player_fleets)\n                + sum(shipyard.ship_count for shipyard in player_shipyards)\n        )\n\n        value_shipyards = weight_assets * SHIPYARD_COST * (\n            sum(shipyard.max_spawn * WEIGHTS_MAX_SPAWN[shipyard.max_spawn] for shipyard in player_shipyards)\n        )\n\n        value_kore_in_cargo = weight_cargo * sum(fleet.kore for fleet in player_fleets)\n\n        modifier = 1 if player.is_current_player else -1\n        board_value += modifier * (value_kore + value_fleets + value_shipyards + value_kore_in_cargo)\n\n    return board_value\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile rl_environment.py\nimport gym\nimport numpy as np\nfrom gym import spaces\nfrom math import floor\nfrom kaggle_environments import make\nfrom kaggle_environments.envs.kore_fleets.helpers import ShipyardAction, Board, Direction\nfrom typing import Union, Tuple, Dict\nfrom rl_reward_utils import get_board_value\nfrom rl_config import (\n    N_FEATURES,\n    ACTION_SIZE,\n    GAME_AGENTS,\n    GAME_CONFIG,\n    DTYPE,\n    MAX_OBSERVABLE_KORE,\n    MAX_OBSERVABLE_SHIPS,\n    MAX_ACTION_FLEET_SIZE,\n    MAX_KORE_IN_RESERVE,\n    WIN_REWARD,\n)\n\n\nclass KoreGymEnv(gym.Env):\n\n    def __init__(self, config=None, agents=None, debug=None):\n        super(KoreGymEnv, self).__init__()\n\n        if not config:\n            config = GAME_CONFIG\n        if not agents:\n            agents = GAME_AGENTS\n        if not debug:\n            debug = True\n\n        self.agents = agents\n        self.env = make(\"kore_fleets\", configuration=config, debug=debug)\n        self.config = self.env.configuration\n        self.trainer = None\n        self.raw_obs = None\n        self.previous_obs = None\n\n        self.action_space = spaces.Box(\n            low=-1,\n            high=1,\n            shape=ACTION_SIZE,\n            dtype=DTYPE\n        )\n\n        self.observation_space = spaces.Box(\n            low=-1,\n            high=1,\n            shape=(self.config.size ** 2 * N_FEATURES + 3,),\n            dtype=DTYPE\n        )\n\n        self.strict_reward = config.get('strict', False)\n\n        self.reward = 0\n        self.n_steps = 0\n        self.n_resets = 0\n        self.n_dones = 0\n        self.last_action = None\n        self.last_done = False\n\n    def reset(self) -> np.ndarray:\n        self.trainer = self.env.train(self.agents)\n        self.raw_obs = self.trainer.reset()\n        self.n_resets += 1\n        return self.obs_as_gym_state\n\n    def step(self, action: np.ndarray) -> Tuple[np.ndarray, float, bool, Dict]:\n        kore_action = self.gym_to_kore_action(action)\n        self.previous_obs = self.raw_obs\n        self.raw_obs, _, done, info = self.trainer.step(kore_action)  # Ignore trainer reward, which is just delta kore\n        self.reward = self.compute_reward(done)\n\n        self.n_steps += 1\n        self.last_done = done\n        self.last_action = kore_action\n        self.n_dones += 1 if done else 0\n\n        return self.obs_as_gym_state, self.reward, done, info\n\n    def render(self, **kwargs):\n        self.env.render(**kwargs)\n\n    def close(self):\n        pass\n\n    @property\n    def board(self):\n        return Board(self.raw_obs, self.config)\n\n    @property\n    def previous_board(self):\n        return Board(self.previous_obs, self.config)\n\n    def gym_to_kore_action(self, gym_action: np.ndarray) -> Dict[str, str]:\n        action_launch = gym_action[0] > 0\n        action_build = gym_action[0] < 0\n        number_of_ships = int(\n            clip_normalize(\n                x=abs(gym_action[0]),\n                low_in=0,\n                high_in=1,\n                low_out=1,\n                high_out=MAX_ACTION_FLEET_SIZE\n            )\n        )\n\n        board = self.board\n        me = board.current_player\n        for shipyard in me.shipyards:\n            action = None\n            if action_build:\n                max_spawn = shipyard.max_spawn\n                max_purchasable = floor(me.kore / self.config[\"spawnCost\"])\n                number_of_ships = min(number_of_ships, max_spawn, max_purchasable)\n                if number_of_ships:\n                    action = ShipyardAction.spawn_ships(number_ships=number_of_ships)\n\n            elif action_launch:\n                shipyard_count = shipyard.ship_count\n                number_of_ships = min(number_of_ships, shipyard_count)\n                if number_of_ships:\n                    direction = round((gym_action[1] + 1) * 1.5)  # int between 0 (North) and 3 (West)\n                    action = ShipyardAction.launch_fleet_in_direction(number_ships=number_of_ships,\n                                                                      direction=Direction.from_index(direction))\n            shipyard.next_action = action\n\n        return me.next_actions\n\n    @property\n    def obs_as_gym_state(self) -> np.ndarray:\n        gym_state = np.ndarray(shape=(self.config.size, self.config.size, N_FEATURES))\n\n        board = self.board\n        our_id = board.current_player_id\n\n        for point, cell in board.cells.items():\n            gym_state[point.y, point.x, 0] = cell.kore\n\n            fleet = cell.fleet\n            if fleet:\n                modifier = 1 if fleet.player_id == our_id else -1\n                gym_state[point.y, point.x, 1] = modifier * fleet.ship_count\n                gym_state[point.y, point.x, 2] = fleet.direction.value\n            else:\n                gym_state[point.y, point.x, 1] = gym_state[point.y, point.x, 2] = 0\n\n            shipyard = cell.shipyard\n            if shipyard:\n                gym_state[point.y, point.x, 3] = 1 if shipyard.player_id == our_id else -1\n            else:\n                gym_state[point.y, point.x, 3] = 0\n\n        gym_state[:, :, 0] = clip_normalize(\n            x=np.log2(gym_state[:, :, 0] + 1),\n            low_in=0,\n            high_in=np.log2(MAX_OBSERVABLE_KORE)\n        )\n\n        gym_state[:, :, 1] = clip_normalize(\n            x=gym_state[:, :, 1],\n            low_in=-MAX_OBSERVABLE_SHIPS,\n            high_in=MAX_OBSERVABLE_SHIPS\n        )\n\n        gym_state[:, :, 2] = clip_normalize(\n            x=gym_state[:, :, 2],\n            low_in=1,\n            high_in=4\n        )\n\n        output_state = gym_state.flatten()\n\n        player = board.current_player\n        opponent = board.opponents[0]\n        progress = clip_normalize(board.step, low_in=0, high_in=GAME_CONFIG['episodeSteps'])\n        my_kore = clip_normalize(np.log2(player.kore+1), low_in=0, high_in=np.log2(MAX_KORE_IN_RESERVE))\n        opponent_kore = clip_normalize(np.log2(opponent.kore+1), low_in=0, high_in=np.log2(MAX_KORE_IN_RESERVE))\n\n        return np.append(output_state, [progress, my_kore, opponent_kore])\n\n    def compute_reward(self, done: bool, strict=False) -> float:\n        board = self.board\n        previous_board = self.previous_board\n\n        if strict:\n            if done:\n                agent_reward = self.raw_obs.players[0][0]\n                opponent_reward = self.raw_obs.players[1][0]\n                return int(agent_reward > opponent_reward)\n            else:\n                return 0\n        else:\n            if done:\n                agent_reward = self.raw_obs.players[0][0]\n                opponent_reward = self.raw_obs.players[1][0]\n                if agent_reward is None or opponent_reward is None:\n                    we_won = -1\n                else:\n                    we_won = 1 if agent_reward > opponent_reward else -1\n                win_reward = we_won * (WIN_REWARD + 5 * (GAME_CONFIG['episodeSteps'] - board.step))\n            else:\n                win_reward = 0\n\n            return get_board_value(board) - get_board_value(previous_board) + win_reward\n\n\ndef clip_normalize(x: Union[np.ndarray, float],\n                   low_in: float,\n                   high_in: float,\n                   low_out=-1.,\n                   high_out=1.) -> Union[np.ndarray, float]:\n    assert high_in > low_in and high_out > low_out, \"Wrong limits\"\n\n    try:\n        x[x > high_in] = high_in\n        x[x < low_in] = low_in\n    except TypeError:\n        x = high_in if x > high_in else x\n        x = low_in if x < low_in else x\n\n    a = (high_out - low_out) / (high_in - low_in)\n    b = high_out - high_in * a\n\n    return a * x + b\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"miningは真っすぐに進むだけで、shipyardを作ったり、attackはありません。  \nこれから作っていこうと思います。","metadata":{}},{"cell_type":"code","source":" IS_RL_TRAI=False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if IS_RL_TRAIN:\n    !pip install --target=lib --no-deps stable-baselines3 gym\n    import os\n    import sys\n    KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n    if os.path.exists(KAGGLE_AGENT_PATH):\n        sys.path.insert(0, os.path.join(KAGGLE_AGENT_PATH, 'lib'))\n    else:\n        sys.path.insert(0, os.path.join(os.getcwd(), 'lib'))\n    kore_env = KoreGymEnv(config=dict(randomSeed=997269658))  # TODO: This seed is not enough. Seed everything!\n    monitored_env = Monitor(env=kore_env)\n    model = PPO('MlpPolicy', monitored_env, verbose=1)\n    model.learn(total_timesteps=50000)  ","metadata":{},"execution_count":null,"outputs":[]}]}