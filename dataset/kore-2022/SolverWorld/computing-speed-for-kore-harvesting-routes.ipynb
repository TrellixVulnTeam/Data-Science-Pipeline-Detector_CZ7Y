{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"One of the fundamental parts for a Kore agent is to calculate the Kore harvest along various routes.\nWhat is the fastest way to do these calculations?\nWe will explore a few options.  We will assume that we can precompute route information once ahead of time.  That is, we have a set of routes we will examine and we can precompute those before our first agent() call.\n\n* Edited (v2):  Added np.einsum thanks to @robga\n* Edited (v3):  Don't be alarmed at the possible weird shape of the graph below.  The timing depends on other things the processor cores are doing, and I have \nseen some strange things sometimes.  When I run it to save the notebook, the shape changes, so I don't know how to comment on the shape that you will get when you see it.\n* Edited (v5):  Added some more cases thanks to @robga and @qihuaz\n\nWe will compare the following methods.  Note that certains ones (mat vector and mat mult) do 1000 routes at a time.\n1. **mat_mult** Storing the kore levels in a matrix and storing the route in another 21x21 matrix, where the entries in the matrix are the fraction of the kore that gets harvested for the entire route, e.g. 0.10 for an 8-ship fleet.  Note that we could have this value increase by 2% each step along the route at no additional calculation cost.\n2. **mat_lookup** Storing the kore levels in a matrix and using a list of positions for the route, and then using a list comprehension to sum up the kore harvest along the route.\n3. **mat_index** Using advanced indexing, we can do the matrix lookup without list comprehension\n4. **dict_lookup** Store the kore levels as a dict mapping position->kore and using a list of positions for the route\n5. **dict_incr** same but have an increasing weight at 2% per step representing the growth in kore\n6. **mat_einsum** same as mat mult, but use np.einsum to vectorize 1000 routes at once.\n7. **mat_vector** similar to mat_einsum, but we use array broadcasting to multiply element-wise the 21x21 kore field times the 21x21x1000 routes and then sum along proper dimensions\n\nA few more assumptions:\n* About 200 of the 441 cells have positive kore","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pprint\nimport sys\nimport numpy as np\nimport random\nimport timeit\nimport matplotlib.pyplot as plt\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-05T20:08:54.359725Z","iopub.execute_input":"2022-06-05T20:08:54.360254Z","iopub.status.idle":"2022-06-05T20:08:54.366597Z","shell.execute_reply.started":"2022-06-05T20:08:54.36021Z","shell.execute_reply":"2022-06-05T20:08:54.36565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Just to check data sizes:\nm16=np.zeros((21,21),dtype=np.float16)\nm32=np.zeros((21,21),dtype=np.float32)\nm64=np.zeros((21,21),dtype=np.float64)\namt=4.5\nprint(f'm16 {m16.dtype}')\nprint(f'm32 {m32.dtype}')\nprint(f'm64 {m64.dtype}')\nprint(np.finfo(np.float64))\nprint(f'float {sys.float_info}')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:08:54.373046Z","iopub.execute_input":"2022-06-05T20:08:54.373637Z","iopub.status.idle":"2022-06-05T20:08:54.387058Z","shell.execute_reply.started":"2022-06-05T20:08:54.373601Z","shell.execute_reply":"2022-06-05T20:08:54.385893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like a np.float64 is the same as a python 'float'","metadata":{}},{"cell_type":"markdown","source":"Here is our compare function that tries all the methods.  It also uses 3 different matrix datatypes: 16, 32 and 64 bit entries for the matrix.","metadata":{}},{"cell_type":"code","source":"def compare_float(N):\n  #N is the length of a route\n  kore=dict()\n  #assume 200 squares have positive kore\n  mat_kore16 = np.zeros((21,21), dtype=np.float16)\n  mat_kore32 = np.zeros((21,21), dtype=np.float32)\n  mat_kore64 = np.zeros((21,21), dtype=np.float64)\n  mat_kore64_dim3 = mat_kore64.reshape(21,21,1)   # Need to reshape so broadcasting will work below\n  for i in range(200):\n    #put random core in a spot\n    x,y=random.randint(0,20),random.randint(0,20)\n    amt=random.random()*100\n    mat_kore16[(x,y)]=amt\n    mat_kore32[(x,y)]=amt\n    mat_kore64[(x,y)]=amt\n    kore[(x,y)]=amt\n  #Set the routes\n  mat_route16 = np.zeros((21,21), dtype=np.float16)      \n  mat_route32 = np.zeros((21,21), dtype=np.float32)\n  mat_route64 = np.zeros((21,21), dtype=np.float64)\n  big_route=np.zeros((21,21,1000),dtype=np.float64)\n  route=[]\n  for i in range(N):\n    #The route, use a float\n    x,y=random.randint(0,20),random.randint(0,20)\n    mat_route16[x,y]=.30\n    mat_route32[x,y]=.30\n    mat_route64[x,y]=.30    \n    for j in range(1000):\n      big_route[x,y,j]=0.30\n    route.append((x,y))\n  #make a list of P values increasing at 2% per step  \n  plist=[.10*(1.02)**i for i in range(N)]  \n  #Make the route into a matrix for mat_lookup method\n  route_mat=np.array(route,dtype=np.int32)\n  #How long does it take to compute the kore along the route of length N\n  def comp_mat_mult16():\n    #a single matrix multiply with precomputed route and kore matrix\n    return (mat_kore16 * mat_route16).sum()\n  def comp_mat_mult32():\n    #a single matrix multiply with precomputed route and kore matrix\n    return (mat_kore32 * mat_route32).sum()\n  def comp_mat_mult64():\n    #a single matrix multiply with precomputed route and kore matrix\n    return (mat_kore64 * mat_route64).sum()\n  def comp_mat_lookup():\n    p=0.10\n    #use a matrix to look up the kore and sum\n    return p*sum([ mat_kore32[x,y] for x,y in route ])\n  def comp_mat_index():\n    #a use advanced indexing to so the lookup with sum\n    return mat_kore64[route_mat[:,0],route_mat[:,1]].sum()\n  def comp_dict_lookup():\n    #Use a dict to look up the kore and sum\n    p=0.10\n    return p*sum([ kore.get((x,y),0) for x,y in route ])\n  def comp_dict_incr():\n    #Use a dict to look up the kore and sum, but have weights increase at .02 per step\n    return sum([ p*kore.get((x,y),0) for p,(x,y) in zip(plist,route) ])\n  def comp_mat_einsum():\n    return np.einsum('ij,ijk->k',mat_kore64,big_route)\n  def comp_mat_vector():\n    return np.sum(mat_kore64_dim3 * big_route, axis=(0,1))\n        \n        \n  num=10000\n  results=[]\n  results.append(timeit.timeit(comp_mat_mult16,  number=num))\n  results.append(timeit.timeit(comp_mat_mult32,  number=num))\n  results.append(timeit.timeit(comp_mat_mult64,  number=num))\n  results.append(timeit.timeit(comp_mat_lookup,  number=num))\n  results.append(timeit.timeit(comp_mat_index,  number=num))\n  results.append(timeit.timeit(comp_dict_lookup, number=num))\n  results.append(timeit.timeit(comp_dict_incr, number=num))\n  results.append(timeit.timeit(comp_mat_einsum, number=num)/1000)   # because we are doing 1000 routes at once\n  results.append(timeit.timeit(comp_mat_vector, number=num)/1000)   # because we are doing 1000 routes at once\n\n  #convert to microseconds per iteration\n  results=[1e6*x/num for x in results]\n  labels=['mat mult 16','mat mult 32','mat mult 64', 'mat lookup','mat index','dict lookup','dict incr','mat einsum','mat vector']\n  return results, labels","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:10:26.099574Z","iopub.execute_input":"2022-06-05T20:10:26.099974Z","iopub.status.idle":"2022-06-05T20:10:26.125232Z","shell.execute_reply.started":"2022-06-05T20:10:26.099943Z","shell.execute_reply":"2022-06-05T20:10:26.124222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Let's look at the numbers before plotting them:\nres,labels=compare_float(10)\nres","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:10:33.893292Z","iopub.execute_input":"2022-06-05T20:10:33.893704Z","iopub.status.idle":"2022-06-05T20:10:42.158258Z","shell.execute_reply.started":"2022-06-05T20:10:33.89367Z","shell.execute_reply":"2022-06-05T20:10:42.157258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remember that last small number.  Remember its 1/1000 of the time to do 1000 routes.","metadata":{}},{"cell_type":"code","source":"\nvals=[]\nresults=[]\nfor N in range(4,32,2):\n  #N=int(N)\n  print(f'N={N}')\n  res,labels=compare_float(N)\n  results.append(res)\n  vals.append(N)\ndata=np.array(results)\nfor i, label in enumerate(labels):\n  plt.plot(vals,data[:,i],label=label,marker='.')\n#plt.ylim(0,8e-6)\nplt.title('time per route calculation vs route length')\nplt.ylabel('microseconds per route')\nplt.xlabel('length of route in steps')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:10:45.726357Z","iopub.execute_input":"2022-06-05T20:10:45.727008Z","iopub.status.idle":"2022-06-05T20:12:40.503324Z","shell.execute_reply.started":"2022-06-05T20:10:45.726974Z","shell.execute_reply":"2022-06-05T20:12:40.502356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"RESULTS:\nEDIT:  Clearly, if you can precompute the routes and can group them in large batches, einsum is the way to go\n\nFor single routes at a time:\nFor shorter routes, the dict lookup is faster, but has more overhead if you want to carefully calculate the kore with 2% growth.  For a longer route, say a 5x5 box (around 20 steps), the 2% growth results in a 50% increase of kore towards the end of the route, so it might be important depending on how accurate you want your results.\n\nThe surprising result here is that float16 math is quite slow.","metadata":{}}]}