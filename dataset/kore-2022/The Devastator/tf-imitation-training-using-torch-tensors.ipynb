{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Torch & Tensorflow users to be united! âœŠ\n\n**Training a tensorflow network using torch tensors**\n\n_____\n\nThis is a highly experimental notebook attempting to train a tensorflow network using torch tensors. \nThe notebook is based on the [great tmitation training notebook](https://www.kaggle.com/code/huikang/kore-2022-imitation-training) by [huikang](https://www.kaggle.com/huikang).\n\nThe only difference is the network itself. \nI tried to translate everything as 1-to-1 as possible between torch and tensorflow so the actual changes between both implementations would be minimal.\nThe training loop is implemented to be very similar to the original using `GradientTape` instead of `autograd` and the tensors are fed from a `DataLoader` generated from the original datasets.\nAll tensors are converted before fed into the network with `tf.constant(states, dtype=tf.float32)`.\n\nMay this be the start of a great new age of collaboration..","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"%reset -sf\n!echo $KAGGLE_KERNEL_RUN_TYPE","metadata":{"lines_to_next_cell":2,"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:34.291028Z","iopub.execute_input":"2022-06-22T13:54:34.291571Z","iopub.status.idle":"2022-06-22T13:54:36.175955Z","shell.execute_reply.started":"2022-06-22T13:54:34.291531Z","shell.execute_reply":"2022-06-22T13:54:36.175047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install kaggle-environments -U > /dev/null\n!cp ../input/kore-2022-feature-generator/kore_analysis.py .\n!cp ../input/kore-2022-feature-generator/feature_generator.py .","metadata":{"lines_to_next_cell":2,"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:36.178854Z","iopub.execute_input":"2022-06-22T13:54:36.179367Z","iopub.status.idle":"2022-06-22T13:54:47.634566Z","shell.execute_reply.started":"2022-06-22T13:54:36.179327Z","shell.execute_reply":"2022-06-22T13:54:47.633608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.core.magic import register_cell_magic\n\n@register_cell_magic\ndef writefile_and_run(line, cell):\n    argz = line.split()\n    file = argz[-1]\n    mode = 'w'\n    if len(argz) == 2 and argz[0] == '-a':\n        mode = 'a'\n    with open(file, mode) as f:\n        f.write(cell)\n    get_ipython().run_cell(cell)","metadata":{"lines_to_next_cell":2,"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:47.636638Z","iopub.execute_input":"2022-06-22T13:54:47.637213Z","iopub.status.idle":"2022-06-22T13:54:47.644404Z","shell.execute_reply.started":"2022-06-22T13:54:47.637177Z","shell.execute_reply":"2022-06-22T13:54:47.643456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile_and_run -a imitation_training_helper.py\n\nimport torch\nimport matplotlib\nimport numpy as np\nimport pandas as pd\nfrom torch import nn\nimport torch.optim as optim\nimport os, collections, random\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom scipy.special import softmax\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\ntorch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"lines_to_next_cell":2,"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:47.648368Z","iopub.execute_input":"2022-06-22T13:54:47.649066Z","iopub.status.idle":"2022-06-22T13:54:47.658193Z","shell.execute_reply.started":"2022-06-22T13:54:47.649028Z","shell.execute_reply":"2022-06-22T13:54:47.657488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from feature_generator import plot_3d_matrix","metadata":{"lines_to_next_cell":2,"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:47.659485Z","iopub.execute_input":"2022-06-22T13:54:47.660175Z","iopub.status.idle":"2022-06-22T13:54:47.670901Z","shell.execute_reply.started":"2022-06-22T13:54:47.660137Z","shell.execute_reply":"2022-06-22T13:54:47.67004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    os.environ['PYTHONHASHSEED'] = str(seed_value)    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\nseed = 42\nseed_everything(seed)","metadata":{"lines_to_next_cell":0,"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:47.673355Z","iopub.execute_input":"2022-06-22T13:54:47.67389Z","iopub.status.idle":"2022-06-22T13:54:47.682622Z","shell.execute_reply.started":"2022-06-22T13:54:47.673845Z","shell.execute_reply":"2022-06-22T13:54:47.68198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset and Dataloader","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"actions_df = pd.read_csv(\"../input/kore-2022-feature-generator/actions_df.csv\")\nactions_df.shape","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:47.683757Z","iopub.execute_input":"2022-06-22T13:54:47.685007Z","iopub.status.idle":"2022-06-22T13:54:47.840443Z","shell.execute_reply.started":"2022-06-22T13:54:47.684978Z","shell.execute_reply":"2022-06-22T13:54:47.839748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actions_df = actions_df[(actions_df[\"diff_x\"] != 0) | (actions_df[\"diff_y\"] != 0)]\nactions_df = actions_df[abs(actions_df[\"diff_x\"]) <= 10]\nactions_df = actions_df[abs(actions_df[\"diff_y\"]) <= 10]\nactions_df = actions_df[actions_df[\"action_class\"] >= 0]\n# actions_df = actions_df[abs(actions_df[\"turn_idx\"]) <= 20]\n# actions_df = actions_df[abs(actions_df[\"diff_x\"]) + abs(actions_df[\"diff_y\"]) <= 11]\n# actions_df = actions_df[abs(actions_df[\"diff_x\"]) + abs(actions_df[\"diff_y\"]) >= 3]\nactions_df[\"diff_x\"] = (actions_df[\"diff_x\"] + 10)\nactions_df[\"diff_y\"] = (actions_df[\"diff_y\"] + 10)\nactions_df.loc[actions_df[\"action_class\"] == 3, \"action_class\"] = 0  # recast attack action as build action\nactions_df.shape","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:47.841689Z","iopub.execute_input":"2022-06-22T13:54:47.842288Z","iopub.status.idle":"2022-06-22T13:54:47.886699Z","shell.execute_reply.started":"2022-06-22T13:54:47.842248Z","shell.execute_reply":"2022-06-22T13:54:47.885967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actions_df.sample(5)","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:47.88813Z","iopub.execute_input":"2022-06-22T13:54:47.888634Z","iopub.status.idle":"2022-06-22T13:54:47.905465Z","shell.execute_reply.started":"2022-06-22T13:54:47.888589Z","shell.execute_reply":"2022-06-22T13:54:47.904688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actions_df[\"action_class\"].value_counts()","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:47.908917Z","iopub.execute_input":"2022-06-22T13:54:47.909174Z","iopub.status.idle":"2022-06-22T13:54:47.919439Z","shell.execute_reply.started":"2022-06-22T13:54:47.90914Z","shell.execute_reply":"2022-06-22T13:54:47.918757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actions_df.head()","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:47.92067Z","iopub.execute_input":"2022-06-22T13:54:47.922035Z","iopub.status.idle":"2022-06-22T13:54:47.938374Z","shell.execute_reply.started":"2022-06-22T13:54:47.921997Z","shell.execute_reply":"2022-06-22T13:54:47.937546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,12))\nplt.scatter(actions_df[\"diff_x\"] + (actions_df[\"turn_idx\"]//20)/ 25 - 0.4, actions_df[\"diff_y\"] + (actions_df[\"turn_idx\"] %20)/ 25 - 0.4, s=actions_df[\"ship_amount\"], c=actions_df[\"action_class\"], cmap=\"winter_r\")\nplt.gca().xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\nplt.gca().yaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\nplt.gca().set_aspect('equal')\nplt.show()","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:47.939999Z","iopub.execute_input":"2022-06-22T13:54:47.940636Z","iopub.status.idle":"2022-06-22T13:54:51.106084Z","shell.execute_reply.started":"2022-06-22T13:54:47.940594Z","shell.execute_reply":"2022-06-22T13:54:51.104507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile_and_run -a imitation_training_helper.py\n\ndef append_source_specific_features(input_matrix):\n    kore_matrix = input_matrix[3,:,:]\n    kore_matrix_hori = np.zeros((21, 21))\n    kore_matrix_vert = np.zeros((21, 21))\n    dist_from_shipyard = np.add.outer(np.abs(np.arange(-10,11)), np.abs(np.arange(-10,11)))\n    assert dist_from_shipyard[10,10] == 0\n    dist_from_shipyard[10,10] = 1  # avoid divide by zero error later\n    shipyard_ship_count = np.full((21, 21), input_matrix[-11,10,10])\n\n    for i in range(10):  # first direction\n        kore_matrix_hori[10,10+i+1] += kore_matrix_hori[10,10+i] + kore_matrix[10,10+i+1]\n        kore_matrix_hori[10,10-i-1] += kore_matrix_hori[10,10-i] + kore_matrix[10,10-i-1]\n        kore_matrix_vert[10+i+1,10] += kore_matrix_vert[10+i,10] + kore_matrix[10+i+1,10]\n        kore_matrix_vert[10-i-1,10] += kore_matrix_vert[10-i,10] + kore_matrix[10-i-1,10]\n    \n    for i in range(10):  # second direction\n        kore_matrix_vert[:,10+i+1] += kore_matrix_vert[:,10+i] + kore_matrix[:,10+i+1]\n        kore_matrix_vert[:,10-i-1] += kore_matrix_vert[:,10-i] + kore_matrix[:,10-i-1]\n        kore_matrix_hori[10+i+1,:] += kore_matrix_hori[10+i,:] + kore_matrix[10+i+1,:]\n        kore_matrix_hori[10-i-1,:] += kore_matrix_hori[10-i,:] + kore_matrix[10-i-1,:]\n    \n    # each cell is visited twice except the destination cell\n    kore_matrix_hori = (2*kore_matrix_hori - kore_matrix) / dist_from_shipyard\n    kore_matrix_vert = (2*kore_matrix_vert - kore_matrix) / dist_from_shipyard\n    input_matrix = np.concatenate(([kore_matrix_hori, kore_matrix_vert, dist_from_shipyard, shipyard_ship_count], input_matrix), axis=0)\n    input_matrix = np.clip(input_matrix, 0, 10)\n    return input_matrix\n\ndef action_encoder(action_class, diff_x, diff_y):\n    assert 0 <= action_class < 3\n    assert 0 <= diff_x < 21\n    assert 0 <= diff_y < 21\n    return action_class*21*21 + diff_x*21 + diff_y\n\ndef action_decoder(clf_idx):\n    action_class, clf_idx = divmod(clf_idx, 21*21)\n    diff_x, diff_y = divmod(clf_idx, 21)\n    return action_class, diff_x, diff_y","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:51.107432Z","iopub.execute_input":"2022-06-22T13:54:51.10787Z","iopub.status.idle":"2022-06-22T13:54:51.126907Z","shell.execute_reply.started":"2022-06-22T13:54:51.107835Z","shell.execute_reply":"2022-06-22T13:54:51.126323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_actions_df = actions_df[actions_df[\"episode_id\"]%10 != 0]\nval_actions_df = actions_df[actions_df[\"episode_id\"]%10 == 0]\n\ndef aggregate_into_episode_and_turn(df):\n    samples_build = collections.defaultdict(list)\n    samples = collections.defaultdict(list)\n    for record in df.to_dict('records'):\n        if record[\"turn_idx\"] <= 3: continue\n        submission_episode_turnidx = record[\"submission_id\"], record[\"episode_id\"], record[\"turn_idx\"]\n        submission_id, episode_id, turn_idx = submission_episode_turnidx\n        npy_path_name = f\"\"\"../input/kore-2022-feature-generator/npy/{submission_id}_{episode_id}_{turn_idx-1:03d}_inputs.npy\"\"\"\n        if not os.path.isfile(npy_path_name): continue\n        if record[\"action_class\"] == 0:  # is build action\n            samples_build[submission_episode_turnidx].append(record)\n        else: samples[submission_episode_turnidx].append(record)            \n    return list(samples.items()) + list(samples_build.items())\ntrain_samples = aggregate_into_episode_and_turn(train_actions_df)\nval_samples = aggregate_into_episode_and_turn(val_actions_df)","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T13:54:51.128164Z","iopub.execute_input":"2022-06-22T13:54:51.128662Z","iopub.status.idle":"2022-06-22T13:55:34.135276Z","shell.execute_reply.started":"2022-06-22T13:54:51.128618Z","shell.execute_reply":"2022-06-22T13:55:34.134233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tensorflow Network Training","metadata":{}},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tqdm.notebook import tqdm\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import GlorotUniform\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom imitation_training_helper import append_source_specific_features, action_encoder, action_decoder\nfrom tensorflow.keras.layers import Layer, InputLayer, Conv2D, Flatten, Dense, Reshape, ReLU, Softmax","metadata":{"execution":{"iopub.status.busy":"2022-06-22T13:55:34.156031Z","iopub.execute_input":"2022-06-22T13:55:34.157963Z","iopub.status.idle":"2022-06-22T13:55:34.164739Z","shell.execute_reply.started":"2022-06-22T13:55:34.157926Z","shell.execute_reply":"2022-06-22T13:55:34.163833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset Loader","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nclass KoreDataset(Dataset):\n    def __init__(self, samples):\n        self.samples = samples\n        \n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        (submission_id, episode_id, turn_idx), samples = self.samples[idx]        \n        npy_path_name = f\"\"\"../input/kore-2022-feature-generator/npy/{submission_id}_{episode_id}_{turn_idx-1:03d}_inputs.npy\"\"\"\n        sample = random.choice(samples)\n        state = np.load(npy_path_name)\n        state = np.roll(state, (0, -sample[\"shipyard_x\"] + 10, -sample[\"shipyard_y\"] + 10), axis = (0, 1, 2))  # center shipyard\n        state = append_source_specific_features(state)        \n        action_tuple = sample[\"action_class\"], sample[\"diff_x\"], sample[\"diff_y\"]\n        action = action_encoder(*action_tuple)\n        assert action_decoder(action) == action_tuple\n        return state, action","metadata":{"execution":{"iopub.status.busy":"2022-06-22T13:57:19.339313Z","iopub.execute_input":"2022-06-22T13:57:19.339569Z","iopub.status.idle":"2022-06-22T14:04:20.251772Z","shell.execute_reply.started":"2022-06-22T13:57:19.33954Z","shell.execute_reply":"2022-06-22T14:04:20.250883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training Loop","metadata":{}},{"cell_type":"code","source":"batch_size = 64\ninput_matrix, action = KoreDataset(train_samples)[200]\nNUM_LAYERS = input_matrix.shape[0]\n\nprint(NUM_LAYERS, input_matrix.shape, action)\n\ninput_matrix, action = KoreDataset(train_samples)[200]\nNUM_LAYERS = input_matrix.shape[0]\nNUM_LAYERS, input_matrix.shape, action\n\nbatch_size = 64\ntrain_loader = DataLoader(KoreDataset(train_samples), batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(KoreDataset(val_samples), batch_size=batch_size, shuffle=False, num_workers=2)\n\ndef train_model(model, dataloaders_dict, criterion, optimizer, num_epochs):\n    best_acc = 0.0\n    for epoch in range(num_epochs):\n        for phase in ['train', 'val']:\n            epoch_loss = 0.0\n            epoch_acc = 0\n            dataloader = dataloaders_dict[phase]\n            for states, actions in tqdm(dataloader, leave=False):\n                states = tf.constant(states, dtype=tf.float32)\n                actions = tf.constant(actions, dtype=tf.int32)\n                with tf.GradientTape() as tape:\n                    policy = model(states)                    \n                    actions = tf.cast(actions, tf.float32)\n                    policy = tf.cast(policy, tf.float32)\n                    loss = criterion(actions, policy)\n                    _, preds = tf.math.top_k(policy, k=1)\n                    if phase == 'train':\n                        gradients = tape.gradient(loss, model.trainable_variables)\n                        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n                    epoch_loss += loss.numpy() * len(policy)\n                    epoch_acc += tf.reduce_sum(tf.cast(tf.equal(tf.cast(preds, tf.int32), tf.cast(actions, tf.int32)), tf.float32))\n            data_size = len(dataloader.dataset)\n            epoch_loss = epoch_loss / data_size\n            epoch_acc = epoch_acc.numpy() / data_size\n            print(f'Epoch {epoch + 1}/{num_epochs} | {phase:^5} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}')\n        if epoch_acc > best_acc:\n            model.save('model.h5')\n            best_acc = epoch_acc\n        if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") == \"Interactive\" and epoch == 2:\n            break  # for interactive runs, only check that it is working","metadata":{"execution":{"iopub.status.busy":"2022-06-22T13:57:19.339313Z","iopub.execute_input":"2022-06-22T13:57:19.339569Z","iopub.status.idle":"2022-06-22T14:04:20.251772Z","shell.execute_reply.started":"2022-06-22T13:57:19.33954Z","shell.execute_reply":"2022-06-22T14:04:20.250883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Network Architecture","metadata":{}},{"cell_type":"code","source":"class BasicConv2d(layers.Layer):\n    def __init__(self, input_dim, output_dim, kernel_size, bn):\n        super().__init__()\n        self.conv = layers.Conv2D(\n            output_dim, \n            kernel_size=kernel_size, \n            padding='same',\n        )\n        self.bn = layers.BatchNormalization() if bn else None\n\n    def call(self, x):\n        h = self.conv(x)\n        h = self.bn(h) if self.bn is not None else h\n        return h\n\nclass KoreNet(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        layers, filters = 12, 32\n        self.conv0 = BasicConv2d(NUM_LAYERS, filters, (3, 3), True)\n        self.blocks = [BasicConv2d(filters, filters, (3, 3), True) for _ in range(layers)]\n        self.conv1 = BasicConv2d(filters, 3, (3, 3), True)\n        self.flat = tf.keras.layers.Flatten()\n        \n    def call(self, x):\n        h = tf.nn.relu(self.conv0(x))\n        for block in self.blocks:             \n            h = tf.nn.relu(h + block(h))\n        h = self.conv1(h)\n        flattened = self.flat(h)        \n        return flattened","metadata":{"execution":{"iopub.status.busy":"2022-06-22T13:57:19.339313Z","iopub.execute_input":"2022-06-22T13:57:19.339569Z","iopub.status.idle":"2022-06-22T14:04:20.251772Z","shell.execute_reply.started":"2022-06-22T13:57:19.33954Z","shell.execute_reply":"2022-06-22T14:04:20.250883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Actual Training","metadata":{}},{"cell_type":"code","source":"kore_net = KoreNet()\ncriterion = tf.keras.losses.SparseCategoricalCrossentropy()\noptimizer = tf.keras.optimizers.Adam(1e-3)\n\ndataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\ntrain_model(kore_net, dataloaders_dict, criterion, optimizer, num_epochs=3)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T13:57:19.339313Z","iopub.execute_input":"2022-06-22T13:57:19.339569Z","iopub.status.idle":"2022-06-22T14:04:20.251772Z","shell.execute_reply.started":"2022-06-22T13:57:19.33954Z","shell.execute_reply":"2022-06-22T14:04:20.250883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"for states, actions in val_loader:    \n    p = kore_net(tf.constant(states, dtype=tf.float32))\n    print(p.shape, actions.shape)","metadata":{"lines_to_next_cell":2,"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T14:10:12.909383Z","iopub.execute_input":"2022-06-22T14:10:12.909978Z","iopub.status.idle":"2022-06-22T14:10:21.883481Z","shell.execute_reply.started":"2022-06-22T14:10:12.909934Z","shell.execute_reply":"2022-06-22T14:10:21.882616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert states[0].numpy()[-2,10,10] != 0","metadata":{"lines_to_next_cell":2,"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T14:05:48.43744Z","iopub.execute_input":"2022-06-22T14:05:48.437742Z","iopub.status.idle":"2022-06-22T14:05:48.443271Z","shell.execute_reply.started":"2022-06-22T14:05:48.43769Z","shell.execute_reply":"2022-06-22T14:05:48.442244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_3d_matrix(states[0].numpy())","metadata":{"lines_to_next_cell":2,"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T14:05:51.824648Z","iopub.execute_input":"2022-06-22T14:05:51.82524Z","iopub.status.idle":"2022-06-22T14:05:52.797204Z","shell.execute_reply.started":"2022-06-22T14:05:51.825197Z","shell.execute_reply":"2022-06-22T14:05:52.796531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kore_slice = states[0].numpy()[:1]\nplot_3d_matrix(kore_slice, scene_camera_eye=dict(x=3, y=3, z=3))","metadata":{"lines_to_next_cell":2,"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T14:06:02.769239Z","iopub.execute_input":"2022-06-22T14:06:02.769499Z","iopub.status.idle":"2022-06-22T14:06:02.927064Z","shell.execute_reply.started":"2022-06-22T14:06:02.76947Z","shell.execute_reply":"2022-06-22T14:06:02.926244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kore_slice = states[0].numpy()[1:2]\nplot_3d_matrix(kore_slice, scene_camera_eye=dict(x=3, y=3, z=3))","metadata":{"lines_to_next_cell":2,"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T14:06:10.686464Z","iopub.execute_input":"2022-06-22T14:06:10.686753Z","iopub.status.idle":"2022-06-22T14:06:10.851816Z","shell.execute_reply.started":"2022-06-22T14:06:10.686716Z","shell.execute_reply":"2022-06-22T14:06:10.850772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"action_decoder(actions[0].numpy())","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-06-22T14:09:45.532367Z","iopub.execute_input":"2022-06-22T14:09:45.533004Z","iopub.status.idle":"2022-06-22T14:09:45.539215Z","shell.execute_reply.started":"2022-06-22T14:09:45.53296Z","shell.execute_reply":"2022-06-22T14:09:45.538431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The use of the model to build an imitation agent will be done in another notebook.\n","metadata":{"pycharm":{"name":"#%% md\n"}}}]}