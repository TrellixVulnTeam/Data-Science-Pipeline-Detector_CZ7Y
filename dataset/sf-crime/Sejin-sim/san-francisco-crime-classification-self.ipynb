{"cells":[{"metadata":{"_uuid":"e74d4f90-24c4-43b0-a032-c4a741fa2b18","_cell_guid":"677b50a9-6938-460c-965e-457a099cdfd0","trusted":true},"cell_type":"markdown","source":"1. EDA\n1. Data Preprocess\n1. Single Model\n1. Feature Engineering\n1. Stacking\n1. submit"},{"metadata":{"_uuid":"cdf2ea67-7e32-47ff-8f32-20bc962af3e9","_cell_guid":"28f262e9-b6cc-44d5-9a42-71bdcac3e28e","trusted":true,"scrolled":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4c0b5ac-512a-433a-b48f-cdf8b3997acd","_cell_guid":"343cf751-f97e-41bd-8968-b9796fd431da","trusted":true,"scrolled":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fd8fdc1-48a0-4b1a-82ce-1b12b942ba51","_cell_guid":"130cfeb8-bfcf-49ed-8af0-9a28270cbb06","trusted":true,"scrolled":false},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/sf-crime/train.csv.zip')\ntest = pd.read_csv('/kaggle/input/sf-crime/test.csv.zip', index_col='Id')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/sf-crime/sampleSubmission.csv.zip',index_col='Id')\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4d75951-cade-4b1b-9fa9-a9ddff769211","_cell_guid":"02b14718-5c61-4548-854a-05dcd36517eb","trusted":true,"scrolled":false},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4f46ac4-7dbe-4535-8776-11616da6f6bd","_cell_guid":"47a16436-ab1d-4400-9d92-7f54dc3c3727","trusted":true,"scrolled":false},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ff3133a-c253-4990-8f96-3b0f7bfd3d81","_cell_guid":"9e7caf09-ae8e-46da-be1a-6719a6ae0f1f","trusted":true,"scrolled":false},"cell_type":"code","source":"Tename = list(test)\nTename","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcf0ab4e-5f57-4919-bd73-9003a455797e","_cell_guid":"9da99e0d-5c17-474d-bcff-e76f65239e21","trusted":true,"scrolled":false},"cell_type":"code","source":"df_train = train[Tename]\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae669807-b078-4355-9831-d58e9b1f893b","_cell_guid":"d0cadda5-f1d1-4ab9-aeee-cfc30a9a8b8f","trusted":true,"scrolled":false},"cell_type":"code","source":"df = pd.concat((df_train,test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76de0cf1-a5e4-4bf4-b152-b38de7c6d1b2","_cell_guid":"2dd63df2-4691-4d1a-8200-74842d1f43b6","trusted":true,"scrolled":false},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a549fbf5-f9b8-4c84-91fe-a7eb853b4de0","_cell_guid":"59496434-7db3-484b-99a1-012b6df9f0c3","trusted":true,"scrolled":true},"cell_type":"code","source":"target = train['Category']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e48d406-36bc-4651-8d4c-0518cddec8de","_cell_guid":"45e89cb8-c69c-4c57-a132-d0abe9ab8fd5","trusted":true,"scrolled":true},"cell_type":"code","source":"target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86b579d6-2db5-45ca-a04a-aef425c8f9a5","_cell_guid":"4ca4e179-beb9-428c-8193-976df1c30a20","trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nLB = LabelEncoder() \ntarget = LB.fit_transform(target)\nprint(LB.classes_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c39d781-6da6-4dd0-852b-6f9f2a676588","_cell_guid":"3364b1aa-267a-4529-b54e-4c6c0ba6d66f","trusted":true,"scrolled":true},"cell_type":"code","source":"target","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca350dd7-fa1f-4e83-9016-de1fbcacfe0e","_cell_guid":"f5d6a881-3179-4404-9495-a50327423479","trusted":true,"scrolled":true},"cell_type":"code","source":"date = pd.to_datetime(df['Dates'])\ndf['Date'] = date.dt.date\ndf['Year'] = date.dt.year\ndf['Month'] = date.dt.month\ndf['Day'] = date.dt.day\ndf['Hour'] = date.dt.hour\ndf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9dcfb47e-78cc-44b5-9352-5573b92f080f","_cell_guid":"ae4df569-0720-4071-af86-a6aa74f679a6","trusted":true,"scrolled":true},"cell_type":"code","source":"df.drop('Dates', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fba311d-4eca-4962-8022-3a72c09297ca","_cell_guid":"0f009f85-9f49-406c-9b28-5b6b50bb948a","trusted":true,"scrolled":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b46ddf4b-3c00-4952-a752-e25204841378","_cell_guid":"a6af118e-17bc-4a3a-9c13-b5ec8e64cc4c","trusted":true,"scrolled":true},"cell_type":"code","source":"year = df.groupby('Year').count().iloc[:,0]\nmonth = df.groupby('Month').count().iloc[:,0]\nhour = df.groupby('Hour').count().iloc[:,0]\ndayofweek = df.groupby('DayOfWeek').count().iloc[:, 0]\n\nfigure, axs = plt.subplots(2,2, figsize = (15,10))\n\nsns.barplot(x=year.index, y= year,ax = axs[0][0])\nsns.barplot(x=month.index, y= month,ax = axs[0][1])\nsns.barplot(x=hour.index, y= hour,ax = axs[1][0])\nsns.barplot(x=dayofweek.index, y= dayofweek,ax = axs[1][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb = LabelEncoder()\ndf['PdDistrict'] = lb.fit_transform(df[\"PdDistrict\"])\ndf['DayOfWeek'] = lb.fit_transform(df[\"DayOfWeek\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Address\"].value_counts().head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Block'] = df['Address'].str.contains('Block')\ndf['ST'] = df['Address'].str.contains('ST')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Block'] = lb.fit_transform(df[\"Block\"])\ndf['ST'] = lb.fit_transform(df[\"ST\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(\"Address\", axis =1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"샌프란시스코 위도(x): 37.7272, 경도(y): -123.032"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df[\"X\"].min(), df[\"X\"].max())\nprint(df[\"Y\"].min(), df[\"Y\"].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"위도\t32°30'N ~ 42°N   \n경도\t114°8'W ~ 124°24'W"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(df.loc[df[\"X\"] >= -120.5]))\nprint(len(df.loc[df[\"Y\"] >= 90]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df[\"X\"] >= -120.5, \"X\"] = df[df[\"X\"] < -120.5][\"X\"].median()\ndf.loc[df[\"Y\"] >= 90, \"Y\"] = df[df[\"Y\"] < -90][\"Y\"].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['X+Y'] = df['X'] + df['Y']\ndf['X-Y'] = df['X'] - df['Y']\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(\"Date\", axis = 1, inplace = True)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"III. 모델링\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = df[:train.shape[0]]\nnew_test = df[train.shape[0]:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://nurilee.com/2020/04/03/lightgbm-definition-parameter-tuning/"},{"metadata":{"trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport xgboost as xgb\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split\n\n\nclf = xgb.XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor', objective ='multi:softprob')\n\nparam_grid = {\n        'silent': [False],\n        'max_depth': [6, 10, 15, 20],\n        'learning_rate': [0.001, 0.01, 0.1, 0.2, 0,3],\n        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n        'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n        'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n        'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n#         'max_bin' : [100, 200, 300 ,400, 500],\n        'gamma': [0, 0.25, 0.5, 1.0],\n        'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n        'n_estimators': [100]}\n\n# fit_params = {'eval_metric': 'mlogloss',  'early_stopping_rounds': 10,   'eval_set': [(x_valid, y_valid)]}\n\nrs_clf = RandomizedSearchCV(clf, param_grid, n_jobs=-1, verbose=1, cv=2,\n                            scoring='neg_log_loss', refit=False, random_state=42) # n_iter=10,\n\nprint(\"Randomized search\")\nsearch_time_start = time.time()\n\nrs_clf.fit(new_train, target)\nprint(\"Randomized search time:\", time.time() - search_time_start)\n\nbest_score = rs_clf.best_score_\nbest_params = rs_clf.best_params_\nprint(\"Best score: {}\".format(best_score))\nprint(\"Best params: \")\n\nfor param_name in sorted(best_params.keys()):\n    print('%s: %r' % (param_name, best_params[param_name]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# XGBoost 분류기 생성\nxgb_clf = xgb.XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor', objective ='multi:softprob')\n\nxgb_param_grid={ \n                 'silent':[True],\n                 'max_depth':[5,6,8],\n                 'min_child_weight':[1,3,5],\n                 'gamma':[0,1,2,3],\n                 'nthread':[4],\n                 'colsample_bytree':[0.5,0.8],\n                 'colsample_bylevel':[0.9],\n                 'subsample': [0.6, 0.8, 1.0],\n                 'n_estimators':[50],\n                 'random_state':[42]}\n\n\n# Create a GridSearchCV object\n\nhr_grid = GridSearchCV(estimator=xgb_clf,\n                       param_grid=xgb_param_grid,\n                       scoring='neg_log_loss',\n                       n_jobs=-1,\n                       cv=5,\n                       return_train_score=True)\n\nhr_grid.fit(new_train, target)\n\nbest_score = hr_grid.best_score_\n# 최고성능을 내는 행을 찾아냄\nbest_row = hr_grid.best_index_\n\n# 최적 초모수: max_depth, subsample\nbest_max_depth     = hr_grid.best_params_[\"max_depth\"]\nbest_max_subsample = hr_grid.best_params_[\"subsample\"]\n\nnl = '\\n'\nprint(f'예측모형성능(AUC):  \\t {best_score:.3f}{nl}\\\n        인덱스:           \\t {best_row}{nl}\\\n        max_depth:      \\t {max_depth}{nl}\\\n        subsample:      \\t {subsample}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    'max_depth': 4,     \n    'eta': 0.3,     \n    'silent': 1,    \n    'objective': 'multi:softprob',    \n    'num_class': 39,   "},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = bst.predict(new_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(predictions,columns=LB.inverse_transform(np.linspace(0, 38, 39, dtype='int16')),index=new_test.index)\n#submission.to_csv('LGB.csv', index_label='Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom bayes_opt import BayesianOptimization\nfrom sklearn.model_selection import cross_val_score\n\ndef lgb_evaluate(                \n                numLeaves,\n                maxDepth,\n#                 scaleWeight,\n#                 minChildWeight,\n                Subsample,\n                colSam,\n                train_x, train_y\n                ):\n    clf = lgb.LGBMClassifier(\n        objective = 'multiclass',\n        metric= 'multi_logloss',\n#         eval_metric= 'logloss',\n#         reg_alpha= 0,\n#         reg_lambda= 2,\n#         bagging_fraction= 0.999,\n#         min_split_gain= 0,\n#         min_child_samples= 10,\n#         subsample_freq= 3,\n#         subsample_for_bin= 50000,\n#         n_estimators= 100,\n#         tree_method = 'gpu_hist',\n        device_type = 'gpu',\n        num_leaves= int(numLeaves),\n        max_depth= int(maxDepth),\n#         scale_pos_weight= scaleWeight,\n#         min_child_weight= minChildWeight,\n        subsample= Subsample,\n        colsample_bytree= colSam)\n#     clf.fit(train_x, train_y)\n    scores = cross_val_score(clf, train_x, train_y, scoring='neg_log_loss')  # cv=5,\n    print(scores.mean())\n\n    return scores.mean()\n   \ndef bayesOpt(train_x, train_y):\n    def dtc_crossval(numLeaves,\n                    maxDepth,\n#                     scaleWeight,\n#                     minChildWeight,\n                    subsample,\n                    colSam):\n        return lgb_evaluate(\n            numLeaves= int(numLeaves),\n            maxDepth= int(maxDepth),\n#             scaleWeight= scaleWeight,\n#             minChildWeight= minChildWeight,\n            Subsample= subsample,\n            colSam= colSam,\n            train_x=train_x,\n            train_y=train_y,\n        )    \n    \n    lgbBO = BayesianOptimization(dtc_crossval,\n                                 {'numLeaves':  (5, 50),\n                                    'maxDepth': (2, 50),\n#                                     'scaleWeight': (1, 10000),\n#                                     'minChildWeight': (0.01, 70),\n                                    'subsample': (0.4, 1),                                                \n                                    'colSam': (0.4, 1)\n                                  \n                                            })\n    \n\n    lgbBO.maximize(init_points=5, n_iter=5)\n    \n    print(\"Final result:\", lgbBO.max)\n#   print(lgbBO.res['max'])\n    \nbayesOpt(new_train, target)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}