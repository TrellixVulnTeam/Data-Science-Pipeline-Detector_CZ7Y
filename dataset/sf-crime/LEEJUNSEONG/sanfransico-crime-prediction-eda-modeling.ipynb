{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport matplotlib  \nimport matplotlib.pyplot as plt ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/sf-crime/train.csv.zip')\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Dates']=pd.to_datetime(train['Dates'])\ntrain['Year'] = train['Dates'].dt.year\ntrain['QTR'] = train['Dates'].dt.quarter\ntrain['Month'] = train['Dates'].dt.month\ntrain['Hour'] = train['Dates'].dt.hour\ndaynumber = {\n    'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6,'Sunday':7\n}\ntrain['DayOfWeek'] = train['DayOfWeek'].map(daynumber)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_data = train.groupby(['Month','Hour']).agg({'Category':'count'}).\\\npivot_table(index='Hour',columns='Month')['Category']\nfig = plt.figure() \nax = fig.add_subplot() \nx = plot_data.index \nfor col in plot_data.columns:\n    y = plot_data[col]\n    ax.plot(x,y,'o-',label=col)\nax.legend(title='Month') \nax.grid('both',alpha=0.3)\nax.set_xlabel('Hour')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_data = train.groupby(['Year','Month']).agg({'Category':'count'}).\\\npivot_table(index='Month',columns='Year')['Category']\nfig = plt.figure() \nax = fig.add_subplot() \nx = plot_data.index \nfor col in plot_data.columns:\n    y = plot_data[col]\n    ax.plot(x,y,'o-',label=col)\nax.legend(title='Year') \nax.grid('both',alpha=0.3)\nax.set_xlabel('Month')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_data = train.groupby(['DayOfWeek']).agg({'Category':'count'})\nfig = plt.figure() \nax = fig.add_subplot() \nx = plot_data.index \nfor col in plot_data.columns:\n    y = plot_data[col]\n    ax.plot(x,y,'o-',label=col)\n# ax.legend(title='Year') \nax.grid('both',alpha=0.3)\nax.set_xlabel('DayOfWeek')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,20)) \nax = fig.add_subplot() \nfor dist in train['PdDistrict'].unique():\n    idx = train['PdDistrict'] == dist\n    df2 = train[idx].copy() \n    x = df2['X']\n    y = df2['Y']\n    ax.scatter(x,y,label=dist)\nax.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 이상치 해결\ntrain2 = train[(train['X'] < -121)]\nXYS = train2.groupby(['PdDistrict']).agg({'X':np.mean,'Y':np.mean})\nfor i in train.index:\n    v = train.loc[i,'X']\n    d = train.loc[i,'PdDistrict']\n    if v > -121:\n        train.loc[i,['X','Y']] = XYS.loc[d,['X','Y']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,20)) \nax = fig.add_subplot() \nfor dist in train['PdDistrict'].unique():\n    idx = train['PdDistrict'] == dist\n    df2 = train[idx].copy() \n    x = df2['X']\n    y = df2['Y']\n    ax.scatter(x,y,label=dist)\nax.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dist = train['PdDistrict'].unique()[4]\nidx = train['PdDistrict'] == dist \ndf2 = train[idx].copy() \nplot_data = df2.groupby(['Year','Month']).agg({'Category':'count'}).\\\npivot_table(index='Month',columns='Year')['Category']\n\nfig = plt.figure() \nax = fig.add_subplot() \nx = plot_data.index \nfor col in plot_data.columns:\n    y = plot_data[col]\n    ax.plot(x,y,'o-',label=col)\n# ax.legend(title='Year') \nax.grid('both',alpha=0.3)\nax.set_xlabel('Month')\nax.set_title(dist)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby(['PdDistrict']).agg({'Category':'count'}).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby(['PdDistrict','Category']).\\\nagg({'Resolution':'count'}).\\\npivot_table(index='Category',columns='PdDistrict')['Resolution']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby(['PdDistrict','Category']).\\\nagg({'Resolution':'count'}).\\\npivot_table(index='Category',columns='PdDistrict')['Resolution'].plot(kind='barh',stacked=True,figsize=(5,20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ct2 = train['Category'].value_counts()[train['Category'].value_counts() > 10000].index\ntrain['Category2']=train['Category'].apply(lambda x: 'Others' if x not in ct2 else x)\ntrain['Category2'].unique()\n\ntrain.groupby(['PdDistrict','Category2']).\\\nagg({'Resolution':'count'}).\\\npivot_table(index='PdDistrict',columns='Category2')['Resolution'].plot(kind='bar',stacked=True,figsize=(10,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = train.groupby(['PdDistrict','Category2']).\\\nagg({'Resolution':'count'}).\\\npivot_table(index='PdDistrict',columns='Category2')['Resolution']\nttl = df3.sum(axis=1)\nratio = df3.copy() \nfor col in df3.columns:\n    ratio[col] = df3[col]/ttl*100\nratio.plot(kind='bar',stacked=True,figsize=(10,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \ntrain = pd.read_csv('/kaggle/input/sf-crime/train.csv.zip')\ntrain['Dates']=pd.to_datetime(train['Dates'])\ntrain['Hour'] = train['Dates'].dt.hour\n# 이상치 제거\ntrain2 = train[(train['X'] < -121)]\nXYS = train2.groupby(['PdDistrict']).agg({'X':np.mean,'Y':np.mean})\nfor i in train.index:\n    v = train.loc[i,'X']\n    d = train.loc[i,'PdDistrict']\n    if v > -121:\n        train.loc[i,['X','Y']] = XYS.loc[d,['X','Y']]\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain[\"Category\"] = le.fit_transform(train[\"Category\"])\nle = LabelEncoder()\ntrain[\"PdDistrict\"] = le.fit_transform(train[\"PdDistrict\"])\nle = LabelEncoder()\ntrain[\"DayOfWeek\"] = le.fit_transform(train[\"DayOfWeek\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train3 = train[:500000].copy() \n# 학습할 모델\ntrain2 = train3[['Category','DayOfWeek','PdDistrict','X','Y','Hour']].copy() \nX = train2.drop(\"Category\",axis=1).values\ny = train2[\"Category\"].values\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors  import KNeighborsClassifier \nfor n in np.arange(5,101,10):\n    model = KNeighborsClassifier(n_neighbors=n) \n    # X_train과 y_train으로 학습을 하고 \n    model.fit(X_train, y_train)\n    # X_vaild와 y_vaild로 예측을 연습 \n    pred_train = model.predict(X_test)\n    score = (pred_train == y_test).mean()\n    print('n_neighbors = {} : '.format(n)+str(score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 범죄의 유형이 너무 많아서 예측하기 어려운 것일까 ? \nimport pandas as pd \nimport numpy as np \ntrain = pd.read_csv('/kaggle/input/sf-crime/train.csv.zip')\ntrain['Dates']=pd.to_datetime(train['Dates'])\ntrain['Hour'] = train['Dates'].dt.hour\n# 이상치 제거\ntrain2 = train[(train['X'] < -121)]\nXYS = train2.groupby(['PdDistrict']).agg({'X':np.mean,'Y':np.mean})\nfor i in train.index:\n    v = train.loc[i,'X']\n    d = train.loc[i,'PdDistrict']\n    if v > -121:\n        train.loc[i,['X','Y']] = XYS.loc[d,['X','Y']]\n\nct2 = train['Category'].value_counts()[train['Category'].value_counts() > 10000].index\ntrain['Category2']=train['Category'].apply(lambda x: 'Others' if x not in ct2 else x)\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain[\"Category\"] = le.fit_transform(train[\"Category\"])\nle = LabelEncoder()\ntrain[\"PdDistrict\"] = le.fit_transform(train[\"PdDistrict\"])\nle = LabelEncoder()\ntrain[\"DayOfWeek\"] = le.fit_transform(train[\"DayOfWeek\"])\n\ntrain3 = train[:500000].copy() \n# 학습할 모델\ntrain2 = train3[['Category2','DayOfWeek','PdDistrict','X','Y','Hour']].copy() \nX = train2.drop(\"Category2\",axis=1).values\ny = train2[\"Category2\"].values\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n\nfrom sklearn.neighbors  import KNeighborsClassifier \nfor n in np.arange(10,101,10):\n    model = KNeighborsClassifier(n_neighbors=n) \n    # X_train과 y_train으로 학습을 하고 \n    model.fit(X_train, y_train)\n    # X_vaild와 y_vaild로 예측을 연습 \n    pred_train = model.predict(X_test)\n    score = (pred_train == y_test).mean()\n    print('n_neighbors = {} : '.format(n)+str(score))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('./test.csv')\ntest['Dates']=pd.to_datetime(test['Dates'])\ntest['Hour'] = test['Dates'].dt.hour\n# 이상치 제거\ntrain2 = test[(test['X'] < -121)]\nXYS = train2.groupby(['PdDistrict']).agg({'X':np.mean,'Y':np.mean})\nfor i in train.index:\n    v = test.loc[i,'X']\n    d = test.loc[i,'PdDistrict']\n    if v > -121:\n        test.loc[i,['X','Y']] = XYS.loc[d,['X','Y']]\nfrom sklearn.preprocessing import LabelEncoder\n# le = LabelEncoder()\n# test[\"Category\"] = le.fit_transform(test[\"Category\"])\nle = LabelEncoder()\ntest[\"PdDistrict\"] = le.fit_transform(test[\"PdDistrict\"])\nle = LabelEncoder()\ntest[\"DayOfWeek\"] = le.fit_transform(test[\"DayOfWeek\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2 = test.loc[:20000,['DayOfWeek','PdDistrict','X','Y','Hour']].copy() \nresult = model.predict(test2)\nresult","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}