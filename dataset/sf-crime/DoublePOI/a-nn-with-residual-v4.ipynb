{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import something I need"},{"metadata":{"trusted":true},"cell_type":"code","source":"#作者：1621430024\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IS GPU available?"},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.is_available()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/sf-crime/train.csv.zip', parse_dates=['Dates'])\ntest_data = pd.read_csv('/kaggle/input/sf-crime/test.csv.zip', parse_dates=['Dates'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data info"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()\ntest_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transform data"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_features = pd.concat((train_data.iloc[:, [0, 3, 4, 6, 7, 8]],\n                          test_data.iloc[:, [1, 2, 3, 4, 5, 6]]),\n                         sort=False)\n\nnum_train = train_data.shape[0]\n\ntrain_labels = pd.get_dummies(train_data['Category']).values\nnum_outputs = train_labels.shape[1]\n\nall_features['year'] = all_features.Dates.dt.year\nall_features['month'] = all_features.Dates.dt.month\nall_features['new_year'] = all_features['month'].apply(\n    lambda x: 1 if x == 1 or x == 2 else 0)\nall_features['day'] = all_features.Dates.dt.day\nall_features['hour'] = all_features.Dates.dt.hour\nall_features['evening'] = all_features['hour'].apply(lambda x: 1\n                                                     if x >= 18 else 0)\n\nwkm = {\n    'Monday': 0,\n    'Tuesday': 1,\n    'Wednesday': 2,\n    'Thursday': 3,\n    'Friday': 4,\n    'Saturday': 5,\n    'Sunday': 6\n}\nall_features['DayOfWeek'] = all_features['DayOfWeek'].apply(lambda x: wkm[x])\nall_features['weekend'] = all_features['DayOfWeek'].apply(\n    lambda x: 1 if x == 4 or x == 5 else 0)\n\nOneHot_features = pd.get_dummies(all_features['PdDistrict'])\n\nall_features['block'] = all_features['Address'].apply(\n    lambda x: 1 if 'block' in x.lower() else 0)\n\nPCA_features = all_features[['X', 'Y']].values\nStandard_features = all_features[['DayOfWeek', 'year', 'month', 'day',\n                                  'hour']].values\nOneHot_features = pd.concat([\n    OneHot_features, all_features[['new_year', 'evening', 'weekend', 'block']]\n],\n                            axis=1).values\n\nscaler = StandardScaler()\nscaler.fit(Standard_features)\nStandard_features = scaler.transform(Standard_features)\n\npca = PCA(n_components=2)\npca.fit(PCA_features)\nPCA_features = pca.transform(PCA_features)\n\nall_features = np.concatenate(\n    (PCA_features, Standard_features, OneHot_features), axis=1)\n\ntrain_features = all_features[:num_train]\nnum_inputs = train_features.shape[1]\ntest_features = all_features[num_train:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definition residual block"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Residual(nn.Module):\n    def __init__(self, num_inputs, num_outputs):\n        super(Residual, self).__init__()\n        self.middle_L = nn.Linear(num_inputs, num_outputs)\n        self.middle_R = nn.ReLU(num_outputs)\n        if num_inputs != num_outputs:\n            self.right = nn.Linear(num_inputs, num_outputs)\n        else:\n            self.right = None\n        self.middle_B = nn.BatchNorm1d(num_outputs)\n    def forward(self, X):\n        Y = self.middle_B(self.middle_R(self.middle_L(X)))\n        if self.right:\n            X = self.right(X)\n        return Y + X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definition net"},{"metadata":{"trusted":true},"cell_type":"code","source":"class build_model(nn.Module):\n    def __init__(self, num_inputs, num_outputs, dp=0.5):\n        super(build_model, self).__init__()\n        self.net = nn.Sequential()\n        self.net.add_module('Residual1', Residual(num_inputs, 1024))\n        self.net.add_module('Residual2', Residual(1024, 512))\n        self.net.add_module('Residual3', Residual(512, 512))\n        self.net.add_module('Residual4', Residual(512, 256))\n        self.net.add_module('Dropout1', nn.Dropout(dp))\n        self.net.add_module('Residual5', Residual(256, 256))\n        self.net.add_module('Residual6', Residual(256, 128))\n        self.net.add_module('Residual7', Residual(128, 128))\n        self.net.add_module('Residual8', Residual(128, 64))\n        self.net.add_module('Dropout2', nn.Dropout(dp))\n        self.net.add_module('Residual9', Residual(64, 64))\n        self.net.add_module('Linear-out', nn.Linear(64, num_outputs))\n        self.net.add_module('Softmax', nn.Softmax(dim=-1))\n    def forward(self, x):\n        return self.net(x)\n\n\nnet = build_model(num_inputs, num_outputs).cuda()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definition loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MultiClassLogLoss(torch.nn.Module):\n    def __init__(self):\n        super(MultiClassLogLoss, self).__init__()\n    def forward(self, y_pred, y_true):\n        return -(y_true *\n                 torch.log(y_pred.float() + 1.00000000e-15)) / y_true.shape[0]\n\n\nloss = MultiClassLogLoss().cuda()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_iter(train_features, train_labels, batch_size):\n    train_features = torch.tensor(train_features, dtype=torch.float).cuda()\n    train_labels = torch.tensor(train_labels).cuda()\n    dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=True)\n\n\ndef show_loss(net, loss, features, labels, team):\n    net.eval()\n    batch = make_iter(features, labels, 1024)\n    loss_num = 0\n    n = 0\n    for x, y in batch:\n        loss_num += loss(net(x), y).sum().item()\n        n += 1\n    print(team, end=' ')\n    print('loss:', loss_num / n)\n\n\ndef train(features, labels, batch_size):\n    net.train()\n    train_iter = make_iter(features, labels, batch_size)\n    for X, y in train_iter:\n        y_hat = net(X)\n        l = loss(y_hat, y).sum()\n        optimizer.zero_grad()\n        l.backward()\n        optimizer.step()\n    show_loss(net, loss, features, labels, '训练集')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set up super parameter"},{"metadata":{"trusted":true},"cell_type":"code","source":"#num_epochs = 10\nnum_epochs = 100\nk_fold_num = 5\nbatch_size = 128\nlr = 0.001\n#k_fold = True\nk_fold = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definition optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(net.parameters(), lr=lr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Start up!"},{"metadata":{"trusted":true},"cell_type":"code","source":"if k_fold:\n    kf = KFold(n_splits=k_fold_num, shuffle=True)\n    for epoch in range(num_epochs):\n        fold_num = 0\n        for train_index, test_index in kf.split(train_features):\n            X_train, X_test = train_features[train_index], train_features[\n                test_index]\n            y_train, y_test = train_labels[train_index], train_labels[\n                test_index]\n            print('第%d轮的第%d折：' % (epoch + 1, fold_num + 1))\n            fold_num += 1\n            train(X_train, y_train, batch_size)\n            show_loss(net, loss, X_test, y_test, '测试集')\nelse:\n    for epoch in range(num_epochs):\n        print('第%d轮：' % (epoch + 1))\n        train(train_features, train_labels, batch_size)\n\n    net.eval()\n    test_iter = torch.utils.data.DataLoader(torch.tensor(test_features,\n                                                         dtype=torch.float).cuda(),\n                                            1024,\n                                            shuffle=False)\n    testResult = [line for x in test_iter for line in net(x).cpu().detach().numpy()]\n    sampleSubmission = pd.read_csv('/kaggle/input/sf-crime/sampleSubmission.csv.zip')\n    Result_pd = pd.DataFrame(testResult,\n                             index=sampleSubmission.index,\n                             columns=sampleSubmission.columns[1:])\n    Result_pd.to_csv('/kaggle/working/sampleSubmission(v0.5).csv', index_label='Id')\n    torch.save(net,'/kaggle/working/net.pkl')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}