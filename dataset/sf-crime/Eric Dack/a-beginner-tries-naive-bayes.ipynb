{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nimport sklearn.preprocessing as preprocessing\nfrom sklearn import linear_model\nfrom sklearn import cross_validation\n\n#ã€€Load data\nData = pd.read_csv('../input/train.csv')\n\n# Change the format of Dates\nData.Dates = np.array([datetime.strptime(date, '%Y-%m-%d %H:%M:%S') for date in Data.Dates])\nData['Time'] = np.array([date.hour for date in Data.Dates])\n\n\n\n# ----------------------------------Rubbish bin--------------------------------------------\n#mapData = np.loadtxt('../input/sf_map_copyright_openstreetmap_contributors.txt')\n#fig = plt.figure(figsize = (11.69, 8.27))\n#plt.imshow(mapData, cmap=plt.get_cmap('gray'),extent=lon_lat_box)\n\n#crimeSet = trainData.Category.unique()\n#i = 0\n#for crime in crimeSet:\n#    trainData.Category[trainData.Category == crime] = i\n#    i = i+1\n    \n#ax = plt.figure(figsize=(14,8))\n#trainData.Category.value_counts().plot(kind='bar')\n#plt.title('Crime Category and Total Number')\n#plt.ylabel('Number') \n\n#ax = plt.figure(figsize=(14,8))\n#trainData.DayOfWeek.value_counts().plot(kind='bar')\n#plt.title('Crime occuring in each day')\n#plt.ylabel('Number') \n\n#ax = plt.figure(figsize=(14,8))\n#trainData[trainData.Category == 'LARCENY/THEFT'].Dates.value_counts().plot(kind='bar')\n#plt.title('Crime occuring in each day')\n#plt.ylabel('Number')\n# --------------------------------------------------------------------\n# Get hours in each day\n\n\n\n\n#result = np.zeros((validationY.shape[0],validationY.shape[1]))\n# learning\n#for i in range(20):\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Take samples \nsample_x = pd.DataFrame([])\nsample_y = pd.DataFrame([])\n    # factorization\ndummies_PdDistrict = pd.get_dummies(Data['PdDistrict'], prefix= 'PdDistrict')\nsample_x= pd.concat([sample_x, dummies_PdDistrict], axis=1)\n        # DayOfWeek seems irrelevant to the crimes\n#dummies_DayOfWeek = pd.get_dummies(Data['DayOfWeek'], prefix= 'DayOfWeek')      \n#sample_x = pd.concat([sample_x, dummies_DayOfWeek], axis=1)  \ndummies_Category = pd.get_dummies(Data['Category'], prefix= 'Category')\nsample_y = pd.concat([sample_y, dummies_Category], axis=1)   \n    # Scaling \nallCrime = Data.Category.unique()\nCrimeCenterX = np.array([Data[Data.Category == C].X.mean() for C in allCrime]) \nCrimeCenterY = np.array([Data[Data.Category == C].Y.mean() for C in allCrime]) \n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"scaler = preprocessing.StandardScaler()\nX_scale_param = scaler.fit(Data['X'])\nsample_x['X_scaled'] = scaler.fit_transform(Data['X'], X_scale_param)\n#Y_scale_param = scaler.fit(Data['Y'])\n#sample_x['Y_scaled'] = scaler.fit_transform(Data['Y'], Y_scale_param)\nTime_scale_param = scaler.fit(Data['Time'])\nsample_x['Time_scaled'] = scaler.fit_transform(Data['Time'], Time_scale_param)\n    \nx = sample_x.as_matrix()\ny = sample_y.as_matrix()\n\ntrainX = x[x.shape[0]*0.8:x.shape[0]*0.95,:]\ntrainY = y[y.shape[0]*0.8:y.shape[0]*0.95,:]\nvalidationX = x[x.shape[0]*0.95:,:]\nvalidationY = y[y.shape[0]*0.95:,:]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#clf = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-4)\n#clf.fit(trainX,trainY[:,16])\n#a = clf.predict(validationX)\n#print(validationY[:,16])\n#print(pd.DataFrame({\"columns\":list(sample_x.columns), \"coef\":list(clf.coef_.T)}))\nfrom sklearn import cross_validation\nclf = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\nprint(cross_validation.cross_val_score(clf, x[x.shape[0]*0.85:,:], y[y.shape[0]*0.85:,:], cv=5))"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}