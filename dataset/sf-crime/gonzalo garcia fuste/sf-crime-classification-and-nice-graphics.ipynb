{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## San Francisco Crime Classification\n### Predict the category of crimes that occurred in the city by the bay","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(filename=\"../input/sf-picture/sf1.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image: https://unsplash.com/@mvdheuvel\n  ","metadata":{}},{"cell_type":"markdown","source":"From Sunset to SOMA, and Marina to Excelsior, this competition's dataset provides nearly 12 years of crime reports from across all of San Francisco's neighborhoods. Given time and location, you must predict the category of crime that occurred.","metadata":{}},{"cell_type":"code","source":"#\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\nfrom matplotlib import rcParams\n\n%config InlineBackend.figure_format = 'retina'\nsns.set_style(\"white\")\nrcParams['figure.figsize'] = (8,4)\nimport matplotlib.ticker as ticker\nfrom IPython.display import Image \n\nfrom sklearn.preprocessing import RobustScaler # hay outliers\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import log_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# change astype to np.float32 to reduce memory usage\ndf = pd.read_csv(\"../input/sf-crime/train.csv.zip\",dtype={\"X\":np.float32,\"Y\":np.float32})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove duplicates\nprint(df.duplicated(keep=False).value_counts())\ndf = df.drop_duplicates()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In columns X and Y there seem to be outliers (Y = 90.0000); it seems that this event belongs to another location. So we will remove it !","metadata":{}},{"cell_type":"code","source":"df[[\"X\",\"Y\"]].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's see some information about the non-numeric columns.\nThe most repeated category is LARCENY/THEFT; Fridays seem to be quite entertaining and in SOUTHERN I don't think they get bored. \t","metadata":{}},{"cell_type":"code","source":"df.describe(include=\"object\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to extract information from the columns Date and Adress; for example we can have columns like Year, Month, DayofWeek,Weekend,Minute; and from Adress the cases happen either in a street (ST) or block (Block), so we can create a column called \"Block\".\t\n\nWe will also use LabelEncoder to transform the \"Category\" and \"PdDistrict\" columns.","metadata":{}},{"cell_type":"code","source":"def convert_dataframe(df):\n    \"\"\"\n    remove outliers and create time and block columns. Convert to np.int32 \n    due to memory usage\n    \"\"\"\n    \n    # time columns\n    df[\"Dates\"] = pd.to_datetime(df[\"Dates\"],infer_datetime_format=True)\n    df['Date'] = df['Dates'].dt.date\n    df[\"Year\"] = df[\"Dates\"].dt.year.astype(np.int32)\n    df[\"Month\"] = df[\"Dates\"].dt.month.astype(np.int32)\n    df[\"Day\"] = df[\"Dates\"].dt.day.astype(np.int32)\n    df[\"Hour\"] = df[\"Dates\"].dt.hour.astype(np.int32)\n    df[\"Minute\"] = df[\"Dates\"].dt.minute.astype(np.int32)\n    df[\"Day_week_numeric\"] = df[\"Dates\"].dt.dayofweek.astype(np.int32)\n    df[\"Weekend\"]= np.where((df[\"Day_week_numeric\"] >= 4) & (df[\"Day_week_numeric\"] <=6),1,0)\n    df[\"count_days\"] = (df['Date'] - df['Date'].min()).apply(lambda x: x.days)\n    # create block column from Adress column\n    df[\"Block\"] = df.Address.str.contains(\"Block\").astype(np.int32)\n    # drop\n    df = df.drop([\"Date\",\"Address\"],axis=1)\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_date = convert_dataframe(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encoder Category and PdDistrict\n\nlabel_cat = LabelEncoder()\ndf_date[\"Category_encode\"] = label_cat.fit_transform(df_date.Category)\nlabel_dist = LabelEncoder()\ndf_date[\"PdDistric_encode\"] = label_dist.fit_transform(df_date.PdDistrict)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove outliers\ndf_outliers = df_date.loc[df_date.Y < 90.].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_outliers.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA\nWe have already prepared the dataframe, so now we can do an exploratory analysis to see what information we can obtain.","metadata":{}},{"cell_type":"code","source":"# count values (we can use value_counts() as well)\nmonth_count = df_outliers.groupby([\"Month\"])[\"Dates\"].count().reset_index()\n# lineplot\nax = sns.lineplot(x=\"Month\",y=\"Dates\",data=month_count,color=\"#6549DA\")\n# add horizontal line\nax.axhline(month_count['Dates'].mean(),color=\"#9CDEF6\")\nsns.despine()\n# adding text\nax.text(0.5,83000,\"Case count per Month\",\n        fontsize=13,        \n         fontweight='bold') \nax.text(0.5,81500,\"What happens during the Vacations?\",\n        fontsize=11)\nax.text(10,72000,\"Month,s Cases mean\",\n        fontsize=8,        \n         fontweight='bold')\nplt.xlabel(\"Mounth\")\nplt.ylabel(\"Frecuency\")\n# so only the graphic appears without any text referring to the object type.\nplt.show(block=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At first glance, it seems that during the summer and Christmas months the number of cases is below the monthly average.\n\nLet's do the same but with the days of the week to see if we can see any difference.\nWe can see that cases go up a bit during Wednesdays and Fridays; Sundays are quieter. \n\nThe graph may be misleading and show that there is a big difference between the days, but the range is only between 132500 and 117500 (Day of Week) and 80000-65000 (Month).\n\nMany will think it is common sense that during the vacation months and Sundays there are fewer cases, but it never hurts to show it in a graph.","metadata":{}},{"cell_type":"code","source":"day_count = df_outliers.groupby([\"Day_week_numeric\"])[\"Dates\"].count().reset_index()\n#lineplot\nax = sns.lineplot(x=\"Day_week_numeric\",y=\"Dates\",data=day_count,color=\"#6549DA\")\n# add horizontal line\nax.axhline(day_count['Dates'].mean(),color=\"#9CDEF6\")\nsns.despine()\n# add text\nax.text(-0.1,136000,\"Case count per Day of Week\",\n        fontsize=13,        \n         fontweight='bold') \nax.text(-0.1,134500,\"Are Sundays quieter?\",\n        fontsize=11)\nax.text(5,124000,\"Day,s Cases mean\",\n        fontsize=11,        \n         fontweight='bold')\n# axis title\nplt.xlabel(\"Day of Week\")\nplt.ylabel(\"Frecuency\")\n# so only the graphic appears without any text referring to the object type.\nplt.show(block=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is not surprising that, if we graph the cases by time of day, we see that during the night there are fewer cases.","metadata":{}},{"cell_type":"code","source":"hour_count = df_outliers.groupby([\"Hour\"])[\"Dates\"].count().reset_index()\n#barplot\nax = sns.barplot(y=\"Dates\",x=\"Hour\",data=hour_count,color=\"#B8EBE9\")\n# with axvline we can draw a vertical line\nax.axhline(hour_count[\"Dates\"].mean(),color=\"#6549DA\")\n\nplt.ylabel(\"Frecuency\")\nplt.xlabel(\"Hour\")\nplt.grid(False)\nsns.despine()\n\n# add text anotation\nax.text(18,34000, \"Hour,s Cases Mean\", horizontalalignment='left', size='medium', color='black', weight='semibold')\nax.text(-0.1,59000,\"Cases Count per Hour\",\n        fontsize=13,        \n         fontweight='bold') \nax.text(-0.1,55000,\"Nights are for sleeping?\",\n        fontsize=11) \nplt.show(block=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us now see which are the most common categories, expressed as a percentage of the total,and the districts where there are more incidences.","metadata":{}},{"cell_type":"code","source":"# dataframe\ncategory_counts = df_outliers.Category.value_counts(normalize=True).reset_index().head(10)\n#barplot\nax=sns.barplot(y=\"index\",x=\"Category\",data=category_counts,color=\"#04A4B5\")\n\nplt.ylabel(\"\")\nplt.xlabel(\"Cases,s Percentage\")\nplt.grid(False)\nsns.despine()\n#add text\nax.text(0,-2,\"Cases Percentage per Category\",\n        fontsize=13,        \n         fontweight='bold') \nax.text(0,-1.3,\"Protect your pockets well...\",\n        fontsize=11)\n# with a loop I add the values to the graphic\nfor num,text in zip(range(10),round(category_counts[\"Category\"],2)):\n    ax.text(text,num,text)\nplt.show(block=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's make a graph of cases by districts; using cumsum we can see the cumulative. We can see that 54 percent of the cases occur in only four districts.","metadata":{}},{"cell_type":"code","source":"#Let's use cumsum to see a cumulative\ndistric_counts_cumsum = df_outliers.PdDistrict.value_counts(normalize=True).cumsum().reset_index()\n#barplot\nax=sns.barplot(y=\"PdDistrict\",x=\"index\",data=distric_counts_cumsum,color=\"#30BFBF\")\n\nplt.ylabel( \"Cases,s Percentage\")\nplt.xlabel(\"\")\nplt.xticks(rotation=45)\nplt.grid(False)\nsns.despine()\n#add text\nax.text(-0.2,1.10,\"Cumulative Cases Percentage per PdDistrict\",\n        fontsize=13,        \n         fontweight='bold') \nax.text(-0.2,1.0,\"Where should I buy my house?\",\n        fontsize=11)\n# with a loop I add the values to the graphic\nfor num,text in zip(range(10),round(distric_counts_cumsum[\"PdDistrict\"],2)):\n    ax.text(num,text,text)\nplt.show(block=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using pd.crosstab we can see by categories which are the districts where there are more incidences (using normalize=\"index\" shows us the percentages per row).\n\nWe can see, for example, that 48 percent of the prostitution cases take place in Mission, 32 percent of the Drug cases take places in Tenderloin..\n\n","metadata":{}},{"cell_type":"code","source":"distric_category = pd.crosstab(columns=df_outliers[\"PdDistrict\"],index=df[\"Category\"],normalize=\"index\")\ncategory_district_max = pd.concat([distric_category.idxmax(axis=1),distric_category.max(axis=1)],axis=1).sort_values(by=1,ascending=False).reset_index()\ncategory_district_max.columns = [\"Category\",\"District\",\"Percentage\"]\ncategory_district_max.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also see by districts and weekends (Friday-Sunday); it strikes me that Tinderloin, where 32 percent of the drug cases occur there, the weekends are quieter.","metadata":{}},{"cell_type":"code","source":"pd.crosstab(index=df_outliers.PdDistrict,columns=df_outliers.Weekend,normalize=\"index\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model\nI could go on and on analyzing the cases for example by year, by resolution, focusing on a category (see scatter below) etc... but let's go directly to the model.\n\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.scatterplot(x=\"X\",y=\"Y\",data=df_outliers.loc[df_outliers.Year==2012],alpha=0.5,color=\"#B3BDB2\")\nsns.scatterplot(x=\"X\",y=\"Y\",data=df_outliers.loc[(df_outliers.Year==2012)&(df_outliers.Category==\"PROSTITUTION\")],alpha=0.8,color=\"r\")\n\n\n#add text\nplt.text(-122.514741,37.829977,\"San Francisco Prostitution Cases by District in 2012\",\n        fontsize=15,        \n         fontweight='bold') \nplt.text(-122.416145,37.761631,\"MISSION\",\n        fontsize=12,        \n         fontweight='bold') \nplt.text(-122.420296,37.788879,\"NORTHERN\",\n        fontsize=12,        \n         fontweight='bold') \n\n\nplt.show(block=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nFor this, the first thing I am going to do, using Kmeans, is to create a new feature that can help to improve the predictions.","metadata":{}},{"cell_type":"code","source":"X = df_outliers.drop([\"Dates\",\"Category\",\"Descript\",\"DayOfWeek\",\"PdDistrict\",\"Resolution\",\"Category_encode\"],axis=1).copy()\ny = df_outliers[\"Category_encode\"]\n\n# train and validation split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.25, random_state = 21)\n\n# Feature Scaling\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\n\n#kmeans\nkmeans = KMeans(n_clusters=6,random_state=0).fit(X_train)\n  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#I have to convert the array X_train into a dataframe to add a new column\nX_train_df = pd.DataFrame(X_train)\nX_val_df = pd.DataFrame(X_val)\n## add new columns\nX_train_df[\"Kmean\"] = kmeans.labels_\nX_val_df[\"Kmean\"] = kmeans.predict(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting Random Forest Classification to the Training set\nclassifier = RandomForestClassifier( n_jobs = -1,random_state =50,max_depth=10,max_features=\"auto\",min_samples_split=4)\nclassifier.fit(X_train_df, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict\npredict_proba = classifier.predict_proba(X_val_df)\nlog_loss(y_val,predict_proba)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submision","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(\"../input/sf-crime/test.csv.zip\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_transformed = convert_dataframe(test_data)\ntest_data_transformed[\"PdDistric_encode\"] = label_dist.fit_transform(test_data_transformed.PdDistrict)\ntest_data_final = test_data_transformed.drop([\"DayOfWeek\",\"PdDistrict\",\"Dates\",\n                \"Id\"],axis=1).copy()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_scaler = scaler.transform(test_data_final)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scaler\ntest_data_final = pd.DataFrame(test_data_scaler)\n#add kmean column\ntest_data_final[\"Kmean\"] = kmeans.predict(test_data_final)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_pred_proba = classifier.predict_proba(test_data_final)\n#from label encoder we use classes to have the original values of Category, \n#and we will use them as columns in the submission dataframe.\nkeys = label_cat.classes_\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = pd.DataFrame(data=test_data_pred_proba,columns=keys)\nresult.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.to_csv(path_or_buf=\"classifier_sf.csv\",index=True, index_label = 'Id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}