{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\ntrain = pd.read_csv('../input/train.csv', parse_dates=['Dates'])\ntest = pd.read_csv('../input/test.csv', parse_dates=['Dates'], index_col='Id')\n\nfrom keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(list(train[\"Address\"]) + list(test[\"Address\"]))\n\nhaha = tokenizer.texts_to_sequences(train[\"Address\"])\nhaha2 = tokenizer.texts_to_sequences(test[\"Address\"])\n\nfrom keras.preprocessing.sequence import pad_sequences\npadded = pad_sequences(haha, maxlen=7)\npadded2 = pad_sequences(haha2, maxlen=7)\n\nfrom keras import Sequential\nfrom keras.layers import Flatten, Embedding, Dense \nmodel = Sequential()\nmodel.add(Embedding(2201, 1, input_length=7))\nmodel.add(Flatten())\nmodel.add(Dense(39, activation='softmax'))\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n\nfrom sklearn.preprocessing import LabelEncoder\nle2 = LabelEncoder()\ny= le2.fit_transform(train['Category'])\nmodel.fit(padded, y, epochs = 10 , batch_size = 2048)\n\npreds = model.predict(padded)\npreds2 = model.predict(padded2)\n\nfrom sklearn.decomposition import PCA\n\npca1 = PCA(n_components=2)\nX_low = pca1.fit_transform(preds)\nX_low2 = pca1.transform(preds2)\n\ntrain['Date'] = train['Dates'].dt.date\ntrain['n_days'] = (train['Date'] - train['Date'].min()).apply(lambda x: x.days)\ntrain['Day'] = train['Dates'].dt.day\ntrain['DayOfWeek'] = train['Dates'].dt.weekday\ntrain['Month'] = train['Dates'].dt.month\ntrain['Year'] = train['Dates'].dt.year\ntrain['Hour'] = train['Dates'].dt.hour\ntrain['Minute'] = train['Dates'].dt.minute\ntrain['Block'] = train['Address'].str.contains('block', case=False)\ntrain['ST'] = train['Address'].str.contains('ST', case=False)\ntrain[\"X_Y\"] = train[\"X\"] - train[\"Y\"]\ntrain[\"XY\"] = train[\"X\"] + train[\"Y\"]\n\ntest['Date'] = test['Dates'].dt.date\ntest['n_days'] = (test['Date'] - test['Date'].min()).apply(lambda x: x.days)\ntest['Day'] = test['Dates'].dt.day\ntest['DayOfWeek'] = test['Dates'].dt.weekday\ntest['Month'] = test['Dates'].dt.month\ntest['Year'] = test['Dates'].dt.year\ntest['Hour'] = test['Dates'].dt.hour\ntest['Minute'] = test['Dates'].dt.minute\ntest['Block'] = test['Address'].str.contains('block', case=False)\ntest['ST'] = test['Address'].str.contains('ST', case=False)\ntest[\"X_Y\"] = test[\"X\"] - test[\"Y\"]\ntest[\"XY\"] = test[\"X\"] + test[\"Y\"]\n\nfrom sklearn.preprocessing import LabelEncoder\nle1 = LabelEncoder()\ntrain['PdDistrict'] = le1.fit_transform(train['PdDistrict'])\ntest['PdDistrict'] = le1.transform(test['PdDistrict'])\n\nle2 = LabelEncoder()\ny= le2.fit_transform(train['Category'])\n\ntrain = pd.concat([train, pd.DataFrame(X_low)], 1)\ntest = pd.concat([test, pd.DataFrame(X_low2)], 1)\n\nle3 = LabelEncoder()\nle3.fit(list(train['Address']) + list(test['Address']))\ntrain['Address'] = le3.transform(train['Address'])\ntest['Address'] = le3.transform(test['Address'])\n\ntrain.drop(['Dates','Date','Descript','Resolution', 'Category'], 1, inplace=True)\ntest.drop(['Dates','Date',], 1, inplace=True)\n\nfrom lightgbm import LGBMClassifier\nhyper = {'colsample_bytree': 0.625,\n 'is_unbalance': False,\n 'learning_rate': 0.025,\n 'min_child_samples': 105,\n 'num_class': 39,\n 'num_leaves': 233,\n 'objective': 'multiclass',\n 'reg_alpha': 0.4000134592012641,\n 'reg_lambda': 0.5082596745249518,\n 'subsample': 0.9338693244190213,\n 'subsample_for_bin': 140000,\n 'n_estimators': 600}\nmodel = LGBMClassifier(**hyper)\nmodel.fit(train, y, categorical_feature=[\"PdDistrict\", \"DayOfWeek\"])\npreds = model.predict_proba(test)\nsubmission = pd.DataFrame(preds, columns=le2.inverse_transform(np.linspace(0, 38, 39, dtype='int16')), index=test.index)\nsubmission.to_csv('LGBM_final.csv', index_label='Id')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}