{"cells":[{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"bd68db4b-ca38-eb88-a6f6-c065fcac0029","_uuid":"ca0023cca2c5a163b49d0eeaf1ca47afc5b09b64"},"cell_type":"markdown","source":"# Abstract #\n\nI'm running this kernel for fun and to learn. My job has nothing to do with statistical learning, so feel free to comment if you see any possible improvement.\n\nI intend to put here both my exploration results and the results of the cross validation of my models. For the latter, as the dataset has many observation, I might run them separately on my personal computer and simply plot the graph in this kernel.\nAs for the models themselves, I'll run them in separate kernels that I'll linked to this one (by putting the url in comments)\n\n## Exploration Result ##\nHere's a takeaway from my exploration:\n\n - 8 crime categories out of 39 make up to 80% of the crime (said differently, the remaining 30 categories represent less than 1% of crimes each) => I won't try to spend too long predicting this and I'll concentrate on this 8 categories to explore the data (this will free up some space in my graphs)\n - In the long run, the data exhibit some regime changes, especially around 2006 and 2010. While I would not like my model to integrate this directly (I want to put myself in the shoes of a data scientist who makes prediction for the future), I'll try to see if I can make some ex post correction to my model to take this into account\n - Crimes occur at certain hours through the day. The difficulty here comes from the fact that the pattern seems to be the same for each crime category.\n - The same can be said of weekdays, except that it seems that categories are split between weekend crimes (e.g. larcency, non-criminal) and Wednesday crimes (e.g. narcotic, warrants)\n - For an unknown reason, the crime rate seems to be higher during winter and decrease through the year. I expected the contrary and I found no explanation for this phenomenon so far.\n - An analysis of crime spread through districts shows that:\n    - Some district are closely associated with certain crimes (e.g. Mission district and prostitution)\n    - Unfortunately, larcency/theft and other offenses still represent the largest share of crimes for each district\n\n\n## Models and Scores ##\n- Null model: 3.65 LB\n - Time only, naive Bayes: 3.57 (HUUUUGE improvement ^_^)\n\n# Retrieving Data #\n\nLet's load a bunch of library"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"968daa99-d022-f4dc-eb9d-305c3bcf317e","_uuid":"c52cbdf8a5ef482ddbd6b1aa9d410f8ace28438b"},"cell_type":"code","source":"%matplotlib inline\n#Basic libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\n#Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n#Format\nfrom datetime import tzinfo, timedelta, datetime\n#Models\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import RadiusNeighborsClassifier\nfrom sklearn.neighbors import KNeighborsClassifier"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"c3ff7d74-1451-b9c3-2733-49c37011df95","_uuid":"4712b6c230a6e10509b99a1d46cacdb1f5c98105"},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/train.csv\",index_col=None)\ndf_train.dtypes"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"941d5241-02b4-a55c-dfd5-1b1fd5bf73fd","_uuid":"e214b44f35e5267e5a066d5d8565d11573519a89"},"cell_type":"markdown","source":"What do we have?\n\n - Category: what is intended to be predicted\n - Description: not so useful for now, but can be later for further analysis (e.g. see crimes that are linked to each other)\n - Dates (in datetime): it could be a good idea to split this in two or more columns (date, time, season and so on) and days of week\n - District: district names\n - Address: \n - X and Y coordinates: a class to manage this will probably helpful\n\n# Single Variable Analysis #\n\nFirst, I'll have a look at single variables to see what I have\n\n## Categories ##\n\nThe most important things to begin is to get individual categories. The Evaluation sections specifies that the orders for the submission file does not matter."},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"7631e5d8-0c9f-1924-b90a-30141a35402c","_uuid":"bfaa24e09356133333b03f33b0d8c1e0f164e9be"},"cell_type":"code","source":"Crime_Categories = list(df_train.loc[:,\"Category\"].unique())\nprint(\"Number of crime categories: \" + str(len(Crime_Categories)))\nfor crime in Crime_Categories:\n    print(crime)"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"5dd20442-03fc-f352-7f0c-ac69bd16d428","_uuid":"344a0046ad666e8a3db6660aee110e2cebb4f1a7"},"cell_type":"code","source":"number_of_crimes = df_train.Category.value_counts()\n\n_n_crime_plot = sns.barplot(x=number_of_crimes.index,y=number_of_crimes)\n_n_crime_plot.set_xticklabels(number_of_crimes.index,rotation=90)"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"eab179b7-2f02-974b-4dfc-4bc63837b1f0","_uuid":"47888eb53c2c765c0ab4e77773dffa5c916e672d"},"cell_type":"code","source":"pareto_crime = number_of_crimes / sum(number_of_crimes)\npareto_crime = pareto_crime.cumsum()\n_pareto_crime_plot = sns.tsplot(data=pareto_crime)\n_pareto_crime_plot.set_xticklabels(pareto_crime.index,rotation=90)\n_pareto_crime_plot.set_xticks(np.arange(len(pareto_crime)))\n                              "},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"cfa91b45-2e9a-a77e-7ede-350de9e36b6d","_uuid":"83c56999241d28b3d2d17c014e82ff3c17316af3"},"cell_type":"markdown","source":"As predicted by our beloved friend Vilfredo, about 20% (exactly 9 out of 39, which is 23%) of the categories account for (nearly exactly) 80% of the crimes.\n\nMy take on this: just concentrate on these 9. The remainder 30 categories won't be of any help to get a good score."},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"db849406-d0f3-74f1-74c0-6d78737c084f","_uuid":"5b4304aa636c76dce70a4aee99deccf434c0cf47"},"cell_type":"code","source":"Main_Crime_Categories = list(pareto_crime[0:8].index)\nprint(\"The following categories :\")\nprint(Main_Crime_Categories)\nprint(\"make up to {:.2%} of the crimes\".format(pareto_crime[8]))"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"768e84ab-15e3-af11-3ac7-3873bf84163a","_uuid":"d8fa25d76c0a4d8c0d1f7523ed655d9230c27899"},"cell_type":"markdown","source":"Concerning the remaining categories, I'll see later what to do with them.\n\n## Dates and Days of Week ##\n\nLet's first check the format used for the days of week and see how many crimes do we have for each of them"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"7abea2fd-81c1-d04a-7fb3-c304abe9fed2","_uuid":"a7a786073eace16754134219fe5d4ba728e1531f"},"cell_type":"code","source":"df_train.DayOfWeek.value_counts()"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"39775189-353f-4fa4-dc9a-525c73b75de3","_uuid":"9c30630484e0292a887598c6d50e06d077223ae4"},"cell_type":"markdown","source":"Not so much to say here: the full names of the days are used and it seems that there are no material differences in term of number of crime for each day.\n\nIt doesn't mean that this is not an interesting variable as it may be useful to predict some crimes (I suspect that more DRUG/NARCOTIC crimes are recorded from Thursday pm to Sunday am than during other days).\n\nWhat about the date format?"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"04da4f62-c952-a72f-d911-83f34b0de711","_uuid":"45db8892f8b2d249fa1d818e48dc65b1004832c1"},"cell_type":"code","source":"df_train.head().Dates"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"7e60798a-40a4-8ef7-75b0-b8af074c7c6b","_uuid":"003eff430e94f3e411db79c327ef91a154cc42b3"},"cell_type":"markdown","source":"So basically: YYYY-MM-DD hh:mm:ss\nI think it worths to stop here for a moment and to think about the way to split this.\n\n 1. First, I think that the repartition of crime types will likely evolve as the population changes within a given area. Therefore, I intend to use a relative time scale with 0 = 2013-01-01 00:00:00 and +1 for each day\n 2. I would like to manually label certain period of the days. Certain crimes are more likely to occur during day time, other at night\n 3. A week day / week-end binary variable should be a good idea as well. I'll try to take into account holidays as well\n 4. Concerning the hour of the day, I would like to avoid non-linearity: crimes that occur at 11:00 pm are more likely to occur as well at 03:00am than at 5:00pm. To overcome this, I could either start the scale for hours at an arbitrary but better time (e.g. 6:00am) or use a categorical variable.\n\n### Relative Time Scale ###"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"8ec8fb35-5617-8ccb-30b1-0f3bb3eacc33","_uuid":"c0f25d22aea9befd31cd657db7b3a73b7543e7e4"},"cell_type":"code","source":"origin_date = datetime.strptime('2003-01-01 00:00:00','%Y-%m-%d %H:%M:%S')\n\ndef delta_origin_date(dt):\n    _ = datetime.strptime(dt,'%Y-%m-%d %H:%M:%S') - origin_date\n    return(_.days+(_.seconds/86400))\n\ndelta_origin_date(df_train.loc[1,\"Dates\"])"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"53c722c4-f0af-a1ff-69d8-0ac6aa7846de","_uuid":"227f7b8aab19c0473cef1383a734bc991a52dec5"},"cell_type":"code","source":"tmp = df_train.loc[:,[\"Dates\",\"Category\"]]\ntmp[\"RelativeDates\"]=df_train.Dates.map(delta_origin_date)\ntmp.head()"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"7de48689-9ce6-3e16-ffdc-f068d2d4047e","_uuid":"ec742ce3dcd46fbd4eb7a5f0546a73c10c1ff735"},"cell_type":"markdown","source":"At this stage, it can be interesting to see how the number of crimes per ~ quarter evolved to see if the RelativeDates variable makes sense.\nTo proceed, I'll cut my variables by buckets of roughly 90 days and plot it as a stacked area plot. This will allow to see at once both the increase/decrease of total crimes and the split of crime categories over time."},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"c125ab35-e1a1-078e-e018-9ef7c8a93535","_uuid":"be644c4b0a0b132c5cd9bee4e0f82d76e44ba4fe"},"cell_type":"code","source":"tmp[\"QuarterBucket\"]=tmp.RelativeDates.map(lambda d: int(d/90.0))"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"d9372eb0-7f31-ecfc-aac3-9fe4d6b65a24","_uuid":"7f1a9b45e75cfa660df45737be4fda3f8be83c73"},"cell_type":"code","source":"pt = pd.pivot_table(tmp,index=\"QuarterBucket\",columns=\"Category\",aggfunc=len,fill_value=0)\npt = pt[\"Dates\"]\npt[Main_Crime_Categories].iloc[:49,:].cumsum(1).plot()"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"2aaf4dbd-9905-a734-cca4-bdabcdaa3a37","_uuid":"fa5d5f5d4af4b212eb44c05eb67575b9b0839a9e"},"cell_type":"markdown","source":"There's a lot of noise in this graph. I'll take a 3Q-smoothed average of it to make trends easier to see."},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"0e666498-2aee-ad40-fbdf-ede2cbbd6a8d","_uuid":"168ea9e2e9b073af43eb3e28c76f24b90ae06c8a"},"cell_type":"code","source":"pd.rolling_mean(pt[Main_Crime_Categories],3).iloc[2:49,:].plot()"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"209b659f-cce9-d244-5854-6f8bf42019f2","_uuid":"1abbd35dcb7668f529da86c331e8f91cdd8ccbb5"},"cell_type":"markdown","source":"Some observations at this stage (probably more will come when I'll cross these data with locations):\n\n - From 2011 onward, the LARCENCY/THEFT categories saw a huge increase\n - The NON-CRIMINAL followed the same trend, bug began slightly before (middle of 2010)\n - DRUG/NARCOTIC decreased roughly starting from the same period\n - The largest drop comes from VEHICLE THEFT in 2006\n\nThis clearly indicates that crime categories experienced at least two regime changes, one in 2006, on in 2010. I'd rather like not to use this indicator directly to predict the probability of crime categories, but rather as a correcting factor (this has nothing to do about obtaining a good score, but it's rather about make it as kinda \"real\" tool for crime prediction)\n\n### Hour of the Day ###\n\nLet's have a look at the hour at which crimes occur through days."},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"b663a7dc-a25f-147f-e737-bf73bfe71f42","_uuid":"bd76fdfcb7a6fe1e661e69331d2cf3a018b13da6"},"cell_type":"code","source":"tmp = df_train.loc[:,[\"Dates\",\"Category\"]]\n\ntmp.loc[:,\"Hour\"] = df_train.Dates.map(lambda d: datetime.strptime(d,'%Y-%m-%d %H:%M:%S').hour)\ntmp.describe()\n\npt = pd.pivot_table(tmp,index=\"Hour\",columns=\"Category\",aggfunc=len,fill_value=0)[\"Dates\"]\npt.loc[:,Main_Crime_Categories].plot()"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"0773d16c-2160-aadc-7e91-a1a8927fbb43","_uuid":"79b252cb132e0c410dbe2a93c3c181b0d1620c75"},"cell_type":"markdown","source":"Well, that does not seem very useful now. All categories follow the same kind of trend: nothing append at 5am and the majority of them occurs around 6pm.\nI'll see later if other trends appear when mixed with other variables.\n\n### Weekend / Weekdays ###\n\nIs there any difference between weekdays and weekend?"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"887c0446-a27d-126f-0a1c-6c3db8a7ae10","_uuid":"d2b36682161905542b3a1e7753f3d0ac1cd5ff45"},"cell_type":"code","source":"tmp = df_train.loc[:,[\"DayOfWeek\",\"Category\"]]\npt = pd.pivot_table(tmp,index=\"DayOfWeek\",columns=\"Category\",aggfunc=len,fill_value=0)\npt.loc[[\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"],\n       Main_Crime_Categories].plot()"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"708aaebb-fb6f-f99c-d1c8-205e360fce5c","_uuid":"f30d0e5ed730d8af6a05f6fdeffb96779f6dfe54"},"cell_type":"markdown","source":"It does not seem that the difference is significant. However, it is worth noting that the real shift seems to occur in Friday and Monday, not in Saturday and Sunday. We also have some \"Wednesday crimes\" here. I would visually split the categories this way:\n \n- Weekend crimes:\n  - LARCENCY/THEFT\n  - NON-CRIMINAL\n  - VEHICLE THEFT\n  - VANDALISM\n  - ASSAULT\n- Wednesday crimes:\n  - OTHER OFFENSES\n  - DRUG/NARCOTIC\n  - WARRANTS\n### Seasons ###\n\nIs there any difference between summer and winter?"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"3ef66191-3155-ffb2-5541-7197cfe4245a","_uuid":"7c34e6ad52736b01526e9dec268fd22997262fdf"},"cell_type":"code","source":"tmp = df_train.loc[:,[\"Dates\",\"Category\"]]\n\ndef assign_season(dt):\n    _ = datetime.strptime(dt,'%Y-%m-%d %H:%M:%S')\n    if _.month >= 11 or _.month <= 2:\n        return(\"Winter\")\n    elif _.month > 2 and _.month < 6:\n        return(\"Spring\")\n    elif _.month >= 6 and _.month < 9:\n        return(\"Summer\")\n    else:\n        return(\"Fall\")\n    \ntmp.loc[:,\"Season\"] = tmp.Dates.map(assign_season)\npt = pd.pivot_table(tmp,index=\"Season\",columns=\"Category\",aggfunc=len,fill_value=0)[\"Dates\"]\npt.loc[[\"Winter\",\"Spring\",\"Summer\",\"Fall\"],Main_Crime_Categories].plot()"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"d6046f61-6a63-b67e-f049-f2e0d15aa2c9","_uuid":"f08fd5ed86dcc4fab6127c6a7f8af7e7d34ce8bb"},"cell_type":"markdown","source":"Aggregating by season clearly lack in granularity. Therefore, I'll try with months.\n\n### Months ###"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"490c553b-2c3d-d8b8-c18d-27b20c6c8ac0","_uuid":"b0be381bef01c124813c620c662f28b0c6ac7bd9"},"cell_type":"code","source":"tmp = df_train.loc[:,[\"Dates\",\"Category\"]]\ntmp.loc[:,\"Month\"] = tmp.Dates.map(lambda dt: datetime.strptime(dt,'%Y-%m-%d %H:%M:%S').month)\npt = pd.pivot_table(tmp,index=\"Month\",columns=\"Category\",aggfunc=len,fill_value=0)[\"Dates\"]\npt.loc[:,Main_Crime_Categories].plot(ylim=0)"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"27eec91c-8e79-64a9-52b2-face6e056202","_uuid":"09c4832cac006c93e8a8ae3dcdc9e9ecddb848b6"},"cell_type":"markdown","source":"That's quite unexpected: why do we have such a surge in October? I recall reading that most crimes occurred during summer and I see here that it looks like these data show the contrary."},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"e3d6eeac-3506-c2fc-d551-e9eac002b7ec","_uuid":"67f243d2c7c8271f0e76b7d1a01adac4925bd354"},"cell_type":"code","source":"tmp.loc[:,\"Year\"] = tmp.Dates.map(lambda dt: datetime.strptime(dt,'%Y-%m-%d %H:%M:%S').year)\npt = pd.pivot_table(tmp,index=[\"Year\",\"Month\"],columns=\"Category\",aggfunc=len,fill_value=0)[\"Dates\"]\npt[Main_Crime_Categories].plot()\n\n#Remember to delete this, this is just for a test for FFT\ny = pt"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"87e3ec0c-5818-b8d6-8af9-c0c7ec17f0e7","_uuid":"5d1184571006549b89a8a22fc5751d9f78966a11"},"cell_type":"code","source":"pt = pd.pivot_table(tmp,index=\"Month\",columns=\"Year\",aggfunc=len,fill_value=0)[\"Dates\"]\npt.plot()"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"057c9cb7-4360-0cdb-fce6-ab8eae9016e7","_uuid":"3e7b4b806f4279d1da40bc97eb4ffe95f322e08b"},"cell_type":"markdown","source":"At this stage, I'm still a bit puzzled. It seems from the long term disaggregated data that the occurrence of crimes is periodic, while it can hardly be seen on monthly aggregated graph.\n\nI'll try a DFT on the data to see if anything interesting comes up."},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"08255535-0274-f405-5956-3c590ac3987b","_uuid":"8a34751ba398bc995f942bd55e0ba7ab9bdf5142"},"cell_type":"code","source":"for cat in Main_Crime_Categories:\n    spectrum = np.fft.fft(y[cat].iloc[:]-y[cat].iloc[:].mean())\n    freq = np.fft.fftfreq(len(spectrum))\n    plt.plot(freq, np.absolute(spectrum))\n    plt.title(cat)\n    plt.show()"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"0a649dc1-ca3a-97f4-e3da-da322b9f8f07","_uuid":"3d422e244d6cf9c79a35998bceba2819ddddface"},"cell_type":"markdown","source":"All of the spectrum have a spike at around the 0.17 frequency, which corresponds to about 6 months. This is consistent with the number of crimes by month which shows a first high in April, followed by a second one in October.\n\n## Locations ##\n\nLet's have a look to the location of crimes\n\n### District ###\n\nI'll first begin with the districts. I expect this information to be redundant with the coordinates of the crimes, but it will make the exploration easier to begin.\n\nFirst of all, are there any districts that are more dangerous than others?"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"783714a8-8baa-1a5e-fe35-b168f1739174","_uuid":"95fc3bedff9508bf40d4a050a939e1d7f59c3883"},"cell_type":"code","source":"most_dangerous_districts = df_train.PdDistrict.value_counts()\n_n_crime_plot = sns.barplot(x=most_dangerous_districts.index,y=most_dangerous_districts)\n_n_crime_plot.set_xticklabels(most_dangerous_districts.index,rotation=90)"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"97ca8eec-b5bb-90a0-0e06-99725cca32cc","_uuid":"2899667e271e8c5f93b85d32dfe1271013a2727c"},"cell_type":"markdown","source":"Clearly, there are differences in the occurrence of crimes through district.\n\nLet us now have a look on how crimes spread through these districts:"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"c4272d2c-900b-6673-f678-04ef57a97b86","_uuid":"22c4a31f3584acb160ce11dd9f57eb99e50b6bcd"},"cell_type":"code","source":"pt = pd.pivot_table(df_train,index=\"PdDistrict\",columns=\"Category\",aggfunc=len,fill_value=0)[\"Dates\"]\n_ = pt.loc[most_dangerous_districts.index,number_of_crimes.index]\nax = sns.heatmap(_)\nax.set_title(\"Number of Crimes per District\")"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"486ff9b9-8420-6932-6266-95d81948006f","_uuid":"132805c82dcf0eb12021b29295a9c0c84425dcde"},"cell_type":"markdown","source":"Due to the high number of LARCENCY/THEFT category in the data, this does not really allow to see things more clearly.\n\nAn important thing to look at at this stage is to see whether some crimes occur more at certain locations."},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"0a7278b4-8cfd-d487-c37c-20d9847d9e43","_uuid":"1df394a80987818e6bd9eff32851416f0303e07e"},"cell_type":"code","source":"pt = pd.pivot_table(df_train,index=\"PdDistrict\",columns=\"Category\",aggfunc=len,fill_value=0)[\"Dates\"]\npt = pt/pt.sum(axis = 0)\n_ = pt.loc[most_dangerous_districts.index,number_of_crimes.index]\nax = sns.heatmap(_)\nax.set_title(\"Repartition of Crimes accross Districts\")"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"044df866-7428-39d3-1372-a65400120ab3","_uuid":"05f46ffed2e6b3656bead9ca6dc2643d8a38b83a"},"cell_type":"markdown","source":"This heatmap deserves a lot of comments:\n\n - Larcency and theft are roughly equally split through districts, although the Souther, Norther and Central districts concentrate a large part of it\n - The Tenderloin district seems to be the drug sales point\n - Mission district concentrate a large share of prostitution related offenses\n - Bayview concentrate a large share of arson\n\nThis graph shows that certain categories of crimes seems to be more frequent in some areas, which is a good starting point. However, the next heatmap reveals that the high number of larcency crimes relative to other categories will complicate the task:"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"1feb3226-446b-9ff7-8f33-9a717a2fa44e","_uuid":"6d0d4794530ee7d2a97b3b6d1d6b2774b7cf7a3e"},"cell_type":"code","source":"pt = pd.pivot_table(df_train,index=\"PdDistrict\",columns=\"Category\",aggfunc=len,fill_value=0)[\"Dates\"]\npt = pt.div(pt.sum(axis = 1),axis=0)\n_ = pt.loc[most_dangerous_districts.index,number_of_crimes.index]\nax = sns.heatmap(_)\nax.set_title(\"Most Prevalent Crime per District\")"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"39472052-4523-f8f2-52f2-df425abad081","_uuid":"67ccbb25da0a13cc17808ce0bd672ade0b0bf521"},"cell_type":"markdown","source":"Except for the Tenderloin district where the main crime category is related to drugs, all other districts are overwhelmed by LARCENCY/THEFT and OTHER OFFENSES categories."},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"d7ea656d-bccc-0e58-e0d1-592209a58920","_uuid":"a5c2770776f44b5e0fc933988debacf50d5def27"},"cell_type":"markdown","source":"### Crime Coordinates ###\n\nNow that a first analysis of districts has been done, let's have a look at x,y coordinates. The previous analysis should help us to dig dipper in the data, but for now, let's get the whole train set and see what comes out.\n\nI'll first assign a new value to X and Y coordinates when the value seems strage (i.e. it's a bit far from SF)"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"229af556-e0ba-ce5e-3bf7-1a7ab1cbf558","_uuid":"08884a78ba1c5df97700271f2a6bd294b38527a8"},"cell_type":"code","source":"def correct_coordinates(district):\n    tmp = df_train[df_train[\"PdDistrict\"] == district]\n    x_avg = tmp.X.mean()\n    y_avg = tmp.Y.mean()\n    return([x_avg,y_avg])\n\nindex_to_correct = df_train[(df_train[\"X\"] > -121)|(df_train[\"Y\"] > 50)].index\n\nfor i in index_to_correct:\n    tmp = correct_coordinates(df_train.loc[i,\"PdDistrict\"])\n    x = tmp[0]\n    y = tmp[1]\n    df_train.loc[i,\"X\"] = x \n    df_train.loc[i,\"Y\"] = y"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"f9047993-b3b2-91b3-b1a6-378861a307e9","_uuid":"566475fc34ab8f817f8a000d6c75d30916d31501"},"cell_type":"code","source":"xy_box = np.zeros([2,2])\n\nxy_box[0,0] = df_train[\"X\"].min()\nxy_box[0,1] = df_train[\"X\"].max()\nxy_box[1,0] = df_train[\"Y\"].min()\nxy_box[1,1] = df_train[\"Y\"].max()\n\n\nbarycenter = [df_train[\"X\"].sum()/len(df_train[\"X\"]),df_train[\"Y\"].sum()/len(df_train[\"Y\"])]\nprint(\"Coordinates box: {}\".format(xy_box))\nprint(\"Barycenter: {}\".format(barycenter))\n\ndf_plot_coordinates = df_train[[\"X\",\"Y\"]].sample(frac=0.001)\nsns.stripplot(df_plot_coordinates[\"X\"],df_plot_coordinates[\"Y\"])"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"e32ef3b6-f836-23e8-e578-f03c2328f1c6","_uuid":"beaf3cec028e4d6ce349192b2d8824ea669f737d"},"cell_type":"markdown","source":"We have far too many points to plot, so I'll try a different approach. Some categories seem to be located in certain district, so I'll try to see I can refine this analysis to find hotspots for these crimes (and potentially compute the distance between these hotspots and crime locations)"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"e422450e-04b5-57ff-93a6-f6a5dcde6d79","_uuid":"104e50cac29a6377ca70e126ac70e997cd05c8dc"},"cell_type":"code","source":"for c in pareto_crime.index[:25]:\n    df_tmp = df_train.loc[df_train.Category == c,[\"X\",\"Y\"]]\n    with sns.axes_style(\"white\"):\n        sns.jointplot(x=df_tmp[\"X\"] , y=df_tmp[\"Y\"], stat_func = None,kind=\"hex\", color=\"r\");\n        sns.plt.title(c)"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"2519a446-e9a7-e945-33b0-4e5c68fdb4b2","_uuid":"03ca507dcfe5625f449969d5ac8cb0bfa87ff5cf"},"cell_type":"markdown","source":"(NB: after a first try, I plotted only the 25 first categories. The remainder did not brought many information)\n\n"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"3d2d41f7-3b46-4566-87ed-3a4cc68707de","_uuid":"4ba6b6264b5fff858ada1089850544b886d8f828"},"cell_type":"markdown","source":"# Training Models #\n\nBefore to go any further, let's load the test set."},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"72dce216-4579-01ee-434d-6f096c914edc","_uuid":"bcb0562f6d1de9d2b2a395e2601efc385fc63d30"},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/test.csv\",index_col=None)\ndf_test.head()"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"58c3d216-3060-6a94-7b09-489d85509f99","_uuid":"2880e8eaa06b5c4eac90d9c8df856b32a12b835b"},"cell_type":"markdown","source":"\n\n## Null Model: Average ##\n\nSince my job is in now way related to Kaggle, it's hard for me to have a clear self-evaluation of how well I'm doing. So I'll make a first submission with the average of each crime and consider it as a starting point to see if I'm improving my model compared to it."},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"78c6d476-4c2d-ede6-2f7e-82ee7c9f1d66","_uuid":"00f38615a3835d1db5cb8a523de3ece56ccadfdc"},"cell_type":"code","source":"model_null = df_test[[\"Id\"]]\nfor crime in Crime_Categories:\n    model_null[crime] = number_of_crimes[crime]/sum(number_of_crimes)\nmodel_null.head()\n#The output file seems to be to heavy\n#model_null.to_csv(\"model_null.csv\")"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"8e0fa387-cc39-7dfa-e95a-73524c39d7c9","_uuid":"6503a3bb53b8b6920edd5aecbe7b087ac8d42c08"},"cell_type":"markdown","source":"## Time-Only Model ##\nThe first real model that I'll try will only use the inputs from the time of the crimes (including days of the week, hours and months). Because of the constraint I imposed on myself not to benefit from a look-ahead bias, I'll train 11 different models, using only data from the previous years (except for 2013 for which I have no other choices but to use the data from 2013. This said, the number 11 comes from 13 years - 2003 - 2015)"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"3c6aca38-5a44-1400-c15c-b630b7ecc82e","_uuid":"3d2ed2d41940c55a7faf797010f15aee7889aaf3"},"cell_type":"code","source":"def is_weekend(d):\n    if d in [\"Friday\",\"Saturday\",\"Sunday\"]:\n        return(1)\n    else:\n        return(0)\n    \ndef get_hour(d):\n    h = datetime.strptime(d,'%Y-%m-%d %H:%M:%S').hour\n    s = datetime.strptime(d,'%Y-%m-%d %H:%M:%S').second\n    return((h+s/60.0)/24.0)\n    \n\n#df_train_time_only = df_train\n#df_train_time_only[\"Year\"] = df_train_time_only.Dates.map(lambda dt: datetime.strptime(dt,'%Y-%m-%d %H:%M:%S').year)\n#df_train_time_only[\"Month\"] = df_train_time_only.Dates.map(lambda dt: datetime.strptime(dt,'%Y-%m-%d %H:%M:%S').month/12.0)\n#df_train_time_only[\"Hour\"] = df_train_time_only.Dates.map(get_hour)\n#df_train_time_only[\"IsWeekend\"] = df_train_time_only.DayOfWeek.map(is_weekend)\n#df_train_time_only.head()"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"388d8a9c-623a-2bb9-28ea-1cc1b5bc2f0f","_uuid":"58c5f1a270917a6e53bb570fb7f26009eb463c81"},"cell_type":"code","source":"def make_as_OTHER(crime):\n    if crime in Main_Crime_Categories:\n        return(crime)\n    else:\n        return(\"OTHER_MANUAL\")\n\n#df_tmp = df_train_time_only#[df_train_time_only['Year'].isin([2008,2009,2010,2011,2012,2013,2014])]\n#df_tmp[\"Category\"] = df_tmp.Category.map(make_as_OTHER)\n\n\n\n#df_x = df_tmp[[\"Month\",\"IsWeekend\",\"Hour\"]]\n#df_y = df_tmp[\"Category\"]\n\n#scores = []\n#for i in range(5):\n#    knn = KNeighborsClassifier(n_neighbors = i + 2)\n#    scores.append(cross_val_score(knn,df_x,df_y,cv=2))"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"3ba87ea3-aad8-c61c-44f7-983ab72bc414","_uuid":"76b9f1cffbed867b0c81aeefd48a2930fdcf7157"},"cell_type":"code","source":""}],"nbformat":4,"metadata":{"_is_fork":false,"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"_change_revision":0,"language_info":{"nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","pygments_lexer":"ipython3","version":"3.6.0","name":"python","file_extension":".py"}},"nbformat_minor":0}