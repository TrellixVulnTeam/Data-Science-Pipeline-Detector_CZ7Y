{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ce6f087-5522-4207-a054-e8d86e7bf293"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a6fd3a5d-4ae0-4f94-9ec3-388188366fa5"},"outputs":[],"source":"# Preprocessing\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.cross_validation import train_test_split\n\ndef extract_features(data):\n    data = data.fillna(0)\n    train_data, validate_data = train_test_split(data, test_size=0.2, random_state=42)\n\n    # Dates\n    data['Hour'] = data.Dates.dt.hour\n    data['Day'] = data.Dates.dt.day\n    data['DayOfWeekNum'] = pd.Categorical.from_array(data.DayOfWeek).codes\n    data['DayOfMonth'] = data.Dates.dt.day\n    data['DayOfYear'] = data.Dates.dt.dayofyear\n    data['WeekOfYear'] = data.Dates.dt.weekofyear\n    data['Month'] = data.Dates.dt.month\n    data['Year'] = data.Dates.dt.year\n    data[\"Fri\"] = np.where(data.DayOfWeek == \"Friday\",1,0)\n    data[\"Sat\"] = np.where(data.DayOfWeek == \"Saturday\",1,0)\n    data[\"Weekend\"] = data[\"Fri\"] + data[\"Sat\"]\n\n    # PdDisrict\n    data['PdDistrictCat'] = pd.Categorical.from_array(data.PdDistrict).codes\n  \n    \n    # Lat/Long\n    \n    data = data[data.X <-121]\n    data = data[data.Y<40]\n    \n    data[\"X_reduced\"] = data.X.apply(lambda x: \"{0:.2f}\".format(x)).astype(float)\n    data[\"Y_reduced\"] = data.Y.apply(lambda x: \"{0:.2f}\".format(x)).astype(float)\n    data[\"X_reduced_cat\"] = pd.Categorical.from_array(data.X_reduced).codes\n    data[\"Y_reduced_cat\"] = pd.Categorical.from_array(data.Y_reduced).codes\n    \n    data[\"rot_45_X\"] = .707*data[\"Y\"] + .707*data[\"X\"]\n    data[\"rot_45_Y\"] = .707* data[\"Y\"] - .707* data[\"X\"]\n\n    data[\"rot_30_X\"] = (1.732/2)*data[\"X\"] + (1./2)*data[\"Y\"]\n    data[\"rot_30_Y\"] = (1.732/2)* data[\"Y\"] - (1./2)* data[\"X\"]\n\n    data[\"rot_60_X\"] = (1./2)*data[\"X\"] + (1.732/2)*data[\"Y\"]\n    data[\"rot_60_Y\"] = (1./2)* data[\"Y\"] - (1.732/2)* data[\"X\"]\n\n    data[\"radial_r\"] = np.sqrt( np.power(data[\"Y\"],2) + np.power(data[\"X\"],2) )\n\n    # Output feature - crime category\n    data['CategoryNum'] = pd.Categorical.from_array(data.Category).codes\n    \n    classes = pd.Categorical.from_array(data.Category).categories\n    \n    return pd.concat([data.Hour,\n                      data.Day,\n                      data.DayOfWeekNum,\n                      data.DayOfMonth,\n                      pd.get_dummies(data.Month),\n                      pd.get_dummies(data.Year),\n                      data.PdDistrictCat,\n                      data.rot_45_X,\n                      data.rot_45_Y,\n                      data.CategoryNum\n                     ], axis=1), classes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08d87585-ab56-4892-854e-a465bda6f692"},"outputs":[],"source":"# Set parameters for XGBoost\ndef set_param():\n    \n    # setup parameters for xgboost\n    param = {}\n    param['objective'] = 'multi:softprob'\n    param['eta'] = 0.4\n    param['silent'] = 0\n    param['nthread'] = 4\n    param['num_class'] = num_class\n    param['eval_metric'] = 'mlogloss'\n\n    # Model complexity\n    param['max_depth'] = 8 #set to 8\n    param['min_child_weight'] = 1\n    param['gamma'] = 0 \n    param['reg_alfa'] = 0.05\n\n    param['subsample'] = 0.8\n    param['colsample_bytree'] = 0.8 #set to 1\n\n    # Imbalanced data\n    param['max_delta_step'] = 1\n    \n    return param"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62eb7108-5f3e-4b5a-bf7c-50fde01e711e"},"outputs":[],"source":"# Load data and extract features\ndata = pd.read_csv('../input/train.csv', parse_dates=['Dates'])\ndata, classes = extract_features(data)\n# Split into train/validate test\ntrain_data, validate_data = train_test_split(data, test_size=0.2, random_state=42)\n\ntrain_X = train_data.drop('CategoryNum', 1)\ntrain_Y = train_data.CategoryNum\nvalidate_X = validate_data.drop('CategoryNum', 1)\nvalidate_Y = validate_data.CategoryNum\n\ndtrain = xgb.DMatrix(train_X, label=train_Y)\ndtest = xgb.DMatrix(validate_X, label=validate_Y)\n\nnum_class = len(data.CategoryNum.unique())\n\nparam = set_param()\nwatchlist = [ (dtrain,'train'), (dtest, 'eval') ]\nnum_round = 10\n\n# Train XGBoost    \nbst = xgb.train(param, dtrain, num_round, watchlist);\nyprob = bst.predict(dtest).reshape( validate_Y.shape[0], num_class)\nylabel = np.argmax(yprob, axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e85f7e5-6e7b-98e7-f305-db80adc12ac1"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}