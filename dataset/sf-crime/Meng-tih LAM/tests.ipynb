{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import csv\nimport gzip\n###\nimport numpy as np\n###\nfrom keras.layers.advanced_activations import PReLU\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Sequential\nfrom keras.utils import np_utils\nfrom sklearn import metrics\nfrom sklearn.cross_validation import KFold\nfrom sklearn.preprocessing import StandardScaler\n\n\ndef get_data(fn):\n  data = []\n  with open(fn) as f:\n    reader = csv.DictReader(f)\n    data = [row for row in reader]\n  return data\n\n\ndef get_fields(data, fields):\n  extracted = []\n  for row in data:\n    extract = []\n    for field, f in sorted(fields.items()):\n      info = f(row[field])\n      if type(info) == list:\n        extract.extend(info)\n      else:\n        extract.append(info)\n    extracted.append(np.array(extract, dtype=np.float32))\n  return extracted\n\n\ndef shuffle(X, y, seed=1337):\n  np.random.seed(seed)\n  shuffle = np.arange(len(y))\n  np.random.shuffle(shuffle)\n  X = X[shuffle]\n  y = y[shuffle]\n  return X, y\n\n\ndef preprocess_data(X, scaler=None):\n  if not scaler:\n    scaler = StandardScaler()\n    scaler.fit(X)\n  X = scaler.transform(X)\n  return X, scaler\n\n\ndef dating(x):\n  date, time = x.split(' ')\n  y, m, d = map(int, date.split('-'))\n  time = time.split(':')[:2]\n  time = int(time[0]) * 60 + int(time[1])\n  return [y, m, d, time]\n\ndays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\ndistricts = ['BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\nlabels = 'ARSON,ASSAULT,BAD CHECKS,BRIBERY,BURGLARY,DISORDERLY CONDUCT,DRIVING UNDER THE INFLUENCE,DRUG/NARCOTIC,DRUNKENNESS,EMBEZZLEMENT,EXTORTION,FAMILY OFFENSES,FORGERY/COUNTERFEITING,FRAUD,GAMBLING,KIDNAPPING,LARCENY/THEFT,LIQUOR LAWS,LOITERING,MISSING PERSON,NON-CRIMINAL,OTHER OFFENSES,PORNOGRAPHY/OBSCENE MAT,PROSTITUTION,RECOVERED VEHICLE,ROBBERY,RUNAWAY,SECONDARY CODES,SEX OFFENSES FORCIBLE,SEX OFFENSES NON FORCIBLE,STOLEN PROPERTY,SUICIDE,SUSPICIOUS OCC,TREA,TRESPASS,VANDALISM,VEHICLE THEFT,WARRANTS,WEAPON LAWS'.split(',')\ndata_fields = {\n    'X': lambda x: float(x),\n    'Y': lambda x: float(x),\n    'DayOfWeek': lambda x: days.index(x) / float(len(days)),\n    'Address': lambda x: [1 if 'block' in x.lower() else 0],\n    'PdDistrict': lambda x: [1 if x == d else 0 for d in districts],\n    'Dates': dating,  # Parse 2015-05-13 23:53:00\n}\nlabel_fields = {'Category': lambda x: labels.index(x.replace(',', ''))}\n\nprint('Loading training data...')\nraw_train = get_data('../input/train.csv')\nprint('Creating training data...')\nX = np.array(get_fields(raw_train, data_fields), dtype=np.float32)\nprint('Creating training labels...')\ny = np.array(get_fields(raw_train, label_fields))\ndel raw_train\n\nX, y = shuffle(X, y)\nX, scaler = preprocess_data(X)\nY = np_utils.to_categorical(y)\n\ninput_dim = X.shape[1]\noutput_dim = len(labels)\nprint('Input dimensions: {}'.format(input_dim))\n\n\ndef build_model(input_dim, output_dim, hn=32, dp=0.5, layers=1):\n    model = Sequential()\n    model.add(Dense(input_dim, hn, init='glorot_uniform'))\n    model.add(PReLU((hn,)))\n    model.add(Dropout(dp))\n\n    for i in range(layers):\n      model.add(Dense(hn, hn, init='glorot_uniform'))\n      model.add(PReLU((hn,)))\n      model.add(BatchNormalization((hn,)))\n      model.add(Dropout(dp))\n\n    model.add(Dense(hn, output_dim, init='glorot_uniform'))\n    model.add(Activation('softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    return model\n\nEPOCHS = 1\nBATCHES = 128\nHN = 64\nRUN_FOLDS = False\nnb_folds = 4\nkfolds = KFold(len(y), nb_folds)\nav_ll = 0.\nf = 0\nif RUN_FOLDS:\n  for train, valid in kfolds:\n      print('---' * 20)\n      print('Fold', f)\n      print('---' * 20)\n      f += 1\n      X_train = X[train]\n      X_valid = X[valid]\n      Y_train = Y[train]\n      Y_valid = Y[valid]\n      y_valid = y[valid]\n\n      print(\"Building model...\")\n      model = build_model(input_dim, output_dim, HN)\n\n      print(\"Training model...\")\n\n      model.fit(X_train, Y_train, nb_epoch=EPOCHS, batch_size=BATCHES, validation_data=(X_valid, Y_valid), verbose=0)\n      valid_preds = model.predict_proba(X_valid)\n      ll = metrics.log_loss(y_valid, valid_preds)\n      print(\"LL:\", ll)\n      av_ll += ll\n  print('Average LL:', av_ll / nb_folds)\n\nprint(\"Generating submission...\")\n\nmodel = build_model(input_dim, output_dim, HN)\nmodel.fit(X, Y, nb_epoch=EPOCHS, batch_size=BATCHES, verbose=0)\n\nprint('Loading testing data...')\nraw_test = get_data('../input/test.csv')\nprint('Creating testing data...')\nX_test = np.array(get_fields(raw_test, data_fields), dtype=np.float32)\ndel raw_test\nX_test, _ = preprocess_data(X_test, scaler)\n\nprint('Predicting over testing data...')\npreds = model.predict_proba(X_test, verbose=0)\n\nwith gzip.open('sf-nn.csv.gz', 'wt') as outf:\n  fo = csv.writer(outf, lineterminator='\\n')\n  fo.writerow(['Id'] + labels)\n\n  for i, pred in enumerate(preds):\n    fo.writerow([i] + list(pred))"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}