{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_columns=None\npd.options.display.max_rows = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data ranges from 1/1/2003 to 5/13/2015. The training set and test set rotate every week, meaning week 1,3,5,7... belong to test set, week 2,4,6,8 belong to training set.\n### Data fields\n- Dates - timestamp of the crime incident \n- Category - category of the crime incident (only in train.csv). This is the target variable you are going to predict.\n- Descript - detailed description of the crime incident (only in train.csv)\n- DayOfWeek - the day of the week\n- PdDistrict - name of the Police Department District\n- Resolution - how the crime incident was resolved (only in train.csv)\n- Address - the approximate street address of the crime incident \n- X - Longitude\n- Y - Latitude <br>\nSubmissions are evaluated using the multi-class logarithmic loss. Each incident has been labeled with one true class. For each incident, you must submit a set of predicted probabilities (one for every class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nimport time\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/sf-crime/train.csv.zip')\n#train_df = train_data.copy()\ntrain_df = train_data.copy()\n\ntest_data = pd.read_csv('../input/sf-crime/test.csv.zip')\n#test_df = test_data.copy()\ntest_df = test_data.copy()\n\nsample_res = pd.read_csv('../input/sf-crime/sampleSubmission.csv.zip')\nprint(sample_res.shape) #39 categories\nsample_res.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Pre-processing\n## Drop 'Resolution' & 'Description' columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_df.drop(['Resolution','Descript'], axis=1, inplace=True)\ntrain_df2.drop(['Resolution','Descript'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extract time and date from 'Dates' column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df2['Dates'] = [datetime.datetime.strptime(d, \"%Y-%m-%d %H:%M:%S\") for d in train_df2[\"Dates\"]]\ntest_df2['Dates'] = [datetime.datetime.strptime(d, \"%Y-%m-%d %H:%M:%S\") for d in test_df2[\"Dates\"]]\n\n# extracting date from timestamp\n#train_df2['Date'] = [datetime.datetime.date(d) for d in train_df2['Dates']] \n# extracting time from timestamp\n#train_df2['Time'] = [datetime.datetime.time(d) for d in train_df2['Dates']] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df2['Hour'] = [d.hour for d in train_df2['Dates']]\ntrain_df2['Month'] = [d.month for d in train_df2['Dates']]\n\ntest_df2['Hour'] = [d.hour for d in test_df2['Dates']]\ntest_df2['Month'] = [d.month for d in test_df2['Dates']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-------------------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_df2.drop(['Date','Time'],axis=1,inplace=True)\ntype(train_df2['Hour'][0])\ntrain_df2['Hour'].unique()\ntrain_df2['Hour'].value_counts()\ntrain_df2.head()\ntrain_df2['Month'].unique()\nnp.sort(train_df2['Category'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"offenseByHour = pd.DataFrame(train_df2.groupby(['Hour','Category'])[['Category']].count())\noffenseByHour.columns = ['Count']\noffenseByHour.reset_index(inplace=True)\noffenseByHour.sort_values(by=['Hour','Count'], ascending=False, inplace=True)\noffenseByHour.head()\n\n#Top 5 offenses by Hour\ntop5ByHour=pd.DataFrame()\nfor x in range(24):\n    top5ByHour = top5ByHour.append(offenseByHour[offenseByHour['Hour']==x][:5])\n#topTenOffensesbyYear = topTenOffensesbyYear.append(offensesByYearCatg[offensesByYearCatg['YEAR'] == years[x]][:10])\n\nfigure = plt.figure(figsize=(20,6))\nsns.barplot(x=top5ByHour['Hour'], y=top5ByHour['Count'], hue=top5ByHour['Category'], palette='Set1')\n#plt.legend(bbox_to_anchor=(1,1), loc='best', borderaxespad=1.1)\nplt.title('Top 5 offenses by Hour')\n#sns.despine()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"offenseByMonth = pd.DataFrame(train_df2.groupby(['Month','Category'])[['Category']].count())\noffenseByMonth.columns = ['Count']\noffenseByMonth.reset_index(inplace=True)\noffenseByMonth.sort_values(by=['Month','Count'], ascending=False, inplace=True)\noffenseByMonth.head()\n\n#Top 5 offenses by Hour\ntop5ByMonth=pd.DataFrame()\nfor x in range(12):\n    top5ByMonth = top5ByMonth.append(offenseByMonth[offenseByMonth['Month']==(x+1)][:10])\n#topTenOffensesbyYear = topTenOffensesbyYear.append(offensesByYearCatg[offensesByYearCatg['YEAR'] == years[x]][:10])\n\nfigure = plt.figure(figsize=(20,6))\nsns.barplot(x=top5ByMonth['Month'], y=top5ByMonth['Count'], hue=top5ByMonth['Category'], palette='Set3')\n#plt.legend(bbox_to_anchor=(1,1), loc='best', borderaxespad=1.1)\nplt.title('Top 10 offenses by Month')\n#sns.despine()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categoryByMonth = pd.DataFrame(train_df2.groupby(['Category','Month'])[['Category']].count())\ncategoryByMonth.columns=['Count']\ncategoryByMonth.reset_index(inplace=True)\ncategoryByMonth.sort_values(by=['Category','Count'], ascending=False, inplace=True)\ncategoryByMonth.head()\n\ncategoryByHour = pd.DataFrame(train_df2.groupby(['Category','Hour'])[['Category']].count())\ncategoryByHour.columns=['Count']\ncategoryByHour.reset_index(inplace=True)\ncategoryByHour.sort_values(by=['Category','Count'], ascending=False, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp1 = categoryByMonth.pivot('Month','Category','Count')\nplt.figure(figsize=(25,5))\nplt.title(\"Heatmap of Category count by Month\")\nsns.heatmap(data=tmp1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp2 = categoryByHour.pivot('Hour','Category','Count')\nplt.figure(figsize=(25,7))\nplt.title(\"Heatmap of Category count by Hour\")\nsns.heatmap(data=tmp2, linewidths=.1, cmap=sns.color_palette(\"coolwarm\", 7)) # annot=True;BuGn_r;  GnBu_d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categoryByDistrict = pd.DataFrame(train_df2.groupby(['Category','PdDistrict'])[['Category']].count())\ncategoryByDistrict.columns=['Count']\ncategoryByDistrict.reset_index(inplace=True)\ncategoryByDistrict.sort_values(by=['PdDistrict','Count'], ascending=False, inplace=True)\n\ntmp3 = categoryByDistrict.pivot(\"PdDistrict\",\"Category\",\"Count\")\nplt.figure(figsize=(25,7))\nplt.title(\"Heatmap of Category count by District\")\nsns.heatmap(data=tmp3, linewidths=.1, cmap=sns.color_palette(\"GnBu_d\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----------------------\n### How to detect and classify seasonal crimes making use of datetime data??\n- Seasonal: Summer(June-August); Autumn(Sept-Nov); Winter(Dec-Feb); Spring(March-May)\n- Periods of day: Midnight(23-2), Dawn(3-6), Morning(7-10), Afternoon(11-14), Evening(15-18), Night(19-22)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def group_cols(df):\n    seasons = []\n    periods = []\n    for key,value in df.iterrows():\n        if ((value['Month']>=6) & (value['Month']<=8)):\n            seasons.append('summer')\n        elif ((value['Month']>=9)&(value['Month']<=11)):\n            seasons.append('autumn')\n        elif ((value['Month']==12)|(value['Month']<=2)):\n            seasons.append('winter')\n        else:\n            seasons.append('spring')\n\n        if ((value['Hour']==23)|(value['Hour']<=2)):\n            periods.append('midnight')\n        elif ((value['Hour']>=3)&(value['Hour']<=6)):\n            periods.append('dawn')\n        elif ((value['Hour']>=7)&(value['Hour']<=10)):\n            periods.append('morning')\n        elif ((value['Hour']>=11)&(value['Hour']<=14)):\n            periods.append('noon')\n        elif ((value['Hour']>=15)&(value['Hour']<=18)):\n            periods.append('evening')\n        else:\n            periods.append('night')\n    return seasons, periods","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seasons, periods = group_cols(train_df2)\ntrain_df2['Seasons'] = seasons\ntrain_df2['DayPeriods'] = periods\n\nseasons, periods = group_cols(test_df2)\ntest_df2['Seasons']= seasons\ntest_df2['DayPeriods']= periods","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install jovian --upgrade --quiet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import jovian\njovian.commit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}