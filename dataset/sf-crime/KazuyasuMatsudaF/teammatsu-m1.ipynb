{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# カテゴリを予測\n## 特徴量\n\n## アルゴリズム\nXGBoost\n\n## 結果","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport gc\npd.set_option('display.max_columns', 200)\n\ntrain_csv = pd.read_csv(\"../input/sf-crime/train.csv.zip\")\ntest_csv  = pd.read_csv(\"../input/sf-crime/test.csv.zip\")\nsample_csv  = pd.read_csv(\"../input/sf-crime/sampleSubmission.csv.zip\")\n# col = ['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict','Resolution', 'Address', 'X', 'Y']\n# train.shape = (878049, 9)\ntrain_csv.head(3)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-19T04:10:20.74609Z","iopub.execute_input":"2021-08-19T04:10:20.746701Z","iopub.status.idle":"2021-08-19T04:10:29.97474Z","shell.execute_reply.started":"2021-08-19T04:10:20.746588Z","shell.execute_reply":"2021-08-19T04:10:29.973527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@function_define\n# データ変換によってレコード数が誤って増減していないか確認する\ndef check(pre, new, columns=False):\n    print(\"---------- check ----------\")\n    print(\"pre.shape = \", pre.shape)\n    print(\"new.shape = \", new.shape)\n    if columns:\n        print(\"new.columns = \", new.columns)\n    print(\"---------------------------\")","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:29.976639Z","iopub.execute_input":"2021-08-19T04:10:29.977075Z","iopub.status.idle":"2021-08-19T04:10:29.984935Z","shell.execute_reply.started":"2021-08-19T04:10:29.97703Z","shell.execute_reply":"2021-08-19T04:10:29.98372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 外れ値の処理\nX=-120.5, Y=90になっているレコードを外れ値として扱う。おそらく何かしらの不具合？\n\n非外れ値側のPdDistrict毎のXとYの平均を計算し、外れ値側のX,Yをそれに置き換える","metadata":{}},{"cell_type":"code","source":"# trainデータの外れ値の分割\ntrain_raw = train_csv[train_csv[\"Y\"] < 60]\ntrain_raw_outlier = train_csv[train_csv[\"Y\"] >= 60]\n\nagg_pddistrict = train_raw[[\"PdDistrict\", \"X\", \"Y\"]].groupby(\n    [\"PdDistrict\"],\n    as_index=False\n).agg(\n    {\"X\": np.mean, \"Y\": np.mean}\n)\ntrain_raw_outlier = train_raw_outlier.drop([\"X\", \"Y\"],axis=1).merge(agg_pddistrict, on=\"PdDistrict\")\ntrain_raw = pd.concat([train_raw, train_raw_outlier], axis=0)\n\ncheck(train_csv, train_raw)\ntrain_raw.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:29.993951Z","iopub.execute_input":"2021-08-19T04:10:29.994341Z","iopub.status.idle":"2021-08-19T04:10:30.279234Z","shell.execute_reply.started":"2021-08-19T04:10:29.994299Z","shell.execute_reply":"2021-08-19T04:10:30.278246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainデータの外れ値の分割\ntest_raw = test_csv[test_csv[\"Y\"] < 60]\ntest_raw_outlier = test_csv[test_csv[\"Y\"] >= 60]\n\nagg_pddistrict = test_raw[[\"PdDistrict\", \"X\", \"Y\"]].groupby(\n    [\"PdDistrict\"],\n    as_index=False\n).agg(\n    {\"X\": np.mean, \"Y\": np.mean}\n)\ntest_raw_outlier = test_raw_outlier.drop([\"X\", \"Y\"],axis=1).merge(agg_pddistrict, on=\"PdDistrict\")\ntest_raw = pd.concat([test_raw, test_raw_outlier], axis=0)\n\nall = pd.concat([train_raw, test_raw], axis=0)[[\"X\", \"Y\"]]\n\ncheck(test_csv, test_raw)\ntest_raw.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:30.28042Z","iopub.execute_input":"2021-08-19T04:10:30.280708Z","iopub.status.idle":"2021-08-19T04:10:31.147998Z","shell.execute_reply.started":"2021-08-19T04:10:30.280679Z","shell.execute_reply":"2021-08-19T04:10:31.147096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# マスタを作成","metadata":{}},{"cell_type":"code","source":"category = train_raw[\"Category\"].drop_duplicates().to_list()","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:31.14922Z","iopub.execute_input":"2021-08-19T04:10:31.149493Z","iopub.status.idle":"2021-08-19T04:10:31.212066Z","shell.execute_reply.started":"2021-08-19T04:10:31.149467Z","shell.execute_reply":"2021-08-19T04:10:31.210966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 特徴量生成に利用する関数の定義","metadata":{}},{"cell_type":"code","source":"#@function_define\n# 交差点で起きた事故、事件(=Addressに\"/\"が入っている)ものは、そうでないものと分ける\n\ndef add_intersection(data):\n    data[\"Intersection\"] = data[\"Address\"].str.contains(\"/\")\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:31.213341Z","iopub.execute_input":"2021-08-19T04:10:31.213641Z","iopub.status.idle":"2021-08-19T04:10:31.22232Z","shell.execute_reply.started":"2021-08-19T04:10:31.213611Z","shell.execute_reply":"2021-08-19T04:10:31.221462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@function_define\n# サンフランシスコで犯罪件数が多い通りの名前\nstreet_name = [\"SAN JOSE AV\", \"DOLORES ST\", \"VALENCIA ST\", \"MISSION ST\"]\ndef add_street_flag(data):\n    def get_st_name(x):\n        st_flag = [(st in x) for st in street_name]\n        if np.any(st_flag):\n            return street_name[st_flag.index(True)]\n        else:\n            return \"\"\n    data[\"Street_flag\"] = data[\"Address\"].map(get_st_name)\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:31.225676Z","iopub.execute_input":"2021-08-19T04:10:31.226098Z","iopub.status.idle":"2021-08-19T04:10:31.239083Z","shell.execute_reply.started":"2021-08-19T04:10:31.226067Z","shell.execute_reply":"2021-08-19T04:10:31.238153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@function_define\n# 日付から月、時刻、TimeGroup(朝昼晩区分)を追加する関数\n\ndef add_timegroup(data):\n    data[\"Dates\"] = pd.to_datetime(data[\"Dates\"])\n    data[\"Year\"] = data[\"Dates\"].dt.year\n    data[\"Month\"] = data[\"Dates\"].dt.month\n    data[\"Hour\"] = data[\"Dates\"].dt.hour\n    # 定義は適当にPanasonicのスマート家電からhttps://panasonic.jp/pss/qa/answer167.html\n    def func_cate(x):\n        if  x >= 3 and x < 11:  # 朝は、3時から10時59分まで\n            return \"morning\"\n        elif x >= 11 and x < 18: # 昼は、11時から17時59分まで\n            return \"daytime\"\n        else:  # 夜は18時から26時59分まで\n            return \"evening\"\n    data['TimeGroup'] = data[\"Hour\"].apply(func_cate)\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:31.240817Z","iopub.execute_input":"2021-08-19T04:10:31.241323Z","iopub.status.idle":"2021-08-19T04:10:31.250538Z","shell.execute_reply.started":"2021-08-19T04:10:31.241292Z","shell.execute_reply":"2021-08-19T04:10:31.249668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@function_define\n# 指定した文字列カラムを数字に変換する(LabelEncode)\nfrom sklearn.preprocessing import LabelEncoder\n\ndef label_encode(data, columns):\n    label_masters = {}\n    for column in columns:\n        le = LabelEncoder()\n        le.fit(data[column])\n        data[column+\"_id\"] = le.transform(data[column])\n        label_masters.update({\n            column: le.classes_\n        })\n    return data, label_masters","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:31.2518Z","iopub.execute_input":"2021-08-19T04:10:31.252318Z","iopub.status.idle":"2021-08-19T04:10:31.385124Z","shell.execute_reply.started":"2021-08-19T04:10:31.252284Z","shell.execute_reply":"2021-08-19T04:10:31.383996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@function_define\n# 周辺のカテゴリ別の犯罪件数の分布を付与する\ndef add_category_distribution(data, x_range, y_range, n_splits):\n    # 指定した緯度経度の範囲をでn_split等分する\n    x_div = (x_range[1]-x_range[0])/n_splits\n    y_div = (y_range[1]-y_range[0])/n_splits\n    def to_left(v):\n        if type(v) is float:\n            return v\n        else:\n            return v.left\n    data[\"x_group\"] = [to_left(x) for x in pd.cut(\n        data[\"X\"], np.arange(x_range[0], x_range[1]+x_div, x_div), right=False)]\n    data[\"y_group\"] = [to_left(y) for y in pd.cut(\n        data[\"Y\"], np.arange(y_range[0], y_range[1]+x_div, y_div), right=False)]\n    \n    # 各範囲毎の犯罪件数を集計する\n    agg = data.copy()\n    agg[\"count\"] = 1\n    agg = agg.groupby(\n        [\n            \"Category\",\n            \"x_group\",\n            \"y_group\"\n        ],\n        as_index = False\n    ).agg(\n        {\"count\": np.sum}\n    )\n    agg=agg.pivot(\n        index=['x_group', 'y_group'], columns='Category', values='count'\n    ).fillna(0).reset_index()\n    \n    # 各行ごとに犯罪の件数から割合に変換する\n    agg_category = agg.drop([\"x_group\", \"y_group\"], axis=1)\n    agg[\"sum\"] = agg_category.sum(axis=1)\n    for col in agg_category.columns:\n        agg[col] = agg[col]/agg[\"sum\"]\n    agg = agg.drop(\"sum\", axis=1)\n    \n    # dataの取り方によっては犯罪件数が0件のカテゴリが生じる\n    # その場合は0で埋める\n    for col in category:\n        if not col in agg.columns:\n            agg[col] = 0\n\n    return pd.merge(data, agg, on=['x_group', 'y_group'],how='left'), agg","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:31.386598Z","iopub.execute_input":"2021-08-19T04:10:31.38706Z","iopub.status.idle":"2021-08-19T04:10:31.400353Z","shell.execute_reply.started":"2021-08-19T04:10:31.387015Z","shell.execute_reply":"2021-08-19T04:10:31.398992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 上記関数を利用して特徴量生成\ntrain = train_raw.copy()\ntrain = add_intersection(train)\ntrain = add_street_flag(train)\ntrain = add_timegroup(train)\ntrain, masters = label_encode(train, [\"Street_flag\", \"Category\"])\ncheck(train_raw, train, columns = True)\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:31.401519Z","iopub.execute_input":"2021-08-19T04:10:31.401792Z","iopub.status.idle":"2021-08-19T04:10:42.623763Z","shell.execute_reply.started":"2021-08-19T04:10:31.401766Z","shell.execute_reply":"2021-08-19T04:10:42.623048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# trainデータを利用して学習する","metadata":{}},{"cell_type":"markdown","source":"## クロスバリデーション\nStratifiedKFoldは指定したカテゴリーが各foldに均等に配分されるように分割してくれる。  \n今回はCategory毎にレコード数に大きな差があり、普通のKFoldを使うとCategoryに偏りが生じてしまうため、StratifiedKFoldを利用している","metadata":{}},{"cell_type":"code","source":"#@function_define\nfrom sklearn.model_selection import StratifiedKFold\ndef cross_validation():\n    skf = StratifiedKFold(n_splits=config.n_splits)\n    return [v for v in skf.split(train, train[\"Category_id\"])]","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:42.624859Z","iopub.execute_input":"2021-08-19T04:10:42.625311Z","iopub.status.idle":"2021-08-19T04:10:42.69865Z","shell.execute_reply.started":"2021-08-19T04:10:42.625279Z","shell.execute_reply":"2021-08-19T04:10:42.697913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost\nxgboostライブラリのxgb.trainを利用する","metadata":{}},{"cell_type":"code","source":"#@function_define\nimport xgboost as xgb\n\ndef run_single_xgboost(dtrain, dvalid, params):\n    evals = [(dtrain, 'train'), (dvalid, 'eval')]\n    \n    # 学習過程を記録するための辞書\n    evals_result = {}\n\n    # モデルの学習の実行\n    bst = xgb.train(\n        params,\n        dtrain,\n        config.num_round,\n        evals = evals,\n        evals_result = evals_result,\n    )\n\n    return bst, evals_result","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:42.699674Z","iopub.execute_input":"2021-08-19T04:10:42.700079Z","iopub.status.idle":"2021-08-19T04:10:42.785478Z","shell.execute_reply.started":"2021-08-19T04:10:42.70005Z","shell.execute_reply":"2021-08-19T04:10:42.784627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@function_define\n# 学習結果の描画\nimport operator\nimport datetime\n\ndef visualize(bst, evals_result):\n    train_metric = evals_result['train']['mlogloss']\n    plt.plot(train_metric, label='train mlogloss')\n    eval_metric = evals_result['eval']['mlogloss']\n    plt.plot(eval_metric, label='eval mlogloss')\n    plt.grid()\n    plt.legend()\n    plt.xlabel('rounds')\n    plt.ylabel('mlogloss')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:42.786517Z","iopub.execute_input":"2021-08-19T04:10:42.786944Z","iopub.status.idle":"2021-08-19T04:10:42.792959Z","shell.execute_reply.started":"2021-08-19T04:10:42.78691Z","shell.execute_reply":"2021-08-19T04:10:42.792059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ハイパーパラメータのチューニング\nOptunaを利用して、xgboostのハイパーパラメータをチューニングする。  \nxgboostのパラメータについては[こちらのQiita記事](https://qiita.com/FJyusk56/items/0649f4362587261bd57a)を参考にした。  \noptunaの使い方に関しては[こちらのQiita記事](https://qiita.com/mamorous3578/items/912f1a2be0e9da7e9140)を参考にした。","metadata":{}},{"cell_type":"code","source":"#@function_define\n\ndef run_fold_xgboost(hyperparams):\n    config.trial_count += 1\n    eta = hyperparams.suggest_uniform('eta', 0.0, 1.0) # デフォルトは0.3\n    gamma = hyperparams.suggest_uniform('gamma', 0.0, 100.0) # デフォルトは0\n    n_splits_xy = hyperparams.suggest_int('n_splits_xy', 100, 1000)\n    print(\"eta: \", eta)\n    print(\"gamma: \", gamma)\n    print(\"n_splits_xy: \", n_splits_xy)\n    \n    metric = []\n    fold = 0\n    for train_t_iloc, train_v_iloc in config.cross_validation:\n        fold += 1\n        print(\"---- fold \" + str(fold) + \"/\" + str(config.n_splits) + \" ----\")\n        train_t = train.iloc[train_t_iloc].copy()\n        train_v = train.iloc[train_v_iloc].copy()\n        \n        # ■ 周辺のカテゴリ別の犯罪件数を付与する\n        # validationデータにつけた犯罪数分布は本来予測して得られるものなので外し、代わりに学習用データから作成した犯罪件数を付与する。\n        x_range = [min(all[\"X\"]), max(all[\"X\"])]\n        y_range = [min(all[\"Y\"]), max(all[\"Y\"])]\n        train_t, crime_hist = add_category_distribution(train_t, x_range, y_range, n_splits_xy)\n        train_v, _ = add_category_distribution(train_v, x_range, y_range, n_splits_xy)\n        train_v = train_v.drop(category, axis=1)\n        train_v = train_v.merge(crime_hist, on=['x_group','y_group'], how=\"left\")\n        \n        # ■ 必要なカラムだけ選択\n        train_t_select = train_t[[\n            'DayOfWeek',\n            'PdDistrict',\n            'Month',\n            'TimeGroup',\n            'Intersection',\n            'Street_flag_id',\n            'Category_id',\n            *crime_hist.columns\n        ]]\n        train_v_select = train_v[[\n            'DayOfWeek',\n            'PdDistrict',\n            'Month',\n            'TimeGroup',\n            'Intersection',\n            'Street_flag_id',\n            'Category_id',\n            *crime_hist.columns\n        ]]\n\n        # ■ 決定木用にデータを処理\n        # One-hot Encodingを行う\n        train_dummies_t = pd.get_dummies(train_t_select)\n        train_dummies_v = pd.get_dummies(train_v_select)\n        # 特徴量と目的変数をxgboostのデータ構造に変換する\n        dtrain = xgb.DMatrix(train_dummies_t.drop(\"Category_id\", axis=1), label=train_dummies_t[\"Category_id\"])\n        dvalid = xgb.DMatrix(train_dummies_v.drop(\"Category_id\", axis=1), label=train_dummies_v[\"Category_id\"])\n        \n        gc.collect()\n        \n        # ■ 学習実行\n        # パラメータの設定\n        params = {\n            # GPU\n            # \"tree_method\": 'gpu_hist',\n            # 'n_gpus': 1,\n            # Learning Parameters\n            \"objective\": 'multi:softprob',\n            'num_class': 39,\n            'eval_metric':'mlogloss',\n            # Booster Parameters(ベイズ最適化の対象)\n            # 固定値はライブラリで定められたデフォルト値をそのまま利用している。\n            \"eta\": eta,\n            \"gamma\": gamma,\n            \"max_depth\": 6,\n            \"min_child_weight\": 1,\n            \"max_delta_step\": 0,\n            \"subsample\": 1,\n            \"colsample_bytree\": 1,\n            \"colsample_bylevel\": 1,\n            \"lambda\": 1,\n            \"alpha\": 0\n        }\n        # 学習を実行\n        bst, evals_result = run_single_xgboost(dtrain, dvalid, params)\n        # 学習結果を保存\n        config.storage_model(bst, fold)\n        config.storage_importance(bst, fold)\n        # 計算結果を可視化\n        # visualize(bst, evals_result)\n        \n        metric.append({\n            \"train_metric\": evals_result['train']['mlogloss'][-1],\n            \"eval_metric\": evals_result['eval']['mlogloss'][-1]\n        })\n    \n    print(\"---- fold finish ----\")\n    # 計算結果をファイル保存\n    result = {\n        \"metric\": metric,\n        \"train_ave\": np.mean([m[\"train_metric\"] for m in metric]),\n        \"eval_ave\": np.mean([m[\"eval_metric\"] for m in metric])\n    }\n    config.result.append(result)\n    config.storage_result(result)\n    \n    return result[\"eval_ave\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:42.794328Z","iopub.execute_input":"2021-08-19T04:10:42.794947Z","iopub.status.idle":"2021-08-19T04:10:42.814537Z","shell.execute_reply.started":"2021-08-19T04:10:42.794908Z","shell.execute_reply":"2021-08-19T04:10:42.813505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@function_define\n# 学習全般に関するパラメータの管理\nimport os\nimport json\nimport pickle\nclass Config(object):\n    def __init__(self):\n        self.n_splits = 4   # Foldの数\n        self.n_trials = 50   # Optuna(ハイパーパラメータチューニング)の試行回数\n        self.num_round = 50   # xgboostの試行回数\n        \n        self.trial_count = 0\n        self.cross_validation = []\n        self.result = []\n        \n        # modelの計算結果をファイルとして保存するためのフォルダを作成\n        dt_now = dt.datetime.now().strftime('%Y%m%d-%H%M%S')\n        self.dir_name = \"model_\" + dt_now\n        os.makedirs(self.dir_name)\n    \n    def storage_model(self, bst, fold):\n        file_name = self.dir_name + \"/model_trial-\" + str(self.trial_count) + \"_fold-\" + str(fold) + \".bst\"\n        bst.save_model(file_name)\n\n    def storage_importance(self, bst, fold):\n        file_name = self.dir_name + \"/importance_trial-\" + str(self.trial_count) + \"_fold-\" + str(fold) + \".json\"\n        with open(file_name, 'w') as f:\n            json.dump(bst.get_fscore(), f, indent=2)\n\n    def storage_result(self, result):\n        file_name = self.dir_name + \"/result_trial-\" + str(self.trial_count) + \".json\"\n        with open(file_name, 'w') as f:\n            json.dump(result, f, indent=2)\n\n    def storage_best_params(self, study):\n        file_name = self.dir_name + \"/best_params.json\"\n        with open(file_name, 'w') as f:\n            json.dump({\n                \"best_params\": study.best_params,\n                \"best_value\": study.best_value\n            }, f, indent=2)\n    \n    def storage_study(self, study):\n        file_name = self.dir_name + \"/study.pickle\"\n        with open(file_name, mode=\"wb\") as f:\n            pickle.dump(study, f)\n        \n    def storage_submission(self, submission):\n        file_name = self.dir_name + \"/submission.csv\"\n        submission.to_csv(file_name, index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:10:42.815908Z","iopub.execute_input":"2021-08-19T04:10:42.81643Z","iopub.status.idle":"2021-08-19T04:10:42.830495Z","shell.execute_reply.started":"2021-08-19T04:10:42.816396Z","shell.execute_reply":"2021-08-19T04:10:42.829356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\n\nfolder_name = None\nif folder_name:\n    print(\"----- load \"+folder_name+\" -----\")\n    with open(\"./\"+folder_name+\"/study.pickle\", mode=\"rb\") as f:\n        study = pickle.load(f)\nelse:\n    study = optuna.create_study()\n    # hyperparamsの初期値を設定\n    study.enqueue_trial({\n        'eta': 0.14504447778508744,\n        'gamma': 41.441405792041834,\n        'n_splits_xy': 100\n    })\n\n# 学習パラメータを設定\nconfig = Config()\nconfig.n_splits = 3  # Foldの数\nconfig.n_trials = 15   # Optuna(ハイパーパラメータチューニング)の試行回数\nconfig.num_round = 50   # xgboostの試行回数\n\n# クロスバリデーション\nconfig.cross_validation = cross_validation()\n\n# 最適なhyperparams探索を実行\nstudy.optimize(run_fold_xgboost, n_trials=config.n_trials)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:11:03.11001Z","iopub.execute_input":"2021-08-19T04:11:03.110367Z","iopub.status.idle":"2021-08-19T04:11:54.882076Z","shell.execute_reply.started":"2021-08-19T04:11:03.110338Z","shell.execute_reply":"2021-08-19T04:11:54.879228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config.storage_best_params(study)\nconfig.storage_study(study)\n\n# 最適パラメータの表示\nprint(study.best_params)\n# 最小化された目的関数を表示\nprint(study.best_value)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:11:54.883297Z","iopub.status.idle":"2021-08-19T04:11:54.883721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"# ■ 周辺のカテゴリ別の犯罪件数を付与する\nx_range = [min(all[\"X\"]), max(all[\"X\"])]\ny_range = [min(all[\"Y\"]), max(all[\"Y\"])]\ntrain_all, _ = add_category_distribution(train, x_range, y_range, study.best_params[\"n_splits_xy\"])\n\n# ■ 必要なカラムだけ選択\ntrain_all_select = train_all[[\n    'DayOfWeek',\n    'PdDistrict',\n    'Month',\n    'TimeGroup',\n    'Intersection',\n    'Street_flag_id',\n    'Category_id',\n    *_.columns\n]]\n\n# ■ 決定木用にデータを処理\n# One-hot Encodingを行う\ntrain_dummies_all = pd.get_dummies(train_all_select)\n\n# 特徴量と目的変数をxgboostのデータ構造に変換する\ndtrain_all = xgb.DMatrix(train_dummies_all.drop(\"Category_id\", axis=1), label=train_dummies_all[\"Category_id\"])\n\ngc.collect()\n# ■ 学習実行\n# パラメータの設定\nconfig.num_round = 100   # xgboostの試行回数\nparams = {\n    # Learning Parameters\n    \"objective\": 'multi:softprob',\n    'num_class': 39,\n    'eval_metric':'mlogloss',\n    # Booster Parameters(ベイズ最適化の対象)\n    # 固定値はライブラリで定められたデフォルト値をそのまま利用している。\n    \"eta\": study.best_params[\"eta\"],\n    \"gamma\": study.best_params[\"gamma\"],\n    \"max_depth\": 6,\n    \"min_child_weight\": 1,\n    \"max_delta_step\": 0,\n    \"subsample\": 1,\n    \"colsample_bytree\": 1,\n    \"colsample_bylevel\": 1,\n    \"lambda\": 1,\n    \"alpha\": 0\n}\n# 学習を実行\nbst, evals_result = run_single_xgboost(dtrain_all, dtrain_all, params)\n# 学習結果を保存\nconfig.trial_count = \"finish\"\nconfig.storage_model(bst, 0)\nconfig.storage_importance(bst, 0)\n# 計算結果を可視化\nvisualize(bst, evals_result)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:11:54.884791Z","iopub.status.idle":"2021-08-19T04:11:54.885297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_raw.copy()\ntest = add_intersection(test)\ntest = add_street_flag(test)\ntest = add_timegroup(test)\ntest, _ = label_encode(test, [\"Street_flag\"])\n\ntmp = test.copy()\ntmp[\"Category\"] = \"-\"\nx_range = [min(all[\"X\"]), max(all[\"X\"])]\ny_range = [min(all[\"Y\"]), max(all[\"Y\"])]\n_, master_all = add_category_distribution(train_raw, x_range, y_range, study.best_params[\"n_splits_xy\"])\ntmp, _ = add_category_distribution(tmp, x_range, y_range, study.best_params[\"n_splits_xy\"])\ntest = tmp.drop([\"-\"]+category, axis=1).merge(master_all, on=['x_group', 'y_group'], how=\"left\")\n\ntest_select = test[[\n    'DayOfWeek',\n    'PdDistrict',\n    'Month',\n    'TimeGroup',\n    'Street_flag',\n    'Street_flag_id',\n    'Intersection',\n    *master_all.columns\n]]\n\n\ntest_dummies = pd.get_dummies(test_select)\nprint(test.shape)\ntest_dummies.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:11:54.886331Z","iopub.status.idle":"2021-08-19T04:11:54.886966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dummies_select = test_dummies[[*train_dummies_all.drop(\"Category_id\", axis=1).columns]]\n\ndtest = xgb.DMatrix(test_dummies_select)\npred_test = bst.predict(dtest)\n\n# 提出用ファイルの作成\nsubmisson = pd.DataFrame(pred_test, columns = masters[\"Category\"])\nsubmisson[\"Id\"] = test_raw[\"Id\"].to_list()\n\nconfig.storage_submission(submisson)\n\nsubmisson.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:11:54.890683Z","iopub.status.idle":"2021-08-19T04:11:54.891607Z"},"trusted":true},"execution_count":null,"outputs":[]}]}