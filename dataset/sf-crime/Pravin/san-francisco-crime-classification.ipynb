{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport zipfile\n\nsns.set()\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = zipfile.ZipFile('/kaggle/input/sf-crime/test.csv.zip')\nprint(z.namelist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(z.open('test.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = zipfile.ZipFile('/kaggle/input/sf-crime/sampleSubmission.csv.zip')\nprint(z.namelist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampleSubmission = pd.read_csv(z.open('sampleSubmission.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = zipfile.ZipFile('/kaggle/input/sf-crime/train.csv.zip')\nprint(z.namelist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(z.open('train.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['Category']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['year'] = train['Dates'].apply(lambda x : x.split()[0].split('-')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Week'] = train['Dates'].apply(lambda x : x.split()[0].split('-')[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Hours'] = train['Dates'].apply(lambda x : x.split()[1].split(':')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train.isnull())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.PdDistrict.value_counts().plot(kind='bar', figsize=(8,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['DayOfWeek'].value_counts().plot(kind='bar', figsize=(8,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Category'].value_counts().plot(kind='bar', figsize=(8,10))\nplt.xlabel('Category of crime')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train['Category'].unique()\nprint(target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dict = {}\ncount = 1\nfor data in target:\n    data_dict[data] = count\n    count+=1\ntrain[\"Category\"] = train[\"Category\"].replace(data_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dayofweeks = train['DayOfWeek'].unique()\nprint(dayofweeks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_week_dict = {\n    \"Monday\":1,\n    \"Tuesday\":2,\n    \"Wednesday\":3,\n    \"Thursday\":4,\n    \"Friday\":5,\n    \"Saturday\":6,\n    \"Sunday\":7\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['DayOfWeek'] = train['DayOfWeek'].replace(data_week_dict)\ntest['DayOfWeek'] = test['DayOfWeek'].replace(data_week_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['PdDistrict'] = labelencoder.fit_transform(train['PdDistrict'])\ntest['PdDistrict'] = labelencoder.fit_transform(test['PdDistrict'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_columns = train.columns\nprint(train_data_columns)\ntest_data_columns = test.columns\nprint(test_data_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train.corr()\nprint(corr['Category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrMat = train[['Category','DayOfWeek','PdDistrict','X','Y']].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = np.array(corrMat)\n# print(mask)\nmask[np.triu_indices_from(mask)] = False\n# print(mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(11, 9))\nfig.set_size_inches(20,10)\nsns.heatmap(corrMat,mask=mask,vmax=.3,square=True,annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skew = train.skew()\nprint(skew)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feautes = [\"DayOfWeek\",\"PdDistrict\",\"X\",\"Y\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train[feautes]\ny_train = train['Category']\nX_test = test[feautes]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle(y,y_pred,convertExp = True):\n  if convertExp:\n    y = np.exp(y)\n    y_pred = np.exp(y_pred)\n  log1 = np.nan_to_num(np.array([np.log(v+1) for v in y]))\n  log2 = np.nan_to_num(np.array([np.log(v + 1) for v in y_pred]))\n  calc = (log1 - log2)**2\n  # print(calc)\n  return np.sqrt(np.mean(calc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nimport warnings\npd.options.mode.chained_assignment = None\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n# Initialize logistic regression model\nlModel = LinearRegression()\n\n# Train the model\nyLabelsLog = np.log1p(y_train)\nlModel.fit(X = X_train,y = yLabelsLog)\n\n# Make predictions\npreds = lModel.predict(X= X_train)\nprint (\"RMSLE Value For Linear Regression: \",rmsle(np.exp(yLabelsLog),np.exp(preds),False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import OrderedDict\ndata_dict_new = OrderedDict(sorted(data_dict.items()))\nprint(data_dict_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_dataframe = pd.DataFrame({\n    \"Id\": test[\"Id\"]\n})\nfor key,value in data_dict_new.items():\n    result_dataframe[key] = 0\ncount = 0\nfor item in predictions:\n    for key,value in data_dict.items():\n        if(value == item):\n            result_dataframe[key][count] = 1\n    count+=1\nresult_dataframe.to_csv(\"submission_knn.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}